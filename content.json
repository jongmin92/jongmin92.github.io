{"pages":[{"title":"","text":"","link":"/404.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"About","text":"","link":"/about/index.html"},{"title":"Archives","text":"","link":"/archive/index.html"}],"posts":[{"title":"Qvic 서비스 아키텍처 설계","text":"회사에서 새로운 서비스를 준비하며 이번 9-b 스프린트동안 구축한 Qvic의 AWS 구조는 다음과 같습니다. 각각의 서비스에 대한 자세한 내용은 AWS 사이트와, 책을 참조 하였고, 이번 글에서는 이와 같은 환경을 구축하며 생겼던 문제들과 앞으로는 조금 더 쉽게 구축 할 수 있도록 일련의 과정에 대해 설명하고자 합니다. 1. IAM 생성IAM은 Identity and Access Management(식별 및 접근 관리)의 약어로 사용자와 그룹을 생성하고 AWS의 각 리소스에 대해 접근제어와 권한관리를 제공한다. 이러한 IAM 을 EC2 Instance를 생성하며 설정할 수가 있는데 이미 만들어진 EC2 Instance에는 IAM 역할을 설정할 수가 없다. (처음에 모르고 하다가 나중에 지우고 다시 EC2를 생성하며 IAM을 설정하는 일이 생길 수 있다.) 물론 IAM 을 설정하지 않아도 EC2 Instance에서 API로 액세스 키와 시크릿 키를 설정해서 AWS 리소스에는 접근할 수 있지만 나중에 Auto Scaling 기능으로 자동으로 생성되는 EC2 인스턴스에 액세스키와 시크릿키를 일일이 설정해주는 것은 상당히 귀찮은 일이다. 이를 위해 먼저 IAM 을 생성한 후 EC2를 생성하는 것이 좋다.* IAM 생성 후 생성 된 IAM에 권한을 부여하는 것은 나중에도 가능하므로 자세한 내용을 알지 못한다면 일단 생성 후 EC2에 적용만 해놓아도 된다. 2. EC2 생성 -&gt; 개발환경 구축 -&gt; AMI 생성사용중인 AWS 계정이 Free Tier 라면 t2.micro (1달 750시간 무료) Instance로 생성하여 AMI(Amazon Machine Image)를 생성하는 것도 효율적인 방법이다. 추후에 AMI를 사용하여 EC2를 새로 생성할 수도 있고, 이미 생성된 EC2 Type을 변경할 수도 있다. EC2의 Instance는 다음과 같이 생성하였다. (모두 Ubuntu Image를 사용하였다. EC2를 생성할때 만들어지는 .pem 파일의 백업은 중요하다!)Express를 사용하여 프로젝트를 진행하였기 때문에 3000번 포트가 필요하여 Security Group 설정에서 Add Rule을 통해 3000번 포트를 추가해 주었다. Blue-Green Deployment 를 위해 Auto Scaling (자동으로 EC2 인스턴스를 생성하여 서비스를 확장하는 기능) 을 적용한 Prod 용 Instance 2개 Dev 용 Instance 1개 먼저 Dev 용으로 Instance를 생성 하였고, 다음과 같은 개발환경을 구축하였다. 기본 ubuntu 계정을 제외하고 팀원들의 각각 사용자 계정 추가 (비밀번호 설정, root 권한을 사용할 수 있도록 설정) 각 사용자마다 .pem 키를 사용하여 로그인 하는 것이 보안상 안전하지만 편의상 비밀번호로 로그인 할 수 있도록 설정 (ssh 의 공개키와 비공개키 개념 필요) node v6.6.0 설치 (사용자가 여러명이고 진행중인 프로젝트마다 node의 버전이 다르다면 nvm 을 설치하는것 추천) git 다운로드 및 ssh 설정 bash 및 vim 설정 (만들어진 script 파일을 받아 실행) 다음은 Prod 용 Instance 개발환경 구축이다. Prod 용은 Dev Instance 와는 다르게 Auto Scaling을 적용할 것이기 때문에 Dev Instance 와는 조금 다른 설정이 필요하다. Auto Scaling은 트래픽이 증가하면 자동으로 EC2 Instance를 생성하여 서비스를 확장하기 때문에 자동으로 생성된 EC2 Instance가 자동으로 서비스를 시작 할 수 있도록 구축해야 한다. 따라서 다음과 같은 설정이 필요하다. node v6.6.0 설치 git 다운로드 및 ssh 설정 bash script 파일 Auto Scaling 그룹을 생성기 전에 설정하는 EC2 생성 옵션 설정에서 'User data' 라는 칸에 자동으로 EC2가 생성된 후 root 권한으로 실행할 스크립트를 작성한다. 이때 git에서 프로젝트를 clone 한 후 자동으로 서비스를 시작하도록 하는 코드가 작성되어야 한다. 이 부분이 어려운 부분은 아니지만 경로 등… 여러가지 설정을 한 후 Auto Scaling이 잘 적용되는지 확인하기 위해서는 생성한 Auto Scaling에 인위적으로 부하를 걸어 Instance가 생성되도록 하고 ‘User data’에 작성한 스크립트가 잘 실행되는지 까지 확인해야 한다. 생각보다 시간이 걸리고 인스턴스를 반복적으로 생성하고 삭제 (과금…) 하는 부분이 부담스러워서 직접 EC2 에 bash script 파일을 작성한 후 ‘User data’ 에서는 이 script를 실행하도록만 작성하였다. 작성한 script는 먼저 만들어 두었던 Dev Instance 에서 테스트 한 후 잘 작동하는 것을 확인한 후 Prod Instance로 옮겼다.이렇게 생성한 Dev와 Prod 용 Instance를 사용하여 AMI를 생성한다. 3. ELB (Elastic Load Balancing) 사용Auto Scaling 그룹을 생성 하면서 ELB 를 선택하는 부분이 있기 때문에 ELB를 먼저 생성해야 한다. AWS에서 제공하는 ELB는 2가지가 있다. 1. Application load balancerLayer 7 로드밸런싱을 통해 패킷을 조사하고, HTTP 및 HTTPS 헤더에 접근해서 좀 더 지능적인 부하 분산 작업이 가능하다. 예를들어, URL에 /api 라는 경로를 포함하고 있는 경우, 다른 서버 그룹으로 요청을 보낼 수 있으며 /mobile은 또 다른 서버 그룹으로 보낼 수 있다. 각 애플리케이션 로드밸런서는 10개의 URL 규칙을 만들 수 있으며 이를 통해 여러 개의 마이크로서비스를 독립적으로 실행하고 확장할 수 있다. 2. Classic load balancerLayer 4 로드밸런싱을 사용하여 네트워크 프로토콜 레벨에서 제공 되며, 실제 패킷을 살펴 보지는 못하기 때문에 HTTP나 HTTPS 같은 특정 프로토콜을 인지하지 않고 부하를 분산한다. ELB 생성시 주의할 점은 다음과 같다. Express를 사용하기 때문에 3000번 포트를 추가해 준다. (Security Group 설정에서도 추가) 헬스 체크(Health Check) 기능 설정시 3000번 포트로 변경해준다. 헬스 체크 주기(Health Check Interval)와 Threshold는 적절히 설정해준다. 로드밸런싱할 Instance를 추가할 때 생성해 두었던 Prod 한개를 설정한다. (Blue-Green Deployment 를 하기 위해서는 각각의 Instance에 서로 다른 load balancer를 설정해야 한다.) 혹시 Elastic IP가 적용되어 있었다면 제거한다. 앞으로 서비스에 접속할 때는 EC2 Instance에 바로 접속하지 않고 ELB 의 URL로 접속한다. (후에 Route 53에서 자신의 도메인으로 설정할 수 있다.) 4. Auto Scaling 적용EC2 Instace 생성 옵션을 설정하고, Auto Scaling 그룹을 생성한다. EC2 Instance 생성 옵션을 설정하면서 주의할 점이 몇가지 있다. IAM role 은 자동으로 생성되는 EC2 Instance에서 사용할 IAM 역할이다. IAM 역할을 사용하면 액세스 키와 시크릿 키 없이 AWS API를 사용할 수 있으므로 당장은 AWS API 를 사용하지 않더라도 설정해 두는것이 좋다. Advanced Details를 누르면 나오는 User data는 EC2 Instance가 생성된 후 root 권한으로 자동으로 실행할 script를 입력하는 곳이다. AMI를 생성하며 작성했던 script가 실행되도록 작성한다. #!/bin/bash/home/ubuntu/auto_start.sh Express를 사용하기 때문에 Security Group 설정에서 Add Rule을 통해 3000번 포트를 추가해 준다. 미리 생성해 두었던 ELB를 적용한다. 여러가지 설정들이 있는데 이는 나중에 수정이 가능하므로 처음 생성시에 너무 고민하지 않아도 된다. 필요할 때 수정해주고 모르는것은 좀 더 조사해보면서 수정하면 된다. &lt;종료정책 설정&gt;처음 Auto Scaling을 만들고 테스트를 하면서 당황했던 것이있다. 처음에 유지되고 있던 1개의 Instance에 인위적으로 부하를 걸면 내가 설정해놓은 정책에 따라 Instance가 자동으로 생성되고, 삭제되게 되는데 마지막에 생성된 Instance가 그대로 남고 원래 존재하던 Instance가 제거 되는 것이다. Auto Scaling이 적용된 Instance에는 자동 생성되는 Instance의 AMI 와는 조금 다르게 환경 구축이 되어있는데 사라져서 당황했었다. 이는 Auto Scaling의 종료정책 때문인데 종료정책의 종류는 다음과 같다. OldestInstance : Auto Scaling은 그룹에서 가장 오래된 Instance를 종료한다. NewestInstance : Auto Scaling은 그룹에서 가장 새로운 Instance를 종료한다. OldestLaunchConfiguration : Auto Scaling은 가장 오래된 시작 구성을 가진 Instance를 종료한다. ClosestToNextInstanceHour : Auto Scaling은 다음 번 결제 시간에 가장 근접한 인스턴스를 종료한다. Default : Auto Scaling은 해당 기본 종료 정책을 사용한다. (기본 종료 정책은 네트워크 아키텍처 전반에서 가용 영역이 균일하게 적용 되도록 설계되어있다.) 위와 같은 종료정책은 Auto Scaling 설정시 설정하는 부분이 아니고 생성한 후 변경해 주어야 하는 부분이라 놓칠 수 있다. 기본 종료 정책이 아닌 다른 정책이 필요하다면 변경해 주어야한다. 5. Route 53Route 53은 EC2, ELB, S3, CloudFront와 연동 가능한 DNS 서비스이다. Free Tier에서도 무료로 사용이 불가능하다. Route 53을 사용하기 위해서는 도메인이 필요한데 아직 구매하지 않았다면 Route 53 에서 구매하는 것을 추천한다. 외부에서 구매한 도메인은 네임서버를 따로 설정해 주어야한다.A 레코드를 통해 미리 생성했던 ELB를 쉽게 설정해 줄 수 있다. (후에 Blue-Green Deployment시 2개의 ELB를 서로 교체해주면 된다.) 6. 그외 여러 주의사항 Free Tier 에서 한달에 EC2 Instance는 750시간 무료이고 EBS는 30GB가 무료이다. 보통 EC2 Instance만 신경써서 4~5개를 한번에 만들고 후에 제거하고 하는데 EC2 Instance 생성시 따로 EBS 크기를 정해주지 않으면 기본이 8GB이기 때문에 4개만 생성해도 EBS로 인해 과금이 된다. (정지해도 과금이 된다.) Elastic IP는 EC2 Instance 1개에 대해 할당하고 있을때만 무료이다. 만약 EC2 Instance를 중지하거나 제거한다면 Elastic IP도 제거해 주어야 한다. Free Tier 사용시 CloudWatch 의 주기는 5분일때 무료이다. 주기를 줄이면 과금된다. EC2의 개발환경 세팅시 AMI를 자주 만들어주자… AIM 설정이라던가 Auto Scaling의 종료정책을 몰라서 많이 날려먹었다. 예상하지 못한 과금은 무서우니 알림을 설정해놓자.","link":"/2016/09/29/AWS/qvic_aws_architecture/"},{"title":"<11054> 가장 긴 바이토닉 부분 수열","text":"문제 : https://www.acmicpc.net/problem/11054 먼저 증가하는 수열의 최대 길이와 감소하는 수열의 최대 길이를 구해주었습니다.그 후 각 자리의 최대 길이를 서로 더해준 후 max 값을 비교하여 해결했습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;int main() { int max_value = 0; int n; cin &gt;&gt; n; vector&lt;int&gt; a(n); for (int i = 0; i &lt; n; i++) { cin &gt;&gt; a[i]; } vector&lt;int&gt; plus(n); // 증가하는 수열의 최대 길이 vector&lt;int&gt; minus(n); // 감소하는 수열의 최대 길이 for (int i = 0; i &lt; n; i++) { plus[i] = 1; for (int j = 0; j &lt; i; j++) { if (a[j] &lt; a[i] &amp;&amp; plus[i] &lt; plus[j] + 1) { plus[i] = plus[j] + 1; } } } for (int i = n-1; i &gt;= 0; i--) { minus[i] = 1; for (int j = n-1; j &gt; i; j--) { if (a[j] &lt; a[i] &amp;&amp; minus[i] &lt; minus[j] + 1) { minus[i] = minus[j] + 1; } } } for (int i = 0; i &lt; n; i++) { max_value = max(max_value, plus[i] + minus[i] - 1); } cout &lt;&lt; max_value &lt;&lt; '\\n'; return 0;}","link":"/2017/10/02/Algorithm/boj-11054/"},{"title":"<12100> 2048 (Easy)","text":"문제 : https://www.acmicpc.net/problem/12100 째로탈출2처럼 코드가 깁니다… 째로탈출2와 마찬가지로 2차원 배열을 조작하는 부분에서 코드가 많이 길어지게 되는데 더 간결하게 만들 수 있도록 연습을 해야할 것 같습니다.구현은 combine_map함수를 통해서 방향에 맞게 같은 숫자를 합쳐주고 move_map함수를 통해 빈공간을 제거하는것을 반복하도록 구현했습니다. Easy의 경우 5회 반복이기 때문에 대부분 시간초과 경우는 없을 것 입니다.(테스트 케이스가 문제에 1개 밖에 없다보니 힘들었습니다… 테스트 케이스가 부족하신 분들은 문제 게시판에 가시면 더 찾아보실 수 있습니다.) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263#include &lt;iostream&gt;#include &lt;algorithm&gt;#define MAP_MAX_SIZE 20using namespace std;int map[MAP_MAX_SIZE][MAP_MAX_SIZE];int N;int max_dp[6];void init_map() { for (int i = 0; i &lt; N; i++) { for (int j = 0; j &lt; N; j++) { cin &gt;&gt; map[i][j]; } }}void copy_map(int(*map)[MAP_MAX_SIZE], int(*tmp_map)[MAP_MAX_SIZE]) { for (int i = 0; i &lt; N; i++) { for (int j = 0; j &lt; N; j++) { tmp_map[i][j] = map[i][j]; } }}void recovery_map(int(*map)[MAP_MAX_SIZE], int(*tmp_map)[MAP_MAX_SIZE]) { for (int i = 0; i &lt; N; i++) { for (int j = 0; j &lt; N; j++) { map[i][j] = tmp_map[i][j]; } }}void combine_map(int dir) { // 상 if (dir == 0) { for (int c = 0; c &lt; N; c++) { for (int r = 0; r &lt; N - 1; r++) { int data1 = map[r][c]; if (data1 == 0) { continue; } for (int k = r + 1; k &lt; N; k++) { int data2 = map[k][c]; if (data2 == 0) { continue; } else { if (data1 == data2) { map[r][c] *= 2; map[k][c] = 0; r = k; } break; } } } } } // 하 else if (dir == 1) { for (int c = 0; c &lt; N; c++) { for (int r = N-1; r &gt; 0; r--) { int data1 = map[r][c]; if (data1 == 0) { continue; } for (int k = r - 1; k &gt;= 0; k--) { int data2 = map[k][c]; if (data2 == 0) { continue; } else { if (data1 == data2) { map[r][c] *= 2; map[k][c] = 0; r = k; } break; } } } } } // 좌 else if (dir == 2) { for (int r = 0; r &lt; N; r++) { for (int c = 0; c &lt; N - 1; c++) { int data1 = map[r][c]; if (data1 == 0) { continue; } for (int k = c + 1; k &lt; N; k++) { int data2 = map[r][k]; if (data2 == 0) { continue; } else { if (data1 == data2) { map[r][c] *= 2; map[r][k] = 0; c = k; } break; } } } } } // 우 else if (dir == 3) { for (int r = 0; r &lt; N; r++) { for (int c = N-1; c &gt; 0; c--) { int data1 = map[r][c]; if (data1 == 0) { continue; } for (int k = c - 1; k &gt;= 0; k--) { int data2 = map[r][k]; if (data2 == 0) { continue; } else { if (data1 == data2) { map[r][c] *= 2; map[r][k] = 0; c = k; } break; } } } } }}int move_map(int dir) { int max_value = 0; // 상 if (dir == 0) { for (int c = 0; c &lt; N; c++) { for (int r = 0; r &lt; N; r++) { max_value = max(max_value, map[r][c]); if (map[r][c] == 0 &amp;&amp; r != N - 1) { for (int k = r+1; k &lt; N; k++) { if (map[k][c] != 0) { map[r][c] = map[k][c]; map[k][c] = 0; max_value = max(max_value, map[r][c]); break; } } } } } } // 하 else if (dir == 1) { for (int c = 0; c &lt; N; c++) { for (int r = N-1; r &gt;= 0; r--) { max_value = max(max_value, map[r][c]); if (map[r][c] == 0 &amp;&amp; r != 0) { for (int k = r - 1; k &gt;= 0; k--) { if (map[k][c] != 0) { map[r][c] = map[k][c]; map[k][c] = 0; max_value = max(max_value, map[r][c]); break; } } } } } } //좌 else if (dir == 2) { for (int r = 0; r &lt; N; r++) { for (int c = 0; c &lt; N; c++) { max_value = max(max_value, map[r][c]); if (map[r][c] == 0 &amp;&amp; c != N-1) { for (int k = c + 1; k &lt; N; k++) { if (map[r][k] != 0) { map[r][c] = map[r][k]; map[r][k] = 0; max_value = max(max_value, map[r][c]); break; } } } } } } //우 else if (dir == 3) { for (int r = 0; r &lt; N; r++) { for (int c = N-1; c &gt;= 0; c--) { max_value = max(max_value, map[r][c]); if (map[r][c] == 0 &amp;&amp; c != 0) { for (int k = c - 1; k &gt;= 0; k--) { if (map[r][k] != 0) { map[r][c] = map[r][k]; map[r][k] = 0; max_value = max(max_value, map[r][c]); break; } } } } } } return max_value;}void dfs(int cnt, int max_value) { max_dp[cnt] = max(max_dp[cnt], max_value); if (cnt &gt;= 5) { return; } // 상, 하, 좌, 우 for (int dir = 0; dir &lt; 4; dir++) { int tmp_map[MAP_MAX_SIZE][MAP_MAX_SIZE]; copy_map(map, tmp_map); combine_map(dir); // 기울인 방향으로 합치기 int value = move_map(dir); // 빈칸 땡기기 &amp; 현재 최대값 반환 dfs(cnt + 1, value); recovery_map(map, tmp_map); }}int main() { ios::sync_with_stdio(false); cin &gt;&gt; N; init_map(); dfs(0, 0); cout &lt;&lt; max_dp[5] &lt;&lt; '\\n'; return 0;}","link":"/2017/10/12/Algorithm/boj-12100/"},{"title":"<13460> 째로탈출 2","text":"문제 : https://www.acmicpc.net/problem/13460 처음 풀이 방향을 잘못 잡고, 풀이시 여러 예외 사향을 잘못 생각하는 바람에 시간이 오래 걸렸습니다.코드가 조금 긴 편입니다… 저는 dfs를 활용해서 풀었습니다. 주의해야 할 사항이 몇가지 있었는데,1. 이미 기울였던 방향과 그 반대방향으로 다시 기울여서는 안된다. (이미 기울였던 방향으로 다시 기울이게 된다면 결과는 같을 것 입니다. 또한 방금 기울였던 방향의 반대로 기울인다면 이전과 같은 상태로 돌아가게 됩니다.)2. 기울인 후 파란공과 빨간공의 위치가 겹친다면 기울이기 전의 (1) 기울인 방향, (2) 파란공 위치, (3) 빨간공 위치 를 고려하여 다시 위치를 변경해주어야 한다. 위의 2가지 주의사항을 고려해서 푼다면 큰 문제 없이 풀 수 있을것 입니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276#include &lt;iostream&gt;#include &lt;algorithm&gt;#define MAP_MAX_SIZE 10#define ANS_MAX 11using namespace std;char map[MAP_MAX_SIZE][MAP_MAX_SIZE];int N, M;int ans = ANS_MAX;int rx, ry, bx, by, hx, hy;bool is_r_hall_in, is_b_hall_in;void init_map() { char c; for (int i = 0; i &lt; N; i++) { for (int j = 0; j &lt; M; j++) { cin &gt;&gt; c; map[i][j] = c; if (c == 'R') { rx = i; ry = j; } else if (c == 'B') { bx = i; by = j; } else if (c == 'O') { hx = i; hy = j; } } }}int get_deposit_dir(int dir) { if (dir == 0) { return 1; } else if (dir == 1) { return 0; } else if (dir == 2) { return 3; } else if (dir == 3) { return 2; }}int get_priority(int dir) { // 0 = 빨간공, 1 = 파란공 int priority = -1; // 상 if (dir == 0) { priority = bx &lt; rx; } // 하 else if (dir == 1) { priority = bx &gt; rx; } // 좌 else if (dir == 2) { priority = by &lt; ry; } // 우 else if (dir == 3) { priority = by &gt; ry; } return priority;}int move_x(int x, int y, int dir) { int nx = x; char type; if (dir == 0) { for (int i = x - 1; i &gt; 0; i--) { type = map[i][y]; if (type == '#') { break; } else if (type == 'O') { nx = i; break; } else { nx = i; } } } else { for (int i = x + 1; i &lt; N - 1; i++) { type = map[i][y]; if (type == '#') { break; } else if (type == 'O') { nx = i; break; } else { nx = i; } } } return nx;}int move_y(int x, int y, int dir) { int ny = y; char type; if (dir == 2) { for (int i = y - 1; i &gt; 0; i--) { type = map[x][i]; if (type == '#') { break; } else if (type == 'O') { ny = i; break; } else { ny = i; } } } else { for (int i = y + 1; i &lt; M - 1; i++) { type = map[x][i]; if (type == '#') { break; } else if (type == 'O') { ny = i; break; } else { ny = i; } } } return ny;}void move(int dir) { if (dir == 0 || dir == 1) { // 상, 하 rx = move_x(rx, ry, dir); bx = move_x(bx, by, dir); } else { // 좌, 우 ry = move_y(rx, ry, dir); by = move_y(bx, by, dir); }}void check_hall_in() { if (bx == hx &amp;&amp; by == hy) { is_b_hall_in = true; } if (rx == hx &amp;&amp; ry == hy) { is_r_hall_in = true; }}void priority_move(int priority, int dir) { if (dir == 0) { if (priority == 0) { bx = bx + 1; } else { rx = rx + 1; } } else if (dir == 1) { if (priority == 0) { bx = bx - 1; } else { rx = rx - 1; } } else if (dir == 2) { if (priority == 0) { by = by + 1; } else { ry = ry + 1; } } else if (dir == 3) { if (priority == 0) { by = by - 1; } else { ry = ry - 1; } }}void dfs(int pre_dir, int cnt) { if (cnt &gt; 10) { is_b_hall_in = false; is_r_hall_in = false; return; } if (is_b_hall_in) { is_b_hall_in = false; is_r_hall_in = false; return; } else { if (is_r_hall_in) { is_b_hall_in = false; is_r_hall_in = false; ans = min(ans, cnt); return; } } int brx = rx; int bry = ry; int bbx = bx; int bby = by; // 상, 하, 좌, 우 for (int dir = 0; dir &lt; 4; dir++) { if (dir == pre_dir || dir == get_deposit_dir(pre_dir)) { continue; } int priority = get_priority(dir); // 이동 &amp; 홀 인 체크 move(dir); check_hall_in(); // 공이 겹칠 경우, 우선순위에 따라 이동 if (rx == bx &amp;&amp; ry == by) { priority_move(priority, dir); } if (brx != rx || bry != ry || bbx != bx || bby != by) { dfs(dir, cnt + 1); } rx = brx; ry = bry; bx = bbx; by = bby; }}int main() { ios::sync_with_stdio(false); cin &gt;&gt; N &gt;&gt; M; init_map(); dfs(-1, 0); if (ans == ANS_MAX) { cout &lt;&lt; -1 &lt;&lt; '\\n'; } else { cout &lt;&lt; ans &lt;&lt; '\\n'; } return 0;}","link":"/2017/10/11/Algorithm/boj-13460/"},{"title":"<2632> 피자판매","text":"문제 : https://www.acmicpc.net/problem/2632 피자가 붙어있어야 한다는 조건 때문에 정렬을 할수가 없었습니다. 먼저 A와 B 각각의 피자판에서 만들어 질 수 있는 모든 합의 경우를 map을 사용해 저장한 후 목표하는 크기의 피자를 만들 수 있는 경우를 출력하는식으로 문제를 해결했습니다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;map&gt;#define MAX_SIZE 1000using namespace std;int target;int m, n;int a[MAX_SIZE], b[MAX_SIZE];map&lt;int, int&gt; a_sum, b_sum;void get_all_sum(int* arr, map&lt;int, int&gt;&amp; sum_map, int size) { for (int i = 1; i &lt; size; i++) { // 1개~suze-1개로 만들 수 있는 경우 모두 구하기 for (int j = 0; j &lt; size; j++) { // 시작하는 피자 순서 int sum = 0; for (int k = 1; k &lt;= i; k++) { // j번째 피자부터 i개 만큼 더하기 if (j+k-1 &lt; size) { sum += arr[j+k-1]; } else { sum += arr[j+k-1-size]; } } sum_map[sum] = sum_map[sum] + 1; } } int sum = 0; for (int i = 0; i &lt; size; i++) { // 피자의 모든 조각(size) 합 sum += arr[i]; } sum_map[sum] = 1; return ;}int main() { ios_base::sync_with_stdio (false); cin &gt;&gt; target &gt;&gt; m &gt;&gt; n; for (int i = 0; i &lt; m; i++) { cin &gt;&gt; a[i]; } for (int j = 0; j &lt; n; j++) { cin &gt;&gt; b[j]; } get_all_sum(a, a_sum, m); get_all_sum(b, b_sum, n); int cnt = a_sum[target] + b_sum[target]; // a와 b 각각의 피자만 사용해서 만드는 경우 for (int i = 1; i &lt; target; i++) { // a와 b피자 같이 사용해서 만드는 경우 if (a_sum[i] &amp;&amp; b_sum[target-i]) { cnt += (a_sum[i] * b_sum[target-i]); } } cout &lt;&lt; cnt &lt;&lt; '\\n'; return 0;}","link":"/2017/10/02/Algorithm/boj-2632/"},{"title":"<5014> 스타트링크","text":"문제 : https://www.acmicpc.net/problem/5014 BFS를 사용해 쉽게 해결할 수 있습니다. 다만 if 문에서 visit 배열로 층의 방문 여부를 체크하기전에 배열의 index가 유효한 범위에 속해있는지 확인을 먼저해주어야 합니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;vector&gt;#define MAX_SIZE 1000001using namespace std;bool visit[MAX_SIZE];int cnt[MAX_SIZE];int main() { int f, s, g, u, d; // 전체 층, 현재 층, 목표 층, 업 층, 다운 층 cin &gt;&gt; f &gt;&gt; s &gt;&gt; g &gt;&gt; u &gt;&gt; d; queue&lt;int&gt; q; // 층수 visit[s] = true; cnt[s] = 0; q.push(s); while(!q.empty()) { int now_floor = q.front(); int now_cnt = cnt[now_floor]; q.pop(); int next1 = now_floor + u; int next2 = now_floor - d; if (next1 &lt; MAX_SIZE &amp;&amp; visit[next1] == false) { q.push(next1); visit[next1] = true; cnt[next1] = now_cnt + 1; } if (next2 &gt; 0 &amp;&amp; visit[next2] == false) { q.push(next2); visit[next2] = true; cnt[next2] = now_cnt + 1; } } if (visit[g] == true) { cout &lt;&lt; cnt[g] &lt;&lt; '\\n'; } else { cout &lt;&lt; \"use the stairs\" &lt;&lt; '\\n'; } return 0;}","link":"/2017/10/01/Algorithm/boj-5014/"},{"title":"<14501> 퇴사","text":"문제 : https://www.acmicpc.net/problem/14501 N의 범위가 최대 15로, 작은 경우에 속해서 완전 탐색을 했습니다. 상담을 하는 경우와 하지 않는 경우를 나누어 해결합니다.상담이 필요한 기간에 당일 부터 포함되는 것만 주의하여 범위를 계산하면 될 것 같습니다 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;algorithm&gt;#define MAX_SIZE 16using namespace std;int day[MAX_SIZE];int pay[MAX_SIZE];int n;int sum = 0;void go(int d, int s) { if (d == n + 1) { sum = max(sum, s); return; } if (d + day[d] &lt;= n + 1) { go(d + day[d], s + pay[d]); } if (d + 1 &lt;= n + 1) { go(d + 1, s); }}int main(void) { cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) { cin &gt;&gt; day[i] &gt;&gt; pay[i]; } go(1, 0); cout &lt;&lt; sum &lt;&lt; '\\n'; return 0;}","link":"/2017/09/29/Algorithm/boj-14501/"},{"title":"(이펙티브 자바 2판) 리뷰","text":"Java 개발자라면 꼭 읽어보아야 한다는 Effective Java 책이다.Java 언어를 처음 접하는 개발자보다는 어느정도 Java를 이용해 개발을 하고 있는 개발자에게 많이 추천되는 책이다. 실제 책 도입 부분에서도 Java 언어를 처음 공부하는 개발자 보다는 중급 이상의 프로그래머 반열에 오르려면 반드시 읽어야 할 내용들을 포함하고 있다고 말하고 있다. 나는 아무래도 이직 후 자바 개발과 스프링 프레임워크를 처음 접하게 되었는데, 자바 웹 애플리케이션 개발 전반에 대해 이해하고자 스프링 관련된 서적을 먼저 읽고 있었지만, 여러 팀 동료분들이 코드리뷰를 해주시면서 “이펙티브 자바” 책을 읽어보면 도움이 많이 될 것 같다고 조언해주셔서 읽어보게 되었다. 이 책은 총 78개의 규칙으로 구성되어 있으며, 각 규칙은 최고의 프로그래머와 노련한 프로그래머 대부분이 유용하다고 믿는 지침들을 요약한 것이다. 책에서 등장하는 첫 번째 규칙이 “규칙 1. 생성자 대신 정적 팩터리 메서드를 사용할 수 없는지 생각해 보라”인데, 동료분께 코드리뷰 받으면서 조언 받았던 부분이기도 했다. 그래서 첫 부분부터 아주 재밌게 읽어나갔다. 그 외에도 평소 코드리뷰에서 말씀해 주셨던 여러 내용들을 이 책을 통해 자세하게 알 수 있었다. 책 자체 내용은 쉽게 읽을 수 있는 정도는 아니었다. 오히려 이해하기 위해 고민하는 부분에서 깨닫게 되는 부분도 많은것 같다. (특히 제네릭 부분과 병행성 부분은 아직도 좀 어려운데 이 부분은 앞으로 어느 정도 시간이 지난 후 다시 읽어보면 또 다르게 받아들여지지 않을까 싶다.)결과적으로 책을 읽고 난 후, 이부분을 개발할 때는 어떤 부분을 고려해 보아야 겠다라는 생각이 조금은 들게 된것 같다. 책 자체는 얇지는 않지만 각 파트 별로 여러개의 규칙으로 구성되어 있고, 각 규칙들은 정말 길어봐야 5~6장 정도의 분량이기 때문에 짬내서 읽기에도 좋았던것 같다.Java를 사용해 개발하고 있는 개발자 분들 중 읽어 보시지 않은 분들이 계시다면 꼭 추천드리고 싶은 책이다.","link":"/2018/08/05/Book/effective_java_2e_review/"},{"title":"(웹 프로그래머를 위한 서블릿 컨테이너의 이해) 리뷰","text":"한빛미디어 - 웹 프로그래머를 위한 서블릿 컨테이너의 이해 스프링을 이용해 개발하고 있지만 스프링이 구동되는 서블릿 컨테이너에 대한 이해가 부족해 읽게 되었다. (어떻게 돌아가고 있는지 궁금했다…) 책의 구성은 서블릿 컨테이너를 학습해야 하는 이유를 시작으로 HTTP 프로토콜에 대한 이해 그리고 서블릿의 이해로 이어진다.그 후에는 실제 서블릿 컨테이너에서 HTTP 프로토콜을 어떻게 분석해 서블릿에 전달해주는지, 스레드 풀을 이용해 동시에 들어오는 request 들을 어떻게 처리하는지에 대한 내용을 다루고 있다. 도입 부분(서블릿 컨테이너를 학습해야 하는 이유)에 다음과 같은 이야기가 있다. 특히 성능과 관련된 문제가 발생했을 때, 웹 기반 시스템의 하위 레벨 영역인 웹 애플리케이션 서버가 담당하는 부분을 모르고서는 근본적인 원인 규명 자체가 불가능합니다. 웹 애플리케이션 서버의 내부구조와 동작 원리를 이해하지 못하는지가 웹 프로그램의 고성능, 고가용성에 대한 요구를 충족시킬 수 있는지 결정한다고 할 수 있습니다. 위의 말에 전적으로 동의한다. 스프링을 이용해 웹 애플리케이션을 만들기 위해 스프링을 공부하고 이해하듯, 스프링이 실행되는 서블릿 컨테이너에 대한 공부와 이해도 필요하다. 아마 나와 같이 서블릿을 이용한 개발 경험 없이, 스프링을 시작했다면 이 책을 읽어보기를 더욱 추천하고 싶다.","link":"/2018/08/18/Book/servlet_container_review/"},{"title":"2) 카카오 옐로아이디 만들기","text":"Index 옐로아이디란? 옐로아이디 만들기 옐로아이디란?옐로아이디란 고객과 소통할 수 있는 카카오톡 비즈니스 아이디입니다. 옐로아이디를 무료로 만들어 비즈니스에 활용가능하며 옐로아이디는 별도의 전화번호가 필요없고, 한글 아이디 검색이 가능합니다. 옐로아이디는 API형 자동응답이 가능하기 때문에 사용자의 요청에 따라 자유롭게 답변 시나리오 및 이벤트를 구성할 수 있습니다. 카카오 뿐만 아니라 페이스북, 텔레그램 또한 API형 자동응답 기능을 제공하기 때문에 굳이 옐로아이디를 사용하지 않아도 자동응답 챗봇을 만들 수 있습니다. 옐로아이디 만들기옐로아이디를 사용하기위해서는 먼저 정해진 절차에 따라 가입신청을 해야합니다. Yellow ID 신규가입을 통해 옐로아이디 신청이 가능합니다. 모바일이라면 Yellow ID App 설치 후 신청이 가능합니다. 옐로아이디 API 문서는 공개되어 있기 때문에 옐로아이디 가입신청 후 기획이 되어있다며 바로 개발이 가능합니다. 가입신청이 완료되면 발급받은 API 키만 적용해주면 됩니다. 신청시 주의사항 프로필 이름과 옐로아이디는 개설 후 변경이 불가능합니다.(위의 사진에서 인천대학교 에밀리가 프로필 이름, @인천대학교-에밀리가 옐로아이디를 의미합니다. 주소는 입력하지 않아도 상관없습니다. 홈페이지 주소를 입력하게 되는데 저는 처음 블로그 주소를 기재하였다가 옐로아이디의 목적과 맞지 않다는 이유로 반려되었습니다. 옐로아이디에 대한 설명이 있는 홈페이지가 없다면 페이스북 페이지를 생성한 후 간단히 옐로아이디에 대한 목적과 서비스에 대해 간단한 글을 남긴 후 홈페이지 주소에 페이스북 페이지를 기재하는 방법이 좋습니다. 심사는 2~3일 정도의 시간이 소요됩니다. 심사에서 반려될 경우 해당 반려사유를 참고하여 수정 후 재심사를 요청해야합니다. 재심사도 2~3일 정도의 시간이 소요되기 때문에 처음 신청시 반려되는 불상사가 일어나지 않도록 공들여 작성해야합니다.","link":"/2017/03/21/Emily/2-make-kakao-yellow/"},{"title":"(라즈베리파이 쿡북) 리뷰","text":"벌써 라즈베리파이 강의를 한지 약 한달 정도가 지났습니다. 조금 늦은 감이 있지만 강의를 준비하며 도움을 많이 받은 책이기에 후기를 남깁니다. 강의는 대체로 라즈베리파이를 처음 접하는 학생들이 대부분이었기에 어려운 주제를 다루기보다는 간단히 라즈베리파이에 라즈비안(OS)를 설치하고 리눅스 명령어를 실습, 파이썬 기본 문법, 파이썬을 사용해 라즈베리파이 GPIO 사용하기를 강의 목표로해서 진행했었습니다. 한빛미디어의 라즈베리파이 쿡북은 책의 순서 및 내용이 제가 하고자 했던 강의와 대부분 일치하여 강의 준비를 하면서 많은 도움을 얻을 수 있었습니다. 간단하게 책에서 다루는 내용을 살펴보면 다음과 같습니다. 라즈베리 파이의 구입, 설정, 기본 관리 방법 익히기 네트워크에 라즈베리 파이 연결하기 리눅스 기반의 운영체제와 사용법 익히기 라즈베리 파이에 기본 내장된 소프트웨어를 사용하기 라즈베리 파이를 위한 파이썬 프로그램 익히기 GPIO 커넥터를 통해 하드웨어 제어하기 라즈베리 파이와 함께 다양한 모터 사용하기 디지털 장비를 통한 입출력 살펴보기 센서를 연결해 다양한 상태 살펴보기 라즈베리 파이와 아두이노를 혼합한 프로젝트 만들기 너무 어렵지 않은 주제들을 다루고 있고, 처음 프로그래밍을 접하는 사람도 천천히 따라하면 파이썬을 사용해 라즈베리파이 프로젝트를 할 수 있을 정도로 내용을 다루고 있습니다. 책에서 다루는 센서들도 대부분 많이 사용하고 있는 센서들이기 때문에 검색을 통해 추가적인 자료를 얻는것도 쉽습니다. 라즈베리파이를 사용해 프로젝트를 해보고자 하시는 분들은 라즈베리파이 쿡북을 참고해서 진행해보는것을 추천드립니다!","link":"/2017/08/08/Book/raspberry-cookbook/"},{"title":"1) 에밀리 개발 시작하기","text":"Index 들어가기 앞서 인천대학교-에밀리? 에밀리와의 대화방식 현재의 에밀리 앞으로의 에밀리 마치며 들어가기 앞서기술 블로그의 좋은 글과 책을 통해 배우는 것도 많지만, 개인 프로젝트를 하며 배우는 점도 많은것 같습니다. 이번에는 퇴근 후 저녁시간과 주말을 이용해 진행했던 인천대학교-에밀리 프로젝트에 대해 포스팅하려 합니다.이전에도 여러 개인 프로젝트를 해왔지만 대부분 중도 마무리되거나, 완성 후 실제적으로 운영하지는 않았습니다. 아무래도 완성을 해도 이용자가 없다보니 내가만든걸 누군가가 사용한다는 기쁨을 맛보지 못해 그만두었던것 같습니다. 그래서 그동안 개인 프로젝트를 하는데에는 공부했던 것을 토대로 무언가를 만들어보자는 목적이었다면, 이번에는 사용자의 범위를 최대한 좁혀 모든 기능을 특정 사용자에 맞추고 두고두고 사용할 수 있는 그런 서비스를 만들어 보고싶었습니다. 위의 사진은 카카오 플러스친구인 웨더뉴스에서 매일 오전 날씨정보를 제공해주는 모습입니다. 하루 한번 날씨 정보를 제공해주는데, 글을 작성하는 2017-03-10 기준으로 531,980명이 이용하고 있습니다. 날씨를 제공해주는 서비스는 이전부터 많이 제공되고 있었지만 제일 사용빈도가 높은 카카오톡 서비스와 결합하다 보니 더 사용자들이 많이 찾는것 같았습니다. 저 또한 굳이 인터넷 검색이나 다른 앱을 실행하지 않고도 정보를 얻을 수 있다는 점에 가장 큰 가치를 두고 사용하고 있었습니다. 이점이 큰 메리트라고 느꼈고 이를 토대로 인천대학교-에밀리 프로젝트를 기획하고 개발하게 되었습니다. 인천대학교-에밀리?왜 하필 에밀리일까요? 네이버 웹툰 - 신의탑을 보면 다음과 같이 에밀리가 등장합니다. 신의탑 웹툰에서 에밀리는 사용자가 궁금해 하는것을 모두 알려줍니다. 이러한 에밀리의 특징과 사용자의 범위를 최대한 좁히기 위해 제가 다녔던 인천대학교의 학생을 사용자로 맞추어 인천대학교-에밀리를 개발하게 되었습니다. 에밀리와의 대화방식인천대학교 학생들을 위해 필요한 정보를 쉽게 제공해준다.라는게 이번 서비스의 목표입니다. 후에 다시 한번 알아보겠지만 카카오톡의 플러스친구/옐로아이디는 자동응답 API를 제공하는데 이를 통해 (1)사용자가 직접 메시지를 입력 혹은 (2)버튼을 통해 객관식으로 정해진 내용을 입력하도록 할 수 있습니다.사용자가 쉽고 빠르게 정보를 얻을 수 있게 하기 위해서는 메시지보다는 버튼을 통해 사용자가 이용할 수 있는 기능을 알려주고 직접 선택 할 수 있도록 하는게 편리하고 빠르다는 생각에 버튼 방식으로 개발하기로 하였습니다. 현재의 에밀리현재 에밀리는 다음과 같은 사용 가능합니다. 열람실, 메뉴, 날씨 정보를 제공하고 있습니다. # 사용법 (에밀리의 간단한 사용방법을 알 수 있습니다.) # 열람실 (실시간 지하 도서관의 열람실 정보와 좌석도(링크)를 제공합니다.) # 메뉴 (학생식당, 기숙사식당 등… 교내 식당의 당일 메뉴를 제공합니다.) # 날씨 (어제와 오늘 인천대학교 날씨 정보를 제공합니다.) 앞으로의 에밀리지금까지 제공하는 기능들은 대부분 학교 홈페이지 크롤링을 이용하거나 외부 API를 사용해 제공하는 기능였습니다. 앞으로도 정보제공에 관한 기능들도 추가할 것이지만, 단순한 정보제공 외에도 인천대학교 학생들이 생활하는데 있어 편리할만한 기능을 추가할 예정입니다.가령 자신의 학교 시간표를 에밀리를 통해 제공받은 웹 페이지에서 작성한 후 저장하면, 그 후로는 에밀리를 통해 자신의 시간표에 대한 정보를 제공받을 수 있습니다. 다음 수업의 시간과 강의실 정보, 오늘 전체적인 시간표 보기 등… 사용자가 입력한 정보를 바탕으로 개개인에 맞게 정보를 제공할 생각입니다. 마치며실제로 사용자가 이용할 수 있는 서비스를 만드는것은 정말 재밌는 일인것 같습니다. 앞으로 계속해서 기능을 추가할 것이며, 앞으로의 포스팅은 지금까지 에밀리를 만들었던 과정과, 앞으로 추가하며 작업하는 내용을 다룰 예정입니다. 인천대학교-에밀리를 사용해보시고 혹시나 궁금한 점이 있으시다면 댓글로 남겨주시면 답변드리겠습니다.","link":"/2017/03/10/Emily/1-start-emily/"},{"title":"5) AWS Lambda 사용하기","text":"Index AWS Lambda란? CloudWatch와 Lambda 구성하기 정리하며 저번 포스팅에서 작성한 학식 메뉴 크롤링(학식 메뉴를 크롤링해 DB에 저장) 코드를 AWS Labmda를 사용해 일주일에 한번씩 실행되도록 스케쥴링을 해보겠습니다. AWS(아마존 웹 서비스)에 대한 기본적인 내용은 생략합니다. AWS Lambda란?어떠한 이벤트에 따라 Cron 프로세스를 구성하는데에는 다양한 방법이 존재합니다. 서버 인스턴스를 띄워놓고 일정 시간에 이벤트를 발생시키는 것이 일반적인 방법 중 하나이지만 이러한 방법으로 구성할 시에는 해당 시간에 Event를 발생시키는 일을 제외하고는 서버 인스턴스를 낭비하게 됩니다. AWS Lambda는 이벤트에 응답하여 코드를 실행하고 자동으로 기본 컴퓨팅 리소스를 관리하는 서버 없는 컴퓨팅 서비스입니다. AWS Lambda를 사용하여 커스텀 로직으로 다른 AWS 서비스를 확장하거나, AWS 규모, 성능 및 보안으로 작동하는 자체 백엔드 서비스를 만들 수 있습니다. AWS Lambda는 Amazon S3 버킷의 객체에 대한 변경 또는 Amazon DynamoDB의 테이블 업데이트와 같은 다양한 이벤트에 대한 응답으로 코드를 자동 실행할 수 있습니다. AWS Lambda는 코드가 실행되지 않을 때는 요금이 부과되지 않습니다. 즉, 서버 인스턴스를 계속 띄워놓는 것과 비교했을 때 더 저렴합니다. AWS Lambda의 자세한 요금 정책은 AWS 홈페이지에서 확인 가능합니다. (Lambda 함수가 다른 AWS 서비스를 사용하거나 데이터를 전송하는 경우 추가 요금이 부과될 수 있으므로 필히 확인바랍니다.) CloudWatch와 Lambda 구성하기1) AWS에 로그인 후 Lambda 서비스를 클릭합니다. 2) 저와 같이 이미 생성한 Lambda 함수가 있는 경우는 아래와 같이 Create a Lambda Function 버튼을 클릭하고 처음으로 Lambda 함수를 생성하는 경우는 Get Started Now 버튼을 클릭합니다. 3) Blueprint는 자주 사용되어지는 미리 준비된 Lambda 함수의 환경을 제공합니다. 저희는 Blank Function을 선택해서 직접 trigger(Event)와 환경을 설정합니다. 4) Lambda를 일정 시간 규칙에 맞게 호출할 것이기 때문에 CloudWatch Events - Schedule를 선택합니다. CloudWatch는 AWS에서 실행되는 애플리케이션을 위한 모니터링 서비스 뿐만 아니라 Schedule도 제공합니다.(Lambda를 실행시키기 위한 trigger로 다양한 방법이 제공됩니다. 한가지 예시로 S3의 특정 Bucket에 이미지 파일이 업로드 될때마다 ReSizing을 하고싶다면 trigger로 S3를 설정한 후 Bucket과 Event type(Delete, Put, Post, Copy)을 설정하여 해당 Lambda를 수행하도록 할 수 있습니다.) 5) CloudWatch Events - Schedule의 내용을 작성합니다. Rule name과 Rule description에는 해당 Schedule의 이름과 설명을 적고, Schedule expression에는 Event를 발생시키고자 하는 주기에 맞게 Cron 식을 작성합니다.Schedule expression에 작성한 Cron 식에 따라 Event가 발생하는 시간이 달라집니다. Cron 식을 처음 접하시는 분은 AWS 홈페이지1, AWS 홈페이지2를 참고해서 Cron 식을 작성합니다.단, Cron 식에 사용되는 시간은 UTC를 기준으로 하기 때문에 유의해야 합니다. 제가 작성한 cron 식 (0 13 ? * SUN *)을 기준으로 하면 매주 일요일 22(13+9)시에 이벤트가 발생합니다. 6-1) 다음과 같이 Lambda function의 이름, 설명, 실행환경(포스팅 기준 Node.js 6.10 이 최신 버전입니다.) 을 작성합니다. 6-2) 다음으로 CloudWatch Events에 의해서 실행될 코드를 기재해야합니다. 코드를 기재하는 방식은 직접 작성, .ZIP 파일로 압축, S3를 이용하는 3가지 방식중 하나로 진행됩니다.만약 작성한 코드가 aws-sdk를 제외한 외부 라이브러리를 사용하고 있다면 코드와 함께 라이브러리 파일(node_modules)을 압축하여 .ZIP 파일을 업로드 해야합니다. 6-3) 기존에 작성했던 코드에서 수정이 필요합니다. Lambda function의 코드가 에러없이 잘 완료되었는지 callback을 통해 결과를 반환해야합니다. 지난번에 작성했던 코드는 다음과 같이 수정됩니다. (예시를 들기위해 간단하게 작성했을 뿐, 실제 DB에 Insert 하는 부분은 생략되어 있습니다.)29, 30번째 줄과, 34번째 줄에 추가된 코드에 주의하셔야 합니다. 12345678910111213141516171819202122232425262728293031323334353637exports.handler = (event, context, callback) =&gt; { const request = require('request'); const cheerio = require('cheerio'); const url = \"http://www.inu.ac.kr/com/cop/mainWork/foodList1.do?siteId=inu&amp;id=inu_050110010000&amp;command=week\"; request(url, (error, response, body) =&gt; { if (error) throw error; let $ = cheerio.load(body); try { let krDay = ''; let corner = ''; let menu = ''; $('table').find('tr').each(function (index, elem) { if (index % 6 === 0) { krDay = $(this).find('th').text().trim(); console.log(`${krDay}`); } else { corner = $(this).find('th').text().trim(); menu = $(this).find('th').next().text().trim(); console.log(`${corner} -&gt; ${menu}`); } callback(null); context.succeed(); }); } catch (error) { console.error(error); callback(err); } });}; 6_4) 필요에 따라 환경변수(Environment variables)와 Advanced settings를 작성한 후 Role을 작성하고 다음단계로 넘어갑니다. (Handler에 index.handler 라고 작성했기 때문에 .ZIP파일로 압축할때 소스코드(.js)의 파일명은 index가 되어야 합니다) 7) 지금까지 설정한 옵션을 확인하고 최종적으로 function을 생성합니다. 8) 생성된 Lambda Function을 테스트할 수 있습니다. Actions -&gt; Configure test event를 통해 테스트를 위한 이벤트를 설정합니다. trigger(Event)로 CloudWatch Events - Schedule를 설정했기 때문에 event template 목록 중 Schedule Event를 선택합니다. 9) 테스트 후 CloudWatch의 로그를 통해서 lambda function 코드에서 출력했던 로그 및 실행결과를 확인할 수 있습니다. 정리하며지금까지 진행한 작업은 다음의 이미지 한장으로 정리가 가능합니다. 이번기회에 lambda를 처음 사용해봤지만 앞으로 개인프로젝트에도 실무에서도 자주 사용하게될 것 같습니다.","link":"/2017/05/28/Emily/5-aws-lambda/"},{"title":"3) Express 프로젝트 생성하기","text":"Index 들어가기 앞서 Express 프로젝트 생성하기 옐로아이디 API 문서 살펴보기 API 작성하기 서버 실행 &amp; API 연동하기 마치며 들어가기 앞서옐로아이디 자동응답API 를 만드는데에는 여러가지 방법이 있습니다. 저는 Express generator를 사용하여 생성한 Express 기반의 프로젝트로 Emily를 만들었고 이 방식으로 설명할 예정입니다. 그러나 간단한 기능만 구현하는 경우 AWS의 Lambda와 API GateWay를 사용해서도 Serverless하게 만들 수 있습니다. 해당 내용은 박상권의 삽질블로그를 참고하면 좋을것 같습니다. Express 프로젝트 생성하기 Node 버전은 6.6.0을 사용합니다. Node가 설치되어 있지 않다면 글을 작성하는 기준으로 LTS 버전인 6.10.3이상의 버전을 설치합니다. 이왕이면 nvm을 이용하여 설치하는것을 권장합니다. (nvm 관련글 참고) npm, Express 에 대해서는 해당 글에서 자세하게 설명하지 않겠습니다. 더 좋은 글들이 많으니 참고하시기 바랍니다!! 이제 Express 프로젝트를 생성하겠습니다. npm을 통해 Express generator를 먼저 설치합니다. (global로 추가하기 위해 -g 옵션을 사용합니다.)1$ npm install express-generator -g Express generator를 사용해서 프로젝트를 생성합니다. 저는 Emily라는 이름으로 프로젝트를 생성했습니다.1$ express Emily 생성된 프로젝트 폴더로 이동하여 모듈을 설치합니다.12$ cd Emily$ npm install 생성된 프로젝트는 다음과 같은 구조입니다. 이제 옐로아이디 API 문서를 참고해서 간단한 봇을 만들어보겠습니다.1234567891011121314151617.├── app.js├── bin│ └── www├── package.json├── public│ ├── images│ ├── javascripts│ └── stylesheets│ └── style.css├── routes│ ├── index.js│ └── users.js└── views ├── error.jade ├── index.jade └── layout.jade API 문서 살펴보기카카오톡 이용자가 플러스친구, 옐로아이디에게 보낸 메세지를 카카오톡 서버를 통해 저희가 전달 받은 후 다시 카카오톡 서버로 응답 메시지를 전달해야하기 때문에 카카오톡에서 정의하고 있는 API 문서에 맞게 코드를 작성해야 합니다. 지금부터 옐로아이디 API 문서를 살펴보겠습니다. 본 포스팅에서는 [이용에 대한 참고사항, 개인정보 수집 및 이용에 대한 주의사항]에 대해서는 따로 설명하지 않습니다. 그러나 개발전에 한번쯤은 꼭 읽어보셔야합니다. 1. 용어먼저 API 문서에서 사용되는 용어에 대해서 살펴보겠습니다. (1) 수신 API카카오톡 이용자가 플러스친구, 옐로아이디에게 보낸 메시지를 전달 받은 후 응답을 할 수 있는 API 입니다.http(s) restful api를 통하여 카카오 API 서버 -&gt; 파트너 서버를 호출합니다. (2) app_key플러스친구/옐로아이디에서 자동응답을 위한 앱 등록시 프로필별로 발급되는 고유 키 값입니다.자동응답 기능만 이용하시는 경우 사용되지 않으며, 일부 app_secret을 통한 별도 인증이 필요한 일부 프로필에만 사용됩니다. (3) app_secret인증을 위해 app_key와 조합하여 사용되는 키 값입니다.자동응답 기능만 이용하시는 경우 사용되지 않으며, 일부 app_secret을 통한 별도 인증이 필요한 일부 프로필에만 사용됩니다. (4) user_key특정 카카오톡 이용자를 구분하기 위한 key 입니다. 카카오에서는 이용자의 개인정보를 외부에 제공하지 않으므로, 외부 파트너사에서 카카오톡 이용자를 구분하기 위해서는 카카오로부터 API를 통해 user_key를 response로 받아야 합니다.user_key는 특정 카카오톡 이용자에 대해 프로필별로 각기 다르게 발급됩니다. 따라서 user_key는 해당 프로필에 대해서만 유효합니다.카카오톡 이용자가 프로필을 차단했다가 다시 추가한 경우에는 user_key가 갱신되지 않으며, 이용자가 카카오톡 탈퇴 후 재가입한 경우 갱신됩니다. 2. API카카오에서 제공하고 있는 옐로아이디 API는 아래와 같이 5개 입니다. 각 API에 대한 자세한 내용은 문서를 참고합니다. Action Method URL 설명 키보드 GET /keyboard 처음에 사용자가 채팅방에 들어왔을때 호출되는 API. 사용자에게 키보드에 보여질 내용을 리턴 메시지 POST /message 사용자가 보내는 메세지/사진/동영상 을 받아 처리해 응답 친구추가 POST /friend 사용자가 옐로아이디를 친구추가했을때 호출되는 API 친구차단(삭제) DELETE /friend 사용자가 옐로아이디를 친구차단(삭제)했을때 호출되는 API 채팅방 나가기(삭제) DELETE /chat_room 사용자가 채팅방 나가기(삭제)했을때 호출되는 API API 작성하기API 문서를 참고하여 코드를 작성하겠습니다. 작성하는 코드는 사용자가 옐로아이디를 친구 추가 후 채팅방에서 입력하는 메시지를 받아 그대로 다시 전달해주는 코드입니다. routes 폴더 아래에 api.js를 추가 후 다음 코드를 작성합니다.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253const express = require('express');const router = express.Router();// 처음에 사용자가 채팅방에 들어왔을때 호출되는 API. 사용자에게 키보드에 보여질 내용을 리턴router.get('/keyboard', function (req, res) { res.status(200).json( { type: 'text' } );});// 사용자가 보내는 메세지/사진/동영상 을 받아 처리해 응답router.post('/message', function (req, res) { const { user_key, type, content } = req.body; console.log(`\"${user_key}\"가 \"${content}\" 메시지 입력`); res.status(200).json({ message: { content } });});// 사용자가 옐로아이디를 친구추가했을때 호출되는 APIrouter.post('/friend', function (req, res) { const userKey = req.body.user_key; console.log(`\"${userKey}\"가 옐로아이디 친구 추가`); res.status(200).json();});// 사용자가 옐로아이디를 친구차단(삭제)했을때 호출되는 APIrouter.delete('/friend/:userKey', function (req, res) { const userKey = req.body.userKey; console.log(`\"${userKey}\"가 옐로아이디 친구 삭제`); res.status(200).json();});// 사용자가 채팅방 나가기(삭제)했을때 호출되는 APIrouter.delete('/chat_room/:userKey', function (req, res) { const userKey = req.body.user_key; console.log(`\"${userKey}\"가 옐로아이디 채팅방 삭제`); res.status(200).json();});module.exports = router; 작성한 router를 app.js에 추가합니다.12const api = require('./routes/api');app.use('/api', api); 서버 실행 &amp; API 연동하기서버는 해당 프로젝트 경로에서 npm start 혹은 node bin/www 로 실행할 수 있습니다. 그러나 해당 서버는 외부에서 접근 가능해야 합니다. 즉, AWS의 EC2와 같은 클라우드 자원을 사용하거나(추천), 본인의 컴퓨터 혹은 노트북에서 서버를 실행한다면 포트포워딩을 통해 외부에서 접근할 수 있도록 설정이 필요합니다. 외부에서 접근할 수 있도록 설정이 끝난 후에는 옐로아이디 홈페이지에서 해당 서버의 URL을 기재합니다. 앱 URL을 기재하고 API TEST 버튼을 누르면 카카오에서 해당 URL에 test request를 요청합니다. test request의 결과를 통해 잘 작동하는지 확인이 가능합니다. 마치며이번 포스팅에서는 Express 프로젝트를 생성하고 API 문서를 토대로 간단한 봇을 만들어보았습니다. 해당 API를 토대로 앞으로 구현하고자 하는 기능을 구현하면 될것입니다. 다음번에는 제가 Emily를 만들며 구현하고자 했던 부분들을 어떤식으로 해결했는지에 대해 포스팅하겠습니다.","link":"/2017/05/17/Emily/3-make-express-project/"},{"title":"6) AWS S3를 이용한 웹 호스팅","text":"Index 에밀리 시간표 웹 페이지 AWS S3란? 도메인 등록 S3 버킷 생성 웹 사이트 데이터 업로드 버킷 정책(Permissions) 설정 버킷 정적 웹 사이트 호스팅 기능 활성화 버킷 Record Set 설정 에밀리 시간표 웹 페이지학생들에게 필요한 기능이 어떤게 있을까 생각하다 에밀리에 시간표 기능을 추가하게 되었습니다. 학생들이 수강하고 있는 수업 데이터를 얻을 수 있으면 좋겠지만 학교 DB에 접근할 수 있는 권한이 없기 때문에 학생들이 직접 에밀리를 통해 시간표를 등록하도록 만들어야 했습니다. 학교 홈페이지에서 제공하는 수업 목록(엑셀 파일)를 활용(파싱)하여 시간표 데이터를 만들고, 이를 학생들이 쉽게 등록 및 수정할 수 있도록 웹 페이지를 만들었습니다 (아무래도 전공도 다양하고 수업의 수도 많다보니 단순히 버튼 및 텍스트로 상호작용하여 시간표를 등록하는것은 불편하다고 판단해 시간이 좀 더 걸리더라도 웹 페이지를 만들기로 결정했었습니다.) 학생들이 많이 사용하는 여러 시간표 앱 및 웹 서비스를 참고해서 다음과 같은 시간표 등록 및 수정 페이지를 만들었습니다. 참고로 에밀리 시간표 등록 및 수정 페이지는 React(Starter-Kit)를 이용해서 만들었습니다. 아무래도 회사에서 React Native를 사용해서 앱을 개발하다보니 React를 사용해 웹 개발을 함에 있어서도 도움이 많이 되었습니다. AWS S3란?사용자들이 에밀리 시간표 페이지를 사용할 수 있도록 하기 위해서는 웹 페이지를 호스팅해야합니다. 간단히 호스팅할 수 있는 여러 방법들이 있지만, AWS 공부도 할겸 S3를 이용해 호스팅해보기로 생각했습니다. 먼저 S3에 대해 간단하게 알아보겠습니다. S3(Simple Storage Service)는 파일을 저장하기 위한 Storage입니다. 일반적인 파일시스템의 개념과는 약간 다르며, 파일 이름을 대표하는 key와 파일 자체로 구분되는 Object Storage입니다. S3는 정적 웹사이트 호스팅 기능을 사용하는 S3 버킷을 Route 53을 통해 도메인과 연결해 사용할 수 있습니다. 여기서 동적 웹 사이트 PHP, JSP 등 서버 측 처리에 의존하는 사이트는 S3를 이용해 호스팅할 수 없습니다. 오직 개별 웹 페이지에서 정적 컨텐츠를 포함하며, 클라이언트 측 스크립트를 포함하고 있는 정적 웹 사이트만이 호스팅 가능합니다. (React의 경우 webpack을 통해 번들링된 파일을 호스팅하면 됩니다.) 도메인 등록이미 등록된 도메인이 있다면 이 단계를 생략하면 됩니다. 그러나 inuemily.com과 같이 등록된 도메인 이름이 없는 경우, 원하는 도메인 이름을 만들어 등록해야 합니다. 도메인이 없으시다면 AWS의 Route53 - Registered domains를 통해 도메인을 생성하고, AWS가 아닌 다른 서비스로부터 도메인을 사용중 이라면 기존 도메인 DNS 서비스 역할을 하는 AWS Route53으로 마이그레이션을 해야 S3를 이용한 정적 웹사이트 호스팅이 가능합니다. 마이그레이션 관련해서는 AWS 문서를 참고하면 좋을것 같습니다. 저는 다음과 같이 inuemily.com 이라는 도메인을 갖고 있습니다. S3 버킷 생성inuemily.com과 같은 루트 도메인, www.inuemily.com과 같은 하위 도메인 양쪽의 요청을 모두 지원하려면 두 개의 버킷을 생성해야합니다. 하나의 버킷에 컨텐츠를 포함하고 다른 버킷은 컨텐츠를 포함하는 버킷에 redirection 하도록 버킷을 구성할 것입니다. 먼저 버킷 이름을 호스팅할 웹 사이트 이름과 일치하게 생성합니다. 저는 inuemily.com과 www.inuemily.com 이름으로 버킷을 생성했습니다. 웹 사이트 데이터 업로드2개의 버킷을 모두 생상하였다면 루트 도메인 버킷(inuemily.com)에 컨텐츠를 업로드합니다. 두 번째 버킷(www.inuemily.com)은 추후에 이 루트 도메인 버킷으로 redirection 하도록 설정할 것입니다. S3 버킷에 파일을 업로드하는 방법으로는 1) 드래그 앤 드롭, 2) AWS CLI 사용 과 같이 2가지 방법이 있습니다. 저는 드래그 앤 드롭을 이용해서 파일을 업로드 하였습니다. (webpack으로 번들링되어 나온 public 폴더의 파일들을 업로드 하였습니다.) 버킷 정책(Permissions) 설정버킷을 생성하고 파일을 업로드했지만 모든 사용자가 버킷에 업로드한 모든 컨텐츠에 접근할 수 있도록 버킷 정책(Permissions)을 설정해야 합니다. 다음의 코드를 복사하여 아래 사진과 같이 버킷 정책을 설정합니다. (10번째 라인의 inuemily.com을 자신의 버킷 이름으로 변경해야 합니다.) 두 번째 버킷에는 파일을 업로드하지 않기 때문에 따로 정책을 설정해주지 않아도 됩니다. 12345678910111213{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Id&quot;: &quot;Policy1484315866648&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;Stmt1484315864175&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::inuemily.com/*&quot; } ]} 버킷 정적 웹 사이트 호스팅 기능 활성화파일 업로드와 정책 설정이 끝난 버킷을 정적 웹 사이트 호스팅으로 사용할 수 있도록 기능을 활성화 해야합니다. 루트 버킷을 정적 웹 호스팅에 사용하기 때문에 User this bucket to host a website 에 체크를 하고, index document에는 자신이 작성한 웹 페이지의 index page의 파일명을 기재합니다. 저의 경우 좀 전에 버킷에 업로드한 파일을 보면 index.html이 있고, 이 파일이 index page의 파일이기 때문에 index.html을 기재했습니다. 이번에는 두번째 버킷으로 들어오는 요청을 루트 버킷으로 redirection 할 수 있도록 설정을 합니다. 루트 버킷과는 달리 Redirect requests에 체크를 하고, Target bucket or domain에 루트 버킷의 이름을 기재합니다. 버킷 Record Set 설정이제 마지막 단계입니다. 지금까지 생성하고 설정을 마친 S3 버킷을 Route 53을 사용해 연결합니다. 도메인에 따른 호스팅 영역과 추가하는 별칭 레코드는 IP 주소 대신 S3 웹 사이트 엔드포인트를 사용함으로써 Route 53은 별칭 레코드와 S3 버킷이 존재하는 IP 주소 간 매핑을 유지합니다. Route 53의 Record Set 까지 설정을 마치면 해당 루트 도메인과 서브 도메인을 통해서 사이트에 접속할 수 있습니다. 참고AWS - 사용자 지정 도메인으로 정적 웹 사이트 설정아마존 웹 서비스를 다루는 기술 - 11장","link":"/2017/07/17/Emily/6-aws-s3-static-web-hosting/"},{"title":"신입 개발자의 취준 후기","text":"8월을 마지막으로 1년 2개월의 스타트업 생활을 마치고, 이번 하반기 신입 채용과정을 거쳐 3곳에 합격했습니다. 퇴사 후 부랴부랴 취업준비를 시작했는데, 이번 포스팅에서는 취업준비를 하며 어떤 식으로 전공 지식과 직무 면접을 준비했는지 다뤄보겠습니다! 자료구조와 알고리즘제일 먼저 준비했던 과목은 자료구조와 알고리즘이었습니다. 제 경우 자료구조와 알고리즘이 다른 전공에 비해 많이 부족해서 가장 먼저 공부를 시작했습니다.대부분 기업이 서류 통과 후 바로 온라인 코딩 테스트 과정이 있기 때문에, 처음부터 차근차근 이론을 공부하고 문제를 푸는것은 시간상 불가능하다고 생각했습니다. 그래서 코드플러스 - SW 역량 테스트 대비 강의를 통해 자주 출제되는 알고리즘들의 유형을 빠르게 익히고 비슷한 문제를 풀어보는 연습을 했습니다. 저는 대표적인 유형의 알고리즘 같은 경우는 코드를 외울 정도로 자주 봤습니다. 사람마다 다르겠지만 제 경우에는 어느정도 문제의 틀이나 해법을 외워두니 비슷한 유형의 문제는 빠르게 풀 수 있었습니다. 처음 코딩 테스트를 준비하시는 분이라면 저처럼 대표적인 유형의 해법 정도는 외워두는게 도움이 많이 될 것 같다고 생각합니다. (당연히 이해를 바탕으로 외워야 합니다.) 자료구조와 알고리즘의 경우 온라인 코딩 테스트를 통과하더라도 다음 절차인 (직무)면접에서도 빠지지 않고 등장하는 과목입니다. 저도 온라인 코딩 테스트를 통과한 후에는 방향을 바꿔서 문제를 많이 풀기보다는 자료구조의 공부에 조금 더 초점을 맞췄습니다. 이 과정에서는 부경대학교 권오흠 교수님 - 알고리즘 강의가 큰 도움이 됐습니다. 운영체제운영체제의 경우 학부생 때 가장 재밌게 공부했던 과목중 하나이다 보니 어느정도 자신있었습니다. 이화여자대학교 반효경 교수님 - 운영체제 강의를 듣고 운영 체제와 정보기술의 원리 책을 통해서 복습하며 빠르게 개념을 다잡았습니다. 운영체제 과목의 경우 학부생 때 공부했을 때와는 다른 느낌이었습니다. 특히 스레드와 프로세스, 경쟁 상태 부분은 제가 주로 사용하는 Node.js의 특징을 이해하는데 큰 도움이 되었습니다. 단순히 개념공부로 끝나는 것이 아닌 실제 이러한 개념이 어떤 환경에서 어떻게 사용되고 있는지 그리고 그로 인해 어떠한 장단점이 있는지를 연관지어 생각해볼 수 있었습니다. 데이터베이스데이터베이스는 아키텍처 구성(다중화), 트랜잭션과 동시성 제어에 중점을 맞춰 공부했습니다. 당연히 기본적인 개념은 숙지하였고, 제가 했던 프로젝트라던가 어떤 서비스를 구축함에 있어 어떻게 아키텍처를 구성해야 하는지 고민해본것이 면접에 가서 도움이 많이 되었습니다.위와 같은 내용을 공부함에 있어 데이터베이스 첫걸음이라는 책이 큰 도움이 되었습니다. 그 외 전산학저는 Tech Interview For Beginner를 통해서 위의 전공들 뿐만 아니라 그 외 과목들에서 필요한 부분을 공부했습니다. 예비 개발자들의 기술 면접 준비를 위한 자료를 정리해놓은 Repository로서 신입 개발자로 취업을 준비하시는 분이라면 많은 도움을 받으실 수 있을 것입니다. 나만의 강점제가 이번 하반기에 3곳에 최종합격 할 수 있었던 저만의 강점을 생각해 본다면 크게 두가지인것 같습니다.첫 번째로 개인 블로그와, 개인 프로젝트입니다. 저는 면접을 보며 개발에 대한 애착 혹은 자기 자기계발에 관련된 질문에는 항상 블로그와 개인 프로젝트를 통해 어필했습니다. 어떤 행동이나 습관으로 끝나는 것이 아닌 그로인한 결과물을 갖고 어필을 했던것이 큰 도움이 되었습니다.두 번째는 서비스를 직접 개발하고 운영해보았다는 점입니다. 1년 2개월 동안 스타트업에서 동료들과 함께 서비스를 기획하고 개발하고 운영했던 경험이 가장 큰 도움이 되었습니다. 단순히 학교 과제나 동아리 활동에서 결과물을 내는 것이 아니라, 실제 사용자에게 서비스를 하기 위한 개발은 여러가지 면에서 차이가 있다고 느꼈습니다. 그런 면에서 항상 고민하고 선배 개발자 분과 이야기를 자주 나눴습니다. 제가 생각하고 고민한 방법에 대해 말씀드리고 그로 인해 다시 생길 수 있는 문제점을 생각해보고 개선해 나가는… 이런 과정들이 면접에 가서 가장 큰 도움이 되었습니다. 실제 면접에 가도 면접관 분들은 지원자가 했던 프로젝트에 대해 물어보시면서 추가적으로 어떤 문제점을 추가로 주고, 이를 면접자가 자신의 전산지식을 바탕으로 해결해가는 과정을 많이 보시는것 같습니다. 마지막으로 드리고싶은 말씀간혹 제 주변 친구들 혹은 지인들이 물어봅니다. 신입 개발자로 취업하기 위해서는 어떤것을 준비해야 하는지, 내가 지금 프로젝트를 더 해야하는지, 영어 점수를 더 올려야 하는지…저는 먼저, 꼭 기본적인 전산학에 대한 공부부터 하시기를 추천드립니다. 결국에는 내가 프로젝트를 하고 그 프로젝트를 자소서에 적더라도, 면접에 가서는 면접관님들은 프로젝트로부터 기본적인 전산학에 관련된 내용을 요구합니다. 그렇기 때문에 꼭 기본적인 전산학 공부를 탄탄히 하시길 바랍니다. 그 후에는 자신이 했던 프로젝트로부터 관련된 전산학 내용을 꼭 정리해보셨으면 좋겠습니다. (예를 들어, Node.js를 사용했다면 Node.js의 특징인 비동기 방식에 대해 운영체제 관점에서 설명할 수 있어야 합니다.)이 부분만 잘 되었다면 면접에서 어려운 질문을 받더라도, 면접관님과 대화를 하면서 문제에 접근하고 조금씩은 풀어갈 수 있는 능력이 생길거라고 생각합니다. (주)두다지 서버개발자 양성 교육 프로그램두다지의 서버개발자 양성 교육 프로그램은 제가 스타트업에 있을때 많은 도움을 받았던 선배 개발자분께서 기획하고 진행하시는 프로그램입니다. 프로그램을 운영하고 계시는 홍석환 멘토님은 제가 대학생일때 멘토 멘티로 만나 스타트업에서의 생활, 그리고 취업을 준비하면서도 계속해서 많은 도움을 주셨습니다.스스로 다시 한 번 전산학 내용을 정리할 수 있는 시간을 가지며 기본을 탄탄히 하고, 학생때는 단순히 학점만을 위해 공부하며 키워온 제 전산학 지식을 쌓아왔다면 실제 실무에서는 어떻게 사용되는지, 필요로 하는지 다양한 경험을 통해 체감할 수 있게 해주셨습니다.제가 과거에 멘티로서 선배 개발자분께 배웠던 과정은 교육 과정에서 확인해 볼 수 있습니다. 교육 과정의 더 자세한 내용과 과정을 수료한 멘티들의 후기도 이곳에서 확인할 수 있습니다.제가 생각하는 신입개발자에게 필요한 것은 단순히 전산지식을 얼마나 많이 아느냐가 아니라, 내가 앞으로 개발하면서 그동안 공부 했던 전산지식을 바탕으로 얼마나 잘 이해하며 활용할 수 있는지 그 능력이 필요하다고 생각합니다. 두다지 교육 프로그램은 그 능력을 키울 수 있도록 방향을 잡아줄 것입니다. 관심이 있으신분은 주저하지 마시고 꼭 연락을 드려보세요!","link":"/2017/12/14/Etc/prepare-for-employment/"},{"title":"PR(Pull Request) merge","text":"PR(Pull Request) merge보통 upstream의 repository를 fork한 후, origin에서 feature branch를 만들어 작업한 후 작업이 완료되면 upstream branch에 반영하기 위해 pull request를 요청해 merge 합니다. (upstream repository에 push 권한이 있는 사람이 merge를 완료할 수 있습니다.) merge conflict가 없다면 pull request를 GitHub에서 merge 할 수 있습니다. 만약, pull request를 merge 할 때, conflict가 있다거나 merge를 하기전에 테스트를 하고 싶다면 command line을 이용해 local에서 pull request를 check out하고 merge할 수 있습니다. 만약, upstream branch에 merge를 원하지 않는다면 pull request를 merge 하지 않고 종료(close)할 수도 있습니다. pull request를 merge 할 때는 (1)Feature branch의 모든 커밋을 유지하거나 (2)모든 커밋을 단일 커밋으로 squash하거나 (3)각각의 커밋을 rebase해서 pull request를 merge 할 수 있습니다. 3가지 방법에 대해서 알아보겠습니다. Merging a pull request on GitHubGitHub repository에서 사용할 수 있는 merge option은 다음과 같습니다. Create a merge commit Squash and merge Rebase and merge Create a merge commit All commits from this branch will be added to the base branch via a merge commit. default 옵션인 Create a merge commit 은 feature branch의 모든 커밋을 base branch에 merge 커밋으로 추가합니다. 해당 pull request는 —no-ff 옵션을 사용해 merge됩니다. —no-ff fast-forward(ff)가 가능하지만 fast-forward를 하지 않고, merge 커밋을 생성합니다. Squash and merge The 4 commits from this branch will be combined into one commit in the base branch. Squash and merge 옵션을 선택하면, pull request의 커밋들이 하나의 커밋으로 squash(압축)됩니다. 즉, topic branch에서 contributor가 작업한 모든 커밋은 하나의 커밋으로 결합되어 base branch로 merge됩니다. 해당 pull request는 –ff 옵션을 사용해 merge합니다. —ff fast-forward(ff)로 merge가 된다면, 새로운 merge 커밋을 만들지 않습니다. Squash and merge는 repository에서 git history를 조금 더 간소화되게 만들 수 있습니다. (Create a merge commit 옵션 과 비교해보면 새로운 merge 커밋이 없습니다.) Rebase and merge The 4 commits from this branch will be released and added to the base branch. Rebase and merge 옵션을 선택하면, pull request의 커밋들을 하나의 커밋으로 병합하지 않고 개별적으로 base branch에 추가됩니다. 해당 pull request는 –ff 옵션을 사용해 merge합니다. GitHub에서의 Rebase and merge는 git의 rebase와는 조금 다릅니다. GitHub의 Rebase and merge는 항상 committer의 정보를 업데이트하고 새로운 commit SHA를 생성하지만, git의 rebase는 조상 commit 후에 rebase를 할 경우 committer의 정보를 변경하지 않습니다. 만약, conflict로 인해 GitHub에서 자동적으로 Rebase and merge를 할 수 없다면, local에서 직접 command line을 이용해서 rebase를 하고 merge conflict를 해결해야 합니다. 그 후 pull request의 topic branch에 Force-push를 하면됩니다. 참고 About pull request merges Merging a pull request","link":"/2018/03/31/Git/pull-request-merge/"},{"title":"4) 학식 메뉴 크롤링 하기","text":"Index 크롤링이란? Scraping - 데이터 가져오기 Parsing - 데이터 추출하기 크롤링 이후 인천대학교-에밀리에 처음 추가한 기능은 교내 식당의 메뉴를 알려주는 기능이였습니다. 학교 DB에 접근할 수 있는 권한이 없었기 때문에 하루마다 매일 갱신되는 식당의 메뉴를 알기 위해서는 학교 홈페이지에서 데이터를 참조하는 방법밖에 없었습니다. 이를 해결하기 위해 크롤링에 대해 공부하고 구현했던 방법에 대해 포스팅하려 합니다. Node 버전은 6.6.0을 사용합니다. 크롤링이란?우리가 흔히 부르는 크롤링(crawling)이란 스크래핑(scraping)이라고도 합니다. 즉 웹 페이지를 그대로 가져와 데이터를 추출해 내는 행위입니다. 크롤링 하는 소프트웨어를 크롤러(crawler)라고 부릅니다. 웹 크롤러(web crawler)는 조직적, 자동화된 방법으로 월드 와이드 웹(WWW)을 탐색하는 프로그램입니다. 검색 엔진과 같은 여러 사이트에서는 데이터의 최신 상태 유지를 위해 웹 크롤링을 합니다. 웹 크롤러는 대체로 방문한 사이트의 모든 페이지 복사본을 생성하는데 사용되며, 검색 엔진은 이렇게 생성된 페이지를 보다 빠른 검색을 위해 인덱싱합니다. 웹 크롤러는 시드(seeds)라고 불리는 URL 리스트에서부터 시작해서 페이지의 모든 하이퍼링크를 인식하여 URL 리스트를 갱신합니다. 갱신된 리스트를 재귀적으로 다시 방문합니다. 결국 웹 크롤러는 엄청난 분량의 웹문서를 사람이 직접 구별해서 모으는 일은 거의 불가능하기 때문에, 이를 자동으로 수행해 주는 것입니다. 웹은 기본적으로 HTML 형태로 되어 있습니다. 아래와 같이 페이지 소스 보기를 통해 확인할 수 있습니다. 위와 같은 HTML의 형태를 분석해서 원하는 정보만을 뽑아오는 것을 웹 크롤링작업이라고 합니다. 웹 사이트의 데이터를 수집하는데 있어서 2가지 단계만 기억하면 됩니다. 일반적으로는 이 2가지 과정을 합쳐 크롤링이라고 부르지만, 각각의 단계는 명확히 구분됩니다. 1.Scraping : 데이터를 어떻게 가져올 것인가? 2.Parsing : 가져온 데이터를 어떻게 추출할 것인가? Scraping - 데이터 가져오기Javascript에서 웹 페이지 데이터를 가져오기 위해서 request 모듈을 사용합니다. 먼저 request 모듈을 설치합니다.1npm install request --save 123456789const request = require('request');const url = \"http://www.inu.ac.kr/com/cop/mainWork/foodList1.do?siteId=inu&amp;id=inu_050110010000&amp;command=week\";request(url, (error, response, body) =&gt; { if (error) throw error; console.log(body);}); 위의 코드를 실행하면 아래와 같이 제가 얻고자 했던 학식 메뉴의 데이터를 포함한 웹 페이지 데이터를 가져옵니다. 해당 데이터는 크롬에서 보기 - 개발자 정보 - 소스 보기를 통해서도 확인이 가능합니다. Parsing - 데이터 추출하기Scraping을 통해 가져온 데이터에서 원하는 데이터만을 추출(Parsing)하기 위해 cheerio 모듈을 사용합니다. cheerio 모듈을 설치합니다.1npm install cheerio --save cherrio 모듈을 사용하면 웹 클라이언트 자바스크립트 라이브러리인 jQuery 에서 사용하는 것 처럼 style을 통해 element를 선택할 수 있어, 기존의 선택자 방식을 그대로 사용할 수 있습니다. 따라서 cherrio를 사용하기 위해서는 Request 모듈을 통해 가져온 HTML 데이터에서 어떤 element가 우리가 원하는 데이터를 갖고 있는지 파악할 필요가 있습니다. 웹 페이지의 HTML 구조는 크롬의 보기 - 개발자 정보 - 개발자 도구를 통해 확인할 수 있습니다. 학식 메뉴 데이터를 포함하고 있는 table은 다음과 같은 구조를 갖고 있습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class=\"bdlrNone\"&gt;29(월)&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;1코너&lt;/th&gt; &lt;td&gt;햄순두부찌개 / 고추장삼겹살볶음 / 훈제오리철판구이 (2인)&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td class=\"bdlrNone\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;2코너&lt;/th&gt; &lt;td&gt;등심돈까스&amp;해쉬포테이토 / 떡갈비난자완스덮밥&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td class=\"bdlrNone\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;3코너&lt;/th&gt; &lt;td&gt;냉모밀&amp;닭갈비덮밥&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td class=\"bdlrNone\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;4코너&lt;/th&gt; &lt;td&gt;삼겹살스테이크,치즈함박스테이크,고르곤졸라피자,치즈오븐스파게티(토마토),빠네파스타,도리아(불닭,불고기),불고기샐러드,닭가슴살샐러드,훈제연어샐러드,옛날통닭&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td class=\"bdlrNone\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;5코너&lt;/th&gt; &lt;td&gt;신라면,신라면정식,만두라면,쫄면,해물짬뽕라면,폭탄라면,떡라면,치즈라면,크림치즈김밥,참치김밥,즉석떡볶이,짜파게티,냄비우동&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td class=\"bdlrNone\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;thead&gt;...&lt;/thead&gt; &lt;tbody&gt;...&lt;/tbody&gt; &lt;thead&gt;...&lt;/thead&gt; &lt;tbody&gt;...&lt;/tbody&gt; &lt;thead&gt;...&lt;/thead&gt; &lt;tbody&gt;...&lt;/tbody&gt; &lt;thead&gt;...&lt;/thead&gt; &lt;tbody&gt;...&lt;/tbody&gt; &lt;thead&gt;...&lt;/thead&gt; &lt;tbody&gt;...&lt;/tbody&gt; &lt;thead&gt;...&lt;/thead&gt; &lt;tbody&gt;...&lt;/tbody&gt;&lt;/table&gt; 제가 필요한 데이터는 1. 날짜, 2. 코너, 3. 메뉴 인데 이 데이터는 다음과 같은 구조로 존재합니다. table 태그 안에 thead &gt; tr &gt; th 에는 날짜, tbody &gt; tr &gt; th 에는 코너, tbody &gt; tr &gt; td 에는 메뉴가 있습니다. thead와 tbody 태그를 사용해서 데이터를 추출할 수 있지만 테이블이 규칙적으로 만들어져 있기 때문에 table 태그의 tr 태그만 추출한 후 규칙을 이용해서도 쉽게 데이터를 추출 할 수 있습니다. table에서 하루의 식단은 6개의 tr 태그마다 반복 되고 있습니다.1번째 tr 태그는 th 태그 안에 날짜 데이터를 갖고 있고,2번째~6번째 tr 태그는 th 태그 안에는 코너 데이터를, td 태그 안에는 메뉴 데이터를 갖고 있습니다. 이를 이용해 다음과 같이 코드를 작성할 수 있습니다. 12345678910111213141516171819202122232425262728293031const request = require('request');const cheerio = require('cheerio');const url = \"http://www.inu.ac.kr/com/cop/mainWork/foodList1.do?siteId=inu&amp;id=inu_050110010000&amp;command=week\";request(url, (error, response, body) =&gt; { if (error) throw error; let $ = cheerio.load(body); try { let krDay = ''; let corner = ''; let menu = ''; $('table').find('tr').each(function (index, elem) { if (index % 6 === 0) { krDay = $(this).find('th').text().trim(); console.log(`${krDay}`); } else { corner = $(this).find('th').text().trim(); menu = $(this).find('th').next().text().trim(); console.log(`${corner} -&gt; ${menu}`); } }); } catch (error) { console.error(error); }}); 결과는 다음과 같습니다. 크롤링 이후크롤링을 통해 원하는 데이터를 추출했다면 이를 활용해야 합니다. 에밀리에서는 사용자의 요청(학생식당, 카페테리아, 사범대식당, 기숙사식당, 교직원식당)에 따라 해당하는 식당의 메뉴를 제공합니다. 메뉴라는 데이터 특성상 실시간으로 변경되는 데이터가 아니기 때문에 한번 크롤링 하고 나면 사용자의 요청(식당)에 따라 다른 응답해주면 될 뿐 데이터 자체는 요일이 변경되지 않는이상 계속 유효합니다. 따라서 학교 사이트에서 메뉴를 크롤링하는 행위는 학교 메뉴가 갱신되는 일주일 주기마다 한번씩만 하고 크롤링한 데이터를 DB에 저장한다면 사용자의 요청마다 반복적인 크롤링을 하지 않을 수 있습니다. 이를 위한 해결 방법으로는 node-schedule 모듈을 사용해서 정해진 시간마다 실행되도록 하는 방법이 있습니다. 혹은 AWS-Lambda를 사용할 수도 있습니다. 저는 AWS-Lambda 를 사용해서 스케쥴링을 하였는데 이와 관련된 내용은 다음에 포스팅하도록 하겠습니다.","link":"/2017/05/26/Emily/4-crawling/"},{"title":"오픈소스 컷 컨트리뷰트 경험기","text":"얼마 전 개발자 생에 처음으로 오픈소스에 컨트리뷰트를 하는 경험을 하였습니다. 이번 포스팅에서는 오픈소스 첫 컨트리뷰트 관련해 이야기 해보려 합니다. 어떻게 시작하게 되었는가?개발자라면 한 번쯤 오픈소스에 기여하고 컨트리뷰터가 되어보고 싶다는 생각을 가져봅니다. 저 역시 언젠가 한 번쯤… 이라는 생각은 오래 전 부터 갖고 있었지만 막상 실행에 옮기기 까지가 쉽지 않았습니다. 이미 오픈소스에 기여해 본 많은 개발자 분들이 오픈소스 기여에 쉽게 입문 할 수 있도록 여러 가이드들도 많이 만들어 주셨지만 저는 그 마저도 이용을 하지 못하고 있었습니다. 그러던 도중 우연히 Armeria Sprint라는 좋은 기회가 찾아왔습니다. LINE의 오픈소스와 Armeria에 대해 조금 더 알아보고 싶다면 다음 글들이 도움이 될 것 같습니다. 비동기를 사랑하는 오픈소스 개발자, 이희승 오픈소스 Armeria의 기여자를 위한 이벤트를 진행하였습니다 GitHub Contributions 그래프를 푸릇푸릇하게 만들어보아요(feat. Armeria Sprint) Armeria Sprint사내에서 개발하여 오픈소스로 공개한 프로젝트인 Armeria에 기여할 수 있도록 사내 개발자를 대상으로 Armeria Sprint 행사가 있었습니다. 오픈소스 스프린트란?오픈소스 스프린트란 오픈소스에 관심있는 사람들이 모여서 오픈소스에 기여해 보는 것이라고 정의할 수 있습니다. 행사마다 편차가 있겠지만 보통 진행 기간을 하루 정도로 잡고 오전에는 다같이 모여서 각자 할 일(어떤 이슈를 맡아서 할지)을 정하고 오후에는 집중해서 코딩을 합니다.참고 : GitHub Contributions 그래프를 푸릇푸릇하게 만들어보아요(feat. Armeria Sprint) 오픈소스에 기여해 보고 싶어도 여러 이유로 시작하지 못하고 있었던 저는 해당 행사의 인원 모집이 시작되자마자 고민없이 바로 신청해 참가할 수 있었습니다. 행사는 이틀에 나누어서 첫째 날에는 환영 세션이 2시간 동안 진행되었고, 둘째 날에는 스프린트가 4시간 동안 진행되었습니다. 행사 동안에는 간단한 자기 소개, 오픈소스에 기여하기 전에 알야아할 것, 스프린트 기간 동안 해결할 이슈 정하기, 그리고 마지막으로 집중해서 코딩하기와 같은 활동들이 있었습니다. Contribute오픈소스에 처음 기여할 때 어려운 부분 중 하나가 “어떤 이슈를 맡아 해결하여 기여를 할 것인가”인데요. 저는 이번 Armeria Sprint를 통해 현재 해결해야 할 이슈들이 어떤 것들이 있는지, 해당 이슈는 어떤 부분에 대한 내용인지에 대해 직접 듣고 모르는 부분은 직접 물어보며 진행 할 수 있었기 때문에 조금은 더 수월하게 진행할 수 있었습니다. 아마 처음 온라인으로 직접 이슈를 처음 선택하기에는 어려운 부분이 있을 것 같은데요. Armeria에서는 good-first-issue 라는 이름의 Label을 붙여 조금은 해결하기 쉬운 이슈들을 표시해주고 있습니다. 해당 이슈들 중 아는 부분이 있거나 해보고 싶은 이슈가 있다면 본인이 해결해 보겠다는 코멘트를 남긴 후 작업을 진행하면 됩니다.내가 맡은 이슈가 어떤 문제를 해결(개선)하기 위한 것인지, 코드의 어떤 부분을 수정해야 하는지 파악하는 것이 처음에 가장 중요하다고 생각합니다. 이를 토대로 처음 PR을 올리게 되면 maintainer 분들이 꼼꼼한 리뷰와 함께 코멘트를 남겨주시기 때문에 같이 고민해가며 코드를 점차 개선해 나아갈 수 있습니다. 아래는 Armeria Sprint 동안 제가 맡았던 Issue와 PR입니다. Issue: Provide a way to get request body in service method. PR: Enable to convert request body to expected result type regardless of content-type 스프린트 2일차 때, 약 4시간 정도의 시간 동안 코딩을 하고 당일날 첫 PR을 올릴 수 있었습니다. 첫 PR을 올리고 다음날 maintainer 분들의 리뷰 코멘트가 달리기 시작했고, 틈틈히 코멘트 반영과 리뷰를 반복한 결과 약 3주 정도 후 첫 PR이 머지될 수 있었습니다. 위 과정을 반복하며 오픈소스에 기여하는데 있어 필요한 부분들을 다시 한 번 생각해 보게 되었습니다. 몇번의 리뷰와 코멘트 반영 없이 한번에 PR이 머지되기는 쉽지 않습니다. 프로젝트의 maintainer가 아닌 이상 내가 작성한 코드가 모든 경우를 다 커버할 수 있을지는 테스트 코드를 작성하더라도 쉽게 확신할 수 없습니다. 그렇기 때문에 이슈 해결을 위한 코드와 테스트 코드를 작성한 후에는 PR을 만들어 리뷰를 요청드리는게 더 빠르게 머지될 수 있는 방법 같습니다. 저는 Armeria Sprint를 통해 처음 궁금했던 부분들에 대해 오프라인에서 직접 여쭤보고 답을 받을 수 있었지만, 실제 오픈소스에 기여하는 과정에서는 모든 과정이 온라인에서 진행됩니다. 따라서 글로 본인의 의사를 잘 전달할 수 있는 능력이 중요합니다. 나의 생각이 어떠한지, 어떤 부분에 대해서 모르는지 아는지를 글로써 잘 전달해야 maintainer 분들도 참고해 도움이 될 수 있는 코멘트를 남겨주실 수 있습니다. 모든 의사소통은 영어를 이용해서 하지만 Google 번역기가 있으니 너무 걱정하지 않아도 됩니다. 후기Armeria Sprint에서 기념품으로 컵을 받았는데요. 뒤에 이런 문구가 적혀 있었습니다. 오픈소스에 그리고 Armeria에 관심이 있다면 여러분들도 한 번 기여해보세요! 처음으로 오픈소스에 기여해보았다는 것, 그리고 그 오픈소스가 Armeria라는 것이 매우 재밌고 뜻 깊은 경험이었습니다. 저도 이번 첫 컨트리뷰트를 시작으로 가능하면 꾸준히 기여를 해보려고 합니다.","link":"/2019/05/18/Etc/open-source-experience/"},{"title":"모바일 화면을 위해 Viewport 사용하기","text":"Index 모바일 친화적 Viewport 정의 필요한 이유 사용 방법 적용 반응형 웹 디자인 마무리 오늘은 회사에서 새로 출시한 ‘eyePoker’ 앱의 이용 약관 페이지를 만들었습니다. 정말 간단해서 일찍 끝내고, 로컬에서 확인을 해보았는데 문제가 발생했습니다. 분명 데스크탑에서는 잘 보이던 것이 모바일에서는 저런 경고를 내뿜었습니다.아래의 사진은 로컬에서 배포 후 모바일(갤럭시 노트5)을 통해 페이지에 접속한것입니다. 왼쪽사진 하단부분에 페이지를 모바일 친화적으로 바꾸세요.라는 문구를 가진 팝업 보입니다. 즉, 제가 만든 페이지가 모바일 친화적이지 않다는 것입니다. 그럼 모바일 친화적이라는 것은 어떤 것일까? 페이지를 모바일 친화적으로 바꾸라는 팝업을 클릭하면 오른쪽 사진과 같이 모바일에서 좀 더 보기 편하게 페이지가 변경되는것을 볼 수 있습니다. 모바일 친화적구글의 Mobile Friendly Websites 페이지에서 모바일 친화적인 사이트에 대해 설명하고 있습니다.사이트가 모바일 친화적이라는 것은 간단하게 사용자가 모바일로 웹 페이지를 이용할 때 편하게 이용할 수 있음을 뜻합니다. 사이트의 데스크톱 버전을 휴대기기에서 보거나 사용한다면 콘텐츠를 읽기 위해 두 손가락으로 화면을 모으거나 확대할 경우가 생길 수가 있고 이는 사용 환경을 번거롭게 느끼게해 사용자가 사이트를 떠날 확률이 높기 때문에 사이트를 모바일 친화적으로 만드는것은 중요합니다. Viewport 정의모바일 브라우저들은 viewport 로 알려진 가상 window상에 페이지를 렌더링합니다. 즉 화면(Display) 상의 표시 영역을 뜻합니다. 모바일 Safari는 viewport meta태그를 도입해 웹 개발자들이 viewport 크기와 스케일을 조정할 수 있게 했고, 웹 표준은 아니지만 이제 대부분 모바일 브라우저들도 이를 지원합니다. 데스크탑과 모바일의 viewport는 다른점이 있습니다. 데스크탑의 viewport는 브라우저 창(visible area)의 viewport와 같고, 사용자가 브라우저 창의 크기를 조절하면서 viewport의 크기도 조절할 수 있습니다. 웹페이지가 viewport보다 크면, 스크롤을 하여 나머지 영역을 볼 수 있습니다. 반면에 모바일 viewport는 웹브라우저 창보다 크거나 작을 수 있고 상하좌우로 움직이거나, 더블탭, 줌인, 줌아웃을 통해 viewport의 배율을 변경할 수 있습니다.(크기가 아닙니다) 필요한 이유모바일 브라우저에서 viewport가 중요한 이유는 모바일 브라우저가 웹 페이지를 브라우징 하는 특징에 있습니다. 현재 스마트폰 브라우저는 모바일 환경에서도 데스크탑 환경처럼 웹 페이지 전체를 자연스럽게 브라우징 할 수 있도록 풀브라우징을 지원합니다. 이 때문에 데스크탑에 기반하여 설계된 웹페이지를 모바일에서 보면 기본 viewport가 980px 이고, 이로 인해 내용이 작게 보입니다.(width가 980px 이상인 컨텐츠가 있다면 좌우로 스크롤 됨) 간단히 말하면 작은 화면의 모바일 단말기에 웹 페이지 모두를 표시하려하니 전체적인 페이지의 배율이 조정되는것 입니다. 결과적으로 모바일 화면에 맞도록 전체적인 페이지가 축소되어 보이지만 페이지의 컨텐츠는 배율축소가 발생해 가독성이 떨어지게 됩니다. 바로 이때 viewport를 설정하면 다양한 모바일 기기에서도 페이지의 너비나 화면 배율을 설정할 수 있습니다. 사용 방법head 태그 사이에 다음을 코드를 입력합니다. 기본적으로 데스크탑 브라우저에서는 viewport 메타 태그를 사용하지 않아 무시합니다.1&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; 1. viewport의 속성 width : viewport의 가로 크기를 조정한다. 일반적인 숫자값이 들어갈 수도 있고, device-width와 같은 특정한 값을 사용할 수도 있다. device-width는 100% 스케일에서 CSS 픽셀들로 계산된 화면의 폭을 의미한다. height : viewport의 세로 크기를 조정한다. initial-scale : 페이지가 처음 로딩될 때 줌 레벨을 조정한다. 값이 1일때는 CSS 픽셀과 기기 종속적인 픽셀 간의 1:1 관계를 형성한다. minimum-scale : viewport의 최소 배율값, 기본값은 0.25이다. maximum-scale : viewport의 최대 배율값, 기본값은 1.6이다. user-scalable : 사용자의 확대/축소 기능을 설정, 기본값은 yes이다. 2. 정의된 속성 값 device-width : 기기의 가로 넓이 픽셀 값 (웹페이지의 가로(width) 값은 기기가 사용하는 가로 넓이 값(device-width) 만큼 적용하여 사용하라는 의미) device-height : 기기의 세로 높이 픽셀 값 3. 주의사항 contents보다 작은 viewport width/height를 설정하면 무시된다. viewport에서 initial-scale을 설정하지 않고 width/height를 설정하면 전체화면이 표시된다. viewport에서 initial-scale도 width/height도 설정하지 않으면 width=980px/height=1091px이 된다. 표시영역과 contents의 크기가 일치하지 않을때 initial-scale를 설정하면, 의도하지 않은 layout이 발생한다. 적용 위의 사진은 viewport를 적용한 후의 페이지 화면입니다. viewport를 적용하니 페이지를 모바일 친화적으로 바꾸세요.라는 문구를 가진 팝업은 사라졌지만 처음 모바일 친화적으로 바꾸어 보았던 페이지같이 폰트는 변경되지 않았습니다. 아마 브라우저 상에서 브라우저에 내장된 폰트를 사용해서 보여주었던것 같아 폰트까지 변경하니 오른쪽 화면과 같은 결과를 얻었습니다. 반응형 웹 디자인패블릿, 태블릿, 데스크탑, 게임콘솔, 티비, 웨어러블 기기 등등 정말 다양한 화면 크기가 있습니다. 화면 크기는 언제나 변하기 때문에 사이트는 어떤 화면 크기에도 언제나 적응 가능하도록 설계되어야 합니다. 미디어 쿼리(@media)는 장치에 따라 각기 다른 레이아웃을 만들거나, 다른 미디어 종류에 따라 다른 css 코드를 작성하는 등, 반응형 웹 페이지를 작성할 때 사용합니다.부트스트랩은 CSS 미디어 쿼리를 사용해 반응형으로 휴대폰에서부터 태블릿, 데스크탑까지 적용되는 사이트를 만들 수 있도록 도와주는 HTML, CSS, JS 프레임워크입니다. 저도 여러번 간단하게 사용했던 적이 있습니다. 적절한 렌더링과 확대/축소를 위해 부트스트랩 시작 페이지에서는 다음 코드를 &lt;head&gt;에 추가하라고 명시합니다.1&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; 지금까지는 이유를 알지 못하고 추가했던 메타 태그였는데 이제는 그 이유를 알 수 있습니다. width=device-width를 추가함으로써 전체적인 웹 페이지의 width가 설정되고 @media 에서 선언된 width의 범위에 따라 css가 적용되어 결과적으로 반응형 웹을 만들 수 있는것 입니다. 마무리간단하게 사용방법만 알아보려했으나, viewport 메타 태그를 통해서 반응형 웹 디자인이 가능하다는 것을 알고 중요하다 생각해서 좀 더 공부하고 포스팅하였습니다. 한줄의 코드를 통해서 물고 물고 물어 여러가지를 다시 공부하고 더 잘 알게된것 같아 좋습니다. 저처럼 viewport 에 대해 자세히 알지 못하고 사용하셨던 분들께 도움이 되었으면 좋겠습니다. 참고 : MDN-viewport meta 태그를 이용해 모바일 브라우저상에서 레이아웃 조종하는 법, meta viewport(메타 뷰포트 태그) 사용법","link":"/2017/02/09/HTML/viewport/"},{"title":"(Gradle dependency) api와 implementation 차이","text":"build script의 dependencies 블록에 여러 가지 다양한 종속성 구성(api, implementation, compileOnly, runtimeOnly, annotationProcessor)을 사용하여 라이브러리 종속성을 선언할 수 있습니다. 다양한 종속성 구성 중 api와 implementation의 차이에 대해서 알아봅니다. api &amp; implementationGradle document에서는 api와 implementation에 대해서 다음과 같이 설명하고 있습니다. api The dependencies required to compile the production source of the project which are part of the API exposed by the project. For example the project uses Guava and exposes public interfaces with Guava classes in their method signatures. 프로젝트에 의해 노출 된 API의 일부인 프로젝트의 프로덕션 소스를 컴파일하는 데 필요한 종속성 implementation The dependencies required to compile the production source of the project which are not part of the API exposed by the project. For example the project uses Hibernate for its internal persistence layer implementation. 프로젝트에 의해 노출 된 API의 일부가 아닌 프로젝트의 프로덕션 소스를 컴파일하는 데 필요한 종속성 위 설명만 가지고는 이해하기가 쉽지 않습니다. Android Developers document에서는 같은 내용을 다음과 같이 한글로 설명하고 있습니다. api Gradle은 컴파일 클래스 경로 및 빌드 출력에 종속성을 추가합니다. 모듈에 api 종속성을 포함하면 다른 모듈에 그 종속성을 과도적으로 내보내기를 원하며 따라서 런타임과 컴파일 시 모두 종속성을 사용할 수 있다는 사실을 Gradle에 알려줄 수 있습니다. 이 구성은 compile(현재 지원 중단됨)과 똑같이 동작합니다. 다만 이것은 주의해서 사용해야 하며 다른 업스트림 소비자에게 일시적으로 내보내는 종속성만 함께 사용해야 합니다. 그 이유는 api 종속성이 외부 API를 변경하면 Gradle이 컴파일 시 해당 종속성에 액세스할 권한이 있는 모듈을 모두 다시 컴파일하기 때문입니다. 그러므로 api 종속성이 많이 있으면 빌드 시간이 상당히 증가합니다. 종속성의 API를 별도의 모듈에 노출시키고 싶은 것이 아니라면 라이브러리 모듈은 implementation 종속성을 대신 사용해야 합니다. implementation Gradle은 종속성을 컴파일 클래스 경로에 추가하여 종속성을 빌드 출력에 패키징합니다. 다만 모듈이 implementation 종속성을 구성하는 경우, 이것은 Gradle에 개발자가 모듈이 컴파일 시 다른 모듈로 유출되는 것을 원치 않는다는 것을 알려줍니다. 즉, 종속성은 런타임 시 다른 모듈에서만 이용할 수 있습니다. api 또는 compile(지원 중단됨) 대신 이 종속성 구성을 사용하면 빌드 시스템이 재컴파일해야 하는 모듈의 수가 줄어들기 때문에 빌드 시간이 상당히 개선될 수 있습니다. 예를 들어, implementation 종속성이 API를 변경하면 Gradle은 해당 종속성과 그 종속성에 직접 연결된 모듈만 다시 컴파일합니다. 대부분의 앱과 테스트 모듈은 이 구성을 사용해야 합니다. 간단하게 차이점을 정리하면 다음과 같습니다. api: 의존 라이브러리 수정시 해당 모듈을 의존하고 있는 모듈들 또한 재빌드 A(api) &lt;- B &lt;- C 일 때, C 에서 A 를 접근할 수 있음 A 수정시 B 와 C 모두 재빌드 implementaion: 의존 라이브러리 수정시 본 모듈까지만 재빌드 A(implementation) &lt;- B &lt;- C 일 때, C 에서 A 를 접근할 수 없음 A 수정시 B 까지 재빌드 참고 https://stackoverflow.com/a/44419574 https://medium.com/mindorks/implementation-vs-api-in-gradle-3-0-494c817a6fa https://www.youtube.com/watch?v=7ll-rkLCtyk&amp;feature=youtu.be&amp;t=29m35s","link":"/2019/05/09/Gradle/gradle-api-vs-implementation/"},{"title":"MySQL - Replication","text":"Database Replication여러 대의 DB 서버가 있을 때 각각의 DB 서버가 동일한 데이터를 유지하도록 하는 메커니즘 혹은 기법을 말한다. Replication(리플리케이션)을 이용해서 백업과 부하분산같은 목적을 달성할 수 있다.master 서버에 데이터가 기록(쓰기)되고, slave 서버들은 master에 기록된 데이터를 전파받으며 보통 읽기에 사용된다. 정리하면 한대의 master 서버는 쓰기, 여러대의 slave 서버들은 읽기에 사용되는 것이다. 백업과 부하분산master DB의 데이터가 빠른 속도로 slave DB에 복제되기 때문에 master DB에 문제가 생겼을 때, slave DB를 master DB로 대체해 빠르게 장애를 복구할 수 있다. 그렇지만 Replication 자체가 완전한 백업을 의미하는 것은 아니다. master DB에 의도하지 않은 작업(데이터를 잘못해서 대량으로 삭제)을 수행했을 때 해당 작업이 slave DB에도 전파가 되기 때문에 이러한 것들은 복구가 불가능하다.그러므로 실시간 성의 백업은 Replication이 담당하고, 시간차를 두고 백업이 필요한 것은 보통 스케쥴링을 통하여 시간 간격을 두고 백업을 하는것이 바람직하다. 읽기와 관련된 부하분산을 할 수 있다는 것이 Replication의 장점이다. 한계라고 하면 쓰기와 관련된 부분인데, 한 대의 master DB에 쓰기가 집중되기 때문에 쓰기 작업에 부하가 많다면 문제가 생길 수 있다. 간략하게 Replication이 동작하는 방식을 확인해보자. 아래 그림은 master DB와 slave DB가 1대1로 연결되어 있는 구조이다. master DB가 Data의 변경사항을 Binary log에 기록한다. master DB가 Slave DB에게 변경이 있음을 통지한다. slave DB가 I/O thread 이용해 Binary log를 가져온다. slave DB의 Relay log에 변경사항을 기록한다. slave DB의 SQL thread를 이용해 변경사항을 반영한다. 아래 그림은 또 다른 구조의 Replication이다. master DB와 slave DB가 존재하고 slave DB에 다시 slave DB가 존재하는 구조이다.가운데의 slave DB가 master DB 처럼 Binary log를 생성해서 다른 slave에게 전달하는 것이다. 이 경우 가장 마지막에 있는 slave DB가 직접 master DB에 접근하는 것이 아니기 때문에 master DB의 부담을 줄일 수 있다.또한 가운데의 slave DB 역시 master DB 처럼 Binary log를 생성하고 있기 때문에 master DB에 문제가 생겼을 때, 빠르고 쉽게 master DB로 대체가 가능하다. Replication 실습그럼 이제 간단하게 MySQL Replication을 구축해보자. 여러 대의 서버에 MySQL을 설치하고 준비하는 것은 번거롭기 때문에 간편하게 도커를 이용해서 진행해보자. MySQL master 컨테이너 실행하기먼저 master DB 컨테이너를 생성하고 접속한다.1234$ docker run --name mysql-master -e MYSQL_ROOT_PASSWORD=asdf1234 -d mysql$ docker exec -it mysql-master /bin/bash$ apt-get update; apt-get install vim -y 설치한 vim을 이용해 MySQL 설정 파일인 /etc/mysql/my.cnf 파일에 다음의 내용을 추가한다.123[mysqld]log-bin=mysql-bin server-id=1 log-bin: 업데이트되는 모든 query들을 Binary log 파일에 기록한다는 의미이다.기본적으로 Binary log 파일은 MySQL의 data directory인 /var/lib/mysql/ 에 호스트명-bin.000001, 호스트명-bin.000002 형태로 생성된다.이때, log-bin 설정을 변경하면 Binary log 파일의 경로와 파일명의 접두어를 변경할 수 있다. log-bin=mysql 이라 설정하면 mysql-bin.000001, mysql-bin.000002 형태로 Binary log 파일이 생성된다. server-id: Replication 설정에서 서버를 식별하기 위한 고유 ID값이다. master, slave 각각 다르게 설정해야 한다. 도커 컨테이너(MySQL)를 재시작해서 변경된 설정 파일을 반영한다.1$ docker restart mysql-master 변경한 설정이 잘 적용되었는지 확인해보자.1234567891011$ docker exec -it mysql-master /bin/bash$ mysql -u root -p mysql&gt; SHOW MASTER STATUS\\G*************************** 1. row *************************** File: mysql-bin.000001 Position: 155 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set:1 row in set (0.00 sec) master DB에 User 생성하기slave DB에서 접근할 수 있도록 master DB에 User 계정을 생성하고 REPLICATION SLAVE 권한을 부여한다.12345678mysql&gt; CREATE USER 'repl'@'%' IDENTIFIED BY 'replpw';Query OK, 0 rows affected (0.01 sec)mysql&gt; ALTER USER 'repl'@'%' IDENTIFIED WITH mysql_native_password BY 'replpw';Query OK, 0 rows affected (0.01 sec)mysql&gt; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';Query OK, 0 rows affected (0.01 sec) User가 생성되었는지 User 테이블을 확인한다.123456789101112131415161718mysql&gt; USE mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; SELECT user, host FROM user;+------------------+-----------+| user | host |+------------------+-----------+| repl | % || root | % || mysql.infoschema | localhost || mysql.session | localhost || mysql.sys | localhost || root | localhost |+------------------+-----------+6 rows in set (0.00 sec) 다음으로, Replication 테스트를 위한 DB와 테이블을 생성한다.123456789101112131415161718192021222324252627mysql&gt; CREATE DATABASE testdb;Query OK, 1 row affected (0.01 sec)mysql&gt; USE testdb;Database changedmysql&gt; CREATE TABLE testtable ( text varchar(20) );Query OK, 0 rows affected (0.03 sec)mysql&gt; DESC testtable;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| text | varchar(20) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+1 row in set (0.01 sec)mysql&gt; INSERT INTO testtable VALUES ('test row');Query OK, 1 row affected (0.01 sec)mysql&gt; SELECT * from testtable;+----------+| text |+----------+| test row |+----------+1 row in set (0.00 sec) master DB dumpslave DB에서 master DB를 연결하기 전에 master DB의 현재 DB 상태(table과 data)를 slave DB에 그대로 반영하기 위해 dump한다.123$ docker exec -it mysql-master /bin/bash$ mysqldump -u root -p testdb &gt; dump.sql dump된 파일을 slave DB 컨테이너에 옮기기 위해 먼저 로컬 PC로 복사한다.123$ docker cp mysql-master:dump.sql .$ cat dump.sql MySQL slave 컨테이너 실행하기slave DB 컨테이너를 생성하고 접속한다.1234$ docker run --name mysql-slave --link mysql-master -e MYSQL_ROOT_PASSWORD=asdf1234 -d mysql$ docker exec -it mysql-slave /bin/bash$ apt-get update; apt-get install vim -y 설치한 vim을 이용해 MySQL 설정 파일인 /etc/mysql/my.cnf 파일에 다음의 내용을 추가한다.slave 서버를 여러 대로 구축하고자 할 때에 각 slave 서버의 server-id는 각각 달라야 한다는 것에 주의하자. (2^32-1 까지 가능하다.)123[mysqld]log-bin=mysql-bin server-id=2 도커 컨테이너(MySQL)를 재시작해서 변경된 설정 파일을 반영한다.1$ docker restart mysql-slave slave DB에 dump 파일 적용로컬 PC로 복사한 master DB의 dump 파일을 slave DB로 옮긴 후 반영한다.1234567891011$ docker cp dump.sql mysql-slave:.$ docker exec -it mysql-slave /bin/bash$ mysql -u root -pmysql&gt; CREATE DATABASE testdb;Query OK, 1 row affected (0.01 sec)mysql&gt; exitBye$ mysql -u root -p testdb &lt; dump.sql 다시 mysql에 접속해 testdb DB에 testtable 테이블과 데이터가 생성되어 있다면 정상적으로 dump 파일이 적용된 것이다.123456789101112mysql&gt; USE testdb;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; SHOW TABLES;+------------------+| Tables_in_testdb |+------------------+| testtable |+------------------+1 row in set (0.00 sec) slave DB에서 master DB 연동하기이제 마지막으로 slave 서버에서 master 서버와 연동하는 작업만 하면 된다. 그 전에 master DB의 mysql에 한번 더 접속하여 Binary log 파일의 현재 상태를 읽어야 한다. 이 Binary log 파일을 통해 master와 slave의 DB가 동기화되므로 반드시 동일한 로그의 위치를 서로 참조하고 있어야 한다.1234567891011$ docker exec -it mysql-master /bin/bash$ mysql -u root -p mysql&gt; SHOW MASTER STATUS\\G *************************** 1. row *************************** File: mysql-bin.000001 Position: 1949 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set:1 row in set (0.00 sec) 출력된 결과에서 File, Position 필드의 값을 기억하도록 한다.File 은 현재 바이너리 로그 파일명이고, Position 은 현재 로그의 위치를 나타낸다. 앞서 DB와 테이블을 생성한 query가 추가됐으므로 이전에 SHOW MASTER STATUS\\G 를 실행했을 때보다 Position 값이 증가했음을 볼 수 있다. 이제 slave 서버의 mysql에 접속하여 master 서버와의 연결에 필요한 변수들을 적절히 설정해주어야 한다. 1234567$ docker exec -it mysql-slave /bin/bash$ mysql -u root -p mysql&gt; CHANGE MASTER TO MASTER_HOST='mysql-master', MASTER_USER='repl', MASTER_PASSWORD='replpw', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=1949;Query OK, 0 rows affected, 2 warnings (0.03 sec)mysql&gt; START SLAVE;Query OK, 0 rows affected (0.00 sec) MASTER_HOST : master 서버의 호스트명 MASTER_USER : master 서버의 mysql에서 REPLICATION SLAVE 권한을 가진 User 계정의 이름 MASTER_PASSWORD : master 서버의 mysql에서 REPLICATION SLAVE 권한을 가진 User 계정의 비밀번호 MASTER_LOG_FILE : master 서버의 바이너리 로그 파일명 MASTER_LOG_POS : master 서버의 현재 로그의 위치 아래의 명령어를 실행해 slave의 상태를 확인해보자.1mysql&gt; SHOW SLAVE STATUS\\G Replication 테스트문제 없이 Replication 설정이 완료되었다면 마지막으로 실제 잘 동작하는지 확인해보자.master DB에서 데이터를 생성하고, slave DB에 복제되어 데이터가 조회되는지 확인한다. master DB에서 데이터를 생성한다.1234567891011121314151617181920$ docker exec -it mysql-master /bin/bash$ mysql -u root -pmysql&gt; USE testdb;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; INSERT INTO testtable VALUES ('test row2');Query OK, 1 row affected (0.01 sec)mysql&gt; SELECT * FROM testtable;+-----------+| text |+-----------+| test row || test row2 |+-----------+2 rows in set (0.00 sec) slave DB에서 데이터를 조회한다.1234567891011$ docker exec -it mysql-slave /bin/bash$ mysql -u root -pmysql&gt; SELECT * from testtable;+-----------+| text |+-----------+| test row || test row2 |+-----------+2 rows in set (0.00 sec)","link":"/2019/11/13/Database/mysql-replication/"},{"title":"Gradle에서 Dependency Pollution 문제 해결하기","text":"지난번에 (Gradle dependency) api와 implementation 차이에 대해서 알아보았다. 이번에는 api와 implementation을 이용해 Dependency Pollution(의존성 오염) 문제와 해결하는 방법에 대해서 알아보자. Dependency Pollution 이란아래 그림과 같이 프로젝트 X가 있다. 프로젝트 X는 라이브러리 A와 B에 의존하고 있다. 또 다른 프로젝트 C는 프로젝트 X에 의존하고 있다. 이때, C는 X에 대한 의존성 갖게 되면서 A와 B에 대한 의존성 역시 갖게 된다. 이러한 상황을 C가 A와 B에 대해 의존성 전이(Transitive Dependency)를 갖는다고 한다. 이러한 의존성을 컴파일 타임에 사용할 수 있다고 생각해보자. X는 A와 B의 클래스들을 사용할 수 있을 것이고, C는 X뿐만 아니라 A와 B의 클래스 역시 사용할 수 있을 것이다. 이렇게 X의 의존성(A, B)이 C의 컴파일 타임시에 classpath에 노출되는 것을 Dependency Pollution이라고 한다. Dependency Pollution 문제Transitive Dependency로 인한 Dependency Pollution 문제를 갖고 있는 C에 어떤 영향이 있는지 알아보자. C를 개발하고 있는 개발자가 라이브러리 A의 클래스를 사용하기로 결정할 수 있다. 하지만 개발자는 라이브러리 A에 대한 의존성이 X를 통해 추가되었음을 인지하지 못하고 사용할 수 있다. X 개발자는 더 이상 라이브러리 A가 필요하지 않다고 결정하고 의존성에서 제거할 수 있다. 이 변경사항에 대해 X 개발자는 프로젝트 X가 제공하는 API에 대해서는 변경하지 않았기 때문에 minor한 업데이트로 간주할 것이다. 이후에 C 개발자가 X에 대한 버전을 업데이트(A가 제거된 버전)하는 경우에 C에서는 더 이상 라이브러리 A의 클래스를 사용할 수 없기 때문에 컴파일 에러가 발생한다. 결국, X의 컴파일 타임 의존성을 C의 컴파일 타임까지 전파하는 경우에 C 개발자는 원하지 않는 컴파일 타임 의존성을 갖게 될 수 있다. Gradle의 해결 방법Gradle을 사용하는 경우 종속성을 제어해 Dependency Pollution 문제를 줄일 수 있다. 방법은 간단한다. api대신 implementation을 사용하는 것이다. X에서 A에 대한 종속성을 implementation을 이용해 선언하면 C는 더 이상 A에 대한 Transitive 컴파일 타임 종속성을 갖지 않게 된다. 따라서 C에서 실수로 A의 클래스를 사용할 수 없게 되는 것이다. 만약 C가 A의 클래스를 사용해야하는 경우에는 A에 대한 종속성을 명시적으로 선언해야한다. 반대로 특정 종속성을 컴파일 타임 종속성에 노출하고자하는 경우에는 implementation가 아닌 api를 사용하면 된다.","link":"/2019/12/07/Gradle/gradle-implementation/"},{"title":"ES6 Class 파헤치기","text":"Index ES6 Class 문법 Class 정의 constructor Prototype 기반 상속(ES5)과 Class 기반 상속(ES6) 비교 super 키워드 static 키워드 마치며 ES6 Class 문법JavaScript Class는 ECMAScript 6을 통해 소개되었습니다. ES6의 Class는 기존 prototype 기반의 상속을 보다 명료하게 사용할 수 있도록 문법을 제공합니다. 이를 Syntatic Sugar라고 부르기도 합니다. Syntatic Sugar : 읽고 표현하는것을 더 쉽게 하기 위해서 고안된 프로그래밍 언어 문법을 말합니다. JavaScript를 ES6를 통해 처음 접하시는 분들은 알아두셔야할 것이 JavaScript의 Class는 다른 객체지향 언어(C++, C#, Java, Python, Ruby 등…)에서 사용되는 Class 문법과는 다르다는 것입니다. JavaScript에는 Class라는 개념이 없습니다.Class가 없기 때문에 기본적으로 Class 기반의 상속도 불가능합니다. 대신 다른 언어에는 존재하지 않는 프로토타입(Prototype)이라는 것이 존재합니다. JavaScript는 이 prototype을 기반으로 상속을 흉내내도록 구현해 사용합니다. Prototype을 처음 접하시는 분은 “Prototype 이제는 이해하자”를 참고하시면 도움이 될것같습니다. Class 정의JavaScript에서 Class는 사실 함수입니다. 함수를 함수 선언과 함수 표현식으로 정의할 수 있듯이 class 문법도 class 선언과 class 표현식 두가지 방법으로 정의가 가능합니다. JavaScript 엔진은 function 키워드를 만나면 Function 오브젝트를 생성하듯, class 키워드를 만나면 Class 오브젝트를 생성합니다. class는 클래스를 선언하는 키워드이고 Class 오브젝트는 엔진이 class 키워드로 생성한 오브젝트입니다. Class 선언함수 선언과 달리 클래스 선언은 호이스팅이 일어나지 않기 때문에, 클래스를 사용하기 위해서는 먼저 선언을 해야합니다. 그렇지 않으면 ReferenceError 가 발생합니다. 123456789class People { constructor(name) { this.name = name; } say() { console.log('My name is ' + this.name); }} Class 표현식Class 표현식은 이름을 가질 수도 있고 갖지 않을 수도 있습니다. 12345678910111213141516171819const People = class People { constructor(name) { this.name = name; } say() { console.log('My name is ' + this.name); }}const People = class { constructor(name) { this.name = name; } say() { console.log('My name is ' + this.name); }} constructorconstructor는 클래스 인스턴스를 생성하고 생성한 인스턴스를 초기화하는 역할을 합니다. new People() 코드를 실행하면 People.prototype.constructor가 호출됩니다. 이를 default constructor라고 하며 constructor가 없으면 인스턴스를 생성할 수 없습니다. 1const people = new People('KimJongMin'); new People(‘KimJongMin’)을 실행하면 People 클래스에 작성한 constructor가 자동으로 호출되고 파라미터 값으로 ‘KimJongMin’을 넘겨 줍니다. new 연산자가 인스턴스를 생성하는 것처럼 보이지만, 사실 new 연산자는 constructor를 호출하면서 파라미터를 넘겨주는 역할만 합니다. 호출된 constructor가 인스턴스를 생성하여 반환하면 new 연산자가 받아 new를 실행한 곳으로 반환합니다. 과정은 다음과 같습니다. new People(‘KimJongMin’)을 실행 new 연산자가 constructor를 호출하면서 파라미터 전달 constructor에 작성한 코드를 실행하기 전에 빈 Object 를 생성 constructor 코드를 실행 생성한 Object(인스턴스)에 property 할당 (인스턴스를 먼저 생성했기 때문에 this로 Object 참조 가능 생성한 Object 반환 다음은 생성된 인스턴스의 구조입니다. 1console.dir(people); people 인스턴스의 __proto__는 People Class 오브젝트와 함께 생성된 Prototype object를 가리키고 있습니다. 결국 Class 문법을 이용한 코드를 prototype 기반의 코드로 변경하면 다음과 같습니다. 1234567function People(name) { this.name = name;}People.prototype.say = function () { console.log('My name is ' + this.name);}; Prototype 기반 상속(ES5)과 Class 기반 상속(ES6) 비교먼저 ES5에서 Prototype을 사용하여 상속을 구현하는 방법을 살펴보고, 그 후 ES6에서 Class로 상속을 구현하는 형태를 보겠습니다. ES5 Prototype 기반 상속1234567891011121314151617181920212223242526272829function Cat(name) { this.name = name;}Cat.prototype.speak = function () { console.log(this.name + ' makes a noise.');};function Lion(name) { // `super()` 호출 Cat.call(this, name);}// `Cat` 클래스 상속Lion.prototype = Object.create(Cat.prototype);Lion.prototype.constructor = Lion;// `speak()` 메서드 오버라이드Lion.prototype.speak = function () { Cat.prototype.speak.call(this); console.log(this.name + ' roars.');};var lion = new Lion('Samba');lion.speak();[결과]Sambda makes a noise.Sambda roars. new Lion()을 실행하면 Lion()이 호출되고, default constructor를 호출합니다. 그래서 Lion()을 생성자(constructor) 함수라고 합니다. 생성자 함수가 있으면 Cat.prototype.speak와 같이 prototype에 메서드를 연결한 코드가 있습니다. 이와 같이 prototype에 작성하지 않으면 각각의 인스턴스에 메서드가 생성되게 됩니다. 이 형태가 ES5에서 인스턴스를 구현하는 기본 형태 입니다. Object.create()를 통해 Cat.prototype에 연결된 메서드를 Lion.prototype.__proto__에 첨부합니다. Lion.prototype에는 constructor가 연결되어 있는데 prototype을 재 할당했기 때문에 지워진 constructor를 다시 할당해 줍니다. 결과적으로 Lion 생성자 함수의 구조는 다음과 같습니다. ES6 Class 기반 상속1234567891011121314151617181920212223class Cat { constructor(name) { this.name = name; } speak() { console.log(this.name + ' makes a noise.'); }}class Lion extends Cat { speak() { super.speak(); console.log(this.name + ' roars.'); }}const lion = new Lion('Samba');lion.speak();[결과]Sambda makes a noise.Sambda roars. ES6에서는 extends 키워드로 상속을 구현합니다. Cat 클래스를 상속받은 Lion 클래스의 구조는 다음과 같습니다. 위의 prototype을 통해 상속을 구현한 Lion 생성자 함수의 구조와 비교했을때 일치합니다. 추가적으로 new Lion(‘Samba’) 를 실행하면 다음의 과정을 거치게됩니다. Lion 클래스의 constructor를 호출 Lion 클래스에 constructor를 작성하지 않았기 때문에 슈퍼 클래스의(Cat) constructor가 호출됨 (내부적으로 프로토타입 체인으로 인해) 슈퍼 클래스의 constructor에서 this는 현재의 인스턴스를 참조하므로 인스턴스의 name 프로퍼티에 파라미터로 전달받은 값을 설정 생성한 인스턴스를 lion에 할당 super 키워드서브 클래스와 슈퍼 클래스에 같은 이름의 메서드가 존재하면 슈퍼 클래스의 메서드는 호출되지 않습니다. 이때 super 키워드를 사용해서 슈퍼 클래스의 메서드를 호출할 수 있습니다. (서브 클래스의 constructor에 super()를 작성하면 슈퍼 클래스의 constructor가 호출됩니다.) static 키워드static 키워드는 클래스를 위한 정적(static) 메소드를 정의합니다. 정적 메소드는 prototype에 연결되지 않고 클래스에 직접 연결되기 때문에 클래스의 인스턴스화(instantiating) 없이 호출되며, 클래스의 인스턴스에서는 호출할 수 없습니다. 동일한 클래스 내의 다른 정적 메서드 내에서 정적 메서드를 호출하는 경우 키워드 this를 사용할 수 있다. 12345678910class Lion { static speak() { console.log('Noise~'); }}Lion.speak();[결과]Noise~ 정적 메소드는 어플리케이션(application)을 위한 유틸리티(utility) 함수를 생성하는데 주로 사용됩니다. 마치며ES6의 Class 문법에 대해 정리해 보았다. JavaScript 언어를 약 1년전 Node.js 를 시작하며 처음 접하게 되었는데 사실 그 당시 Prototype과 상속에 대해 크게 다룰일이 없었다. (어쩌면 너무 무지해서 사용 필요성을 느끼지 못했을 수도…) 그 후 Node.js 버전을 올리고 ES6를 공부하며 Class 문법을 접하게 되었는데 JavaScript의 Prototype에 대한 이해와 지식이 부족하다 보니 이전에 공부했던 C++과 Java의 Class 처럼 이해했던 것 같다. 그래도 그 후 Prototype과 더불이 Class까지 공부하며 지금은 어느정도 이해하게 된것 같다. 결론은… 역시나 JavaScript에서 Prototype을 이해하는건 중요한것 같다. 참고ES6 Class는 단지 prototype 상속의 문법설탕일 뿐인가?MDN - ClassesMDN - 상속과 프로토타입","link":"/2017/06/18/JavaScript/class/"},{"title":"[번역] Client-side rendering VS. Server-sde rendering","text":"Index 성능(Performance) 검색 엔진 최적화(SEO) 사전 렌더링(Prerendering) 더 똑똑해진 크롤러 덜 똑똑한 크롤러 두 세계의 장점 토론 해당 포스팅은 Adam Zerner - Client-side rendering vs. server-side rendering의 글을 번역하였습니다. 초기에, 웹 프레임워크들은 서버(Server)에서 렌더링된 뷰를 갖고있었습니다. 현재는 클라이언트(Client)에서도 렌더링된 뷰를 가집니다. 지금부터 각각의 장점과 단점에 대해 알아보겠습니다. 성능(Performance)서버 측(Server-side)에서 렌더링을 할 경우, 새로운 웹 페이지를 보고 싶을 때마다 다음과 같이 새로운 페이지 요청이 필요합니다. 이것은 먹고 싶은 것이 있을 때마다 슈퍼마켓에 가는것과 비슷합니다. 그러나 클라이언트 측(Client-side) 렌더링을 사용할 경우, 슈퍼마켓에 한 번 방문하고 좀 더 시간을 들여 꽤 오랜 기간동안 먹을 음식을 구매합니다. 그런 다음, 먹고 싶은 것이 있을 때마다 슈퍼마켓에 가지 않고 냉장고에서 찾게됩니다. 각 접근법에서는 성능면에서 장점과 단점이 있습니다. 클라이언트 측 렌더링을 사용하면 초기 페이지로드가 느려집니다. 네트워크를 통한 통신이 느리므로 사용자에게 콘텐츠를 표시하기 전에 서버를 두 번 왕복해야합니다. 그러나 그 후에는 이후의 모든 페이지로드가 엄청나게 빠릅니다. 서버 쪽 렌더링을 사용하면 초기 페이지로드가 크게 느려지지 않습니다. 그렇다고 크게 빠르지는 않을 것입니다. 그리고 이후의 다른 요청도 마찬가지입니다. 보다 구체적으로 말하자면, 클라이언트 측 렌더링을 사용하면 초기 페이지는 다음과 같이 보입니다.123456789&lt;html&gt; &lt;head&gt; &lt;script src=\"client-side-framework.js\"&gt;&lt;/script&gt; &lt;script src=\"app.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=\"container\"&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; app.js는 JavaScript의 모든 HTML 페이지를 다음과 같이 문자열로 유지합니다.12345var pages = { '/': '&lt;html&gt; ... &lt;/html&gt;', '/foo': '&lt;html&gt; ... &lt;/html&gt;', '/bar': '&lt;html&gt; ... &lt;/html&gt;',}; 그런 다음 페이지가 로드되면 프레임워크는 URL 표시줄을 보고 [ ‘/‘] 페이지에서 문자열을 가져 와서 div class = &quot;container&quot;&gt; &lt;/ div&gt;에 삽입합니다. 또한 링크를 클릭하면 프레임워크가 이벤트를 가로 채고 컨테이너에 새 문자열 (예 : 페이지 [ ‘/ foo’])을 삽입하고 브라우저가 정상적으로하는 것처럼 HTTP 요청을 실행하지 못하게 합니다. 검색 엔진 최적화(SEO) 웹 크롤러가 reddit.com 을 요청하기 시작했다고 가정해봅시다. 12345678910var request = require('request');request.get('reddit.com', function (error, response, body) { // body looks something like this: // &lt;html&gt; // &lt;head&gt; ... &lt;/head&gt; // &lt;body&gt; // &lt;a href=\"espn.com\"&gt;ESPN&lt;/a&gt; // &lt;a href=\"news.ycombinator.com\"&gt;Hacker News&lt;/a&gt; // ... other &lt;a&gt; tags ...}); 그러면 크롤러는 응답 본문에있는 &lt;a href&gt; 항목을 사용해서 새 요청을 생성합니다. 12345678910111213var request = require('request');request.get('reddit.com', function (error, response, body) { // body looks something like this: // &lt;html&gt; // &lt;head&gt; ... &lt;/head&gt; // &lt;body&gt; // &lt;a href=\"espn.com\"&gt;ESPN&lt;/a&gt; // &lt;a href=\"news.ycombinator.com\"&gt;Hacker News&lt;/a&gt; // ... other &lt;a&gt; tags ... request.get('espn.com', function () { ... }); request.get('news.ycombinator.com', function () { ... });}); 그 후 크롤러는 espn.com 및 news.ycombinator.com의 링크를 사용하여 크롤링을 계속함으로써 프로세스를 계속 진행합니다. 결국 다음과 같은 재귀 코드처럼 동작합니다. 12345678910var request = require('request');function crawlUrl(url) { request.get(url, function (error, response, body) { var linkUrls = getLinkUrls(body); linkUrls.forEach(function (linkUrl) { crawlUrl(linkUrl); }); });}crawlUrl('reddit.com'); 그렇다면 만약 요청에 의한 응답이 다음과 같은경우는 어떻게 될까요? 123456789&lt;html&gt; &lt;head&gt; &lt;script src=\"client-side-framework.js\"&gt;&lt;/script&gt; &lt;script src=\"app.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=\"container\"&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 위의 코드는 &lt;a href&gt; 태그가 없습니다. 또한 웹 페이지의 내용이 없기 때문에 검색 결과를 표시 할 때 우선순위를 지정하지 않을 것입니다. 크롤러는 거의 알지 못하지만, 클라이언트 측 프레임워크는 멋진 콘텐츠로 &lt;div class = &quot;container&quot;&gt; &lt;/div&gt;&quot;를 채우려합니다. 이러한 이유가 클라이언트 측 렌더링이 SEO에 좋지 않은 이유입니다. 사전 렌더링(Prerendering)2009년에 Google은 이 문제를 해결할 수 있는 방법을 소개했습니다. 크롤러가 www.example.com/page?query#!mystate 를 방문하면 www.example.com/page?query&amp;_escaped_fragment_=mystate 로 변환됩니다. 이렇게하면 서버가 _escaped_fragment_를 사용하여 요청을 받으면 사람이 아닌 크롤러에서 요청을 받는다는 것을 알 수 있습니다. 그렇기때문에 요청이 크롤러에서 온 경우 &lt;div class = &quot;container&quot;&gt; ... &lt;/ div&gt;를 제공할 수 있습니다.일반적인 요청 인 경우 &lt;div class = &quot;container&quot;&gt; &lt;/ div&gt;를 제공하고 JavaScript가 내용을 내부에 삽입하도록 할 수 있습니다. 그러나 문제가 있습니다. 서버가 &lt;div class = &quot;container&quot;&gt; &lt;/ div&gt;안에 무엇이 들어가는지 알지 못하기 때문입니다. 내부에 무엇이 들어가는지 파악하려면 JavaScript를 실행하고 DOM을 만들고 DOM을 조작해야합니다. 전통적인 웹 서버는 이를 수행하는 방법을 모르기 때문에 Headless Browser로 알려진 서비스를 사용합니다. 더 똑똑해진 크롤러6년 후, Google은 크롤러가 한층 더 똑똑해 졌다고 발표했습니다. Crawler 2.0에서 &lt;script&gt; 태그를 볼 때 웹 브라우저처럼 실제로 요청을하고 코드를 실행하고 DOM을 조작한다는 것입니다. 그래서 다음과 같은 코드가1&lt;div class=\"container\"&gt;&lt;/div&gt; 이제는 이렇게 보이는 것입니다.1234567&lt;div class=\"container\"&gt; ... ... ... ... ...&lt;/div&gt; Fetch as Google를 사용하여 Google 크롤러가 특정 URL을 방문했을 때 어떤 내용을 볼지 결정할 수 있습니다. 관련된 발표문의 내용 일부를 첨부합니다. 당시 우리 시스템은 자바 스크립트를 사용하여 사용자에게 콘텐츠를 제공하는 페이지를 렌더링하고 이해할 수 없었습니다. 크롤러는 동적으로 생성 된 콘텐츠를 볼 수 없었기 때문에 웹 마스터가 AJAX 기반 애플리케이션을 검색 엔진으로 인덱싱 할 수 있도록 일련의 방법을 제안했습니다.시대가 바뀌 었습니다. 현재 Googlebot이 자바 스크립트 또는 CSS 파일을 크롤링하는 것을 차단하지 않는 한 일반적으로 최신 브라우저와 같이 웹 페이지를 렌더링하고 이해할 수 있습니다. 덜 똑똑한 크롤러불행히도 Google 만이 유일한 검색 엔진이 아닙니다. Bing, Yahho, Duck Duck Go, Baidu 등도 있으며 실제로 사람들은 이러한 검색 엔진도 빈번하게 사용합니다. 다른 검색 엔진은 JavaScript를 잘 처리하지 못합니다. 다음 글을 참고해보세요. SEO vs. React: Web Crawlers are Smarter Than You Think 두 세계의 장점두 세계(서버 측 렌더링, 클라이언트 측 렌더링)의 장점을 최대한 활용하려면 다음의 방법이 있습니다. 첫 번째 페이지 로드에는 서버 측 렌더링을 사용. 그 후 모든 후속 페이지 로드에는 클라이언트 측 렌더링을 사용. 이것이 의미하는 바를 생각해보세요. 첫 번째 페이지 로드의 경우 사용자가 콘텐츠를 보기 전에 두 번 왕복하지 않습니다. 후속 페이지 로드가 빨라집니다. 크롤러는 간단한 HTML을 얻습니다. 옛날처럼 JavaScript를 실행하거나 _escapedfragment를 처리할 필요가 없습니다. 그러나 이를 위한 설정을 하기위해서는 서버에서 약간의 작업이 필요합니다. Angular, React 및 Ember 모두 이 접근 방식으로 변경했습니다. 토론먼저 고려해야 할 몇 가지 사항은 다음과 같습니다. 약 2%의 사용자가 JavaScript를 사용할 수 없게 설정되어 있는 경우 클라이언트 측 렌더링이 전혀 작동하지 않습니다. 웹 검색의 약 1/4은 Google 이외의 엔진으로 수행됩니다. 모두가 빠른 인터넷 연결을 사용하는 것은 아닙니다. 휴대 전화 사용자는 대개 빠른 인터넷 연결이 필요하지 않습니다. 너무 빠른 UI는 혼란 스러울 수 있습니다. 사용자가 링크를 클릭한다고 가정 해보세요. 앱에서 새로운 뷰로 이동합니다. 그러나 새로운 뷰는 이전의 뷰와 미묘하게 다릅니다. 그리고 변경 사항은 즉시 발생했습니다 (클라이언트 측 렌더링의 장점). 새로운 뷰가 실제로 로드 된 것을 사용자가 알지 못할 수도 있습니다. 또는 사용자가 주의를 기울 였지만 상대적으로 미묘하기 때문에 사용자는 전환이 실제로 발생했는지 여부를 감지하기 위해 약간의 노력을 기울여야합니다. 때로는 약간의 로딩 스피너와 전체 페이지 재 렌더링을 하는 것이 좋습니다. 캐싱이 중요합니다. 따라서 서버 측 렌더링을 사용하면 실제로 사용자가 실제로 모든 것을 서버로 가져갈 필요가 없습니다. 때로는 바다 건너편의 “공식”서버가 아닌 근처의 서버에 가면됩니다. 실제로 성과와 관련하여 때로는 중요하지 않습니다. 때로는 속도가 좋고 속도가 약간 올라가더라도 삶이 더 좋아지지는 않습니다. 대부분의 사용자는 인터넷 연결 상태가 좋으며 충분히 빠릅니다. 특히 Macbook Pro로 yuppies를 타겟팅하는 경우. 초기로드 시간이 너무 길어서 사용자를 잃을 염려가 없습니다. 사용자가 링크를 클릭 할 때 실제로 새 페이지가 로드된다는 사실을 사용자가 알지 못하는 사용성 문제에 대해 걱정할 필요가 없습니다. 그러나 초기 페이지 로드시 서버 측 렌더링을 사용하는 클라이언트 측 렌더링을위한 사용 사례는 확실합니다. 큰 회사의 경우 #perfMatters, 인터넷 연결 속도가 느린 사용자가 있고 최적화에 충분한 시간을 할애 할 수있는 충분한 엔지니어링 팀이있는 경우가 종종 있습니다. 앞으로 이 같은 형태의 웹 프레임 워크 (초기 페이지 로드시 서버 쪽 렌더링을 사용하고 후에는 클라이언트 측 렌더링을 수행)가 보다 안정되고 사용하기 쉬워지기를 기대합니다. 이 시점에서 추가 된 복잡성은 최소화 될 것입니다. 그러나 오늘날,이 모든 것은 매우 새롭고, 많은 추상화가있을 것으로 기대합니다. 앞으로 더 나아가 클라이언트 측 렌더링이 필요하지 않은 곳에 인터넷 연결이 충분해지기 때문에 추세가 다시 서버 측 렌더링으로 되돌아 갈 것으로 예상됩니다.","link":"/2017/06/06/JavaScript/client-side-rendering-vs-server-side-rendering/"},{"title":"자바스크립트 완벽가이드 1장 (자바스크립트 소개)","text":"자바스크립트는 고수준이고 동적이며 타입을 명시할 필요가 없는 인터프리터 언어로, 객체지향 프로그래밍 스타일과 함수형 프로그래밍 스타일을 모두 잘 표현하는 언어이다. 인터프리터는 프로그래밍 언어의 소스 코드를 바로 실행하는 컴퓨터 프로그램 또는 환경을 말한다. 원시 코드를 기계어로 번역하는 컴파일러와 대비된다. 인터프리터는 다음의 과정 가운데 적어도 한 가지 기능을 가진 프로그램이다. 구글의 V8엔진 이라는것은 결국 인터프리터인것이다.출처 : 위키백과 - 인터프리터 자바스크립트는 웹 초창기에 현재 오라클이라고 불리는 썬마이크로시스템즈에서 상표권 라이센스를 갖고 있고, 언어 자체 구현은 현재 모질라라고 불리는 넷스케이프에서 담당했다. 넷스케이프는 이 언어를 표준화 하기 위해서 ECMA(European Computer Manufacturer’s Association)에 제출했는데, 상표권 문제로 언어의 이름을 ECMAScript라고 정했다. 깉은 이유로, 마이크로소프트가 제작한 언어의 이름은 JScript가 되었지만 사람들은 이들 모두를 자바스크립트라고 부른다.지난 십 년 동안 모든 웹브라우저에 탑재된 자바스크립트는 ECMAScript 3 구현체였다. 최근에는 ECMAScript 5 그리고 ECMAScript 6까지 정의되었다.자바스크립트 언어 자체만 볼 때, 실질적인 버전은 ECMAScript 3과 5, 6뿐이다. (ECMAScript 4는 기존의 자바스크립트와 다른점이 많아 세상에 나오지 못했다.) 모든 언어는 기초적인 입출력을 처리하는 데 필요한 함수 API나 기반이 되는 플랫폼 또는 표준 라이브러리를 포함하고 있지만 자바스크립트 언어의 코어는 최소한의 API만 정의하고 입출력과 관련된 기능은 포함하고 있지 않다. 입출력을 비롯해 통신과 파일 저장, 그래픽 처리와 같은 복잡한 기능들은 자바스크립트를 내장하고 있는 ‘호스트 환경’에서 담당한다. 브라우저가 자바스크립트 엔진을 내장하고 있기 때문에 클라이언트 측 자바스크립트의 호스트 환경은 웹브라우저다. 1.1 자바스크립트 코어– 표현식 (expression) : 값으로 평가될 수 있는 구절, 프로그램의 상태를 바꾸지는 않는다.12345var book = {topic: &quot;Javascript&quot;,fat: true};book.topic // =&gt; &quot;Javascript&quot; – 설명문 (statement) : 프로그램의 상태를 변경할 수 있다.123var count = 0;count++;count--; 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/26/JavaScript/complete-guide-to-javascript-chapter-1/"},{"title":"자바스크립트 완벽가이드 2장 (어휘 구조)","text":"프로그래밍 언어의 어휘 구조는 프로그램을 어떻게 작성해야 하는지를 알려주는 기본 규칙이다. 어휘 구조는 가장 저수준 문법이다. 2.1 문자 집합자바스크립트 프로그램은 Unicode 문자 집합을 사용해 작성된다. 2.1.1 대소문자 구분자바스크립트는 대소문자를 구분하는 언어이다. 그러나 HTML은 대소문자를 구별하지 않는다. 2.1.2 공백, 줄바꿈 제어 문자자바스크립트는 프로그램 코드 내의 토큰들 사이에 있는 공백들을 무시한다. 대부분의 경우, 줄바꿈 문자도 무시한다. 2.1.3 유니코드 이스케이프 시퀀스일부 컴퓨터 하드웨어와 소프트웨어에서는 특정 유니코드 글자들을 입력받고서 화면에 출력할 수 없는데 이와 같은 경우 프로그래머가 유니코드를 사용할 수 있도록 일련의 6자리 ASCII 문자열 시퀀스를 정의하고 있다. 유니코드 이스케이프 시퀀스는 \\u로 시작하고, 그 뒤에 16진수 숫자 4개가 온다. (유니코드 이스케이프는 자바스크립트 문자열 리터럴이나 정규 표현식 리터럴에서 사용가능)1&quot;café&quot; === &quot;caf\\u00e9&quot; // true 2.3 리터럴리터럴(literal)은 프로그램에 직접 나타나는 데이터 값이다. 숫자, 문자열, 불리언, null 모두 리터럴이다. 2.5 선택적인 세미콜론 사용자바스크립트가 항상 모든 줄바꿈을 세미콜론으로 해석하는 것은 아니다. 일반적으로 세미콜론 없이 코드를 해석할 수 없는 경우에만 줄바꿈을 세미콜론으로 해석한다. 일반적으로, 문장이 (, [, /, +, - 로 시작하면 자바스크립트 인터프리터는 해당 문장을 이전 문장에 이어서 해석한다.다음 줄을 첫 줄의 문장과 이어서 하나로 처리할 수 없는 경우에만 줄바꿈을 세미콜론으로 해석한다는 일반 규칙에는 두 가지 예외가 있다. return, break, continue 문 바로 다음에 사용했을 경우다. 따라서 return, break, continue와 다음에 오는 키워드 사이에 줄바꿈을 하지 말아야 한다. ++나 – 연산자가 포함된 경우다.1234x++y// 위코드는 x++; y가 아니라 x; ++y로 해석된다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/26/JavaScript/complete-guide-to-javascript-chapter-2/"},{"title":"자바스크립트 완벽가이드 10장 (정규 표현식을 사용한 패턴 매칭)","text":"정규 표현식(regular expression)은 문자의 패턴을 나타내는 객체다. 자바스크립트의 RegExp 클래스는 정규 표현식을 표현하고, String과 RegExp에는 정규표현식을 사용하여 강력한 패턴 매칭을 수행하는 메서드와 텍스트상에서 특정 텍스트를 찾아서 바꾸는 함수가 정의되어 있다. 10.1 정규 표현식 정의자바스크립트에서 정규 표현식은 RegExp 객체로 표현된다. RegExp 객체는 RegExp() 생성자를 사용하여 만들 수 있지만, RegExp() 생성자보다는 정규 표현식 리터럴 문법이 더 자주 사용된다. 정규 표현식 리터럴은 항 쌍의 슬래시(/) 문자 사이에 위치한 문자들이다.12var pattern1 = /s$/;var pattern2 = new RegExp(\"s$\"); 정규 표현식은 연속된 문자로 구성되어 있다. 영문자를 포함한 문자 대부분은 패턴에 적혀 있는 문자 그대로 매치된다. 몇몇 문자는 문자 그대로 매치되지 않으며, 특별한 의미를 지닌다. 정규 표현식 /s$/는 두 문자로 구성되었는데, 먼저 “s”는 문자 그대로 s와 매치되고, “$”는 특수 메타 문자로 문자열의 끝과 매치된다. 따라서 이 정규 표현식은 “s”로 끝나는 모든 문자열과 매치된다. 10.1.1 리터럴 문자모든 영문자와 숫자는 그 문자 그대로 정규 표현식에서 매치된다 특정한 비-알파벳 문자들은 역슬래시로 시작하는 이스케이프 문자열을 통해 지원한다. (역슬래시 문자를 있는 그대로 넣으려면 역슬래시 자체를 이스케이프 해야한다. ( /\\\\/ )몇가지 구두점 문자는 정규 표현식에서 특별한 의미를 지닌다. (^$.*+?=!:|\\/()[]{}) 10.1.2 문자 클래스개별 리터럴 문자들은 그 문자들을 대괄호로 묶어서 문자 클래스로 다룰 수 있다. 문자 클래스는 해당 클래스 내의 모든 문자에 매치된다. /[abc]/는 a,b,c 중 아무 글자에나 매치된다. 부정 문자 클래스도 정의될 수 있는데 이는 대괄호 안에 있는 문자들을 제외한 모든 문자와 매치된다. 캐럿(^)을 사용한다. 정규표현식 /[^abc]/는 a,b,c를 제외한 모든 문자와 매치된다. 문자 클래스 하이픈(-)을 사용하여 문자의 범위를 지정할 수도 있다. /[a-z]/는 라틴 알파벳 소문자와 매치되며, 모든 라틴 알파벳 글자나 숫자와 매치되게 하려면 /[a-zA-Z0-9]/를 사용한다. 10.1.3 반복복잡한 패턴을 작성할 때는 정규 표현식의 요소가 몇 번이나 반복되는지를 나타내는 문법을 사용해야 한다. 반복을 지정하는 문자는 언제나 반복을 지정할 패턴 뒤에 나온다. {n,m} : 앞의 항목이 적어도 n번이상, m번 이하로 나타난다. {n,} : 앞의 항목이 n번 이상 나타난다. {n} : 앞의 항목이 정확하게 n번 나타난다. ? : 앞의 항목이 0번 또는 한 번 나타난다. 앞의 항목이 나오지 않을 수도 있다. {0,1}과 동등 + : 앞의 항목이 한 번 이상 나타난다. {1,}과 동등 * : 앞의 항목이 0번 또는 그 이상 나타난다. {0,}과 동등와 ? 반복 문자를 사용할 때는 조심해야 한다. 예를 들면 정규 표현식 /a/는 실제로 문자열 “bbbb”와 매치된다. 10.1.4 대체, 그룹화, 참조정규 표현식 문법은 대체 표현식, 부분 표현식 그룹화, 이전 부분 표현식을 참조 하는 특별한 문자를 포함하고 있다.파이프 문자(|)는 대체 표현식을 구분한다. /ab|cd|ef/는 문자열 “ab” 또는 문자열 “cd” 또는 문자열 “ef”와 매치된다. 대체 표현식은 매치를 발견할 때까지 왼쪽에서 오른쪽으로 수행된다. 따라서 /a|ab/를 문자열 “ab”에 적용하면, 오직 첫 번째 글자 a만 매치된다.정규 표현식에서 괄호는 여러 목적으로 사용된다. 하나는 여러 항목을 하나의 부분 표현식으로 묶고(그룹화(, 묶인 항목들을 |, *, +, ? 등이 하나의 단위로 취급할 수 있게 한다. /(ab|cd)+|ef/는 “ab” 또는 “cd”가 한 번 이상 반복되는 문자열 혹은 문자열 “ef”와 매치된다.정규 표현식에서 괄호의 다른 목적은 전체 패턴 안에 부분 패턴을 정의하는 것이다. 정규 표현식이 대상 문자열에 성공적으로 매치되면, 괄호로 둘러싸인 특정 패턴과 매치되는 부분 문자열을 추출할 수 있다. 예를 들어 각 매치에 대해 끝에 있는 숫자에만 관심이 있다면, 패턴 일부를 /[a-z]+(\\d+)/와 같이 괄호 안에 두고 찾아낸 매치 결과에서 숫자를 추출할 수 있다. 10.1.6 플래그(flag)정규 표현식 플래그는 고차원 패턴 매칭 규칙을 지정한다. 다른 정규 표현식 문법과는 달리 플래그는 / 문자 쌍 바깥에, 즉 두 번째 슬래시 다음에 등장한다. 자바스크립트는 세 가지 플래그를 지원한다. 플래그들은 조합하여 지정될 수 있다. i : 대소문자를 구별하지 않는 매칭을 수행한다. g : 전역 매칭을 수행한다.. 즉, 처음 매치에서 끝내지 않고 모든 매치를 찾는다. m : 여러 줄 모드 10.2 패턴 매칭을 위한 문자열 메서드문자열에는 정규 표현식을 사용하는 메서드가 네 개 있다. 가장 간단한 것은 search() 메서드다. 이 메서드는 정규 표현식을 인자로 받고, 가장 처음 매칭되는 부분 문자열의 위치를 반환한다. 만약 매칭되는 문자열이 없다면 -1을 반환한다.1\"JavaScript\".search(/script/i); // 4를 반환한다. search()에 넘기는 인자가 정규 표현식이 아니라면, 이 인자는 먼저 RegExp 생성자로 넘겨지고 정규 표현식으로 변환된다. search()는 전역 검색을 지원하지 않기 때문에, 정규 표현식 인자의 g플래그는 무시된다.replace() 메서드는 ‘검색 후 바꾸기’를 수행한다. 첫 번째 인자로는 정규 표현식을 받고, 두 번째 인자로는 교체할 문자열을 받는다. replace() 메서드는 g플래그 사용이 가능하다. replace()의 첫 번째 인자가 정규 표현식이 아니라 일반 문자열인 경우에는 RegExp() 생성자를 사용하여 정규 표현식으로 변환하지 않고 전달된 문자열을 문자열 그대로 찾는다.(search() 와는 반대)match() 메서드는 정규 표현식 하나만을 인자로 받고 매치 결과를 배열로 반환한다. g플래그가 설정되어 있으면, 문자열 내의 모든 매치 부분을 배열로 반환한다. g플래그가 설정되어 있지 않으면, match()는 전역 검색을 수행하지 않고 단순히 첫 번째 매칭만 찾는다. 그러나 결과는 항상 배열로 반환된다.123456789var url = /(\\w+):\\/\\/([\\w.]+)\\/(\\S*)/;var text = \"Visit my blog at http://www.example.com/~david\";var result = text.match(url);if (result != null) { var fullurl = result[0]; // http:/www.example.com/~david var protocol = result[1]; // http var host = result[2]; // www.example.com var path = result[3]; // ~david} split() 메서드는 주어진 인자를 구분자로 삼아, 메서드가 호출된 문자열을 부분 문자열로 쪼갠다.1\"123,456,789\".split(\",\") // [\"123\", \"456\", \"789\"] 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/30/JavaScript/complete-guide-to-javascript-chapter-10/"},{"title":"자바스크립트 완벽가이드 3장 (타입, 값, 변수)","text":"자바스크립트의 타입은 크게 원시 타입(promitive type)과 객체 타입(object type)으로 나뉜다. 원시타입에는 숫자, 텍스트의 나열, 불리언 진리 값이 있다.자바스크립트에서 null과 undefined는 원시값이긴 하지만, 숫자도 아니고, 문자열이나 불리언도 아니다. null과 undefined는 자기 자신만을 값으로 갖는 독립적인 타입이다. 숫자와 문자열, 불리언, null, undefined 외의 값은 객체다. 객체는 이름과 값을 갖는 프로퍼티의 집합이다.자바스크립트에서는 함수도 특별한 객체이다. 함수는 값이고, 자바스크립트 프로그램은 함수를 보통 객체처럼 다룰 수 있다.클래스는 객체 타입의 하위 타입으로 생각할 수 있다. 코어 자바스크립트에서는 Array와 Function 클래스 뿐만 아니라 세 개의 다른 유용한 클래스들을 정의하고 있다. Date : 날짜를 표현하는 객체를 정의 RegExp : 정규 표현식을 표현하는 객체를 정의 Error : 자바스크립트 프로그램에서 발생할 수 있는 문법과 런타임 에러를 표현하는 객체를 정의 자바스크립트 인터프리터는 메모리 관리를 위해 자동으로 가비지 컬렉션을 수행한다. 프로그램이 필요할 때 객체를 생성할 수 있고, 프로그래머는 이 객체를 어떻게 해제할지 걱정할 필요가 없다. 객체에 더 이상 접근할 수 없을 때(프로그램이 더 이상 객체를 참조하지 않을 때) 인터프리터는 그 객체를 자동으로 메모리에서 해제한다.자바스크립트는 객체 지향 언어다. 다양한 타입의 값을 다루는 전역 함수를 정의해두기보다, 어떠한 값과 작동하는 메서드를 그 값의 타입에 정의해둔다는 말이다. 예를 들면, 배열의 원소들을 정렬할 때는 배열 a를 sort() 함수에 인자로 전달하는 것이 아니라 a의 sort() 메서드를 호출하여 정렬하는 것이다. null과 undefined를 제외하고는 모두 메서드를 가질 수 있다. 3.1 숫자다른 프로그래밍 언어들과는 다르게 자바스크립트는 정수 값과 실수 값을 구분하지 않는다. 자바스크립트에서는 모든 숫자를 실수로 표현한다. 3.1.3 산술 연산자바스크립트의 산술 연산은 오버플로와 언더플로, 0으로 나누는 에러를 발생시키지 않는다. 산술 연산의 결과가 표현할 수 있는 가장 큰 수보다 더 크다면(오버플로) Infinity라고 표현하는 무한대의 값을 출력한다. 음의 무한대가 되면 이 값을 -Infinity로 출력한다. 언더플로는 산술 연산의 결과가 표현할 수 있는 가장 작은 값보다 더 0에 가까울 때 발생한다. 이런 경우 자바스크립트는 0을 돌려준다.자바스크립트에서 0으로 나누는 연산은 에러가 아니다. 이런 경우 무한대 또는 음의 무한대가 반환된다. 그러나 0을 0으로 나누는 것은 정의되지 않은 값을 갖고, 그 결과로 숫자가 아닌 특수한 값을 가진다. 자바스크립트에서는 이러한 값을 NaN으로 출력한다. (ECMAScript 5에서는 Infinity와 NaN을 읽기 전용 값으로 정의한다.) Number객체에는 Inifiny와 NaN이 따로 상수로 정의되어 있다. 자바스크립트에서 NaN은 그 자신뿐만 아니라 다른 값과 같은지 비교 할 수 없다. 변수 x가 NaN인지 판단하기 위해 x === NaN 문을 작성할 수 없고, 대신 x != x 라고 작성해야 한다. isNaN() 함수가 이러한 경우에 유용하게 사용할 수 있다. 이 함수는 인자가 NaN이거나, 문자열이나 객체처럼 숫자가 아니라면 참을 반환한다. 3.1.4 이진 부동소수점과 반올림 오류무한히 많은 실수가 있지만 자바스크립트에서는 한정된 숫자만 부동소수점 형태로 표현할 수 있다. 자바스크립트에서 사용하는 IEEE-754 부동소수점 표현 방식은 1/2, 1/8, 1/1024 같은 분수를 정확하게 표현 할 수 있는 이진 표현법이다. 하지만 가장 많이 사용하는 분수는 10진수 분수인데, 이진 표현법으로는 0.1과 같은 간단한 값도 정확하게 표현 할 수 없다.따라서 다음과 같은 상황이 발생한다.12345var x = .3 - .2; // 0.3 - 0.2var y = .2 - .1; // 0.2 - 0.1x == y // =&gt; false: 두 값은 같지 않다.x == .1 // =&gt; false: 0.3 - 0.2는 0.1이 아니다.y == .1 // =&gt; true: 0.2 - 0.1은 0.1과 같다. 이진 부동소수점 숫자를 사용하기 때문에 발생하는 현상이다. 계산된 값은 대부분 적절하지만, 값들을 동등 비교할 경우에 문제가 발생한다. 3.1.5 날짜와 시간날짜와 시간을 표현하는 Date 객체를 사용한다. Date 객체는 숫자 같은 원시 타입이 아니다. 3.2 텍스트문자열(string)은 16비트 값들이 연속적으로 나열된 변경이 불가능한 값으로, 각 문자는 유니코드 문자로 표현된다. 문자열의 길이 값은 문자열에 들어 있는 16비트 값의 개수다. 자바스크립트는 유니코드 문자열 집합으로 UTF-16을 사용한다. 유니코드 문자는 16비트에 적합한 코드 포인트를 갖고 있고, 문자열의 한 문자로 표현할 수 있다. 16비트로 표현할 수 없는 유니코드는 UTF-16 규칙에 따라 두 개의 16비트 값으로 인코딩한다. 따라서, 자바스크립트에서는 길이가 2인 문자열이 하나의 유니코드 문자를 표현하는 경우도 있다.문자열을 다루는 다양한 메서드는 문자를 다루는게 아니라 문자의 16비트 값을 다룬다. 3.2.3 문자열 다루기자바스크립트에서 문자열은 변경되지 않는다. replace()와 toUpperCase() 같은 메서드는 기존 문자열을 변경하지 않고 새문자열을 반환한다. 즉, 문자열 관련 메서드는 호출 시에 기존 문자열을 수정하지 않는다. ECMAScript5에서 문자열은 읽기 전용 배열처럼 취급될 수 있고, 대괄호 대신 charAt() 메서드를 사용해도 문자열의 개별 문자(16비트 값)에 접근할 수 있다. 3.2.4 패턴 매칭자바스크립트는 문자 패턴을 나타내는 객체를 생성하기 위해 RegExp() 생성자를 정의한다. 이 패턴은 정규 표현식이라 부르며, 자바스크립트는 정규 표현식을 위해 펄(Perl)의 구문을 따른다. 문자열과 RegExp 객체는 모두 패턴 매칭과 ‘검색 후 바꾸기’기능을 수행하는 메서드를 갖고 있다. RegExp는 자바스크립트의 원시 타입이 아니다. Date 객체처럼 RegExp는 유용한 API를 갖고 있는 특별한 종류의 객체다.한 쌍의 슬래시 사이에 있는 문자열은 정규 표현식 리터럴을 구성하고, 한 쌍의 슬래시 중 두 번째 슬래시 뒤에는 하나 혹은 그 이상의 문자가 뒤따라 올 수 있는데, 이것은 패턴의 의미를 수정할 수 있다.RegExp 객체에는 유용한 메서드들이 정의되어 있다. 또한 문자열은 RegExp 객체를 인자로 갖는 메서드들을 갖고 있다.1234567var text = \"testing: 1, 2, 3\"; // 간단한 문자열var pattern = /\\b+/g // 하나 이상의 모든 숫자와 일치pattern.test(text); // =&gt; true: 일치하는 문자열이 존재text.search(pattern); // =&gt; 9: 첫 번째로 매치하는 문자열의 위치text.match(pattern); // =&gt; [\"1\", \"2\", \"3\"]: 일치된 항목의 배열text.replace(pattern, \"#\"); // =&gt; \"testing: #, #, #\"text.split(/\\D+/); // =&gt; [\"\", \"1\", \"2\", \"3\"]: 숫자가 아닌 문자(열)를 기준으로 분할 3.3 불리언 값자바스크립트의 어떤 값이든 불리언 값으로 변환될 수 있다. 다음은 모두 불리언 false 값으로 변한다. undefined null 0 -0 NAN “” // 빈 문자열 불리언 값은 문자열 “true” 혹은 “false”로 변환할 수 있는 toString() 메서드를 갖고 있지만 그 밖의 메서드는 갖고있지 않다. 3.4 null과 undefinednull은 보통 아무 값도 갖지 않음을 가리킬 때 사용한다. typeof 연산자를 null에 사용하면 문자열 “object”를 반환한다. 그 결과로 볼 때, null은 ‘객체가 없음’을 뜻하는 특수한 객체 값으로 생각할 수 있다. 하지만 실무에서 null은 값이 null 하나뿐인 어떤 고유한 자료형에 속한 것으로 간주하여, 객체뿐 아니라 수나 문자열 “값이 없음”을 나타내는 데도 쓰인다.자바스크립트에는 값이 없음을 나타내는 또 다른 값, undefined가 있다. undefined는 null보다 심한 부재 상태를 나타낸다. undefined는 초기화되어 있지 않는 변수나, 존재하지 않는 객체 프로퍼티나 배열의 원소 값에 접근하려고 할 때 얻는 값이다. 또한 undefined는 반환값이 없는 함수의 반환값이고, 실 인자가 전달되지 않은 형식인자의 값이다. ECMAScript 5에서 undefined는 읽기 전용이며, typeof 연산자의 결과로 “undefined”가 반환된다. 이는 undefined가 특별한 고유의 값임을 말한다.이러한 차이에도 불구하고 null과 undefined는 둘다 값이 없음을 가리키고, 사용할 때 서로 바꿔 사용할 수도 있다. 동치 연산자 ==를 null과 undefined에 사용하면 두 값이 같다고 간주하며 엄격한 동치 연산자 ===는 다르다고 판단한다.시스템 수준에서 예기치 않은 상황에 발생한, 오류성 값 부재를 표현할 때는 주로 undefined를 사용하고, 일반적인 프로그램 수준에서 일반적으로, 또는 예상 가능한 값 부재 상황을 표현하고 싶을 때는 null을 사용한다. 만약 이들 값 중 하나를 변수나 프로퍼티에 할당할 필요가 있거나 함수에 인자로 전달할 필요가 있다면, undefined보다는 null을 사용하는게 적절하다. 3.6 래퍼(wrapper) 객체자바스크립트 객체는 복합적인 값이다. 객체는 프로퍼티 또는 이름 있는 값들의 집합이다. 프로퍼티의 값이 함수일 때, 그 함수를 메서드라 부른다.문자열의 프로퍼티를 참조하려 할 때, 자바스크립트는 new String()를 호출한 것처럼 문자열 값을 객체로 변환한다. 이 객체는 문자열 메서드를 상속하며, 프로퍼티 참조를 살펴보는 데 사용한다. 일단 프로퍼티 참조가 해제되면 새로 생성된 임시 객체는 메모리에서 회수된다.숫자와 불리언은 문자열과 같은 이유로 메서드를 갖고 있다. 임시 객체는 Number() 혹은 Boolean() 생성자를 통해 만들어지고, 메서드는 임시 객체를 통해 호출된다.123var s = \"test\";s.len = 4;var t = s.len; 위의 코드를 실행시 t의 값은 undefined이다. 2행은 생성된 임시 String 객체의 len 프로퍼티에 4를 할당한다. 그리고 임시 객체는 바로 삭제된다. 3행은 기존 문자열 값과 같은 값을 가진 새로운 String 객체를 생성하고 len 프로퍼티를 읽으려고 하지만 존재하지 않아 undefined를 출력한다. 값을 할당하는 것은 임시 객체에서 수행되며, 지속되지 않는다.문자열, 숫자, 불리언의 프로퍼티에 접근하려고 할 때 생성되는 임시 객체는 래퍼(wrapper) 객체로 알려져 있다. 문자열과 숫자, 불리언 값의 프로퍼티는 읽기 전용이고, 이 값들에 새로운 프로퍼티를 정의할 수 없다는 점에서 이 값들이 객체와 다르다는 사실을 알아야 한다.String()과 Number(), Boolean() 생성자를 사용해 명시적으로 래퍼 객체를 생성할 수도 있다. 자바스크립트는 래퍼 객체를 필요에 따라 기본 타입으로 변환한다. == 동치 연산자는 값과 그 값의 래퍼 객체를 동등하게 다루지만 === 엄격한 동치 연산자로 이를 구별할 수 있다. (typeof 연산자는 기본 타입과 래퍼 객체의 차이점을 보여줄 수 있다.) 3.7 변경 불가능한 원시 타입 값과 변경 가능 객체 참조자바스크립트에서 원시 타입(undefined, null, 불리언, 숫자, 문자열) 값과 객체(배열과 함수를 포함한) 사이에는 근본적인 차이점이 있다. 원시 타입의 값은 수정할 수 없다는것이다. 문자열 같은 경우 문자열을 수정하는 모든 문자열 메서드는 새로운 문자열을 반환한다. 원시 타입은 값으로 비교된다. 두 값은 같은 값이어야만 같다. 문자열 같은 경우 서로 다른 문자열 값을 비교할 때, 자바스크립트는 두 문자열의 길이가 같고 각 인덱스에 있는 문자들이 같다면 두 문자열을 같다고 판단한다.객체는 원시 타입과는 다르다. 객체는 자신의 값을 변경할 수 있다. 객체는 값으로 비교되지 않는다. 두 객체가 같은 프로퍼티와 값을 가지고 있어도 두 객체는 같지 않다. 그리고 두 배열은 같은 순서로 같은 원소를 갖고 있어도 같지 않다.객체는 참조 타입(reference type)으로 불리는데, 이는 자바스크립트의 원시 타입과 구별하기 위해서다. 객체의 값은 참조다. 객체는 참조로 비교될 수 있다. 두 객체 값은 그들이 같은 객체를 참조하면 같다. 객체는 새로운 복사본을 생성하지 않기 때문에 객체 혹은 배열의 새로운 복사본을 만들고 싶다면 명시적으로 객체의 프로퍼티 또는 배열의 원소를 복사해야 한다.12345var a = ['a', 'b', 'c']; // 복사하고자 하는 배열var b = []; // 복사하고자 하는 배열for(var i = 0; i &lt; a.length; i++) { // 배열 a의 각 인덱스 b[i] = a[i]; // a의 원소를 b로 복사한다.} 두 다른 객체 또는 배열을 서로 비교하고 싶다면 그들의 프로퍼티 또는 원소를 비교해야 한다. 3.8 타입 변환자바스크립트는 타입에 매우 유연하다. 자바스크립트가 문자열을 원한다면, 문자열이 올 자리에 어떤 값을 전달하더라도 문자열로 변환될 것이고, 숫자를 원한다면 숫자가 올 자리에 다른 어떤 값이 오더라도 숫자로 변환될 것이다.(또는 의미 있는 변환을 할 수 없다면 NaN으로 변환된다.) 3.8.1 변환과 동치자바스크립트는 값의 타입을 유연하게 변환시킬 수 있다. 따라서, 동치 연산자 ==도 유연하게 동작한다. 다음은 모두 true를 반환한다.1234null == undefined // 이 두 값은 같다고 판단된다.\"0\" == 0 // 비교하기 전에 숫자로 변환된다.0 == false // 불리언은 비교하기 전에 숫자로 변환한다.\"0\" == false // 두 피연선자는 비교하기 전에 숫자로 변환된다. 서로 변환 가능한 값이라고 해서 동치는 아니다. undefined가 불리언 값이 올 자리에 사용되면 false로 변환된다. 하지만 이것이 undefined == false 임을 의미하지는 않는다. if문은 undefined를 false로 변환하지만, == 연산자는 undefined를 불리언으로 변환하지 않는다. 3.8.2 명시적 변환자바스크립트는 많은 형 변환을 자동으로 수행하지만, 명시적 변환이 필요할 때가 있다. 명시적으로 타입변환을 수행하는 가장 간단한 방법은 Boolean(), Number(), String(), Object() 함수를 사용하는 것이다. new 연산자 없이 호출되면, 이 함수들은 변환 함수로 작동한다. 3.8.3 객체에서 원시 타입으로 변환모든 객체는 두 개의 타입 변환 메서드를 상속한다. toString() : 객체를 문자열로 표현하여 반환한다. valueOf() : 기본적으로 원시 타입을 반환하지 않고 단순히 객체 그 자신을 반환한다. 자바스크립트는 toString(), valueOf() 순으로 메서드를 호출하여 문자열로 변환하여 반환한다. 만약 toString() 또는 valueOf() 로부터 원시타입 값을 얻을 수 없다면 TypeError를 발생시킨다. 객체를 숫자로 전환할 때는 문자열과 같은 방식으로 전환하지만, valueOf() 메서드를 먼저 호출한다. 3.9 변수 선언자바스크립트에서는 변수를 사용하기 전에 변수 선언을 해야 한다. var 문을 통해서 변수를 선언하는데, var 문에서 변수에 초기 값을 지정하지 않는다면, 변수는 값이 설정될 때까지 undefined 값을 갖게 된다. 자바스크립트 변수 선언에는 타입을 명시하지 않는다. 3.10 변수의 유효범위변수의 유효범위란 프로그램에서 어떤 변수가 정의되어 있는 영역을 말한다. 3.10.1 함수 유효범위와 끌어올림(hoisting)C 같은 프로그래밍 언어에서 블록 안에 있는 코드는 자신만의 유효범위를 가지며, 변수는 해당 변수가 선언되지 않은 블록 밖에서는 보이지 않는다. 이를 블록 유효범위라고 부른다. 자바스크립트에서는 블록 유효범위의 개념이 없고 함수 유효범위를 사용한다. 변수는 해당 변수가 정의된 함수 안에서 보일 뿐 아니라, 그 함수 안에 중첩된 함수 안에서도 보인다. 이런 자바스크립트의 특징을 비공식적으로 끌어올림(hoisting)이라고 한다. 자바스크립트의 코드는 함수 안에 있는 모든 변수를 함수 맨 위로 ‘끌어올린’ 것처럼 동작한다.123456var scope = \"global\";function f() { console.log(scope); // \"global\"이 아니라 \"undefined\"를 출력한다. var scope = \"local\"; // 여기서 초기호하지만, 정의는 다른 곳에서 이루어진다. console.log(scope); // \"local\"을 출력한다.} 위의 함수는 실제로 다음 코드와 같다.123456function f() { var scope; // 지역 변수는 함수 맨 꼭대기에서 선언한다. console.log(scope); // scope 변수는 존재하지만 아직 \"undefined\" 값이다. scope = \"local\"; // 이제 scope 변수가 초기화되고 제대로 된 값이 있다. console.log(scope); // 여기서는 기대한 값이 들어있다.} 함수의 유효범위 규칙 때문에 지역 변수는 함수 전체에 걸쳐 정의된다. 지역 변수가 함수 전체에 걸쳐 정의되었더라도 var 문이 실행되고 나서야 실제로 초기화 된다. 따라서 변수 선언은 함수 맨 위로 ‘끌어올려(hoisting)’지고 초기화는 나중에 이루어지게 된다.블록 유효범위를 가진 프로그래밍 언어에서 일반적으로 변수를 선언하는 좋은 프로그래밍 방법은, 가능한 한 그 변수가 사용되는 가장 가까운 곳에서 선언하는 것이다. 하지만 자바스크립트는 블록 유효범위를 가지고 있지 않기 때문에 함수의 맨 위에 선언해야할지도 모른다. 3.10.3 유효범위 체인자바스크립트는 언어적으로 유효범위를 갖고 있는 언어다. 변수의 유효범위란 정의된 변수를 사용 가능한 소스코드의 집합으로 생각할 수 있다.지역 변수를 객체의 프로퍼티로 생각한다면, 변수 유효범위를 다른 관점으로 볼 수도 있다. 자바스크립트의 모든 코드 무더기는 그것과 연관된 유효범위 체인을 갖고 있다. 이 유효범위 체인은 해당 코드 무더기의 ‘범위 안’에 있는 변수를 정의하는 객체의 체인, 리스트다.최상위 자바스크립트 코드의 경우, 유효범위 체인은 단 하나의 ‘전역 객체’만으로 이루어진다. 중첩되지 않은 함수의 유효 범위 체인은 두 개의 객체로 이루어진다. 하나는 함수 매개변수와 지역 변수를 정의하는 객체고, 다른 하나는 전역 객체다. 중첩된 함수에서 유효범위 체인은 세 개 이상의 객체를 갖는다. 함수가 호출될 때, 해당 함수의 지역변수를 저장하기 위해서 새로운 객체를 하나 생성하고, 해당 객체를 기존에 저장된 유효범위 체인에 추가한다. 중첩 함수의 경우에는 외부에서 함수를 호출할 때마다 중첩된 함수가 매번 선언된다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/26/JavaScript/complete-guide-to-javascript-chapter-3/"},{"title":"자바스크립트 완벽가이드 4장 (표현식과 연산자)","text":"표현식(expression)은 자바스크립트 인터프리터가 값으로 평가하는 자바스크립트 구문이다. 4.1 기본 표현식가장 간단한 형태의 표현식은 ‘기본 표현식’으로, 다른 표현식을 포함하지 않은 독립적 표현식이다. 자바스크립트에서 기본 표현식은 상수나 리터럴 값, 특정 키워드들 그리고 변수 참조를 말한다.this는 상수가 아니고 프로그램 안에서 위치에 따라 각기 다른 값으로 평가된다. this 키워드는 객체 지향 프로그래밍에서 주로 사용된다. 메서드의 본문 안에서 this는 메서드를 호출한 객체로 평가된다. 자바스크립트에서는 프로그램 안에 존재하는 각 식별자들을 일단 변수라고 가정하고 값을 살펴보는데 해당 식별자를 이름으로 하는 변수가 없다면, 해당 표현식은 undefined 값으로 평가된다. 하지만 ECMAScript 5의 strict 에서는 존재하지 않는 변수를 평가하려고 하면 ReferenceError 예외가 발생한다. 4.2 객체와 배열의 초기화 표현식객체와 배열 초기화 표현식은 새로 생성된 객체나 배열을 값으로 하는 표현식이다. 일반 리터럴과는 달리, 이들은 기본 표현식이 아니다. 이들 리터럴은 프로퍼티와 원소의 값을 지정하는 수많은 하위 표현식을 포함할 수 있기 때문이다. 4.4 프로퍼티 접근 표현식두 프로퍼티 접근 표현식 모두 점(.)이나 대괄호([) 왼쪽 표현식이 먼저 평가된다. 만약 평가된 값이 null이나 undefined이면 이들 값은 프로퍼티를 갖지 않기 때문에 표현식은 TypeError 예외를 발생시킨다. 만약 값이 객체(또는 배열)가 아니면 객체로 변환된다. 객체에 해당 프로퍼티가 존재하지 않으면, 프로퍼티 접근 표현식의 값은 undefined가 된다.‘. 식별자’ 문법이 두 방법 중 좀 더 간단하지만 접근하려는 프로퍼티 이름이 ‘합법적’ 식별자일 때만 사용 가능하고, 프로그램을 작성할 때 그 식별자를 미리 알고 있어야 한다. 만약 프로퍼티 이름이 예약어이거나, 구두점 문자나 공백을 포함, 숫자일 때는 반드시 대괄호를 사용해야 한다. 대괄호는 프로퍼티 이름이 고정되어 있지 않고, 그 이름 자체가 어떤 연산의 결과인 경우에도 사용할 수 있다. 4.5 호출 표현식값을 반환하기 위해 return문을 사용하면, 그 값이 결국 호출 표현식의 값이 된다. 함수가 값을 반환하지 않는다면, 함수 표현식의 값은 undefined가 된다.모든 호출 표현식은 한 쌍의 괄호 ()와, 괄호 앞에 오는 표현식으로 이뤄진다. 만약 그 표현식이 프로퍼티 접근 표현식이면, 호출 표현식은 메서드 호출이 된다. 메서드가 호출되면 함수의 몸체가 실행되는 동안 프로퍼티 접근 표현식이 가리키는 객체나 배열이 모두 this의 값이 된다.메서드 호출이 아닌 호출 표현식은 보통 전역객체를 this 키워드의 값으로 사용한다. 하지만 ECMAScript 5에서는 메서드 호출이 아닌 호출 표현식을 ‘엄격모드’에서 사용할 경우, 전역 객체 대신 undefined가 this의 값이 된다.’ 4.6 객체 생성 표현식객체 생성 표현식은 새 객체를 생성하고 생성자라고 부르는 함수를 호출해 객체에 속한 프로퍼티들을 초기화한다. 객체 생성 표현식이 평가될 때, 자바스크립트 인터프리터는 먼저 새로운 빈 객체를 생성한다. 이때 생성된 객체는 객체 초기자 {}에 의해 생성되는 객체와 동일하다. 다음으로, 주어진 인자들과 함께 생성자를 호출하는데, 이때 방금 생성된 새 객체를 this 키워드의 값으로 설정하여 전달한다. 생성자 함수는 이 this 키워드를 사용해 새로 생성된 객체의 프로퍼티들을 초기화한다. 4.8 산술 표현식수로 변환 불가능한 피연산자는 NaN 값으로 변환되며, 피연산자중 하나라도 NaN일 경우에는 연산 결과도 NaN이다./ 연산자는 첫 번째 피연산자를 두 번째 피연산자로 나눈다. 정수를 정수로 나누면 계산 값이 당연히 정수가 되리라고 예상하겠지만, 자바스크립트에서 모든 숫자는 부동소숫점 숫자로 취급된다. 따라서 모든 나눗셈 연산의 결과 또한 부동소숫점 숫자 값이 된다. 예를 들어 5/2는 2가 아니라 2.5로 평가된다. 값을 0으로 나누면 양의 무한도 또는 음의 무한대 값이 되고, 0/0의 값은 NaN로 평가된다.% 연산자 결과의 부호는 첫 번째 피연산자의 부호와 동일하다. 4.8.1 덧셈 연산자 +12345671 + 2 // =&gt; 3: 덧셈\"1\" + \"2\" // =&gt; '12': 이어붙이기\"1\" + 2 // =&gt; '12': 숫자를 문자열로 바꾼 후 이어붙이기1 + {?} // =&gt; \"1[object Object]\": 객체를 문자열로 바꾼 후 이어붙이기true + true // =&gt; 2: 불리언 값을 숫자로 바꾼 후 더하기2 + null // =&gt; 2: null 값을 0으로 바꾼 후 더하기2 + undefined // =&gt; NaN: undefined를 NaN으로 바꾼 후 더하기 4.8.2 단항 산술 연산자증가(++)표현식 ++x는 x=x+1과 항상 같지 않다. ++ 연산자는 절대 문자열 결합을 하지 않고, 항상 피연산자를 숫자로 바꾼 후에 값을 하나 증가시킨다. 예를 들어, x가 문자열 “1”이면 ++x는 숫자 2가 되지만 x+1은 문자열 “11”이 된다. 4.9 관계형 표현식4.9.1 동치와 부등치 연산자==와 === 연산자 모두 주어진 두 값이 같은지를 확인하는 데 쓰이지만 같음을 정의하는 기준이 서로 다르다. 두 연산자 모두 피연산자 타입을 가리지 않고, 주어진 피연산자들이 같으면 true, 다르면 false를 반환한다. === 연산자는 일치(엄격한 동치) 연산자로 알려져 있는데, 같음을 정의하는 기준을 매우 엄격하게 정의하여, 두 피연산자가 ‘일치’하는지 확인한다.자바스크립트는 =(할당), ==(동치), ===(일치) 연산자를 지원하고 있다. 4.9.2 비교 연산자비교 연산자는 피연산자 타입에 제한이 없다. 하지만 오직 숫자와 문자열만 비교할 수 있기 때문에, 숫자나 문자열이 아닌 피연산자는 먼저 변환된다.문자열 비교는 대소문자를 구분한다. 모든 ASCII 대문자는 모든 ASCII 소문자보다 작다. 대소문자를 구분하지 않고 문자열을 비교하려면, 우선 String.toLowerCase()나 String.toUpperCase() 메서드를 사용해야 한다. 4.9.3 in 연산자in 연산자는 좌변의 피연산자로 문자열(또는 문자열로 변환될 수 있는 것)을 받고, 우변의 피연산자로는 객체나 배열을 받는다. 좌변 값이 우변 객체의 프로퍼티 이름에 해당할 경우 연산 결과는 true이다.12345678var point = { x:1, y:1 }; // 객체 정의\"x\" in point // =&gt; true: 프로퍼티 x가 있다.\"z\" in point // =&gt; false: 프로퍼티 z가 없다..\"toString\" in point // =&gt; true: 상속된 프로퍼티var data = [7,8,9]; // 원소가 0, 1, 2 위치에 차례로 7, 8, 9\"0\" in data // =&gt; true: 배열에 0번째 원소가 있기 때문1 in data // =&gt; true: 배열에 1번째 원소가 있기 때문3 in data // =&gt; false: 배열에 4번째 원소가 없기 때문 4.9.4 instanceof 연산자instanceof 연산자는 좌변의 피연산자로 객체를, 우변의 피연산자로 객체 클래스의 이름을 받는다. 자바스크립트에서 객체의 클래스는 객체를 초기화하는 생성자 함수로부터 정의된다. 그러므로 instanceof의 우변 피연산자는 함수가 되어야 한다.12345678var d = new Date(); // Date() 생성자로 새로운 객체를 생성한다.d instanceof Date; // =&gt; true: d는 Date()에 의해 생성되었다.d instanceof Object; // =&gt; true: 모든 객체는 Object의 인스턴스.d instanceof Number; // =&gt; false: d는 Number의 객체가 아니다.var a = [1, 2, 3]; // 배열 리터럴 문법으로 새로운 배열을 생성한다.a instanceof Array; // =&gt; true: a는 배열이다.a instanceof Object; // =&gt; true: 모든 배열은 객체다.a instanceof RegExp; // =&gt; false: 배열은 정규 표현식이 아니다. 4.10 논리 표현식4.10.1 논리 AND (&amp;&amp;)&amp;&amp; 연산자의 피연산자로 반드시 불리언 값이 올 필요는 없다. 모든 자바스크립트 값은 true 또는 false로 평가될 수 있기 때문이다. 피연산자 모두 true로 평가되는 값이면, &amp;&amp; 연산자는 true로 평가되는 값을 반환한다. 하지만 적어도 하나의 피연산자가 false로 평가될 경우에는 false로 평가되는 값을 반환한다.&amp;&amp; 연산자의 특성을 ‘단축 평가’라고도 부르고 다음과 같이도 사용 가능하다.12if (a == b) stop();(a == b) &amp;&amp; stop(); &amp;&amp; 연산자는 우변 표현식을 평가할 수도, 하지 않을 수도 있기 때문에 &amp;&amp; 우변에 부수 효과가 일어나는 표현식(하당, 증가, 감소, 함수 호출)을 사용할 때는 각별히 주의해야 한다. 이러한 부수 효과가 일어나는 표현식은 &amp;&amp; 좌변 값에 따라 실행 여부가 결정되기 때문이다. 4.10.2 논리 OR (||)|| 연산자는 일반적으로, 다음 코드와 같이 여러 값중에 최초로 true로 평가되는 값을 선택하는 경우에 사용된다.1234// max_width가 정의되어 있으면 이것을 사용한다.// 이 외의 경우 preference 객체에 속한 값을 찾아본다.// 그것조차 정의되어 있지 않을 경우 하드 코딩된 상수를 사용한다.var max = max_width || preferences.max_width || 500; 4.13 기타 연산자들4.13.2 typeof 연산자typeof의 피연산자 값이 null일 때 연산자는 “object”를 반환한다. 만약 다른 Object들과 null을 구분하고 싶다면, typeof를 사용하기 보다는 명시적으로 null인지를 테스트해야한다.typeof 연산자는 함수를 제외한 모든 객체와 배열을 “object”로 평가하기 때문에, 객체를 다른 원시 타입과 구분하는 용도로만 사용할 수 있다. 객체의 클래스를 구분하기 위해서는 instanceof 연산자나 class 속성 또는 constructor 프로퍼티와 같은 다른 수단을 사용해야 한다.자바스크립트에서 함수는 객체의 일종이지만, typeof 연산자는 함수들이 자신의 반환 값을 가지고 있다는 점 때문에 일반 객체와는 충분히 다르다고 본다. 자바스크립트에서는 함수와 ‘호출 가능한 객체’ 사이에 미묘한 차이점이 있다. 모든 함수는 호출 가능하다. 하지만 실제로는 함수가 아닌데도 함수처럼 호출이 가능한 객체도 있을 수 있다.ECMAScript 5 표준은 typeof 연산자가 모든 호출 가능한 객체에 대해 일반 개체든 호스트 객체든 관계없이 ‘function’을 반환하도록 명세를 확장했다. 4.13.3 delete 연산자delete는 단항 연산자이며, 피연산자로 지정된 객체 프로퍼티, 배열 원소 또는 변수의 삭제를 시도한다. delete 연산자는 보통 연산자가 가진 부수 효과(프로퍼티 삭제) 때문에 사용하는 것이며, 연산자가 반환하는 값 때문에 사용하는 것이 아니다. (단, 배열의 원소를 delete 연산자를 사용하여 삭제해도 배열의 길이는 변하지 않는다.)삭제된 프로퍼티나 배열의 원소는 단순히 undefined 값으로 설정된 것이 아니라는 점을 유의해야한다. 어떤 프로퍼티가 삭제되면 그 프로퍼티는 더 이상 존재하지 않는다. 그런데 존재하지 않는 프로퍼티에 접근하려고 해도 undefined가 반환되므로, 프로퍼티가 객체에 존재하는지 여부를 검사하려면 in 연산자를 쓰면 된다.그러나 모든 변수나 프로퍼티를 삭제할 수는 없다. var 문으로 선언한 사용자 정의 변수나 내장 코어 프로퍼티, 클라이언트 측 프로퍼티는 삭제할 수 없다. function 문으로 정의한 함수와 함수 매개변수도 삭제할 수 없다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/27/JavaScript/complete-guide-to-javascript-chapter-4/"},{"title":"자바스크립트 완벽가이드 5장 (문장)","text":"문장(statement), 즉 ‘문’은 자바스크립트 문장, 다시 말해 명령이다. 자바스크립트 문장은 세미콜론(;)으로 끝난다. 표현식은 어떤 값을 생성하기 위해 평가되지만, 구문은 어떤 일을 하기위해 실행되는 것이다. 5.2 복합문과 빈 문장문장 블록은 여러 문장을 하나의 복합문으로 묶는다. 자바스크립트에는 블록 단위의 유효범위(scope)가 존재하지 않기 때문에, 구문 블록 안에 선언된 변수는 블록뿐 아니라 블록 밖에서도 접근할 수 있다.자바스크립트 문법은 대체로 하나의 하위문을 허용한다. 예를 들어, while 루프 문법은 루프 몸체로 하나의 문장을 허용한다. 문장 블록을 사용하면 문법이 허용하는 하나의 하위문 자리에 얼마든지 많은 문장을 넣을 수 있다.결과적으로 복합문은 자바스크립트 문법에서 하나의 문장이 있어야 할 곳에 여러 문장을 사용할 수 있게 한다. 빈문장은 정 반대다. 하나의 문장이 있어야 할 곳에 아무런 문장도 두지 않을 수 있도록 한다. 빈 문장은 ;을 사용하여 표현한다. 임의로 빈 문장을 사용할 경우에는, 코드에 고의로 사용했다는 설명을 주석으로 표시하는 것이 좋다. 5.3 선언문5.3.1 varvar문은 하나 또는 그 이상의 변수를 선언한다. var문에서 변수에 초기 값을 지정하지 않으면 변수의 초기 값은 undefined가 된다. 스크립트나 함수 안에서 선언된 변수는 해당 스크립트나 함수 전체에 걸쳐 유효하다. 하지만 초기화된 var문이 선언된 시점에서 발생하고, 그 전까지는 변수 값은 undefined가 된다. 5.3.2 function함수 선언문은 자바스크립트 최상위 단계 코드에서 나타날 수도 있고, 다른 함수 내에 중첩될 수도 있다. 하지만 함수가 다른 함수 속에 중첩될 때는, 중첩된 함수 내에서 최상위 단계에 위치해야 한다. 즉, 함수 선언은 if문이나 while문 등의 다른 문장 안에 있을 수 없다.함수 선언문은 함수 이름을 포함한다는 점에서 함수 정의표현식과는 차이가 있다. 둘 다 새 함수 객체를 만들지만, 함수 선언문은 함수 이름을 변수로 선언한 후 이 변수에 함수 객체를 할당한다는 차이가 있다. var로 선언한 변수와 같이, 함수 선언문으로 정의된 함수는 스크립트나 함수 유효범위 최상단에 위치하게 되어(hoisted) 해당 유효범위 내에서 사용할 수 있다. var 문을 이용하면 변수 선언만 유효범위 최상단으로 끌어올려지지만(변수 초기화 코드는 원래 위치에 그대로 유지), 함수 선언문을 이용하면 함수의 이름과 본문 모두 유효범위 최상단으로 끌어올려진다. 이때 스크립트 내의 모든 함수 또는 함수의 중첩 함수는 다른 코드가 실행되기 전에 선언된다. 이는 자바스크립트 함수를 호출하는 코드가 선언문이 나오기 전에도 올 수 있다는 뜻이다. 5.4 조건문5.4.1 if대다수의 프로그래밍 언어와 마찬가지로 자바스크립트 규칙에 의하면 else 절은 기본적으로 가장 가까운 if문에 속한다. 모하함을 없애고 읽기 쉽고 이해하기 쉬운 동시에 유지보수와 디버깅을 쉽게 하려면 반드시 중괄호를 사용해야 한다. 5.4.3 switchswitch문은 if문에서처럼 동일한 표현식이 여러 번 반복되는 문제점을 확실히 해결한다. 다음은 실용적인 switch 문의 예제이다. 이 예제에서는 어떤 값을 문자열로 바꾸는데, 그 값의 타입에 따라 각기 다른 방법을 적용해 문자열로 변환한다.12345678910function convert(x) { switch(typeof x) { case 'number': // 주어진 숫자를 16진수 정수로 변경한다. return x.toString(16); case 'string': // 문자열을 큰따옴표로 묶어서 반환한다. return '\"' + x + '\"'; default: // 이 외의 타입은 문자열로 변환한다. return String(x); }} switch문이 실행될 때마다 모든 case 표현식이 매번 평가되지는 않기 때문에, case 표현식에 함수 호출이나 값 할당과 같이 부수 효과를 일으킬 수 있는 표현식을 사용해서는 안된다. 가장 안전한 방법은 case 표현식을 상수 표현식만으로 제한하는 것이다. case를 판별할 때는 동치 연산자 ==가 아닌 일치 연산자 ===가 사용된다. 5.5 루프자바스크립트에는 네 개의 루프문이 있다. while do/while for for/in 5.5.4 for/infor/in문은 for 키워드를 사용하지만, 일반적인 for 루프와는 전혀 다른 종류다.12for (변수 in 객체) 문장 ‘변수’는 보통 변수 이름이지만 좌변 값으로 평가되는 표현식이거나, 단일 변수를 선언하는 var문일 수도 있다. ‘객체’는 객체로 평가되는 표현식이어야 한다. ‘문장’은 루프 몸체를 구성하는 문장 또는 문장 블록이다.일반적인 for 루프를 사용하면 다음과 같이 배열의 원소를 쉽게 순회할 수 있다.12for(var i = 0; i &lt; a.length; i++) console.log(a[i]); 이와 비슷하게 for/in 루프를 사용하면 객체가 가진 프로퍼티들을 쉽게 순회할 수 있다.123for(var p in o) { // 변수 p에 객체 o가 가진 프로퍼티 이름을 할당한다. console.log(o[p]);} for/in문을 실행하기 위해서 자바스크립트 인터프리터는 먼저 객체 표현식을 평가한다. 이때 표현식이 null이나 undefined로 평가되면 인터프리터는 해당 루프를 중단하고 다음 문장을 실행한다. 만약 표현식이 원시 값으로 평가되면 해당 값은, 값과 상응하는 Wrapper 객체로 바뀐다. 이 외에 표현식은 객체로 평가된다.for/in 루프에서 사용하는 ‘변수’로는 할당 표현식의 좌변에 적합한 무언가로 평가되는 임의의 표현식을 사용할 수 있다. 이 표현식은 루프가 돌 때마다 평가되는데, 이때 매번 다르게 평가될 수 있다. 다음과 같은 코드를 사용하면 주어진 객체의 모든 프로퍼티 이름을 배열에 복사할 수 있다.123var o = {x:1, y:2, z:3};var a = [?], i = 0;for(a[i++] in o) /* 비어 있음 */; 자바스크립트 배열은 단순히 특별한 종류의 객체에 지나지 않는다. 따라서 for/in 루프는 객체의 프로퍼티와 마찬가지로 배열 인덱스 또한 하나씩 열거할 수 있다.for/in 루프는 실제로 객체가 가진 모든 프로퍼티를 열거하지 않고 오직 ‘열거 할 수 있는 프로퍼티’만 열거한다. 자바스크립트 코어에 정의된 다양한 내장 메서드들은 일반적으로 열거할 수 없다. (예를 들면 toString() 메서드) 5.6 점프문5.6.4 return함수를 호출하는 것 역시 표현식이고, 모든 표현식에는 값이 있다. return문은 함수 호출 표현식의 값, 즉 함수에서 반환하는 값을 지정하는 데 쓰인다. return문은 오직 함수 몸체 내부에서만 나타날 수 있다. 다른 곳에서 사용하면 문법 에러가 발생한다. return문이 실행되면 ‘표현식’이 평가되어 그 결과가 함수의 값으로 반환된다. 함수 내에 return문이 없다면 함수 호출은 단지 함수 몸체의 끝에 도달할 때까지 모든 구문을 차례로 실행하고, 호출한 지점으로 돌아간다. 이 경우에 해당 함수 호출 표현식의 값은 undefined가 된다. return문은 주로 함수의 마지막에 위치하지만 반드시 마지막에 있어야 하는것은 아니며, 함수 몸체 내에서 return문이 실행되면 아직 남은 문장들이 있어도 함수를 호출한 지점으로 돌아간다. 5.6.5 throw자바스크립트에서는 런타임 에러가 일어날 때마다 예외를 발생시킨다. Error 객체는 에러의 종류를 담고 있는 name 프로퍼티와 Error 클래스 생성자 함수에 넘기는 문자열 값을 담고 있는 message 프로퍼티를 갖고 있다.예외가 발생하면 자바스크립트 인터프리터는 정상적인 프로그램 실행을 즉시 중단하고 가장 가까운 예외 처리기로 넘어간다. 예외를 발생시킨 코드 블록이 catch절과 연결되어 있지 않으면, 인터프리터는 바로 상위 단계를 감싸고 있는 코드 블록에 연결된 예외 처리기가 있는지 확인한다. 이 과정은 처리기를 찾을 때까지 계속된다. 이같은 방법으로 자바스크립트의 언어적인 구조를 따라서, 즉 호출 스택을 따라서 예외가 전파되어 올라간다. 예외 처리기를 찾을 수 없는 경우 해당 예외는 에러로 취급되고 사용자에게 보고된다. 5.6.5 try/catch/finally try : 단순히 예외가 발생할지도 모르는 코드 블록을 정의하는 역할 catch : try 블록 내부에서 예외가 발생할 경우 호출되는 문장 블록 finally : try 블록에서 일어난 일에 관계없이 항상 실행이 보장되어야 할 뒷정리용 코드가 포함 정상적인 경우에, 자바스크립트 인터프리터는 try 블록의 끝까지 도달하고 난 후, finally 블록으로 이동해 무언가 필요한 뒷정리를 수행한다. 만일 인터프리터가 return, continue, break 문 등을 만나 try 블록의 제어를 벗어날 경우, 새 지점으로 이동하기 전에 finally 블록이 실행된다.만일 예외를 처리할 catch 블록이 없다면 인터프리터는 일단 finally 블록을 실행한 후 상위 블록으로 예외를 전파하여, 해당 예외를 처리할 수 있는 가장 가까운 catch 절로 이동한다. 5.7 기타5.7.1 withwith문은 유효범위 체인의 첫 번째에 ‘객체’를 추가한다. 그 후에 ‘문장’을 실행한 다음, 유효범위 체인을 ‘객체’를 추가하기 전 상태로 되돌려 놓는다. with문을 사용하는 자바스크립트 코드는 최적화하기 힘들고 with문을 사용하지 않는 코드에 비해 느리기 때문에 사용하지 않는것이 좋다. 5.7.2 debuggerdebugger문은 평소에는 아무것도 하지 않지만 디버거 프로그램을 사용할 수 있고 디버거가 실행 중일 때, 자바스크립트 구현체는 해당 위치에서 정의된 코드 디버깅을 수행한다. debugger문은 코드의 중단점(breakpoint)와 같이 동작한다. 자바스크립트 코드의 실행을 잠시 멈추고 디버거 프로그램을 사용해 변수의 값을 출력할 수 있고, 호출 스택등을 살펴볼 수 있다. 5.7.3 “use strict”'use strict'는 ECMAScript 5에서 처음 소개된 지시어다. ‘use strict’ 지시어를 사용하는 목적은 지시어 다음에 오는 (스크립트나 함수의) 코드들이 엄격 모드를 따르게 하기 위해서다. 스크립트의 최상단에 ‘use strict’ 지시어가 있으면 최상단(함수가 아닌) 코드는 엄격한 코드(엄격 모드를 따르는 코드)다.엄격한 코드는 엄격 모드에서 실행된다. ECMAScript 5의 엄격 모드는 언어의 일부 기능이 제한된 부분 집합으로, 몇 가지 주용한 언어적 문제점을 수정하고 강력한 에러 검사와 향상된 보안 기능을 제공한다. 다음과 같은 부분이 일반 모드와 다르다. with문은 엄격 모드에서 사용 불가능 하다. 엄격 모드에서 모든 변수는 반드시 선언되어야 한다. 선언되지 않은 변수나 함수, 함수 인자, catch 절 인자, 전역 객체 프로퍼티에 값을 할당하는 경우 ReferenceError 예외가 발생한다. 엄격 모드에서 함수는 메서드로 호출된 것이 아닌, 함수로 호출된 함수의 this 값은 undefined다. (표준 모드에서는 함수가 함수로 호출될 때 항상 전역 객체를 this의 값으로 넘겨주게 된다.) 또한 엄격 모드에서는 함수를 call()이나 apply()로 호출하면, this의 값은 정확히 call()이나 apply() 함수의 첫 번째 인자 값으로 설정된다. (표준 모드에서는 null과 undefined 값은 전역 객체로 대체되고, 객체가 아닌 값들은 객체로 바뀌게 된다.) 엄격 모드에서 함수의 arguments 객체는 함수에 전달된 값의 정적 사본을 갖고 있지만 표준 모드에서 arguments 배열의 원소와 함수의 전달인자는 동일한 값을 참조한다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/27/JavaScript/complete-guide-to-javascript-chapter-5/"},{"title":"자바스크립트 완벽가이드 6장 (객체)","text":"자바스크립트의 기본 데이터 타입은 객체다. 객체는 일종의 복합체로, 여러 값(원시 타입, 다른 객체)들을 묶어 이름으로 저장하고, 값을 가져올 수 있다. 객체는 이름과 값으로 구성된 프로퍼티들의 정렬되지 않은 집합이다. 자바스크립트 객체는 객체가 가진 고유 프로퍼티를 유지하는 것 외에 ‘프로토타입’이라고 하는 다른 객체의 프로퍼티를 상속 받는다. 객체의 메서드들은 일반적으로 상속받은 프로퍼티이고, 이를 '프로토타입 상속'이라고 한다. 프로토타입 상속은 자바스크립트의 핵심적 특징이다.자바스크립트 객체는 프로퍼티를 동적으로 추가하고 제거할 수 있기 때문에 동적이지만 자바스크립트의 객체는 정적 객체를 흉내 낼 수도 있고, 정적 타입 언어에서의 ‘구조체’처럼 사용할 수도 있다.자바스크립트에서는 문자열(string)과 숫자(number), true/false와 null/undefined를 제외한 나머지는 객체다. 비록 문자열과 숫자, 불리언 값은 객체는 아니지만 변경 불가능한 객체(Wrapper 객체)처럼 동작한다.객체의 각 프로퍼티는 ‘프로퍼티 속성’(쓰기, 열거, 설정) 이라고 하는 연관된 값을 갖는다.프로퍼티뿐 아니라, 모든 개체는 세 가지의 속성을 갖는다. prototype은 상속받은 프로퍼티들을 가진 객체를 참조한다. class는 객체의 자료형(타입)을 특정짓는 문자열이다. extensible 속성(ECMAScript 5)은 객체에 새 프로퍼티를 추가할 수 있는지를 결정한다. 참고 세 부류의 자바스크립트 객체 ‘네이티브 객체’는 ECMAScript 명세에 정의된 객체 또는 그 객체의 클래스다. Array, Function, Date, 정규 표현식들은 전부 네이티브 객체다. ‘호스트 객체’는 브라우저와 같이 자바스크립트 인터프리터가 내장된 호스트 환경에 정의된 객체다. ‘사용자 정의 객체’는 자바스크립트 코드의 실행으로 생성된 객체다. 두 종류의 프로퍼티 ‘고유 프로퍼티’는 객체에 직접 정의된 프로퍼티다. ‘상속받은 프로퍼티’는 객체의 프로토타입 객체가 정의한 프로퍼티를 말한다. 6.1 객체 생성하기객체 리터럴을 통해 만들 수도 있고, new 키워드를 사용해 만들 수도 있으며, ECMAScript 5의 Object.create() 함수를 통해서도 생성할 수도 있다. 6.1.1 객체 리터럴객체 리터럴은 평가될 때마다 새로운 객체를 생성하고 초기화하는 표현식이다. 각 프로퍼티의 값 또한 리터럴이 평가될 때마다 새롭게 계산된다. 따라서 하나의 객체 리터럴은 수많은 객체를 만들 수 있다. 객체 리터럴이 반복적으로 호출되는 함수 내부의 루프 몸체에 있는 경우, 매 순간 생기는 객체의 프로퍼티 값들은 서로 다를 것이다. 6.1.2 new를 사용해 객체 생성하기new 연산자는 객체를 만들고, 초기화한다. new 키워드 다음에는 반드시 함수 호출문이 와야한다. 이때 호출되는 함수를 생성자(constructor)라고 한다. 새로 생성된 객체를 초기화하는 역할을 한다. 코어 자바스크립트는 기본 타입에 대한 생성자를 내장하고 있다. 6.1.3 프로토타입자바스크립트의 모든 객체는 또 다른 자바스크립트 객체와 연관되어 있다. 이 두번째 객체는 프로토타입(prototype)으로 알려져있고, 이때 객체는 프로토타입으로부터 프로퍼티들을 상속받는다. 객체 리터럴로 생성된 모든 객체는 프로토타입 객체가 같으며, 자바스크립트 코드에서 이 프로토타입 객체는 Object.prototype으로 참조할 수 있다.new 키워드를 사용해 생성자를 호출하면, 생성자 함수의 프로토타입이 생성된 객체의 프로토타입이된다. 따라서 new Object()로 생성된 객체는 {}로 생성된 객체와 마찬가지로 Object.prototype를 상속받는다. 마찬가지로, new Array()로 생성된 객체는 Array.prototype을 객체의 프로토타입으로 사용하고, new Date()로 생성된 객체는 Date.prototype을 객체의 프로토타입으로 사용한다. 모든 내장 생성자는 (그리고 대부분의 사용자 정의 생성자는) Object.prototype을 상속하는 객체를 프로토타입으로 갖는다. 예를 들어, Date.prototype은 Object.prototype의 프로퍼티들을 상속받는다. 따라서 new Date()를 통해 생성한 Date 객체는 Date.prototype과 Object.prototype으로부터 프로퍼티를 상속받는다. 이처럼 프로토타입 객체들이 연결된 것을 '프로토타입 체인'이라고 한다. 6.1.4 Object.create()ECMAScript 5는 객체를 생성하는 Object.create() 메서드를 지원한다. 이 메서드의 첫 번째 인자가 프로토타입 객체다. Object.create()는 새 객체의 프로퍼티 정보를 두 번째 인자로 받을 수 있는데, 이 인자는 생략할 수 있다.Object.create()는 정적 함수로, 개별 객체를 통해 호출되는 메서드가 아니다. 함수를 사용하기 위해서는 단순히 프로토타입 객체를 넘기기만 하면 된다.1var o1 = Object.create({x:1, y:2}); // o1은 x, y 프로퍼티를 상속받는다. 프로토타입을 갖지 않는 새 객체를 만들기 위해서는 함수에 null을 전달하면 된다. 하지만 이 경우 새롭게 생성된 객체는 어떠한 객체도 상속받지 않기 때문에 toString() 메서드와 같은 기본적인 메서드조차 사용할 수 없다. 만약 {} 또는 new Object()가 만들어내는 것과 같은 일반적인 빈 객체를 만들고 싶다면, 함수에 Object.prototype을 전달한다.1var o2 = Object.create(Object.prototype); // o2은 {} 또는 new Object()와 같은 객체다. 6.2 프로퍼티 접근 및 설정6.2.1 연관 배열로서의 객체1object[\"property\"] 위와 같은 형태는 마치 문자열을 인덱스로 갖는 배열에 접근하는 형태와 유사하다. 이러한 형태의 배열을 연관 배열이라고 하고, 해시나 맵, 사전이라고도 한다. 모든 자바스크립트 객체는 연관 배열이다.자바스크립트는 C나 C++, 자바에 비해 타입의 제약이 느슨하다. 프로그램은 객체 안에 수많은 프로퍼티들을 만들 수 있다. 하지만 마침표(.) 연산자를 사용해 객체의 프로퍼티에 접근할 때는 프로퍼티의 이름을 반드시 식별자로 표현해야 한다. 식별자는 자바스크립트 프로그램에 직접 타이핑해 넣은 이름이며 자료형이 없으므로 프로그램이 실행되는 도중이 변경할 수 없다.반면에 [] 연산자를 사용해 객체의 프로퍼티에 접근할 때는 프로퍼티의 이름을 문자열로 표현한다. 문자열은 자바스크립트의 자료형이므로 프로그램 실행중에 생성하고 조작할 수 있다. 따라서 다음의 코드가 가능하다. 다음의 코드는 customer 객체의 address0, address1, address2, address3 프로퍼티 값을 읽고, 읽은 값을 addr 변수에 차례대로 이어 붙인다.1234var addr = \"\";for(i = 0; i &lt; 4; i++) { addr += customer[\"address\" + i] + '\\n';} 6.2.2 상속자바스크립트 객체는 고유 프로퍼티들을 갖고 있고, 동시에 해당 객체의 프로토타입 객체로부터 여러 프로퍼티들을 상속받는다.객체 o에서 프로퍼티 x를 찾는다고 했을때, 객체 o가 프로토타입 객체에 고유 프로퍼티 x가 없다면, 해당 프로토타입 객체에서 x를 찾는다. 만약 프로토타입 객체에 고유 프로퍼티 x가 없다면, 해당 프로토타입 객체가 역시 또 다른 프로토타입을 가진 경우, 그 또 다른 프로토타입 객체에서 프로퍼티 x를 찾는다. 이 작업은 프로퍼티 x를 찾거나 prototype이 null인 객체가 발견될 때까지 계속된다. 이처럼 객체의 prototype 속성은 프로퍼티가 계승되는 체인 또는 연결리스트를 생성한다.다음은 객체 o의 프로퍼티 x에 값을 설정하는 경우이다. 객체 o가 상속받지 않은 고유 프로퍼티 x를 갖고 있는 경우에는 기존의 프로퍼티 값을 단순히 바꿀 수 있다. 프로퍼티 x를 갖고 있지않은 경우에는 객체 o에 프로퍼티 x를 만든 후 값을 설정한다. 따라서 만약 객체 o가 프로퍼티 x를 상속받은 상태였다면, 기존에 상속받은 프로퍼티의 x값은 새로 설정되는 값에 의해 가려지게 된다.객체의 프로퍼티에 값을 설정할 때는 해당 프로퍼티에 값을 설정할 수 있는지 알아보기 위해 프로토타입 체인을 검사한다. 예를 들어, 객체 o가 상속한 프로퍼티 x가 읽기 전용이라면 해당 프로퍼티에는 값을 설정할 수 없다. 하지만 값 설정이 허용된다면 원래 객체에 새로운 프로퍼티가 만들어지거나 그 값이 설정되며, 프로토타입 체인은 결코 변경되지 않는다. 프로퍼티를 질의 할 때는 상속이 동작하지만 설정할 때는 그렇지 않다는 것은 자바스크립트의 중요한 특징 중 하나다. 계승된 프로퍼티를 선택적으로 재정의 할 수 있기 때문이다. 6.2.3 프로퍼티 접근 에러프로퍼티 접근 표현식을 사용해도 항상 값을 얻을 수 있거나 값을 설정할 수 있는 것은 아니다.존재하지 않는 프로퍼티에는 접근해도 에러가 발생하지 않는다. 존재하지 않는 프로퍼티는 undefined로 평가된다. 하지만 존재하지 않는 객체의 프로퍼티에 접근하려고 하면 에러가 발생한다. null과 undefined 값은 어떠한 프로퍼티도 갖지 않기 때문에 이들 값에 프로퍼티로 접근을 시도하면 에러가 발생한다. 6.3 프로퍼티 삭제하기delete 연산자는 객체의 프로퍼티를 삭제한다. 이 연산자는 프로퍼티의 값을 지우는 것이 아니라 프로퍼티를 지운다. delete 연산자는 상속받은 프로퍼티가 아닌 고유 프로퍼티만 지울 수 있다. (상속받은 프로퍼티를 지우기 위해서는 해당 프로퍼티가 정의된 프로토타입 객체에서 지워야 하고, 삭제에 성공하면 프로토타입 객체를 상속한 모든 객체가 영향을 받는다.) 6.4 프로퍼티 검사하기in 연산자 왼쪽에는 프로퍼티 이름이 문자열로 와야하고 오른쪽에는 개체가 와야한다. 객체에 해당 프로퍼티가 존재하면 true가 반환된다.123var o = { x: 1 }\"x\" in o; // 객체 o에 고유 프로퍼티 x가 존재하므로 true를 반환한다.\"toString\" in o; // 객체 o에 상속받은 프로퍼티 toString가 있기 때문에 true를 반환한다. 객체의 hasOwnProperty() 메서드는 주어진 이름의 프로퍼티가 객체에 존재하는지 검사한다. 상속받은 프로퍼티의 경우는 false를 반환한다.123var o = { x: 1 }o.hasOwnProperty(\"x\"); // 객체 o에 고유 프로퍼티 x가 존재하므로 true를 반환한다.o.hasOwnProperty(\"toString\"); // toString은 상속받은 프로퍼티이기 때문에 false를 반환한다. propertyIsEnumerable() 메서드는 hasOwnProperty()보다 상세한 검사를 한다.undefined가 아니지만 확인할 때는 in 연산자 대신 논리 연산자 !==를 사용하는 편이 훨씬 효과적이다.123var o = { x: 1 }o.x !== undefined; // true: 객체 o에 프로퍼티 x가 존재한다.o.y !== undefined; // false: 객체 o에 프로퍼티 y가 존재하지 않는다. in 연산까지 사용하면 객체에 프로퍼티가 존재하지 않는 경우와 객체에 프로퍼티가 존재하지만 값이 undefined인 경우를 구별할 수 있다.12345var o = { x: undefined } // 프로퍼티가 분명히 존재하지만 값이 undefined다.o.x !== undefined // false: 프로퍼티가 존재하지만 값이 undefined다.o.y !== undefined // false: 프로퍼티가 존재하지 않는다.하지만 값이 undefined다.\"x\" in o // true: 프로퍼티가 존재한다.\"y\" in o // false: 프로퍼티가 존재하지 않는다. 6.5 프로퍼티 열거하기객체가 가진 모든 프로퍼티들을 순회하고 싶을 때는 보통 for/in 루프토 해결한다.지정한 객체가 가진 고유 프로퍼티 또는 상속된 프로퍼티들 중 열거 가능한 프로퍼티들마다 for/in 루프의 몸체가 실행된다. 상속받은 내장 메서드는 열거할 수 없지만, 사용자가 임의로 추가한 프로퍼티들은 열거할 수 있다.(임의로 열거할 수 없도록 설정하는 함수를 사용할 수도 있다.)12345var o = { x:1, y:2, z:3 } // 열거할 수 있는 3개의 고유 프로퍼티o.propertyIsEnumerable(\"toString\"); // =&gt; false: toString은 열거할 수 없는 프로퍼티for(p in o) // 객체 o의 모든 프로퍼티에 대해 console.log(p); // 프로퍼티 이름을 출력. 결과는 x, y, z가 출력 // toString은 출력되지 않는다. for/in 루프 말고도 ECMAScript 5에는 프로퍼티 이름을 열거하는 두가지 함수가 더 있다. Object.keys() : 객체가 가진 고유 프로퍼티 중에 열거할 수 있는 프로퍼티 이름을 배열에 담아 반환한다. Object.getOwnPropertyNames() : 프로퍼티를 열거하는 함수다. Object.keys()는 객체가 가진 ‘열거할 수 있는’ 고유 프로퍼티들을 배열에 담아 반환하지만, Object.getOwnPropertyNames()는 해당 객체가 가진 모든 고유 프로퍼티의 이름을 배열로 반환한다. 6.6 프로퍼티 Getter와 SetterECMAScript 5에서 프로퍼티의 값은 getter/setter 메서드로 대채할 수 있다. getter/setter 메서드로 정의된 프로퍼티는 단순히 값을 갖는 ‘데이터 프로퍼티’와는 다른 '접근자 프로퍼티'라고 한다.프로그램이 객체의 접근자 프로퍼티의 값에 접근하면, 자바스크립트 엔진은 getter 메서드를 아무런 인자없이 호출하고 이때 반환 값이 프로퍼티 접근 표현식의 값이 된다. 프로그램이 프로퍼티의 값을 변경하려고 하면, 자바스크립트 엔진은 setter 메서드를 호출한다. 이때 할당자(=)의 오른쪽에 있는 값을 setter 메서드의 인자로 전달한다. setter 메서드는 프로퍼티의 값을 ‘설정’하는 것을 담당하고, 그 반환값은 무시된다.데이터 프로퍼티가 writable(쓰기) 속성을 갖는 반면, 접근자 프로퍼티는 쓰기 속성이 없다. 만약 프로퍼티가 getter/setter 메서드를 모두 갖고 있으면, 읽기/쓰기 모두 가능한 프로퍼티인 것이고, 프로퍼티가 getter 메서드만 갖고 있다면, 읽기 전용 프로퍼티인 것이다. 프로퍼티가 setter 메서드만 갖고 있으면 쓰기 전용 프로퍼티고, 이때 읽기를 시도하면 항상 undefined가 반환된다.접근자 프로퍼티는 다음과 같이 확장된 객체 리터럴 문법을 사용하여 쉽게 정의할 수 있다.1234567var o = { // 데이터 프로퍼티 data_prop: value, // 한 쌍의 함수로 정의된 접근자 프로퍼티 get accessor_prop() { /* 함수 몸체 */ }, set accessor_prop(value) { /* 함수 몸체 */ },} 접근자 프로퍼티는 그 이름이 프로퍼티 이름과 같은 하나 또는 두 개의 함수이며, 함수 정의에 사용되는 function 키워드 대신 get/set을 사용한다.자바스크립트는 getter/setter 함수를 객체의 메서드로서 호출한다. 이는 함수의 몸체 안에 사용된 this 키워드가 객체 자신을 가리킨다는 뜻이다. 접근자 프로퍼티는 데이터 프로퍼티와 마찬가지로 상속할 수 있다. 6.7 프로퍼티 속성프로퍼티에는 프로퍼티로 할 수 있는 작업을 결정하는 세 가지 속성이 있다. writable : 프로퍼티 값의 변경 가능 여부를 결정 enumerable : 프로퍼티가 열거될 수 있는지 여부를 결정 configurable : configurable 속성뿐 아니라 writable 속성과 enumerable 속성 값의 변경 가능 여부를 결정 접근자 프로퍼티의 getter/setter 메서드를 프로퍼티가 가진 속성으로 다룬다면 접근자 프로퍼티의 네 가지 속성은 get, set, enumerable, configurable이다.ECMAScript 5에서는 프로퍼티의 속성 값을 질의하고, 값을 설정할 수 있는 프로퍼티 디스크립터라는 객체를 제공한다. 이 객체의 프로퍼티 이름은 표현 대상 속성의 이름과 같다. 데이터 프로퍼티의 프로퍼티 디스크립터 객체의 프로퍼티 : value, writable, enumerable, configurable 접근자 프로퍼티의 프로퍼티 디스크립터 객체의 프로퍼티 : get, set, enumerable, configurable객체가 가진 특정 프로퍼티에 대한 프로퍼티 디스크립터 객체는 Object.getOwnPropertyDescriptor()를 통해 얻을 수 있다. (Object.getOwnPropertyDescriptor()는 객체의 고유 프로퍼티에서만 동작한다.)12// { value: 1, writable: true, enumerable:true, configurable:true }를 반환한다.Object.getOwnPropertyDescriptor({x:1} \"x\"); 프로퍼티의 속성을 설정하거나 임의의 속성으로 새 프로퍼티를 만들기 위해서는 Object.defineProperty()를 호출한다. 함수의 인자로, 수정할 객체와 추가하거나 변경할 프로퍼티 이름, 프로퍼티의 디스크립터 객체를 넘긴다.12var o = { };Object.defineProperty(o, \"x\", {value: 1, writable: true, enumerable: false, configurable:true}); 6.1 절에 있었던 ECMAScript 5 메서드인 Object.create() 메서드의 첫 번째 인자로는 새로 생성할 객체의 프로토타입 객체이며, 두 번째 선택 인자는 Object.defineProperty() 의 두 번째 인자와 같다. 이 두 번째 인자는, 생성된 객체에 프로퍼티로 추가된다.12345678910111213141516171819202122232425262728// Object.getOwnPropertyDescriptor()와 Object.defineProperty() 메서드를 사용하여 프로퍼티가 가진 속성까지 복사하는 extend() 함수//// Object.prototype에 열거되지 않는 메서드 extend()를 추가한다.// 이 메서드는 호출 시에 인자로 전달된 객체에서 프로퍼티들을 복사하여 객체를 확장한다.// 단순 프로퍼티의 값뿐 아니라 모든 프로퍼티 속성을 복사한다.// 인자로 넘긴 객체가 소유한 모든 고유 프로퍼티는 대상 객체에 같은 이름의// 프로퍼티가 존재하지 않는 한 대상 객체에 복사된다.Object.defineProperty(Object.prototype, \"extend\", // Object.prototype.extend를 정의한다. { writable: true, enumerable: false, // 열거 불가능 configurable: true, value: function(o) { // Object.prototype.extend 메서드의 값은 함수다. // 열거되지 않는 프로퍼티들을 포함한 고유 프로퍼티에 대해 var names = Object.getOwnPropertyNames(o); for(var i = 0; i &lt; names.length; i ++) { // this 객체에 이미 같은 이름의 프로퍼티가 존재하면 건너뛴다. if (names[i] in this) continue; // 객체 o의 프로퍼티 디스크립터를 가져온다. var desc = Object.getOwnPropertyDescriptor(o, names[i]); // this 객체에 프로퍼티를 생성할 때 앞에서 가져온 디스크립터 객체를 사용한다. Object.defineProperty(this, name[i], desc); } } }); 6.8 객체 속성모든 객체는 prototype, class, extensible 속성을 갖고 있다. 6.8.1 prototype 속성prototype 속성은 객체가 만들어지는 시점에 설정된다. 객체 리터럴을 통해 만든 객체는 Object.prototype을 객체의 프로토타입으로 설정하고, new를 사용해 만든 객체는 생성자 함수의 prototype 프로퍼티값이 prototype이 된다. Object.create() 메서드로 만든 객체는 메서드의 첫 번째 인자가 프로토타입 속성의 값이 된다.객체 A가 객체 B의 프로토타입(또는 프로토타입 체인의 일부)인지 알아보기 위해서는 isPrototypeOf() 메서드를 사용한다.1234var p = { x: 1 }var o = Object.create(p);p.isPrototypeOf(o) // =&gt; true: 객체 o는 객체 p를 상속받는다.Object.prototype.isPrototypeOf(p) // =&gt; true: 객체 p는 Object.prototype을 상속받는다. 6.8.2 class 속성객체의 class 속성은 객체의 타입에 대한 정보를 담고 있는 문자열이다.Object.prototype으로부터 상속되는 기본(default) toString() 메서드는 객체의 타입을 아래 형태의 문자열로 반환한다.1[object class] 따라서 객체의 클래스 정보를 알아보기 위해서는 객체의 toString() 메서드를 호출하면 된다. 6.8.3 extensible 속성객체의 extensible 속성은 객체에 새 프로퍼티를 추가할 수 있는지 여부를 결정한다. extensible 속성의 목적은 ‘잠겨있는’ 객체의 상태를 고정하고, 외부에서 변경하는 것을 막는 것이다. ECMAScript 5에서는 모든 내장 객체와 사용자 정의 객체는 확장할 수 없게 바뀌지 않는한 확장 가능하고, 호스트 객체의 확장성은 구현체에 따라 다르다.확장할 수 있는 객체인지 알아보려면 object.isExtensible() 함수에 해당 객체를 인자로 넘긴다. 객체를 확장할 수 없도록 하려면, Object.preventExtensions()에 해당 객체를 인자로 넘긴다. 해당함수를 사용하면 전 상태로 돌아갈 수 없다. 또한 extensible 속성 값이 false인 객체라도, 프로토타입에 새 프로퍼티를 추가하면, 추가된 프로퍼티는 해당 객체에 상속된다. 6.9 객체 직렬화하기객체 직렬화는 객체의 상태를 문자열로 변환하는 과정을 말한다. ECMAScript 5는 자바스크립트 객체를 직렬화하는 JSON.stringify() 메서드와 직렬화한 문자열을 객체로 복원하는 JSON.parse() 메서드를 지원한다. 이 두 함수는 JSON 데이터 교환 형식을 사용한다. JSON은 ‘JavaScript Object Notation’의 줄임 표현이다.JSON 문법은 자바스크립트 문법의 부분 집합이기 때문에, 자바스크립트의 모든 값을 표현할 수는 없다. Function, RegExp, Error 객체와 undefined 값은 직렬화하거나 복원할 수 없다. JSON.stringify() 메서드는 객체가 가진 열거 가능한 고유 프로퍼티만 직렬화한다. 6.10 객체 메서드모든 자바스크립트 객체는 Object.prototype의 프로퍼티를 상속받는다. 상속된 프로퍼티들은 대부분 메서드이고, 어느 객체에서도 사용할 수 있기 때문에 주요 메서드라고 할 수 있다. 6.10.1 toString() 메서드toString() 메서드는 어떠한 인자도 받지 않고, 호출 대상 객체의 값을 어떠한 방식으로든 문자열로 만들어서 반환한다. 자바스크립트는 객체를 문자열로 변환해야 할 때 항상 toString() 메서드를 사용한다. 6.10.3 toJSON() 메서드Object.prototype에는 toJSON() 메서드가 정의되어 있지 않다. 하지만 JSON.stringify() 메서드는, 직렬화할 객체에 toJSON() 메서드가 있는지 찾고, 만약 있다면, toJSON() 메서드가 호출되고 그 결과 값이 원래 객체 대신 직렬화된다. 6.10.4 vluaeOf() 메서드valueOf() 메서드는 toString() 메서드와 매우 비슷하다. 이 메서드는 객체가 원시 타입 값을 필요로 하는 문맥 안에서 사용될 때, 자바스크립트는 valueOf() 메서드를 자동으로 호출한다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/28/JavaScript/complete-guide-to-javascript-chapter-6/"},{"title":"자바스크립트 완벽가이드 9장 (클래스와 모듈)","text":"자바스크립트에서 클래스는 프로토타입 기반의 상속 메커니즘을 기반으로 하고있다. 두 객체가 같은 프로토타입 객체로부터 프로퍼티를 상속받았다면, 둘은 같은 클래스의 인스턴스다. 자바스크립트의 클래스와 프로토타입 기반 상속 메커니즘은 자바나 그와 비슷한 언어의 클래스 상속과는 상당히 다르다. 자바스크립트 클래스의 중요한 특징 중 하나는 동적으로 확장될 수 있다는 것이다. 클래스를 정의한 다는 말은 모듈화되고 재사용 가능한 코드를 작성한다는 뜻이다. 9.1 클래스와 프로토타입자바스크립트의 클래스는 같은 프로토타입 객체로부터 프로퍼티를 상속받은 객체의 집합이다. 따라서 프로토타입 객체는 클래스의 핵심이다. 9.2 클래스와 생성자생성자는 새로 생성된 객체를 초기화하는 용도로 사용되는 함수다. 생성자는 new 키워드를 사용하여 호출한다. 생성자를 호출하면 자동으로 새로운 객체가 생성되고, 생성자 함수 내부에서 새로 생성된 객체를 사용하기 때문에, 생성자 함수는 새 객체의 상태를 초기화하는 데만 신경 쓰면 된다. 생성자 호출의 핵심적인 특징은 생성자의 prototype 프로퍼티가 새 객체의 프로토타입으로 사용된다는 것이다. 이는 한 생성자를 통해 생성된 모든 객체는 같은 객체를 상속하고, 따라서 같은 클래스의 멤버임을 뜻한다.클래스와 생성자 함수의 이름은 대문자로 시작하는 것은 매우 일반적은 코딩 규칙이다. 일반 함수와 메서드는 소문자로 이름을 시작한다.새 객체는 생성자 함수가 실행되기 전에 자동으로 생성되고, 생성자 함수 내에서 this 값으로 접근할 수 있다. 생성자는 그저 새 객체를 초기화하기만 하면 되고 생성된 객체를 반환할 필요도 없다. 생성자를 호출하면 새 객체는 자동으로 생성되고, 새 객체의 메서드로서 생성자 함수가 호출된 다음, 초기화가 완료된 새 객체가 반환된다. 생성자 호출이 일반적인 함수 호출과 크게 다른것이 생성자 이름의 첫 글자를 대문자로 하는 또 하나의 이유다. 생성자는 new 키워드를 사용하여 호출된다고 가정하기 때문에, 일반적인 함수 호출처럼 호출하면 보통 제대로 작동하지 않는다. 9.2.1 생성자와 클래스 구별프로토타입 객체는 클래스를 구별할 때 핵심적인 역할을 한다. 두 객체는 같은 프로토타입 객체를 상속한 경우에만 같은 클래스의 인스턴스다. 새로 생성된 객체의 상태를 초기화하는 생성자 함수는 클래스 구별의 핵심이 아니다. 서로 다른 두 생성자 함수라도 같은 프로토타입 객체를 가리키는 prototype 프로퍼티를 가질 수 있다. 그러면 두 생성자는 같은 클래스의 인스턴스를 만드는데 사용될 수 있다.생성자가 prototype 만큼 객체 구별에 핵심적인 역할을 하지는 않더라도, 생성자는 클래스를 대표하는 역할을 한다. 생성자는 객체가 어떤 클래스에 속한 것인지 검사할 때 instanceof 연산자와 같이 사용된다.1r instanceof Rnage // r이 Range.prototype을 상속했다면 true를 반환한다. instanceof 연산자는 실제로 r이 Range 생성자에 의해 초기화되었는지를 검사하지는 않고, r이 Range.prototype을 상속하는지를 검사한다. 9.2.2 constructor 프로퍼티모든 자바스크립트 함수는 생성자로 사용될 수 있는데, 함수가 생성자로 호출되려면 prototype 프로퍼티가 있어야 한다. 따라서 모든 자바스크립트 함수에는 자동으로 prototype 프로퍼티가 설정된다. 이 prototype 프로퍼티의 값은 constructor 프로퍼티 하나만 가진 객체다. constructor 프로퍼티는 열거되지 않으며 constructor 프로퍼티의 값은 해당 함수 객체다.1234var F = function() {}; // 함수 객체다.var p = F.prototype; // F와 연관이 있는 프로토타입 객체다.var c = p.constructor; // 프로토타입과 관련한 함수 객체다.c === F // =&gt; true: 모든 함수에 대해 F.prototype.constructor==F이다. 미리 정의된 프로토타입 객체가 있고 이 프로토타입 객체가 constructor 프로퍼티를 갖고 있다는 말은, 일반적으로 어떤 객체가 자기 자신의 생성자를 가리키는 constructor 프로퍼티 또한 상속하고 있음을 뜻한다.별도로 정의한 프로토타입 객체에는 constructor 프로퍼티가 없다. 따라서 해당 클래스의 인스턴스에도 constructor 프로퍼티는 없을 것이다. 이 문제는 명시적으로 프로토타입 객체에 constructor 프로퍼티를 추가함으로써 해결한다. 일반적인 또 다른 기법은 constructor 프로퍼티가 미리 정의되어 있는 prototype 객체를 사용하는 것이다. 거기에 하나씩 메서드를 추가해가면 된다. 9.3 자바 스타일 클래스자바스크립트가 자바와 다른 점 한가지는 함수가 값이라는 점이고, 따라서 메서드와 필드 사이에는 뚜렷한 구분이 없다. 프로퍼티 값이 함수라면 그 프로퍼티는 메서드이고, 함수가 아니라면 보통의 프로퍼티나 ‘필드’일 뿐이다.자바스크립트가 자바 스타일의 클래스 멤버를 흉내 낼 수 있지만, 자바의 중요한 특징 중 자바스크립트가 지원하지 않는 것이 몇 가지 있다. 먼저 자바는 인스턴스 메서드 안에서 인스턴스 필드를 메서드의 지역 변수처럼 사용할 수 있고, this를 비롯한 어떤 접두사도 붙일 필요가 없다. 자바스크립트는 이를 지원하지 않지만, with문을 사용하여 비슷한 효과를 얻을 수 있다.(권장X) 자바에서는 final을 사용하여 상수 필드를 정의할 수 있다. 그리고 클래스 내부에서만 사용하고 외부에서 볼 수 없는 필드나 메서드는 private으로 정의할 수 있다. 자바스크립트에는 이런 키워드들이 없다. 따라서 힌트를 제공하는 표기 규칙을 사용한다.(값이 변경되면 안 되는 프로퍼티들은 이름이 대문자이고, 밑줄로 시작하는 이름의 프로퍼티는 클래스 외부에서 사용하면 안된다는 뜻이다.)private 프로퍼티는 클로저의 지역 변수로 흉내 낼 수 있고, 상수 프로퍼티는 ECMAScript 5에서는 사용 가능하다. 9.4 클래스 확장하기자바스크립트의 프로토타입 기반 상속 메커니즘은 동적이다. 객체는 자신의 프로토타입에서 프로퍼티를 상속받는데, 심지어 이는 객체가 생성된 이후에 프로토타입이 변경되더라도 마찬가지다. 다시말해 자바스크립트 객체의 프로토타입에 메서드를 추가함으로써 간단히 자바스크립트 클래스를 확장할 수 있다는 뜻이다.Object.prototype에도 메서드를 추가할 수 있고, 그러면 모든 객체에서 추가된 메서드를 사용할 수 있지만 이 프로퍼티는 모든 for/in 루프에서 열거될 것이기 때문에 권장하지 않는다.호스트 환경(웹브라우저 같은)에서 정의된 클래스를 이러한 방식으로 확장할 수 있는지는 호스트 환경의 구현체마다 다르다. 이 때문에 클라이언트 측 프로그래밍에서 이러한 기법의 사용은 몹시 제한받는다. 9.5 클래스와 자료형9.5.1 instanceof 연산자왼쪽 피연산자는 클래스를 판별하려는 객체이며, 오른쪽 피연산자는 생성자 함수여야 하는데, 이 생성자 함수의 이름이 곧 해당 클래스의 이름이다. 표현식 o instanceof c는 만약 o가 c.prototype을 상속한다면 true다.(상속은 직접적일 필요없고, 만약 o가 c.prototype을 상속한 어떤 객체를 상속한다해도 이 표현식은 true이다.)instanceof 연산자는 생성자 함수를 요구하지만, 실제로 instanceof 연산자는 객체가 어떤 프로토타입을 상속했는지를 검사하여 객체를 생성하는 데 어떤 생성자를 사용했는지 테스트하지는 않는다. 만약 생성자 함수를 검사의 기준으로 삼고 싶다면, isPrototype() 메서드를 대신 사용할 수 있다. 9.5.2 constructor 프로퍼티어떤 객체의 클래스를 구별하는 또 다른 방법은 constructor 프로퍼티를 사용하는 것이다. constructor 프로퍼티를 사용하는 이 기법은 instanceof와 같은 문제가 있으며 자바스크립트 객체 가운데는 constructor 프로퍼티가 없는 것도 있을 수 있다. 9.6 자바스크립트의 객체 지향 기법9.6.3 표준 변환 메서드객체 자료형을 변환하는 데 사용되는 중요한 메서드들이 있고, 이 중 몇 가지 형 변환이 푤아할 때 자바스크립트 인터프리터에 의해 자동으로 호출된다. 작성한 클래스에 변환 메서드를 구현하지 않았다면, 이는 단순히 술수로 구현하지 않은 것이 아니라 의도적인 것이어야 한다.먼저, 가장 중요한 메서드는 toString()이다. 이 메서드의 목적은 객체의 문자열 표현을 반환하는 것이다. 자바스크립트는 필요할 때 자동으로 이 메서드를 호출한다. 프로퍼티 이름 같이 문자열을 요구하는 곳에 객체를 사용했을 때 또는 문자열 결합을 위해 + 연산자를 사용했을 때 toString() 메서드가 호출된다. 만약 이 메서드를 구현하지 않으면, 클래스는 Object.prototype의 기본 구현을 상속할 것이고, 그 기본 구현 메서드는 쓸모 없는 문자열 “[object Object]”를 반환할 것이다.다음 메서드는 valueOf()이다. 이 메서드는 객체를 원시 값으로 변환한다. 예를 들면, valueOf() 메서드는 객체가 숫자 컨텍스트에서 산술 연산자(+ 제외)나 비교 연산자와 함께 사용될 때 자동으로 호출된다. 객체 대부분은 원시 값으로 변환할 필요가 없으므로, 이 메서드를 정의하지 않는다.다음 메서드는 toJson()이고 JSON.stringify()에 의해 자동으로 호출된다. JSON 형식은 데이터 구조를 직렬화하는데 사용되고 자바스크립트 원시 값, 배열, 일반 객체를 처리할 수 있다. 직렬화 할 때 객체의 프로토타입과 생성자는 무시된다. 9.6.4 비교 메서드자바스크립트의 동치 연산자들은 객체를 비교할 때, 값이 아니라 참조를 사용한다. 즉, 주어진 두 참조가 같은 객체를 가리키고 있는지를 본다. 만약 어떤 클래스를 정의하고 이 클래스의 인스턴스를 비교하려면 비교하는 데 사용할 메서드를 정의해야 한다.인스턴스를 동등 비교하려면, equals()라는 인스턴스 메서드를 정의해야 한다. equals() 메서드는 하나의 인자를 받고, 전달받은 인자와 equals 메서드를 가진 객체가 같다면 true를 반환한다. 클래스 컨텍스트상에서 ‘같다’라는 것이 어떤 의미인지는 구현에 달려있다.객체를 어떤 순서에 따라 비교하는 것도 유용하다. 어떤 클래스의 한 인스턴스가 다른 인스턴스보다 ‘작다’ 또는 ‘크다’라고 말할 수 있게된다. 만약 &lt;와 &lt;=같은 관계 연산자에 객체를 사용하면 자바스크립트는 먼저 해당 객체의 valueOf() 메서드를 호출하고, 이 메서드가 원시 값을 반환하면 값을 비교한다. 그러나 대다수 클래스에는 valueOf() 메서드가 없다. 만약 valueOf() 메서드가 없는 객체들을 명시적으로 선택한 순서에 따라 비교하려면, compareTo() 메서드를 정의해야 한다.compareTo() 메서드는 하나의 인자를 받고, 메서드 호출 대상 객체와 인자를 비교한다. 만약 this 객체가 인자 객체보다 작으면 compareTo()는 0보다 작은 값을 반환해야 하며, this 객체가 인자 객체보다 크면 0보다 큰 값을 반환해야 한다. 만약 두 객체가 같으면 을 반환해야 한다. 가장 좋은 방법은 equals() 메서드와 compareTo() 메서드를 일관성 있게 작성하는 것이다.클래스에 compareTo() 메서드를 정의하는 한 가지 이유는 해당 클래스의 인스턴스들로 구성된 배열을 정렬하기 위함이다. Array.sort() 메서드는 추가 인자로 인스턴스를 비교하는 함수를 받는데, 이 비교 함수는 compareTo() 메서드와 똑같은 반환 값 규칙을 사용한다.1ranges.sort(function(a, b) { return a.compareTo(b); }); 9.6.6 private 상태인스턴스를 생성할 때, 생성자 호출의 클로저에 포착된 변수(혹은 인자)를 사용하면 private 인스턴스 필드를 흉내 낼 수 있다. 그러면 생성자 내부에서 함수들을 정의하고, 이 함수들을 새로 생성한 객체의 프로퍼티로 할당해야 한다.123456789101112131415// 예제) 시작점과 끝점에 대해 약한 캡슐화가 적용된 Range 클래스function Range(from , to) { // this 객체의 프로퍼티로 from, to를 저장하지 말 것. // 대신에 시작점과 끝점을 반환하는 접근자 함수를 정의한다. // 인자로 넘어온 from, to 값은 클로저에 저장된다. this.from = function() { return from; } this.to = function() { return to; } // 프로토타입의 메서드들은 생성자에 인자로 전달된 from, to를 직접 볼 수 없다. // 프로토타입의 메서드들은 다른 모든 것과 마찬가지로 접근자 메서드를 호출해야 한다. Range.prototype = { constructor: Range, includes: function(x) { return this.from() &lt;= x &amp;&amp; x &lt;= this.to(); }; }}; 이러한 캡슐화 기법에는 오버헤드가 있다. 상태를 캡슐화하도록 클로저를 사용하는 클래스는 그렇지 않은 클래스보다 확실히 느리고 크다. 9.7 서브클래스객체 지향 프로그래밍에서 클래스 B는 다른 클래스 A를 확장(extend)하거나 클래스 A의 하위클래스가 될 수 있다. 이런 경우, 클래스 A를 슈퍼클래스라 하고 클래스 B를 서브클래스라고 한다. 클래스 B의 인스턴스는 클래스 A의 모든 인스턴스 메서드를 상속한다. 클래스 B의 메서드가 클래스 A의 메서드를 재정의했을 때, 클래스 B의 재정의된 메서드에서 클래스 A의 원래 메서드를 호출할 수가 있는데 이를 메서드 체이닝이라고 한다. 비슷하게 서브클래스의 생성자 B()가 슈퍼클래스의 생성자 A()를 호출할 필요가 있는데, 이는 생성자 체이닝이라고 한다. 이하 내용은 추후에 업데이트 예정… 다른 부분보다 확실히 이해가 많이 필요한 부분이라 몇 번 더 읽어봐야 할 것 같다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/30/JavaScript/complete-guide-to-javascript-chapter-9/"},{"title":"자바스크립트 완벽가이드 7장 (배열)","text":"자바스크립트의 배열은 타입이 고정되어 있지 않다. 같은 배열에 있는 원소 값의 타입은 서로 다를 수 있다. 배열의 원소는 객체가 될 수도 있고, 또 다른 배열이 될 수도 있다. 자바스크립트 배열은 동적이다. 배열의 크기가 필요에 따라 커지거나 작아질 수 있다. 배열을 생성하거나, 크기가 변경되어 다시 할당을 할 때도 배열 크기를 선언할 필요가 없다. 자바스크립트 배열은 밀집도가 높지 않고, 각 원소의 인덱스가 연속적이지 않아도 되고, 원소들 사이에 빈자리가 있어도 된다. 자바스크립트 배열에는 length 프로퍼티가 존재한다.자바스크립트 배열은 자바스크립트 객체의 특별한 형태이고, 배열의 인덱스는 프로퍼티 이름인데 정수인 것이다. 일반적으로 배열은 객체 프로퍼티를 통해 원소에 접근하는 것보다 정수 첨자를 통해 원소에 접근하는 것이 훨씬 빠르도록 최적화 되어 있다.배열은 Array.prototype의 프로퍼티들을 상속받는다. 7.1 배열 만들기배열을 만드는 가장 쉬운 방법은 배열 리터럴을 사용하는 것이다. 배열 리터럴은 대괄호([,])안에 배열의 원소를 쉼표(,)로 구분해 나열한 것이다.만약 배열 리터럴은 객체 리터럴 또는 다른 배열 리터럴을 포함할 수 있다. 만약 배열 리터럴에서 빠진 부분이 있다면 해당 부분의 원소 값은 undefined가 된다.1var undefs = [,,]; // 두 원소 모두 값은 undefined (배열 리터럴의 문법은 마지막 원소 다음에 쉼표 추가 가능) 배열을 만드는 또 다른 방법은 Array() 생성자를 이용하는 것이다. 생성자는 3가지 방법으로 호출 가능하다.– 인자 없이 호출빈 배열을 생성하고 생성된 배열은 배열 리터럴 []과 동일하다.1var a = new Array(); – 배열의 길이를 의미하는 숫자를 인자로 주어 호출배열에 저장될 원소의 크기를 알고, 미리 공간을 할당할 때 사용한다. 배열에는 어떠한 값도 저장되지 않고, 배열의 인덱스 프로퍼티 값(“0”, “1” …)도 존재하지 않는다.1var a = new Array(10); – 두 개 이상의 원소, 또는 숫자가 아닌 원소 값 하나를 명시적으로 지정생성자의 인자 값들이 배열의 원소가 된다. 리터럴을 사용하는편이 훨씬 더 간단하다.1var a = new Array(5, 4, 3, 2, 1, \"test\"); 7.2 배열의 원소 읽고 쓰기배열의 각 원소에 접근할 때에는 [] 연산자를 사용한다. 배열은 객체의 특별한 종류이다. 배열의 [] 구문은 객체 프로퍼티 접근 때 쓰는 []와 똑같이 동작한다. 자바스크립트는 사용자가 명시한 숫자 배열 인덱스를 문자열 형태로 바꿔서 프로퍼티 이름으로 사용한다.배열의 인덱스와 객체 프로퍼티 이름을 올바르게 구별할 줄 알면 좋다. 모든 인덱스 값은 프로퍼티 이름이지만, 프로퍼티 이름은 0과 2의32승-1 사이의 정수여야만 인덱스가 될 수 있다. 모든 배열은 객체이므로, 어떤 이름의 프로퍼티라도 자유롭게 만들 수 있다. 하지만 배열에는, 프로퍼티 가운데 인덱스인 것들을 사용하면 length 프로퍼티의 값이 자동으로 갱신되는 특별한 기능도 갖추어져 있다.(배열이 일반 객체와 다른 점은 속성 이름으로 2의32승보다 작은 양수를 사용할 때, 자동으로 length 프로퍼티의 값을 바꾼다는 것이다.) 배열 첨자로 양의 정수가 담긴 문자열을 사용하면, 일반적으로 프로퍼티가 아닌 배열 인덱스로 쓰인다. (소수점 아래가 없는 부동 소수점 값도 마찬가지) 반면에 음수나, 정수 아닌 수들을 사용하면 숫자는 문자열로 변환되고, 변환된 문자열은 배열 객체의 프로퍼티 이름으로 사용된다.객체에 존재하지 않는 프로퍼티 이름을 질의하면, 에러가 발생하지 않고 단순히 undefined값이 반환된다. 이러한 성질은 배열에도 적용된다.123a = [true, false]; // 두 개의 원소를 가진 배열을 생성한다.a[2] // =&gt; undefined. 해당 인덱스에 원소가 없어서.a[-1] // =&gt; undefined. '-1'이라는 속성 이름에 해당하는 값이 없어서. 모든 배열은 객체다. 따라서 배열은 객체의 프로토타입으로부터 원소들을 상속 받을 수 있다. 7.3 희소배열희소배열은 배열에 속한 원소의 위치가 연속적이지 않은 배열을 말한다. 보통, 배열의 length 프로퍼티는 배열에 속한 원소의 개수를 의미한다. 그러나 희소배열의 경우, length 프로퍼티의 값은 원소의 개수보다 항상 크다.123a = new Array(5); // 원소가 없는 배열이지만 a.length의 값은 5다.a = [?]; // length 값이 0인 빈 배열을 생성한다.a[1000] = 0; // 하나의 원소를 할당했지만, length 값은 1001이 된다. 희소배열은 보통배열보다 일반적으로 느리고, 메모리를 많이 사용할 뿐 아니라, 원소를 찾는데 걸리는 시간이 일반 객체의 속성 값을 찾는 시간만큼 오래 걸린다.배열 리터럴 사용 시 값을 명시하지 않는 방법으로는 희소배열을 만들 수 없다. 해당 원소의 값이 undefined가 되기 때문이다. 이는 배열에 원소가 아예 존재하지 않는 것과는 다르다. in 연산자를 사용하면 두 경우의 차이점을 알 수 있다.1234var a1 = [,,,]; // 세 개의 원소가 undefined인 배열var a2 = new Array(3); // 원소가 존재하지 않는 배열0 in a1 // =&gt; true: a1에는 0번 인덱스 위치에 원소가 존재한다.0 in a2 // =&gt; false: a2에는 0번 인덱스 위치에 원소가 존재하지 않는다. 7.4 배열의 길이1234a = [1,2,3,4,5]; // 다섯 개의 원소를 가진 배열a.length = 3; // length를 3으로 바꿨기 때문에 결과는 [1,2,3]a.length = 0; // length 값이 0이기 때문에 모든 element를 삭제, 결과는 []a.length = 5; // length 값은 5이지만, 원소가 없다. new Array(5)와 같은 결과 7.5 배열에 원소를 추가하거나 삭제하기배열에 원소를 추가하는 방법 배열의 새 인덱스에 값을 할당한다. push() 메서드를 사용해 배열의 끝에 원소를 추가한다. (a[a.length]에 값을 할당하는것과 같다.) unshift() 메서드를 사용하면 배열의 앞쪽에 원소를 추가할 수 있다. 배열에 원소를 삭제하는 방법 delete 연산자로 배열의 원소를 삭제할 수 있다. (배열의 length는 줄어들지 않는다.) pop() 메서드를 사용해 배열의 앞에서 원소를 삭제한다. 배열의 특정 원소를 지우는 것은, 해당 원소에 undefined 값을 할당하는 것과 의미가 비슷하다. 원소가 지워지더라도 생기는 공백을 다른 원소가 대신하지 않으며, 해당 배열은 희소배열이 된다. 7.6 배열 순회하기ECMAScript 5에는 배열을 순회하는 다양한 메서드가 추가되었다. 사용자가 정의한 함수에 배열의 원소가 인덱스 순서대로 하나씩 넘어오도록 하여 배열을 순회하는 형태다. forEach() 메서드가 대표적이다.12345var data = [1,2,3,4,5];var sumOfSquares = 0;data.forEach(function(x)) { sumOfSquares += x*x;}); 배열을 다룰 때 forEach() 같은 순회 메서드는 간단하고 강력한 함수형 프로그래밍 스타일을 사용할 수 있게 한다. 7.7 다차원 배열자바스크립트는 진정한 의미에서의 다차원 배열을 지원하지는 않는다. 그러나 배열의 배열을 사용해 다차원 배열을 흉내 낼 수 있다. 배열 내의 배열에 있는 원소에 접근하기 위해서는 단순히 [] 연산자를 두 번 사용하면 된다. 7.8 배열 메서드7.8.1 join()Array.join() 메서드는 배열의 모든 원소를 문자열로 변환하고, 변환한 문자들을 이어 붙인 결과를 반환한다. 결과로 반환되는 문자열에서 배열의 원소들을 구별하기 위해 구분자 문자열을 사용한다. 별도로 구분자 문자열을 지정하지 않으면 쉼표(,)가 기본 값으로 사용된다.123456var a = [1, 2, 3];a.join(); // =&gt; '1,2,3'a.join(\" \"); // =&gt; '1 2 3'a.join(\"\"); // =&gt; '123'var b = new Array(10); // 길이가 10인 빈 배열b.join('-') // =&gt; '---------': 아홉 개의 하이픈 문자열 Array.join() 메서드는 String.split() 메서드와는 반대로 작동한다. String.split() 메서드는 문자열을 조각들로 분리하고, 이 조각들을 원소로 하는 배열을 생성한다. 7.8.2 reverse()Array.reverse() 메서드는 배열의 원소 순서를 반대로 뒤집어 반환한다. 순서가 뒤바뀐 새로운 배열을 생성하는 것이 아니라, 이미 존재하는 배열 안에서 원소들의 순서를 뒤바꾼다. 7.8.3 sort()Array.sort() 메서드는 배열 안의 원소들을 정렬하여 반환한다. sort() 메서드는 별도의 인자전달 없이 호출하면, 배열 안의 원소들을 알파벳순으로 정렬한다. 배열에 undefined 원소들이 존재하면, 이 원소들은 배열의 끝부분으로 정렬된다.알파벳순이 아니라 다른 순서로 배열을 정려하려면, sort() 메서드의 전달 인자를 통해 비교 함수를 직접 명시해주어야 한다. 비교 함수는 전달인자를 두 개 받아서, 정렬된 배열에서 어떤 것이 먼저 나타나야 하는지 판단한다. 만약 첫 번 째 인자가 두 번째보다 먼저 나타나야 한다면, 비교 함수는 0보다 작은 숫자를 반환해야 한다. 만약 두 값이 동등하다면 0을 반환해야 한다.123456var a = [33, 4, 1111, 222];a.sort(); // 알파벳순: 1111, 222, 33, 4a.sort(function(a, b) { // 번호순: 4, 33, 222, 1111 return a-b; // 0보다 작은 값, 0, 또는 0보다 큰 값을 반환한다.});a.sort(function(a,b) {return b-a}); // 내림차순 정렬 7.8.4 concat()Array.concat() 메서드는 기존 배열의 모든 원소에 concat() 메서드의 전달인자들을 추가한 새로운 배열을 반환한다. 전달인자로 배열을 전달하면, 이 배열안의 원소들을 꺼내어 반환하는 배열에 추가한다. 하지만 중첩 배열일 경우에는 중첩된 배열의 원소까지는 꺼내지 않는다.12345var a = [1,2,3];a.concat(4, 5); // [1,2,3,4,5]a.concat([4, 5]); // [1,2,3,4,5]a.concat([4, 5], [6, 7]); // [1,2,3,4,5,6,7]a.concat(4, [5, [6, 7]]); // [1,2,3,4,5, [6,7]] 7.8.5 slice()Array.slice() 메서드는 부분 배열을 반환한다. 부분 배열은 배열에서 잘라낸 원소들을 담은 새 배열이다. slice() 메서드는 전달인자를 두 개 받는데, 각 인자는 반환될 부분의 처음과 끝을 명시한다. 반환되는 배열은 첫 번째 전달인자가 지정하는 위치부터 두 번째 전달인자가 지정하는 위치 이전까지의 모든 원소를 포함한다. 만약 전달인자가 하나라면 그 위치에서 배열 끝까지의 모든 원소를 포함하는 부분 배열을 반환한다. 만약 전달인자가 음수라면, 배열의 마지막 원소에서부터의 상대적인 위치를 가리키는 것이다.12345var a = [1,2,3,4,5];a.slice(0, 3); // [1,2,3]a.slice(3); // [4,5]a.slice(1, -1); // [2,3,4]a.slice(-3, -2); // [3] 7.8.6 splice()Array.splice() 메서드는 배열의 원소를 삽입하거나 원소를 제거하려 할 때 범용적으로 사용하는 메서드다. splice() 메서드는 slice()나 concat() 메서드와는 달리 호출 대상 배열을 바로 수정한다.splice()의 첫 번째 전달인자는 배열상에서 삽입 혹은 삭제 작업을 시작할 위치를 지정하고, 두 번째 전달인자는 배열에서 삭제할 원소의 개수를 지정한다. 두 번째 전달인자를 지정하지 않으면 첫 번째 전달인자로 지정한 배열의 시작 위치에서 마지막 원소까지 전부 삭제한다. splice()는 삭제한 배열을 반환하며, 만약 삭제된 원소가 하나도 없다면 빈 배열을 반환한다.1234var a = [1,2,3,4,5,6,7,8];a.splice(4); // [5,6,7,8]을 반환, a는 이제 [1,2,3,4]a.splice(1, 2); // [2, 3]을 반환, a는 이제 [1,4]a.splice(1, 1); // [4]를 반환, a는 이제 [1] 세 번째 전달인자부터는 배열에 새롭게 삽입할 원소들을 지정하는데 사용한다. 삽입 작업은 첫 번째 전달인자로 지정된 시작 위치부터 수행한다.123var a = [1,2,3,4,5];a.splice(2,0, 'a', 'b'); // []를 반환, a는 이제 [1,2,'a','b',3,4,5]apsplice(2,2, [1,2], 3); // ['a', 'b']를 반환, a는 이제 [1,2,[1,2],3,3,4,5] concat() 메서드와 달리 splice() 메서드는 전달인자로 배열이 전달되면, 그 배열의 원소들을 꺼내어 삽입하지 않고 배열 그 자체를 삽입한다. 7.8.7 push()와 pop()push()와 pop() 메서드를 사용하면 배열을 마치 스택처럼 조작할 수 있다. (FILO (선입후출) 스택 구현 가능)push() 메서드는 하나 이상의 원소들을 배열의 끝 부분에 이어 붙이고, 배열의 새로운 length 값을 반환한다pop() 메서드는 배열의 마지막 원소를 제거하고 배열의 length 값을 감소시킨 후, 배열에서 제거한 원소를 반환한다. 7.8.8 unshift()와 shift()push(), pop()과 매우 유사하게 동작하는데, 배열의 끝이 아니라 배열의 맨 앞에서 원소를 추가하고 제거한다.unshift() 메서드는 하나 혹은 그 이상의 원소들을 배열의 맨 앞에 추가하고, 추가된 원소만큼 공간을 만들기 위해 기존 배열 원소들을 인덱스가 높은 방향으로 옮긴 후, 배열의 새로운 length 값을 반환한다.shift() 메서드는 배열의 첫 번째 원소를 제거한 후, 배열에서 제거한 원소를 반환한다. 7.8.9 toString()배열의 toString() 메서드는 배열의 모든 원소를 문자열로 변환하고 이 문자열들을 쉼표(,)로 분리한 목록을 반환한다. 별도의 전달인자를 지정하지 않고 join() 메서드를 호출하면 toString()과 동일한 결과를 얻을 수 있다.123[1,2,3].toString() // '1,2,3'[\"a\", \"b\", \"c\"].toString() // 'a,b,c'[1, [2, 'c']].toString() // '1,2,c' 7.9 ECMAScript 5 배열 메서드ECMAScript 5는 배열을 순회, 매핑, 필터링, 테스팅, 감소, 검색하기위한 아홉 가지 새로운 메서드를 정의한다.대부분의 메서드들은 첫 번째 전달인자로 함수를 받는다. 이 함수는 배열의 각 원소마다 한 번씩 실행하거나 일부 원소들에 한해 실행된다. 만약 배열이 희소배열이라면, 빈 원소의 경우 함수를 호출하지 않는다. 대부분, 첫 번째 전달인자로 지정한 함수는 세 개의 전달인자를 갖고 호출되는데, 배열 원소의 값과 인덱스, 마지막으로 배열 그 자체다. 첫 인자로 함수를 받는 대부분의 ECMAScript 5의 배열 메서드들은 생략 가능한 두 번째 인자를 받는다. 두 번째 전달인자를 지정하면, 첫 번째 전달인자인 함수는 마치 두 번째 인자의 메서드인 것처럼 호출된다. 두 번째 인자는 첫 번째 전달인자인 함수 안에서 this 키워드의 값으로 사용된다. ECMAScript 5 배열 메서드는 호출 대상 배열을 수정하지 않는다. 메서드의 전달인자로 쓰인 함수 안에서는 배열을 수정할 수 있다. 7.9.1 forEach()forEach() 메서드는 배열을 순회하는 메서드이다. 첫 번째 인자로 넘긴 함수를 각각의 원소를 대사응로 호출한다. forEach()는 첫 인자로 전달된 함수를 호출할 때 세가지 인자를 넘긴다. 각 인자는 배열의 원소 값과, 원소의 인덱스 값, 그리고 배열 그 자체다.forEach() 메서드는 배열의 모든 원소가 순회되기 전에는 종료도지 않는다. 루프에서 사용하는 break문은 사용할 수 없다. 루프를 중간에 종료시키려면, 예외를 발생시켜야 하고, forEach()는 try 블록 안에서 호출되어야 한다. 7.9.2 map()map() 메서드는 배열의 각 원소를 메서드의 첫 번째 전달인자로 지정한 함수에 전달하고, 해당 함수의 반환 값을 배열에 담아 반환한다.map() 메서드에 전달한 함수는 forEach()에 전달한 함수와 동일한 형태로 호출되지만 map() 메서드에 인자로 전달된 함수는 반드시 값을 반환해야 한다. map() 메서드는 기존의 배열을 수정하지 않고, 새배열을 반환한다.12a = [1, 2, 3];b = a.map(function(x) { return x*x; }); // b는 [1, 4, 9] 7.9.3 filter()filter() 메서드는 배열의 일부분을 반환한다. 이 메서드에 전달하는 함수는 조건자 함수(항상 true 또는 false 값을 반환하는 함수)여야 한다. filter()의 조건 함수는 forEach()와 map() 메서드와 동일한 형태로 호출된다. 반환값이 true이거나 true로 변환되는 값이면 조건자 함수에 전달된 값은 filter가 반환할 배열에 추가된다.123a = [5, 4, 3, 2, 1];smallvalues = a.filter(function(x) { return x &gt; 3 }); // [2, 1]everyother = a.filter(function(x, i) { return i%2==0 }); // [5, 3, 1] 7.9.4 every()와 some()every()와 some() 메서드는 배열 조건자 함수다. 두 메서드는 인자로 주어진 조건자 함수를 배열에 적용하여, 결과로 true나 false를 반환한다.every() 메서드는 전달인자로 넘긴 함수가 배열의 모든 원소에 대하여 true를 반환하는 경우, every() 메서드는 true를 반환한다.some() 메서드는 전달인자로 넘긴 함수가 배열의 일부 원소에 대해 true를 반환하는 경우, some() 메서드는 true를 반환한다.every()와 some() 메서드는 반환 값이 결정되면 배열의 원소 순회를 중단한다. 7.9.5 reduce()와 reduceRight()reduce()와 reduceRight() 메서드는 인자로 주어진 함수를 사용하여 배열의 원소들을 하나의 값으로 결합한다.reduce() 메서드는 두 개의 인자를 갖는다. 첫 번째 인자는 배열 원소의 감소 작업을 하는 함수다. 이 감소 함수는 배열 원소 중 두 값을 하나로 결합하면서 크기를 줄이고, 마지막 남은 값을 반환한다. 두 번째 인자는 감소 함수에 전달할 시작 값이다.reduce()에 사용되는 함수는 forEach()와 map()과는 조금 다르다. reduce()에서 사용하는 함수의 첫 번째 인자는 함수를 사용해 계산된 값의 누적된 결과다. 그 초기 값은 reduce()의 두 번째 인자로 전달한 값이다. 이후의 호출에서는 전 단계 함수 호출에서 반환된 값을 함수의 첫 번째 인자로 사용한다.reduceRight() 메서드는 reduce()와 동작은 같지만, 배열의 끝부터 시작해 반대 방향으로 처리한다. 감소 함수의 피연사자들 중 오른쪽 피연산자의 우선순위가 높다면, reduceRight()를 사용해야 한다. reduce()와 reduceRight() 메서드는 감소 함수 호출 시 사용할 this 값을 선택인자로 지정할 수 없다. 선택 초기 값 인자만 지정할 수 있다. 만약 감소 함수를 특정 object의 메서드로 호출하고 싶다면, Function.bind() 메서드를 사용해야 한다. 7.9.6 indexOf()와 lastIndexOf()indexOf()와 lastIndexOf() 메서드는 배열의 원소 중에서 특정한 값을 찾는다. 값이 존재하면 해당 값의 인덱스를 반환하고, 존재하지 않을 경우에는 -1을 반환한다. indexOf()는 배열의 처음부터 검색하고, lastIndexOf()는 배열의 끝에서부터 검색한다. indexOf()와 lastIndexOf()는 함수를 인자로 받지 않고, 첫 번째 인자에서 배열에서 찾고자 하는 값, 두 번째 인자에서 검색을 시작할 배열 인덱스를 지정할 수 있다.(생략가능) 7.10 배열 타입ECMAScript 5에서는 Array.isArray()라는 함수를 통해 특정 객체가 배열인지 판단할 수 있다.12Array.isArray([?]) // =&gt; trueArray.isArray({?}) // =&gt; false 7.11 유사 배열 객체length 프로퍼티와 양의 정수 이름의 프로퍼티가 있는 객체는 일종의 배열로 취급할 수 있다. 이를 유사 배열 객체라고 한다.자바스크립트 배열 메서드는 배열뿐 아니라 유사 배열 객체에도 적용이 가능 하도록 범용 메서드로 구현되었다. 유사 배열은 Array.prototype을 상속받지 않기 때문에, 배열 메서드를 해당 객체의 메서드로 호출할 수는 없지만 Function.call 메서드를 통해서 간접적으로 호출할 수 있다.12var a = {\"0\":\"a\", \"1\":\"b\", \"2\":\"c\", length:3}; // 유사 배열 객체Array.prototype.join(a, \"+\") // =&gt; 'a+b+c' 7.12 문자열을 배열처럼 사용하기문자열은 읽기 전용 배열처럼 동작한다. 문자열의 각 문자는 chatAt() 메서드로 접근할 수도 있지만 대괄호 []를 사용해 접근할 수도 있다. 문자열을 인덱스로 접근함으로써 얻을 수 있는 가장 큰 장점은 charAt() 메서드 호출을 단순하게 []로 대체 함으로써 코드가 전보다 간결해지고, 가독성이 높아지는 것이다.문자열은 변하지 않는 값이라서, 읽기 전용 배열로만 다룰 수 있다. push(), sort(), reverse(), splice()와 같은 배열 메서드는 배열을 직접 수정하므로 문자열에서는 작동하지 않는다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/28/JavaScript/complete-guide-to-javascript-chapter-7/"},{"title":"자바스크립트 완벽가이드 8장 (함수)","text":"함수는 한 번 정의하면 몇 번이든 실행할 수 있고 호출할 수 있는 자바스크립트 코드 블록이다. 함수 호출에는 전달인자 외에도 호출 컨텍스트가 포함되는데, this 키워드의 값이 바로 해당 컨텍스트다.어떤 객체의 프로퍼티로 할당된 함수를 해당 객체의 메서드라 한다. 어떤 함수를 객체를 대상(on)으로, 또는 객체를 통해서(through) 호출하면, 이 객체는 해당 함수의 호출 컨텍스트, 즉 호출된 함수의 this 값이 된다. 새로 생성된 객체를 초기화하는 데 쓰이는 함수는 생성자(constructor)라고 한다.자바스크립트 함수는 다른 함수 내에 중첩되어 정의될 수 있고, 중첩된 함수는 해당 함수가 정의된 유효범위 안의 어떤 변수에도 접근할 수 있다. 이는 자바스크립트 함수가 클로저(closure)이며, 클로저가 가능하게 하는 중요하고 강력한 프로그래밍 기법을 자바스크립트도 구사할 수 있음을 뜻한다. 8.1 함수 정의하기함수는 function 키워드에 의해 정의되며, function 키워드는 함수 정의 표현식 또는 함수 선언문에서 사용된다.12345678// 정의된 함수를 변수에 할당할 수 있다.var square = function(x) { return x*x; }// 함수 표현식은 이름을 포함할 수 있다. 이러한 이름은 재귀 호출에 유용하게 사용된다.var f = function fact(x) { if (x &lt;= 1) return 1; else return x*fact(x-1); };// 함수 표현식은 다른 함수의 전달인자로 사용 가능하다.data.sort(function(a, b) { return a-b ; });// 함수 표현식은 정의되는 즉시 호출 가능하다.var tensquared = (function(x) {return x*x;}(10)); 함수 정의 표현식에서 함수 이름은 옵션이다. 함수 선언문이 실제로 하는 일은, 어떤 변수를 정의하고 함수 객체를 그 변수에 할당하는 것이다. 함수 정의 표현식이 이름을 포함하면, 이 함수 몸체의 유효 범위에 해당 함수 객체에 연결된 이름이 포함된다. 사실상 그 함수 이름이 해당 함수의 지역 변수가 되는 것이다. 표현식 형태로 함수를 정의하는 것은 한 번만 사용되는 함수에 특히 적합하다.함수 선언문은 그 함수를 둘러싼 스크립트나 함수의 맨 위로 끌어올려(hoisted)진다. 따라서 해당 함수는 이 함수가 정의된 위치보다 앞서 나오는 코드로부터 호출될 수 있다. 그러나 표현식으로 정의된 함수는 다르다. 함수를 호출하려면 먼저 호출할 함수를 참조할 수 있어야 하는데, 표현식으로 정의된 함수는 변수에 할당되기 전까지는 참조할 수 없다. 변수 선언은 끌어올려지지만, 변수 할당은 그렇지 않다. 그래서 표현식으로 정의된 함수는 정의되는 지점 위에서는 호출할 수 없다.함수 대부분은 return문을 포함하고 있다. return 다음에 오는 표현식의 값을 호출자에게 반환하는데 return 다음에 표현식이 없다면 undefined 값을 반환한다. 함수가 return 문을 포함하지 않는다면, 함수 몸체 내의 각 구문을 실행 후 다음 호출자에게 undefined 값이 반환된다. 8.2 함수 호출하기자바스크립트 함수는 네 가지 방법으로 호출할 수 있다. 일반적인 함수 형태 메서드 형태 생성자 call()과 apply() 메서드를 통한 간접 호출 8.2.1 함수 호출함수가 호출될 때는 먼저, 각각의 전달인자 표현식(괄호 사이에 있는 것)이 평가되고, 평가 결과 값이 해당 함수의 전달인자가 된다. 이 전달인자 값들은 함수 정의에 등장하는 형식인자 각각에 대응된다.일반적인 함수 형태로 호출하도록 작성된 함수는 보통 this 키워드를 사용하지 않는다. 8.2.2 메서드 호출메서드는 객체의 속성으로 저장된 자바스크립트 함수일 뿐이다. 그러나 메서드 호출은 함수 호출에 비해 한 가지 중요한 부분이 다른데, 바로 호출 컨텍스트다. 메서드 호출 표현식에서는 객체가 호출 컨텍스트가 되므로, 함수 몸체에서 this 키워드를 사용해서 객체를 참조할 수 있다.12345678910var calculator = { operand1: 1, operand2: 1, add: function() { // 이 객체를 참조하기 위해 this 키워드를 사용 this.result = this.operand1 + this.operand2; }};calculator.add();calculator.result // =&gt; 2 메서드와 this 키워드는 자바스크립트 객체 지향 프로그래밍 패러다임의 중심이다. 메서드로 사용되는 함수는 메서드의 호출 대상 객체를 암시적 인자로 전달받는다. 메서드 체이닝메서드 체이닝은 객체 이름은 한 번만 사용하고 메서드는 여러 번 호출할 수 있는 방식이다. (메서드가 객체를 반환하면, 메서드의 반환 값을 후속 호출의 일부로 사용) 변수와 달리, this 키워드에는 유효범위(scope)가 없고 중첩 함수는 호출자의 this 값을 상속하지 않는다. 만약 중첩 함수가 메서드 형태로 호출되면, 그 함수의 this 값은 그 함수의 호출 대상 객체다. 가장 흔한 실수는, 함수 형태로 호출된 중첩 함수가 바깥쪽 함수의 호출 컨텍스트를 획득하기 위해 this 값을 사용할 수 있다고 가정하는 것이다. 만약 바깥쪽 함수의 this 값에 접근하고 싶다면, 안쪽 함수의 유효범위에 바깥쪽 함수의 this 값을 별도의 변수로 저장해야 한다. 이러한 용도로 보통 self 변수를 사용한다.123456789101112var o = { m: function() { var self = this; // this 값을 변수에 저장 console.log(this === o); // true: this는 객체 o이다. f(); // 헬퍼 함수 f() 호출 function f() { // 중첩 함수 f() console.log(this === o); // false: this는 global 객체 또는 undefined이다. console.log(self === o); // true: self는 바깥쪽 함수의 this 값이다. } }};o.m(); 8.2.3 생성자 호출함수나 메서드 호출 앞에 new 키워드가 있다면 생성자 호출이다. 생성자 호출은 일반 함수와 메서드 호출에 비해 매개변수, 호출 컨텍스트와 반환 값을 다루는 방식이 다르다.생성자에 전달인자(매개변수) 목록이 없다면, 자바스크립트 생성자 호출 문법은 전달인자 목록과 괄호를 아예 생략하는 것을 허용한다.123var o = new Object();var o = new Obejct;// 위 두개는 같은 코드이다. 생성자를 호출하면 생성자의 prototype 프로퍼티를 상속받은 새로운 빈 객체가 생성된다. 생성자 함수는 객체를 초기화하고, 새로 생성된 이 객체는 생성자 함수의 호출 컨텍스트로 사용된다. 따라서 생성자 함수는 새로 생성된 객체를 this 키워드로 참조할 수 있다. 주의할 것은 생성자 호출이 마치 메서드 호출처럼 보일지라도, 메서드가 속한 객체가 아닌 새로 생성된 객체가 호출 컨텍스트로 사용된다는 점이다. (즉, new o.m()과 같은 표현식에서 o가 호출 컨텍스트로 사용되지는 않는다는 뜻)생성자 함수는 보통 return 키워드를 사용하지 않는다. 일반적으로 생성자 함수는 새 객체를 초기화하고, 생성자 함수 몸체의 끝에 이르면 암시적으로 그 객체를 반환한다. 새 객체가 생성자 호출 표현식의 값이다. 8.2.4 간접 호출자바스크립트 함수는 객체이고, 모든 자바스크립트 객체와 같이 함수에도 메서드가 있다. 이 메서드 중 call()과 apply()는 함수를 간접적으로 호출한다. 두 메서드 모두 호출 때 this 값을 명시적으로 지정할 수 있는데, 이는 어떤 함수든지 특정 객체의 메서드로 호출할 수 있다는 의미다. 심지어 함수가 실제로 그 객체에 속하지 않더라도 말이다. 8.3 함수 전달인자와 매개변수8.3.1 생략 가능한 매개변수정의된 것보다 적은 수의 전달인자로 함수가 호출되면, 나머지 매개변수는 undefined 값으로 설정된다.12345function getPropertyNames(o, /* optional */ a) { if (a === undefined) a = []; // 만약 undefined이면 새 배열을 사용한다. for(var property in o) a.push(property); return a;} getPropertyNames의 첫줄에는 if문 대신, 관용적으로 || 연산자를 사용하기도 한다.1a = a || []; || 연산자는 첫 번째 피 연산자가 true이거나 true로 변환될 수 있는 값이면 첫 번째 피 연산잘르 반환하고, 그렇지 않으면 두 번째 피 연산자를 반환한다. 따라서, 두 번째 인자가 생략된다면(또는 null이거나 false혹은 false로 변환될 수 있는 값이라면), 새로 생성된 빈 배열이 대신 사용될 것이다. 8.3.2 가변길이 전달인자 목록: Arguments 객체함수가 호출될 때 정의된 매개변수보다 더 많은 인자가 전달되면, 매개변수 이름이 붙지 않은 인자 값을 직접적으로 참조할 방법은 없다. Arguments 객체는 이러한 문제에 대한 해결책이다. 함수 몸체 내에서 arguments 식별자는 해당 호출에 대한 Arguments 객체를 참조한다. Arguments 객체는 유사 배열 객체이고, 이름이 아니라 인덱스 숫자를 통해 함수의 전달인자를 얻어올 수 있다. (내장 함수 Math.max()가 Arguments를 사용하여 동작한다.)arguments는 실제로는 배열이 아니라 Arguments 객체이다. 각 Arguments 객체는 숫자 인덱스가 붙은 배열 원소와 length 프로퍼티를 갖고 있다. 그러나 배열은 아니다. 어쩌다가 숫자로 된 프로퍼티를 갖고 있는 객채이다.Arguments 객체의 배열 원소와 매개변수의 이름은 동일한 값을 가리키는 다른 두 이름이다. (Arguments 객체가 평범한 배열이라면, arguments[0]과 x는 같은 값을 가질 수 있지만, 하나를 변경하는 작업이 다른 하나에 영향을 미치지는 않을 것이다.)12345function f(x) { console.log(x); // 전달인자의 초기 값 출력 arguments[0] = null; // 배열 요소를 변경하면 x 또한 변경 console.log(x); // 이제 null을 출력} 8.3.3 객체의 프로퍼티를 전달인자로 사용하기어떤 함수에 세 개 이상의 매개변수가 있다면, 이 함수를 호출할때 인자의 올바른 순서를 기억하기가 어렵다. 따라서 전달인자를 순서에 상관없이 이름/값의 쌍으로 함수에 전달하는 편이 효과적일 수 있다. 단일 객체를 전달인자로 받는 함수를 정의하고, 함수의 사용자에게 함수에서 요구하는 이름/값 쌍을 가진 객체를 함수의 인자로 넘기도록 하면 된다. 8.3.4 전달인자 형식자바스크립트 메서드의 매개변수에는 정의된 형식도 없고, 함수에 전달한 값에 대해서 자료형 검사도 하지 않는다. 한두 번만 사용하고 ‘버릴’함수가 아니라면, 인자 자료형을 검사하는 코드를 추가할 가치가 있다.자바스크립트는 매우 유연하며 자료형을 느슨하게 처리하는 언어이기에, 때로는 인자 개수와 자료형에 유연한 함수를 작성하는 것이 바람직하다. 8.4 값으로서의 함수자바스크립트에서 함수는 문법일 뿐만 아니라 값이기도 한데, 이는 함수가 변수에 할당될 수 있고 객체의 프로퍼티나 배열 원소로 저장될 수도 있으며, 다른 함수의 인자로 전달될 수도 있고, 기타 여러 방식으로 사용될 수 있음을 뜻한다. 8.4.1 자시만의 함수 프로퍼티 정의하기자바스크립트에서 함수는 원시 값이 아니지만 특별한 종류의 객체이고 이는 함수가 프로퍼티를 가질 수 있음을 의미한다. 함수가 여러 번 호출되어도 그 값이 유지되어야 하는 ‘정적’ 변수가 필요할 때는, 전역 변수를 사용하는 것보다 함수의 프로퍼티를 사용하는 것이 편리한 경우가 많다.12345678910// 팩토리얼을 계산하고 계산 결과를 함수 자신의 프로퍼티에 캐시한다.function factorial(n) { if (isFinite(n) &amp;&amp; n&gt;0 &amp;&amp; n==Math.round(n)) { if (!(n in factorial)) // 만약 캐시 해둔 결과가 없다면 factorial[n] = n * factorial(n-1); // 팩토리얼을 계싼하고, 계산 값 캐시 return factorial[n]; // 캐시 결과를 반환 } else return NaN;}factorial[1] = 1; // 캐시를 기본 경우(1)에 대한 값으로 초기화 8.5 네임스페이스로서의 함수자바스크립트는 함수 단위의 유효범위를 갖는다. 함수 내부에 정의된 변수는 해당 함수 내부(중첩 함수를 포함한)에서는 접근 가능하지만, 그 함수 바깥에는 존재할 수 없다. 함수 밖에서 정의된 변수는 전역 변수이고 자바스크립트 프로그램 전체에서 접근할 수 있다.123(function () { // 이름이 없는 표현식으로 함수 작성 // 모듈 코드 위치}()); // 함수 리터럴을 끝내고 바로 호출 단일 표현식으로 함수를 정의하고 호출하는 방식은 관용적으로 자주 사요되는 기법이다. 함수 앞의 시작 괄호는 반드시 필요한데, 만약 시작괄호가 없다면 자바스크립트 인터프리터는 function 키워드를 함수 선언문으로 해석하기 때문이다. 괄호가 있으면 인터프리터는 이것을 표현식 형태의 함수 선언으로 올바르게 인식한다. 괄호가 꼭 필요하지 않은 상황에서도, 정의하자마자 호출할 함수를 괄호로 둘러싸는 건 관용적인 방식이다. 8.6 클로저자바스크립트는 다은 언어와 마찬가지로 어휘적 유효범위를 사용한다. 함수를 호출하는 시점에서의 변수 유효범위가 아니라, 함수가 정의된 시점의 변수 유효범위를 사용하여 함수가 실행된다는 뜻이다. 이러한 어휘적 유효범위를 구현하기 위해, 자바스크립트 함수 객체는 내부 상태에 함수 자체의 코드뿐만 아니라 현재 유효범위 체인에 대한 참조도 포함하고 있다. 함수 객체와 함수의 변수가 해석되는 유효범위(변수 바인딩의 집합)를 아울러 컴퓨터 과학 문헌에서는 클로저(closure)라고 부른다.(내부함수는 외부함수의 지역변수에 접근 할 수 있는데 외부함수의 실행이 끝나서 외부함수가 소멸된 이후에도 내부함수가 외부함수의 변수에 접근할 수 있다. 이러한 메커니즘이 클로저이다.)기술적으로 자바스크립트 함수는 클로저이다. 함수는 객체이고 함수 자신과 관련된 유효범위 체인을 갖고있기 때문이다. 함수 대부분은 함수가 정의되었을 때의 유효범위 체인을 사용하여 호출되고, 클로저가 개입되었는지의 여보는 중요하지 않다.1234567var scope = \"global scope\"; // 전역 변수function checkscope() { var scope = \"local scope\"; // 지역 변수 function f() { return scope; } // 이 유효범위에 있는 값을 반환 return f;}checkscope()() checkscope()는 중첩 함수를 객체 그 자체를 반환한다. 어휘적 유효범위의 기본적은 규칙을 기억해야한다. 자바스크립트 함수는 함수가 정의되었을 때의 유효범위 체인을 사용하여 실행된다. 중첩 함수 f()가 정의된 유효범위 체인에서 변수 scope는 “local scope”로 바인드되어 있다. f가 어디서 호출되든 상관없이, f가 실행될 때 이 바인딩은 항상 유효하다. 따라서 코드의 제일 마지막 줄은 “global scope”가 아니라 “local scope”를 반환한다. 이것이 클로저의 놀랍고 강력한 특성이다. 클로저는 자신을 정의한 바깥쪽 함수에 바인딩된 지역 변수(그리고 전달인자)를 포착한다.1234var uniqueInteger = (function() { // 함수를 정의하고 바로 호출 var counter = 0; // 아래 함수의 내부 상태 return function() { return counter++; };}()); 중첩 함수는 유효범위에 있는 변수에 접근하고, 바깥쪽 함수에 정의된 counter 변수를 사용할 수 있다. 바깥쪽 함수의 실행이 끝나면, 어떤 코드도 counter 변수를 볼 수 없다. 오직 안쪽 함수만 단독으로 counter 변수에 접근할 수 있을 뿐이다. counter와 같은 내부 변수는 여러 클로저가 공유할 수 있다. 즉, 같은 함수 안에 정의된 중첩 함수들은 같은 유효범위 체인을 공유한다.클로저 기법과 getter/setter 프로퍼티들을 결합할 수 있다. 다음 예제는 내부 상태를 다루는 데 일반 객체 프로퍼티 대신 클로저를 사용한다. 123456789101112131415161718function counter(n) { // 함수 전달인자 n은 내부 변수다. return { // getter 메서드 프로퍼티는 counter 변수를 반환하고 증가시킨다. get count() { return n++; }, // setter 메서드는 프로퍼티 n 값을 감소시키는 것을 허용하지 않는다. set count(m) { if ( m &gt;= n) n = m else throw Error(\"count는 오직 더 큰 값으로만 설정될 수 있습니다.\"); } };}var c = conter(1000);c.count // =&gt; 1000c.count // =&gt; 1001c.count = 2000 // =&gt; 2000c.c ount // =&gt; 2000c.count = 2000 // =&gt; 에러! counter() 함수는 지역 변수를 정의하지 않지만, 프로퍼티 접근 메서드들이 공유하는 내부 상태를 보관하기 위해 매개변수 n을 사용한다. 이로써 counter()를 호출하는 쪽에서 내부 변수의 초기 값을 지정할 수 있다. 12345678910// 0-9 값을 반환하는 함수들의 배열을 반환function constfuncs() { var funcs = []; for(var i = 0; i &lt; 10; i++) funcs[i] = function() { return i; }; return funcs;}var funcs = constfuncs();funcs[5]() // 무엇이 반환될까? 위의 코드는 열 개의 클로저를 생성하고, 생성한 클로저들을 배열에 저장한다. 모든 클로저는 같은 함수 내에서 정의되고, 따라서 클로저들은 변수 i에 대한 접근을 공유한다. constfuncs() 실해잉 끝나면, 변수 i의 값은 10이고, 열 개의 클로저 모두 이 값을 공유한다. 클로저와 연관된 유효범위 체인이 ‘살아 있다’는 사실을 기억해야 한다. 중첩 함수는 유효범위에 대한 내부 사본이나 변수 바인딩의 스냅샷 따위는 만들지 않는다. 더 자세한 내용은 다음을 참고클로저(MDN)자바스크립트의 스코프와 클로저 8.7 함수 프로퍼티, 메서드, 생성자자바스크립트에서 함수는 일종의 값이다. typeof 연산자를 사용하면 “function” 문자열을 얻을 수 있지만, 함수는 정말 독특한 자바스크립트 객체다. 함수는 객체이기 때문에 프로퍼티와 메서드를 가질 수 있으며 Function() 이라는 생성자도 갖고 있다. 8.7.2 prototype 프로퍼티모든 함수에는 prototype 프로퍼티가 있는데, 이 프로퍼티는 프로토타입 객체를 참조한다. 모든 함수는 서로 다른 프로토타입 객체를 갖고 있고, 함수가 생성자로 사용될 때, 새로 생성된 객체는 함수의 프로토타입 객체로부터 프로퍼티들을 상속받는다. 8.7.3 call()과 apply() 메서드call()과 apply()는 어떤 함수를 다른 객체의 메서드인 것처럼 간접적으로 호출할 수 있도록 한다. call()과 apply()의 첫 번째 인자는 호출되는 함수와 관련이 있는 개체다. 이 첫 번째 인자는 호출 컨텍스트고 함수 몸체에서 this 키워드의 값이 된다. 함수 f()를 객체 o의 메서드로 호출하려면 다음과 같이 사용한다.12f.call(o);f.apply(o); call()의 첫 번째 호출 컨텍스트 다음에 있는 모든 인자는 호출되는 함수로 전달된다. apply() 메서드는 call() 메서드와 비슷하지만, 함수에 전달할 인자는 배열 형태여야 한다. apply()는 실제 배열과 마찬가지로 유사 배열 객체와도 잘 작동한다. 특히 arguments 배열을 직접 apply()에 넘김으로써, 다른 함수를 호출할 때 현재 함수에 전달된 인자와 같은 인자를 전달할 수 있다.12345678910// 객체 o의 메서드 m을, 원본 메서드 호출 전후에 로그 메시지를 남긴다.function trace(o, m) { var original o[m]; // 원본 메서드를 클로저에 기억 o[m] = function() { console.log(new Date(), \"Entering:\", m); var result = original.apply(this, arguments); // 원본 메서드 호출 console.log(new Date(), \"Exiting:\", m); return result; };} 8.7.4 bind() 메서드bind() 메서드는 ECMAScript 5에 추가되었다. bind()의 주요 목적은 함수와 객체를 서로 묶는 것이다. 함수 f의 bind() 메서드를 호출하면서 객체 o를 전달하면, bind() 메서드는 새로운 함수를 반환한다. 반환된 새 함수를 호출하면, 원래 함수 f가 o의 메서드로 호출된다. 새로운 함수에 전달한 모든 인자는 원래 함수에도 전달된다.1234function f(y) { return this.x + y; } // 바인드되어야 하는 함수var o = { x : 1 }; // 바인드 될 객체var g = f.bind(o); // g(x)를 호출하면 o.f(x)가 호출된다.g(2) // =&gt; 3 ECMAScript 5의 bind() 메서드는 함수를 객체에 바인딩하는 것보다 더 많은 일을 한다. bind()에 전달하는 인자 중 첫 번째 이후의 모든 인자는 this 값과 함께 해당 함수의 인자로 바인딩된다. 이를 커링(currying)이라 부르기도 한다.1234var sum = function(x, y) { return x + y };// 첫 번째 인자는 1로 바인딩된다. 새로운 함수는 단지 하나의 인자만 요구한다.var succ = sum.bind(null, 1);succ(2) // =&gt; 3: x는 1에 바인딩되고 y 인자로 2를 넘긴다. 출처 : “JavaScript: The Definitive Guide, by David Flanagan (O’Reilly). Copyright 2011 David Flanagan, 978-0-596-80552-4”","link":"/2017/01/30/JavaScript/complete-guide-to-javascript-chapter-8/"},{"title":"다시 공부하는 Promise","text":"Index Promise란? Promise 사용법 Promise 상태 Promise.resolve, Promise.reject Promise.prototype.then Promise.all, Promise.race Promise 특징 Promise란?자바스크립트에서는 비동기 프로그래밍 해결을 위해 하나의 패턴으로 콜백을 사용했다. 그러나 콜백 패턴은 비동기 처리 중 발생한 오류를 예외 처리하기 힘들고 여러 개의 비동기 로직을 한꺼번에 처리하는 데도 한계가 있다. 즉 콜백 패턴은 그다지 유용한 패턴이 아니다. 이때 비동기 프로그래밍을 위한 또 다른 패턴으로 Promise가 등장했다. Promise는 비동기 처리 로직을 추상화한 객체와 그것을 조작하는 방식을 말한다. Promise를 지원하는 함수는 비동기 처리 로직을 추상화한 promise 객체를 반환 한다. 그리고 객체를 변수에 대입하고 성공 시 동작할 함수와 실패 시 동작할 함수 를 등록해 사용한다. 함수를 작성하는 방법은 promise 객체의 인터페이스에 의존 한다. 즉, promise 객체에서 제공하는 메서드만 사용해야 하므로 전통적인 콜백 패턴처럼 인자가 자유롭게 결정되는 게 아니라 같은 방식으로 통일된다. Promise 라고 부르는 하나의 인터페이스를 이용해 다양한 비동기 처리 문제를 해결할 수 있다. 복잡한 비동기 처리를 쉽게 패턴화할 수 있다는 뜻이다. 이것이 Promise의 역할이며 Promise를 사용하는 많은 이유 중 하나다. Promise 사용법Promise는 new 연산자를 선언하여 Promise 인스턴스 객체를 생성한다.123const promise = new Promise(function(resolve, reject) { // 비동기 처리 로직 후 resolve 또는 reject를 호출}); new 연산자로 생성된 Promise 인스턴스 객체에는 성공(resolve), 실패(reject)했을 때 호출될 콜백 함수를 등록할 수 있는 Promise.then()이라고 하는 인스턴스 메서드가 있다.1promise.then(onFulfilled, onRejected) 성공했을 때는 onFulfilled가 호출되고 실패했을 때는 onRejected가 호출된다. promise.then()으로 성공 혹은 실패 시의 동작을 동시에 등록할 수 있다. 만약 오류 처리만 한다면 promise.then(undefined, onRejected)와 같은 의미인 promise.catch(onRejected)를 사용하면 된다.1promise.catch(onRejected) Promise 상태생성자 함수를 new 연산하여 생성된 Promise 인스턴스 객체에는 3가지 상태가 존재한다. promise 객체는 Pending 상태로 시작해 Fulfilled나 Rejected 상태가 되면 다시는 변화하지 않는다. (Event 리스너와는 다르게 then()으로 등록된 콜백함수는 한 번만 호출된다.) Pending : 성공도 실패도 아닌 상태, Promise 인스턴스 객체가 생성된 초기상태 Fulfilled : 성공(resolve)했을 때의 상태, onFulfilled가 호출된다. Rejected : 실패(reject))했을 때의 상태, onRejected 호출된다. Promise.resolve, Promise.rejectPromise의 정적 메서드인 Promise.resolve()를 사용하면 new Promise() 구문을 단축해 표기할 수 있다. Promise.resolve()는 Fulfilled 상태인 promise 객체를 반환한다. 또한, Promise. resolve()는 thenable 객체를 promise 객체로 변환할 수 있다. 이것은 Promise.resolve()의 중요한 특징 중 하나다. thenable은 ES6 Promises 사양에 정의된 개념이다. then()을 가진 객체 즉, 유사 promise 객체를 의미한다. length 프로퍼티를 갖고 있지만, 배열이 아닌 유사 배열 객체 Array-like Object와 같다. Promise.resolve()는 thenable 객체의 then() 이 Promise의 then()과 같은 동작을 할 것이라 기대하고 promise 객체로 변환한다. Promise.reject()도 promise 객체를 반환한다. 따라서 에러 객체와 함께 catch()를 이용해 등록한 콜백 함수가 호출된다. Promise.prototype.thenPromise에서는 메서드를 체인하여 코드를 작성할 수 있다. then()은 콜백 함수를 동록하기만 하는것이 아니라 콜백에서 반환된 값을 기준으로 새로운 promise 객체를 생성하여 전달하는 기능도 갖고 있다. Promise.all, Promise.racePromise.all()은 Promise 객체를 배열로 전달받고 객체의 상태가 모두 Fulfilled 됐을 때 then()으로 등록한 함수를 호출한다.Promise.race()는 Promise.all()과 마찬가지로 promise 객체를 배열로 전달한다. Promise.all()과 달리 전달한 객체의 상태가 모두 Fulfilled가 될 때까지 기다리지 않고 전달한 객체 중 하나만 완료(Fulfilled, Rejected)되어도 다음 동작으로 넘어간다. Promise.race는 먼저 완료된 promise 객체가 있더라도 다른 promise 객체를 취소하지 않는다. (ES6 Promise 사양에는 취소라는 개념이 없다.) Promise 특징1. Promise는 항상 비동기로 처리된다.Promise.resolve()나 resolve()를 사용하면 promise 객체는 바로 Fulfilled 상태가 되기 때문에 then()으로 등록한 콜백 함수가 동기적으로 호출될 것이라 생각할 수 있다. 하지만 실제로는 then()으로 등록한 콜백 함수는 비동기적으로 호출된다.동기적으로 처리 가능한 상황에서도 비동기적으로 처리하는 이유는 동기와 비동기가 혼재될때 발생하는 문제를 막기 위함이다. 2. 새로운 promise 객체를 반환하는 thenpromise.then(), catch()는 최초의 promise 객체에 메서드를 체인하는 것처럼 보이지만 실제로는 then()과 catch()는 새로운 promise 객체를 생성해 반환한다.Promise.all()과 Promise.race() 또한 새로운 promise 객체를 생성해 반환한다. 3. 콜백-헬과 무관한 PromisePromise는 callback-hell 을 해결할수는 없고 완화할 수 있을 뿐이다. 완화할 수 있는 이유는 단일 인터페이스와 명확한 비동기 시점 표현, 강력한 에러 처리 메커니즘 때문이다. 이는 비동기 처리 자체를 손쉽게 다룰 수 있도록 하는 것이므로 callback-hell 을 해결하는 방법으로 여기는건 바람직하지 않다.","link":"/2017/06/10/JavaScript/promise/"},{"title":"메모이제이션 (Memoization)","text":"Index 메모이제이션 이란? 메모이제이션 적용하기 결과 비교 마치며 메모이제이션 이란?자바 스크립트에서 함수는 객체이기 때문에 프로퍼티를 가질 수 있습니다. 그리고 언제든지 함수에 사용자 정의 프로퍼티를 추가할 수도 있습니다. 함수에 프로퍼티를 추가하여 결과(반환 값)을 캐시하면 다음 호출 시점에 복잡한 연산을 반복하지 않을 수 있습니다. 이런 활용 방법을 메모이제이션 패턴이라고 합니다. 다음 코드에서는 myFunc 함수에 cache 프로퍼티를 생성합니다. 이 프로퍼티는 일반적인 프로퍼티처럼 myFunc.cache와 같은 형태로 접근할 수 있습니다. cache 프로퍼티는 함수로 전달된 param 매개변수를 키로 사용해서 계산의 결과를 값으로 가지는 객체(해시)입니다. 결과 값은 필요에 따라 복잡한 데이터 구조로 저장할 수도 있습니다. 12345678910111213var myFunc = function (param) { if (!myFunc.cache[param]) { var result = {}; // ... // 비용이 많이 드는 수행 후 result에 결과 저장 // ... myFunc.cache[param] = result; } return myFunc.cache[param];};// 캐시 저장공간myFunc.cache = {}; 메모이제이션 적용하기메모이제이션을 공부한 후 현재 진행중인 에밀리(개인 프로젝트)에 적용해 보았습니다. 어느 부분에 적용했는지 적용 전과 적용 후 얼마나 효율이 올라갔는지를 알아보겠습니다. 1. 수정할 부분메모이제이션 패턴을 적용할 코드가 현재 하고 있는 기능은 다음과 같습니다. 사용자의 요청(학생식당, 카페테리아, 사범대식당, 기숙사식당, 교직원식당)에 따라 미리 크롤링 후 DB에 저장되어 있는 데이터(메뉴)를 가져와 응답합니다.메모이제이션 패턴을 사용함으로써 얻을 수 있는 이점은 비용이 많이 드는 결과를 캐싱하고 그 이후에 재사용함으로써 비용을 줄일 수 있다는 것입니다. 현재 코드에서 비용이 많이 드는 작업은 DB를 조회하는 부분입니다. DB에는 다음과 같이 미리 크롤링한 데이터가 날짜별로 저장되어 있습니다. 사용자의 요청에 따라 해당 날짜의 데이터를 조회한 후 사용자가 요청한 식당에 맞는 데이터를 결과로 반환합니다. 그렇기 때문에 해당 날짜의 최초 요청이 이루어진 후 그 하루 동안에는 계속해서 DB에 같은 쿼리를 통해 같은 결과를 얻게 됩니다. 이 부분이 비용이 많이 드는 작업이기 때문에 메모이제이션 패턴을 통해 개선해보았습니다. 2. 메모이제이션 적용 전먼저 메모이제이션 패턴을 적용하기 전 코드입니다. menuHandler 클래스의 getMenu 함수는 menuService를 통해 DB에서 해당 날짜의 식당 메뉴를 가져와 매개변수로 전달받은 식당의 이름을 사용하여 결과로 반환하는 역할을 합니다. 12345678910111213141516171819202122232425262728293031323334353637383940414243const dateUtil = require('util/dateUtil');const menuService = require('services/menuService');class menuHandler { static getMenu(place) { return new Promise((_s, _f) =&gt; { const today = new Date().yyyymmdd(); let menu = ''; menuService.show(today) .then(menuList =&gt; { if (!menuList) { menu = '데이터가 없습니다. 관리자에게 문의해주세요'; } switch (place) { case '학생식당': menu = menuList.student.join('\\n\\n'); break; case '카페테리아': menu = menuList.cafeteria.join('\\n\\n'); break; case '사범대식당': menu = menuList.education.join('\\n\\n'); break; case '기숙사식당': menu = menuList.dormitory.join('\\n\\n'); break; case '교직원식당': menu = menuList.staff.join('\\n\\n'); break; } _s(menu); }) .catch(err =&gt; { _f(err); }); }); }}module.exports = menuHandler; 3. 메모이제이션 적용 후메모이제이션 패턴을 적용 한 후 코드입니다. setCache, getCache, pickMenu 함수가 추가되었고, getMenu 함수의 코드도 조금 변경되었습니다. 기존 코드의 getMenu 함수에서는 바로 DB를 조회하여 결과를 반환하였지만, 변경된 코드에서는 getCache 함수를 통해 캐시에 저장된 데이터가 있는지 확인 후 분기하여 처리합니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172const dateUtil = require('util/dateUtil');const menuService = require('services/menuService');class menuHandler { static setCache(param, menuList) { menuHandler.cache[param] = menuList; } static getCache(param) { if (menuHandler.cache[param]) { return menuHandler.cache[param]; } else { return null; } } static pickMenu(menuList, place) { let menu = ''; switch (place) { case '학생식당': menu = menuList.student.join('\\n\\n'); break; case '카페테리아': menu = menuList.cafeteria.join('\\n\\n'); break; case '사범대식당': menu = menuList.education.join('\\n\\n'); break; case '기숙사식당': menu = menuList.dormitory.join('\\n\\n'); break; case '교직원식당': menu = menuList.staff.join('\\n\\n'); break; } return menu; } static getMenu(place) { return new Promise((_s, _f) =&gt; { const today = new Date().yyyymmdd(); const cachedMenuList = this.getCache(today); let menu = ''; if (cachedMenuList) { menu = this.pickMenu(cachedMenuList, place); _s(menu); } else { menuService.show(today) .then(menuList =&gt; { if (!menuList) { menu = '데이터가 없습니다. 관리자에게 문의해주세요'; } this.setCache(today, menuList); menu = this.pickMenu(menuList, place); _s(menu); }) .catch(err =&gt; { _f(err); }); } }); }}menuHandler.cache = {};module.exports = menuHandler; Line:70 에서 선언한 menuHandler의 cache Object에는 다음과 같이 데이터가 캐싱될 것입니다.123456{ ... `2017-06-13`: { ... menuList ...} `2017-06-14`: { ... menuList ...} ...} 결과 비교메모이제이션 패턴을 적용하기 전과 적용한 후의 성능 차이는 아래 보이는것처럼 눈에 띄게 차이가 납니다. 메모이제이션 패턴을 적용한 코드는 첫번째 요청(캐싱 하기 전)때는 메모이제이션 패턴 적용 전과 응답속도가 비슷하지만 그 이후의 응답은 캐싱된 데이터를 이용하기 때문에 비교될 정도로 빨라졌습니다. 마치며메모이제이션을 적용하기 전과 후 모두 같은 기능을 결과를 만들어내는 코드이지만 코드를 작성하는 방법에 따라 더욱 더 빠른 효율적인 서비스를 만들 수 있다는 것을 느끼게 되었습니다.현재 제 상황에서는 캐싱된 데이터도 하루가 지나게되면 쓰이지 않고 계속 메모리에 남아있게 되는데 그 부분에 대한 처리를 추가해야할것 같습니다. 이번에 적용한 코드 뿐만 아니라 아직 프로잭트 내에 메모이제이션 패턴을 적용할 수 있는 부분이 더 있습니다. 앞으로 디자인패턴 공부를 계속하여 새로운 패턴들을 적용시키며 리팩토링을 해야겠습니다.","link":"/2017/06/14/JavaScript/memoization/"},{"title":".bashrc 와 .bash_profile 의 차이","text":"Index bash 쉘(Shell) 이란? Login Shell 과 Non-Login Shell .bashrc 와 .bash_profile 의 차이 bash 쉘(Shell) 이란?쉘(Shell)은 운영체제에서 사용자가 입력하는 명령을 읽고 해석하여 대신 실행해주는 프로그램입니다. 운영체제 상에서 다양한 운영체제 기능과 서비스를 구현하는 인터페이스를 제공하며, 사용자와 운영체제의 내부(커널) 사이의 인터페이스를 감싸는 층이기 때문에 셸이라는 이름이 붙었습니다. 쉘은 운영체제에서 필수적으로 존재합니다. 운영체제는 로그인한 사용자가 없다면 하나의 쉘도 실행되지 않은 상태이며, 사용자가 로그인을 시도하면 운영체제는 ID와 패스워드를 받아들이는 로기은 프로그램을 실행하고, 사용자가 입력한 ID와 패스워드를 검증한 후 인증된 사용자라면 쉘을 실행하여 사용자 세션을 쉘에게 전달합니다. 쉘의 역할은 사용자가 입력한 명령을 해석하여 대신 실행해주는 것입니다. 쉘의 내부 명령어라면 스스로 실행한 뒤 화면에 표시해주고 내부 명령어가 아니라면 PATH 환경변수에 지정된 경로에서 입력받은 명령과 같은 파일을 찾아 exec() 시스템콜을 호출하여 실행한 뒤 키보드와 마우스 등의 입력장치와 모니터에 해당하는 표준 출력장치의 제어권을 해당 프로그램에 넘겨준 뒤 프로그램이 끝날 때 까지 대기하는 역할을 합니다. bash 쉘은 유닉스에서 사용하는 커맨드 쉘의 일종으로 GNU 프로젝트를 위해 만들어졌습니다. 초기의 유닉스 쉘인 본 쉘(Bourne Shell)과 새로 태어났다는 뜻의 영어 ‘born again’을 합쳐 본 어게인 쉘(Bourne-again Shell)이라고 불렸으나, 일반적으로 bash로 줄여 부릅니다. Login Shell 과 Non-Login ShellLogin ShellLogin은 ID와 패스워드를 입력해서 Shell을 실행하는 것을 말합니다. 따라서 ssh로 접속하거나 로컬에서 GUI를 통해 Shell을 실행하는 것은 Login Shell 입니다..profile, .bash_profile 이 두 파일은 Login할 때 로드되는 파일입니다. .profile은 꼭 bash가 아니더라도 로그인하면 로드되며, .bash_profile은 꼭 bash로 로그인 할 때만 실행됩니다. Non-Login ShellNon-Login Shell은 로그인 없이 실행하는 Shell을 말합니다. ssh로 접속하고 나서 다시 bash를 실행하는 경우나, GUI 세션에서 터미널을 띄우는 것도 여기 해당합니다. ‘sudo bash’나 ‘su’같은 것도 해당합니다. .bashrc 와 .bash_profile 의 차이.bashrc이미 로그인 한 상태에서 새 터미널 창을 열 때마다 로드됩니다. (Non-Login Shell에서 실행됩니다.) .bash_profile시스템에 로그인할 때마다 로드됩니다. (Login Shell에서 실행됩니다.) 대부분 개별 사용자에 대한 설정에 대한 코드들이 들어갑니다. 예를 들면 nvm(Node Version Manager)은 기본적으로 nvm을 사용하지 않고 Node를 설치할 때와는 다르게 각 사용자의 경로에 설치되게 되는데, 이럴때 nvm의 PATH를 .bash_profile 파일에 기재합니다. .profile로그인할 때 로드됩니다. 개별 사용자에 대한 설정 코드들 중 bash와는 관계없는 부분을 기재합니다. 만약 Mac에서 새 터미널 창을 열 때마다 .bashrc를 로드하고 싶다면 .bash_profile에서 .bashrc를 로드하면 됩니다.1234# Source bashrcif [ -f ~/.bashrc ]; then . ~/.bashrcfi","link":"/2016/12/13/Linux & Ubuntu/bashrc-bash_profile/"},{"title":"ls 명령어 결과 색상 변경하기","text":"미리보는 결과 화면이번 글에서는 다음과 같이 ls 명령어를 사용했을 때 보이는 결과를 색상을 이용하여 쉽게 구분할 수 있도록 만들어 보겠습니다. 색상 표시 여부 설정 &amp; 색상 설정~/.bashrc 또는 ~/.bash_profile 파일에 다음 코드를 추가합니다.123# ls 명령어 색상 표시 여부 &amp; 색상 설정export CLICOLOR=1export LSCOLORS=DxFxBxDxCxegedabagacad 색상 변경하기CLICOLOR는 색상표시 여부를 활성화하는 것이며 0일때 비활성, 1일때 활성입니다.LSCOLORS는 CLICOLOR로 색상이 활성화 되었을 때 각 종류별로 어떤 색으로 표시할 지를 지정하는 것 입니다. 두 글자씩 쌍으로 이루어져 있으며 앞 글자는 전경색(foreground), 뒤의 글자는 배경색(background)를 의미합니다. 각 알파벳이 의미하는 색상은 다음과 같습니다. 1234567891011121314151617a : 검은색b : 빨강색c : 녹색d : 갈색e : 파란색f : 마젠타색(magenta)g : 시안(cyan)h : 밝은 회색A : 두꺼운 검은색(보통 어두운 회색으로 보인다.)B : 두꺼운 빨간색C : 두꺼운 녹색D : 두꺼운 갈색(보통 노란색으로 보인다)E : 두꺼운 파란색F : 두꺼운 마젠타색G : 두꺼운 시안H : 두꺼운 밝은 회색(밝은 흰색처럼 보인다)x : 전경생과 배경색의 기본색상 fb의 쌍 순서는 다음과 같은 순서로 색을 지정합니다.12345678910111. 디렉토리2. 심볼릭 링크3. 소켓4. 파이프5. 실행가능 파일6. 특수 블락7. 특수문자8. setuid 비트가 설정된 실행파일9. setgid 비트가 설정된 실행파일10. sticky비트가 있으면서 다름사람이 쓸 수 있는 디렉토리11. sticky비트가 없으면서 다름사람이 쓸 수 있는 디렉토리","link":"/2016/12/13/Linux & Ubuntu/ls-result-color-change/"},{"title":"Prototype 이제는 이해하자","text":"Index prototype은 왜 어려울까? 객체(object)는 함수(function)로부터 시작된다 함수(function) 생성시 발생하는 일 객체(object) 생성시 발생하는 일 프로토타입 체인(Prototype Chain) 번외 prototype은 왜 어려울까?C++, Java와 같은 클래스 기반 객체지향 언어와 달리 자바스크립트는 프로토타입 기반 객체지향 언어입니다. 프로토타입을 사용하여 객체지향을 추구하기 때문에 자바스크립트를 사용함에 있어 프로토타입을 이해하는 것은 중요합니다. 최근 ECMA6 표준에서 Class 문법이 추가되었지만 C++, Java에서 말하는 클래스가 아닌 프로토타입을 기반으로 하여 만들어진 문법입니다. 자바스크립트의 프로토타입을 처음 공부하면서 prototype, [[prototype]], __proto__, 객체, 함수, prototype chain 과 같은 용어들을 접하게 되는데 공부할수록 서로 뒤엉켜지고, 모르는 것도 아닌 그렇다고 제대로 알고 있는것도 아닌 어중간한 상태가 됩니다. 자바스크립트를 사용한 경험이 있으시다면 아래의 코드와 같은 형태를 경험한적이 있으실겁니다. 지금부터 아래의 코드가 어떤 원리로 동작하게 되는지 알아보겠습니다. 먼저 프로토타입에 대해 이해하기 위해서는 객체(object)는 함수(function)로부터 시작된다라는 것을 알아야 합니다. 이는 prototype을 이해하는데 많은 도움을 줍니다. 객체(object)는 함수(function)로부터 시작된다자바스크립트에서 primitive를 제외하고는 모두 객체(object)입니다. 앞으로 등장하는 Object와 Function은 function(즉, 생성자)입니다. object는 객체를 의미합니다. 다음의 코드를 분석하기 전 객체(object)는 함수(function)로부터 시작된다라는걸 다시한번 기억하겠습니다.12function Book() { } // 함수var jsBook = new Book(); // 객체 생성 위의 코드에서 Book이라는 함수를 통해서 jsBook이라는 객체를 생성했습니다. 이때 Book 함수를 생성자라고 합니다. 생성자는 새로 생성된 객체를 초기화하는 역할을 합니다. 코어 자바스크립트는 기본 타입에 대한 생성자를 내장하고 있는데 이는 다음 코드를 통해 확인이 가능합니다.1var cssBook = {}; // 생성자 선언 없이 객체 생성 위에서는 리터럴 방식을 사용하여 객체를 생성하였습니다. 리터럴 방식 또한 결과적으로는 함수를 통하여 객체를 생성하게 됩니다. 자바스크립트 엔진이 해당 리터럴을 다음과 같이 해석합니다.1var cssBook = new Object(); // 객체 생성 따라서 결과적으로는 리터럴 방식으로 객체를 생성할때도 Object라는 함수(생성자)를 통해서 객체를 생성하게 됩니다. Object 뿐만 아니라 Array, Function, Date, RegExp 모두 함수입니다. 배열도 객체이기 때문에(자바스크립트 배열은 객체의 특별한 형태입니다. 프로퍼티 이름이 정수로 사용되며, length 프로퍼티를 가집니다.) 객체를 생성할때와 마찬가지로 배열(객체)의 생성에도 함수가 관여하게 됩니다. 따라서 무심코 사용했던 배열의 리터럴 표현도 결국에는 자바스크립트 엔진이 다음과 같이 해석합니다.123var books = ['html', 'css', 'js']; // 배열(객체) 생성// 엔진이 다음과 같이 해석합니다.var books = new Array('html', 'css', 'js'); // 배열(객체) 생성 이제 객체(object)는 함수(function)로부터 시작된다라는 것을 알 수 있습니다. 함수(function) 생성시 발생하는 일객체(object)는 함수(function)로부터 시작되기 때문에 사용자가 객체를 생성하기 위해 먼저 함수를 정의하게 됩니다. 이때 발생하는 일에 대해 알아보겠습니다. 여기서는 2가지를 기억해야 합니다. 1.함수를 정의하면 함수가 생성되며 Prototype object가 같이 생성 됩니다. 생성된 Prototype object는 함수의 prototype 속성을 통해 접근할 수 있습니다. (Prototype object같은 경우 함수 생성시에만 됩니다. 일반 객체 생성시에는 생성되지 않습니다.) 2.함수의 생성과 함께 생성된 Prototype object는 constructor와 __proto__를 갖고 있습니다. (cover property를 추가한것 처럼 사용자 임의로 추가 가능합니다.) constructor는 생성된 함수를 가리키며(여기서는 function Book을 가리킵니다.) __proto__는 Prototype Link로서 객체가 생성될 때 사용된 생성자(함수)의 Prototype object를 가리킵니다. Prototype Link는 뒤에서 자세하게 알아보겠습니다. 다이어그램을 통해 확인하면 다음과 같습니다. 객체(object) 생성시 발생하는 일이번에는 객체 생성시 발생하는 일에 대해 알아보겠습니다. 조금 전에 정의한 Book 함수(생성자)를 사용하여 jsBook이라는 객체를 생성해 보겠습니다. 생성자(함수)의 몸체 부분에 어떠한 코드도 작성하지 않았는데 이를 통해 생성한 jsBook 객체가 __proto__라는 프로퍼티를 갖고있습니다. 여기서 __proto__ 는 Prototype Link로서 객체의 생성에 쓰인 생성자 함수의 Prototype object를 가리키고 있습니다. 그렇기 때문에 Book 생성자 함수와 함께 생성된 Prototype object에 추가한 cover라는 프로퍼티가 보이는것을 확인할 수 있습니다. 조금 더 이해하기 쉽게 다이어그램으로 확인하면 다음과 같습니다. 다이어그램에서도 확인할 수 있다시피 prototype property(함수 생성시 함께 생성된 Prototype object를 가리킴)는 함수객체만 가지며 __proto__는 객체라면 모두 갖고 있습니다. 이제 프로토타입 체인(Prototype Chain)에 대해 이해할 수 있는 준비가 되었습니다. 프로토타입 체인(Prototype Chain)결론부터 말씀드리면 프로토타입 체인은 객체의 property를 사용할때 해당 property가 없다면, __proto__ property를 이용해 자신의 생성에 관여한 함수(생성자 함수)의 Prototype object에서 property를 찾습니다. 만약 Prototype object에도 해당 property가 없다면 다시 Prototype object의 __proto__ property를 이용해 Prototype object에서 property를 찾습니다. 이렇게 계속 반복이 이루어지며 해당 property를 찾게 된다면 값을 반환하고 찾지 못한다면 undefined를 반환합니다. 이렇게 __proto__ property를 통해 상위 프로토타입과 연결되어 있는 형태를 프로토타입 체인(Chain)이라고 합니다. 프로토타입 체인에 대해 알게되었으니 다시한번 처음 코드를 살펴보겠습니다. 이제 어떻게 jsBook에 cover라는 property를 추가하지 않았는데도 결과가 출력되는지 이해할 수 있습니다. 다음과 같이 동작할 것입니다. 또한 다음과 같이 프로토타입 체인의 최상위는 Object이기 때문에 Object.prototype의 property들을 모두 사용할 수 있습니다. 자주 사용하는 toString()과 valueOf() 모두 Object.prototype에 선언되어 있습니다.(Book Prototype object는 객체이기 때문에 Object 생성자가 사용될 것입니다. 따라서 Book Prototype object의 __proto__는 Object Prototype object를 가리키게 됩니다.) Prototype object와 __proto__ 그리고 프로토타입 체인에 대해 이해하였으니 다음과 같은 코드도 이해할 수 있습니다. 잘 이해가 되지 않는다면 위의 다이어그램을 참고해보시기 바랍니다. 번외혹시 다이어그램을 보면서 function Book의 __proto__ 는 무엇을 가리키고 있는지 궁금해 하셨을 분들을 위해 추적해보았습니다. 다음 코드를 도식화 하면 다음과 같은 다이어그램이 나오게 됩니다. 간단하게 포스팅을 하려했는데 주제가 주제인지라 길어졌습니다. 저도 프로토타입을 처음 공부하면서 어려움을 많이 겪었는데 조금이나마 도움이 되었으면 좋겠습니다.","link":"/2017/03/14/JavaScript/understand-prototype/"},{"title":"Linux & Ubuntu 계정 추가 & 설정","text":"AWS의 EC2를 사용하면서 ubuntu에 사용자를 추가해주는 경우가 빈번히 생겨 그 과정을 정리해보려 합니다. 각각의 유저가 자신의 사용자 계정을 사용한다면 자신만의 파일과 작업 공간을 가질 수 있고, 잘못사용해서 시스템에 피해가 생기는 일도 어느정도 예방할 수 있습니다. EC2 인스턴스에 사용자를 추가하는 작업에는 (1) 사용자를 시스템에 추가하고 (2) 해당 사용자에게 원격으로 로그인하는 방법을 제공하는 두 가지 작업이 포함됩니다. 올바른 방법은 하나의 EC2에서 생성한 각각의 사용자 계정마다 key pair를 생성해 주고, 각 계정에 맞게 설정된 key pair를 통해서만 접속 할 수 있도록 설정을 해야합니다. 그러나 최초 EC2 인스턴스를 생성하며 만들었던 key pair를 모든 사용자가 공유한다던가, password 기반의 로그인을 활성화 하여 ssh key를 사용하지 않고 password 기반으로 로그인을 할 수도 있습니다. 이번 포스팅에서는 (1) 사용자를 시스템에 추가한 후 (2-1) EC2 인스턴스를 생성하며 사용했던 key pair(기본 사용자 로그인시 사용하는 key pair)를 사용하거나, (2-2) password 기반의 로그인을 활성화하여 ssh key를 사용하지않고 로그인할 수 있도록하는 방법에 대해 정리합니다. 1. root password 설정1[ubuntu ~] $ sudo passwd root 2. password 기반의 로그인을 활성화하기1[ubuntu ~] $ sudo vi /etc/ssh/sshd_config 다음을 수정합니다. no를 yes로 변경합니다.# Change to no to disable tunnelled clear text passwordsPasswordAuthentication no 3. root 계정으로 로그인1[ubuntu ~] $ su - root 4. 다른 사용자 계정 추가1[root ~] $ adduser newuser 5. 새로 생성한 사용자 계정의 비밀번호 변경1[root ~] $ sudo passwd newuser 6. 새로 생성한 사용자 계정에 root 권한을 사용할 수 있도록 설정1[root ~] $ sudo visudo 다음을 수정합니다.root ALL=(ALL) ALL 아래에newuser ALL=(ALL) ALL을 추가합니다. 7. 같은 key pair로 로그인 할 수 있도록 새로 생성한 사용자 계정으로 ubuntu 의 것을 복사* 이부분에 대한 자세한 내용은 SSH KEY 에 대하여 알아야합니다.* ubuntu 계정의 .ssh 폴더를 복사해 newuser 계정에 복사합니다.1[root ~] $ ssudo cp /home/ubuntu/.ssh /home/newuser/.ssh 8. 복사한 key pair의 소유자를 jmkim으로 변경 (-R : 하위 폴더까지 모두 소유권을 바꿔줌)1[root ~] $ sudo chown -R newuser:newuser /home/newuser/.ssh 9. sshd 서비스 재시작-Ubuntu1[root ~] $ sudo service ssh restart -Linux1[root ~] $ sudo service sshd restart 이제 EC2 instance를 생성할때 만들었던 .pem 파일과 설정한 비밀번호를 통해 새로 생성한 계정으로 서버에 접속할 수 있습니다. 참고 : AWS 공식 사이트 - Managing User Accounts on Your Linux Instance","link":"/2016/09/20/Linux & Ubuntu/add_user/"},{"title":"Screen 사용하기","text":"Index Screen 이란? Screen 실행 명령어 Screen 실행 후 명렁어 Screen 이란?terminal 또는 putty를 이용해 원격에서 작업하다 보면 여러개의 창을 띄우고 싶을 때가 많습니다. 이럴때 보통 여러개의 terminal을 띄워서 작업합니다. (저는 screen을 알기 전까지 그랬습니다…) 그런데 창을 하나, 둘 여러개 띄우고 작업을 하다보면 어느 창에서 어떤 작업을 하고 있었는지도 헷갈리기 시작하면서 관리의 어려움이 생기게 됩니다. screen은 한 terminal로 한번만 로그인 한 후에 여러 쉘과 프로그램을 사용할 수 있습니다. 또한 세션관리 기능도 지원합니다. 세션관리 기능은 상당히 유용합니다. 예를 들면, 터미널을 통해 원격 서버에 접속하여 작업을 하다가 네트워크 장애로 연결이 끊어진다면 매우 난감할 수 있습니다. 이때 screen을 사용해서 작업중이 였다면 세션을 유지할 수 있기 때문에 해당 작업은 로컬에서 계속 진행되고 있으며 언제든지 다시 해당 세션을 통해 작업을 계속 할 수 있습니다. 더불어 하나의 서버에 여러명의 사용자가 접속하여 해당 스크린을 공유하여 같은 화면을 공유할 수도 있습니다. screen은 하나의 프로세스 입니다. 따라서 무분별하게 생성하기 보다는 필요한 용도에 맞게 적당한 개수를 유지하며 사용하는것이 중요합니다. Screen 실행 명령어screen 관련 명령어에 대해 알아보겠습니다. 12// screen 을 시작하는 기본 명령어 입니다. 기본 세션명으로 시작합니다.$ screen 12// 해당 세션명으로 스크린을 시작합니다.$ screen -S 세션명 12// 이전에 작업 했던 screen 목록을 불러와 세션명과 함께 보여 줍니다.$ screen -list 123// 이전에 작업 했던 세션이 있을 경우 해당 세션을 불러옵니다.// 세션명을 주지 않았을 경우에는 이전 세션이 한개일 경우 그 작업을 불러오고, 여러개 일 경우에는 작업 리스트를 보여 줍니다.$ screen -R 세션명 12// 스크린을 삭제합니다.$ screen -S 세션명 -X quit Screen 실행 후 명렁어Screen 실행 후의 명령어는 Ctrl-a로 시작합니다. 12// 새로운 쉘을 생성(create) 하여 그 쉘로 이동합니다.$ Ctrl-a, c 12// 바로 전(previous) 창으로 이동합니다.$ Ctrl-a, p 12// 바로 다음(next) 창으로 이동합니다.$ Ctrl-a, n 12// 숫자에 해당하는 창으로 이동합니다.$ Ctrl-a, 숫자 12// 창번호 또는 창이름으로 이동합니다. (&apos; =&gt; 싱글 쿼테이션)$ Ctrl-a, &apos; 12// 창목록을 보여 줍니다. (방향키와 Enter를 통해 창 선택 후 이동가능, &quot; =&gt; 더블 쿼테이션)$ Ctrl-a, &quot; 12// 현재 창의 title을 수정합니다.$ Ctrl-a, A 12// screen의 명령행 모드로 전환합니다. (: =&gt; 콜론)$ Ctrl-a, : 12// 현재 작업을 유지하면서 screen 세션에서 빠져나옵니다.(detach) 세션이 종료 되지 않습니다.$ Ctrl-a, d 12// 해당 스크린을 삭제합니다.$ Ctrl-a, k 12// 해당 스크린에 lock을 겁니다. (해당 유저의 비밀번호를 입력해야 해제할 수 있다.)$ Ctrl-a, x 다음은 창 관련 명령어입니다. 12// 창을 분할합니다(split).$ Ctrl-a, S 12// 분할된 창으로 이동합니다.$ Ctrl-a, Tab 12// 분할된 구역중 현재 구역을 제외하고 나머지를 숨깁니다.$ Ctrl-a, Q 12// Ctrl-a, d(세션 유지) 와는 달리 세션을 완전히 종료합니다.$ exit","link":"/2017/02/26/Linux & Ubuntu/screen/"},{"title":"tail -f 보다 효율적인 less +F에 대해 알아보자","text":"Stop using tail -f얼마전 tail -f를사용하며 스크롤 기능을 사용하고 싶어 검색하던 중 less +F를 알게 되었습니다. less +F에 대해 잘 설명한 글이 있어 번역해보려 합니다. 해당 글은 Stop using tail -f (mostly) 에서 볼 수 있습니다. 파일의 변화를 실시간으로 모니터링하기 위해 여전히 많은 사람들이 tail -f를 사용하고 있습니다. tail-f 보다 less +F 를 사용하는게 조금 더 나은 방법이 될 수 있습니다. less documentation에서 +F에 대해 잘 설명하고 있습니다. Scroll forward, and keep trying to read when the end of file is reached. Normally this command would be used when already at the end of the file. It is a way to monitor the tail of a file which is growing while it is being viewed. (The behavior is similar to the “tail -f” command.) tail -f 명령어와 비슷하다고 하는데, 어떤 점에서 더 좋을까요? 간단하게, less +F를 사용하면 navigation과 watching 모드 사이를 쉽게 변경할 수 있습니다. tail -f를 사용하셨던 분들은 아마 file을 실시간으로 모니터링하면서 해당 파일에서 무언가를 검색하거나 위, 아래로 이동하고 싶었던 적이 있을것 입니다. 그럴때마다 tail 명령어를 종료하거나 새로운 shell로 vim을 통해 문제를 해결했을 것입니다. 그러나 less 명령어를 사용하면 더이상 그런 번거로운 수고를 할 필요 없습니다. production.log 라는 파일을 모니터링한다고 가정해 보겠습니다. 12345678$ less +F production.logImportantloginformationhereWaiting for data... (interrupt to abort) tail 명령어와 결과가 비슷한것 같지만, Ctrl-c를 눌러 normal less 모드로 변경할 수 있습니다. +F 플래그 없이 파일을 오픈한 것과 같은 모드입니다. 그 후, normal less 모드에서 사용할 수 있는 기능들을 똑같이 사용할 수 있습니다. /foo를 검색한다던가, 검색 결과를 n 또는 N을 통해 이동할 수 있습니다. 또한 j와 k를 통해 라인을 이동할 수도 있습니다. 추가적으로 m을 통해 마크도 생성할 수 있습니다. 필요한 작업을 모두 끝내고 나면, F를 눌러 다시 모니터링 모드로 돌아갈 수 있습니다. When not to use less동시에 여러개의 파일을 모니터링 해야하는 경우에는 tail -f가 조금 더 나을 수 있습니다. 12345678910$ tail -f *.txt==&gt; file1.txt &lt;==content for first file==&gt; file2.txt &lt;==content for second file==&gt; file3.txt &lt;==content for third file 변경이 발생할 때, 파일 이름과 새로운 내용이 보이기 때문에 매우 편리합니다. 그러나, less의 경우에는 다음처럼 출력됩니다. 123$ less +F *.txtcontent for first file less는 동시에 오직 하나의 파일 내용만 볼 수 있으며, 2번째 파일을 보고 싶을 경우 Ctrl-c로 normal mode로 변환 후 :n을 눌러 다음 buffer로 이동해야 합니다. 그 후 다시 F를 눌러 모니터링 모드로 돌아가면 됩니다. 필요와 경우에 따라서, less와 tail을 잘 사용하면 조금 더 효율적인 작업을 할 수 있을것 입니다.","link":"/2018/03/29/Linux & Ubuntu/less/"},{"title":"module.exports와 exports 차이 이해하기","text":"Index 모듈이란? 모듈 추출하기(exporting) 모듈 사용하기(importing) 중요 포인트 모듈이란?모듈이란 관련된 코드들을 하나의 코드 단위로 캡슐화 하는 것을 말합니다. Node.js 에서 예시를 살펴보겠습니다.다음과 같은 greeting.js 라는 파일이 있습니다. 이 파일은 두개의 함수를 포함하고 있습니다.12345678// greetings.jssayHelloInEnglish = function() { return \"Hello\";};sayHelloInSpanish = function() { return \"Hola\";}; 모듈 추출하기(exporting)gretting.js 의 코드가 다른 파일에서 사용될 때 그 효용성이 증가할 것입니다. 이러한 일을 하기 위해서는 다음과 같은 3가지의 단계를 거쳐야 합니다. 1.greeting.js 파일의 코드 첫 부분에 다음과 같은 코드가 존재해야 합니다.12// greetings.jsvar exports = module.exports = {}; 2.다른 파일에서 exports 객체를 사용하기를 원한다면 greeting.js 파일에서 다음과 같이 작성해야 합니다.123456789// greetings.js// var exports = module.exports = {};exports.sayHelloInEnglish = function() { return \"HELLO\";};exports.sayHelloInSpanish = function() { return \"Hola\";}; 위의 코드에서 exports 를 module.exports 로 대체할 수 있으며 같은 결과를 얻을 수 있습니다. 이 부분이 잘 이해가 가지 않는다면 exports 와 module.exports 가 같은 객체를 참조한다고 기억하기 바랍니다. 3.module.exports 의 현재 값은 다음과 같습니다.123456789module.exports = { sayHelloInEnglish: function() { return \"HELLO\"; }, sayHelloInSpanish: function() { return \"Hola\"; }}; 모듈 사용하기(importing)main.js 라는 새로운 파일에서 greeting.js 의 메소드를 사용 할 수 있도록 import 하는 과정은 다음과 같습니다. 1.먼저 require이라는 키워드는 Node.js 에서 module(모듈)을 import(추가) 하기 위해 사용합니다. require는 다음과 같이 정의되어 있습니다.123456var require = function(path) { // ... return module.exports;}; 2.main.js에서 greetings.js를 require 합니다.12// main.jsvar greetings = require(\"./greetings.js\"); 위의 코드는 아래와 동일한 코드 입니다.12345678910// main.jsvar greetings = { sayHelloInEnglish: function() { return \"HELLO\"; }, sayHelloInSpanish: function() { return \"Hola\"; }}; 3.main.js 에서 greeting.js 의 값과 메소드에 접근할 수 있습니다.12345678// main.jsvar greetings = require(\"./greetings.js\");// \"Hello\"greetings.sayHelloInEnglish();// \"Hola\"greetings.sayHelloInSpanish(); 중요 포인트require 키워드는 object 를 반환합니다. 그리고 module.exports 와 exports 는 call by reference 로 동일한 객체를 바라보고 있고, 리턴되는 값은 항상 module.exports 입니다. 모듈은 기본적으로 객체이고, 이 객체를 module.exports, exports 모두 바라보고 있는데, 최종적으로 return 되는 것은 무조건 module.exports 라는 것입니다. 123456789var express = require('express');var router = express.Router();/* GET home page. */router.get('/', function(req, res) { res.render('index', { title: 'Express' });});module.exports = router; 위의 소스는 다음과 같이 해석할 수 있습니다.express.Router() 가 리턴한 “객체”에 일부 프로퍼티를 수정한 뒤, 이 객체 자체를 모듈로 리턴한 것입니다.","link":"/2016/08/25/Node/module-exports_exports/"},{"title":"require는 어떻게 동작할까?","text":"Index Node.js의 모듈 로딩 시스템 require가 갖는 문제점 대 / 소문자 구분 NPM 모듈 종속성 마치며 Node.js를 사용하며 문득 require에 대해 궁금증이 생겼습니다. 대부분 자주 사용하는 코드를 모듈 형식으로 만들어 module.exports를 사용해서 객체 인스턴스를 내보내고 이를 다른 파일에서 require를 통해서 사용하게 되는데 대부분 여러 파일에서 모듈을 require해 사용하게 됩니다. 이때 여러파일에서 중복되는 require는 계속해서 새로운 인스턴스를 생성하는지, 그게 아니라면 어떻게 동작되는지 궁금해서 공부하며 찾아본 내용을 포스팅합니다. 1. Node.js의 모듈 로딩 시스템Node.js는 간단한 모듈 로딩 시스템을 갖고 있습니다. Node.js에서 파일과 모듈은 일대일로 대응하며 각 파일은 별도의 모듈로 처리됩니다. 그렇기 때문에 여러곳에서 하나의 파일에 작성된 모듈을 필요로 할때 동일한 인스턴스를 사용할 수 있도록 합니다. 즉, 모듈을 require할 때마다 새로운 인스턴스가 생성되는 것이 아니라 캐싱된 객체 인스턴스를 재사용하는 것 입니다. Node.js 공식 Documentation에서 확인할 수 있듯이 한번 로딩(require)된 모듈은 require.cache라는 객체에 캐싱됩니다. key값으로 해당 모듈 파일의 경로를 갖게 되는데 key값이 삭제된다면 다음 require 요청시 다시 재로딩 하게됩니다. 다음 코드를 통해서 require.cache에 캐싱된 모듈을 확인해보겠습니다. 12345// foo.jsmodule.exports = { foo: \"bar\"}; 123456789// index.jsvar foo = require('./foo');console.log('---------- require.cache ----------')console.log(require.cache);console.log('---------- require.cache keys ----------')console.log(Object.keys(require.cache)); foo.js 와 index.js 파일을 통해 확인한 결과는 다음과 같습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142kimjongmin:~/work/require_test $node index.js---------- require.cache ----------{ &apos;/Users/kimjongmin/work/require_test/index.js&apos;: Module { id: &apos;.&apos;, exports: {}, parent: null, filename: &apos;/Users/kimjongmin/work/require_test/index.js&apos;, loaded: false, children: [ [Object] ], paths: [ &apos;/Users/kimjongmin/work/require_test/node_modules&apos;, &apos;/Users/kimjongmin/work/node_modules&apos;, &apos;/Users/kimjongmin/node_modules&apos;, &apos;/Users/node_modules&apos;, &apos;/node_modules&apos; ] }, &apos;/Users/kimjongmin/work/require_test/foo.js&apos;: Module { id: &apos;/Users/kimjongmin/work/require_test/foo.js&apos;, exports: { foo: &apos;bar&apos; }, parent: Module { id: &apos;.&apos;, exports: {}, parent: null, filename: &apos;/Users/kimjongmin/work/require_test/index.js&apos;, loaded: false, children: [Object], paths: [Object] }, filename: &apos;/Users/kimjongmin/work/require_test/foo.js&apos;, loaded: true, children: [], paths: [ &apos;/Users/kimjongmin/work/require_test/node_modules&apos;, &apos;/Users/kimjongmin/work/node_modules&apos;, &apos;/Users/kimjongmin/node_modules&apos;, &apos;/Users/node_modules&apos;, &apos;/node_modules&apos; ] } }---------- require.cache keys ----------[ &apos;/Users/kimjongmin/work/require_test/index.js&apos;, &apos;/Users/kimjongmin/work/require_test/foo.js&apos; ] 위의 결과에서 확인할 수 있듯이 require.cache 객체는 key값으로 해당 모듈 파일의 경로를 사용해 모듈을 캐싱하고 있습니다. 2. require가 갖는 문제점이제 require를 통해 모듈을 로딩할 경우 파일의 경로를 캐시 키로 사용하여 다른 여러 파일에서 동일한 파일을 필요로하는 경우 동일한 캐싱 된 모듈을 사용하는 것을 알게되었습니다. 이로인해 불필요한 메모리 사용을 피할 수 있습니다. 어찌보면 한번 로딩된 후 재사용되기 때문에 싱글 톤과 같이 동작한다고도 생각할 수 있습니다. 그러나 이러한 모듈의 캐싱 방식이 다음과 같이 제대로 동작하지 않는 경우가 있습니다. 파일 이름의 잘못된 대 / 소문자 사용 다른 모듈이 NPM에서 동일한 모듈을 설치할 때 3. 대 / 소문자 구분Windows 및 macOS는 기본적으로 파일 시스템에서 대 / 소문자를 구분하지 않습니다. 따라서 “foo.js” 라는 파일과 “FOO.js” 라는 파일을 검색 할 경우, 이 두 검색은 실제 파일 이름의 대소 문자와 상관없이 같은 폴더에서 동일한 파일을 찾습니다. 그러나 Node.js에서는 대/ 소문자를 구별하기 때문에 파일 이름을 두 개의 개별 모듈로 취급하므로 “foo.js”와 “FOO.js”가 같은 파일이라는 것을 알지 못합니다. 이 때문에 Windows와 macOS 모두에서 require 호출의 객체 캐시를 쉽게 파기 할 수 있습니다. 다음의 예시 코드에서 쉽게 확인할 수 있습니다. 12345// foo.jsmodule.exports = { foo: \"bar\"}; 123456789101112131415161718// index.jsvar foo = require('./foo');var FOO = require('./FOO');console.log('---------- require.cache keys ----------')console.log(Object.keys(require.cache));FOO.foo = 'different bar';console.log('---- foo object ----');console.log(JSON.stringify(foo, null, 2));console.log('---- FOO object ----');console.log(JSON.stringify(FOO, null, 2));console.log('---- foo object ----');console.log(JSON.stringify(foo, null, 2)); 결과는 다음과 같습니다.123456789101112131415161718kimjongmin:~/work/require_test $node index.js---------- require.cache keys ----------[ &apos;/Users/kimjongmin/work/require_test/index.js&apos;, &apos;/Users/kimjongmin/work/require_test/foo.js&apos;, &apos;/Users/kimjongmin/work/require_test/FOO.js&apos; ]---- foo object ----{ &quot;foo&quot;: &quot;bar&quot;}---- FOO object ----{ &quot;foo&quot;: &quot;different bar&quot;}---- foo object ----{ &quot;foo&quot;: &quot;bar&quot;} 결과에서 확인 가능하듯이 require된 모듈은 key값으로 해당 모듈 파일의 경로를 사용해 캐싱되고 있습니다. require시 대 / 소문자를 구분해 key로 사용하기 때문에 2개의 객체가 생성되었으나, 결과적으로는 파일 시스템에 도달하면 같은 파일이 2번 반환된 것입니다. 즉, 같은 파일에 서로 다른 모듈로 2개가 생성되어 있는 것 입니다. require 문에 파일 이름을 잘못 입력 한 것과 관련된 다른 문제도 있습니다. 대 / 소문자를 구분하는 파일 시스템에 배포하는 경우 실제 파일과 동일하게 처리되지 않은 버전은 파일을 찾지 못합니다. 4. NPM 모듈 종속성모듈 캐싱이 제대로 작동하지 않는 상황은 NPM에서 둘 이상의 모듈 종속성이 같은 모듈을 설치할 때 입니다. 즉, 프로젝트가 NPM의 “Foo”와 “Bar”에 의존하고 Foo와 Bar가 둘 다 “Baz”에 의존하면 NPM (버전 2 이하)은에 의존하는 각 모듈에 대해 “Baz”의 다른 사본을 설치합니다. NPM 버전 3 에서는 종속성 목록을 병합하여 문제를 해결하고 있습니다. Foo와 Bar가 둘 다 동일한 Baz의 버전에 의존하면 하나의 사본만 설치합니다. 그러나, Foo와 Bar가 Baz의 서로 다른 (서로 호환되지 않는) 버전을 사용한다면, 여전히 두 버전을 모두 설치하며, 이 경우 모듈 캐시를 공유하지 않습니다. 5. 마치며반복되는 코드를 모듈화 하거나 각 기능 별로 모듈화 하게되면 결국 다른 파일에서 require를 통해 사용하게 되는데, 이때마다 어떤식으로 동작하게 되는지 궁금했었습니다. 이번 포스팅을 작성하면서 이에 대한 궁금증을 해결할 수 있었고, 결과적으로 한번 로딩된 모듈은 캐싱되어 사용되기 때문에 각기 파일마다 require를 많이 한다고해서 크게 걱정할 필요는 없을 것 같습니다. 또한, 필요에 의해 (필요한 상황이 있을지 모르겠지만…) require.cache에 고의적으로 캐싱된 모듈을 지우고 다시 새로 로딩하여 사용할 수도 있을것 같습니다.","link":"/2017/07/13/Node/require/"},{"title":"NVM (Node Version Manager) 사용하기","text":"Index NVM (Node Version Manager) NVM 사용시 이점 NVM 설치 NVM 명령어 모듈 설치 기존에 설치되어 있던 Node 제거 오늘은 NVM에 대해서 알아보겠습니다. 저는 회사에서 Ionic 을 통해서 하이브리드 앱을 개발하고 있습니다. Ionic의 개발환경은 기본적으로 Node.js를 필요로 합니다. 당시 처음 입사하였을때는 회사에서 사용중인 Node v4.4.0을 설치하여 사용하고 있었습니다. 그러나 후에 여러개의 프로젝트를 하며 ES6 문법을 사용하기 위해 상위 버전의 Node를 사용해야하 하는 일이 생겼습니다. 이런 경우 보통 Node를 제거한 후 상위 버전을 사용하게 된다면 후에 다시 Ionic 프로젝트를 할때 문제가 됩니다. 이럴때 NVM을 사용한다면 여러개의 Node 를 버전별로 쉽게 관리하고 사용할 수 있습니다. 지금부터 NVM을 사용했을때의 이점과 설치 및 사용방법에 대해 알아보겠습니다. NVM (Node Version Manager)NVM은 말 그대로 Node의 버전을 관리해주는 매니저입니다. Ruby에는 RVM이 있듯이 Node에서는 NVM을 사용합니다. 한 사용자 계정에 여러개의 Node 버전을 설치하여 선택하여 사용할 수 있습니다. NVM 사용시 이점 여러 버전의 Node를 쉽게 사용할 수 있습니다. (기존의 버전을 삭제할 필요가 없습니다.) NVM을 사용하지 않고 설치한 Node는 /usr/local/bin/ 경로에 설치되지만 NVM을 사용하여 설치했을 경우에는 /User/kimjongmin/.nvm/versions/node/ 경로에 설치됩니다. NVM을 사용했을 경우 사용자의 종속되어 설치되기 때문에 npm을 통하여 모듈을 설치할 때도 기존과는 달리 -g 옵션을 주지 않아도 설치 가능합니다. (npm또한 Node와 같이 설치되기 때문에 Node 버전마다 다르게 설치됩니다.) Node 버전에 따라 npm도 다르게 설치되기 때문에 모듈의 버전들도 각기 다르게 관리할 수 있습니다. 예를들어, Node v4.4.0 에서는 cordova v5.7.1을 Node v6.6.0 에서는 cordova v6.1.1을 설치하여 사용할 수 있습니다. NVM 설치NVM 설치전 기존에 설치되어 있던 Node를 제거하는것을 권장하지만 NVM 설치 후 제거하여도 괜찮습니다. 12curl을 이용하여 설치$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.31.4/install.sh | bash 설치 후 PATH 정보는 .bashrc에 저장되므로 재로그인 없이 사용하려면 변경된 .bashrc를 다시 적용시켜주어야 합니다.1$ source ~/.bashrc NVM 명령어123// 현재 최신 버전의 Node 설치 (별도의 버전을 지정하지 않고 현재 최신 버전으로 설치합니다.)$ nvm install node$ node -v (버전확인) 123456// 설치된 Node 특정 버전 삭제하기$ nvm uninstall v4.4.0```bash// 설치된 Node는 ~/.nvm/versions/ 경로에서 확인 가능합니다.$ which node 12// NVM에서 지원하는 Node의 버전을 확인할 수 있습니다.$ nvm ls-remote 12// 특정 Node 버전 설치는 다음과 같이 가능합니다.$ nvm install v4.4.0 12// 설치되어 사용가능한 Node 버전 확인$ nvm ls 12// 특정 Node 버전 사용$ nvm use v6.6.0 12// 터미널 시작시 노드 기본버전 설정$ nvm alias default v6.6.0 Tip) 자주쓰는 명령어 alias 등록하기저는 NVM을 통해 Node v4.4.0과 v6.6.0을 설치하여 사용하고 있습니다. 프로젝트마다 Node 버전이 달라 프로젝트 변경시 Node의 버전도 변경해 주어야 하는 번거로움이 있어 ~.bash_custom에 alias 로 등록하여 사용하고 있습니다. (~.bashrc, ~.bash_profile ) 저는 다음과 같이 사용합니다. (파일에 추가 후 source 명령어로 변경된 파일을 적용하거나 새로운 쉘을 열어야 적용됩니다.)123alias nv='node -v'alias n4='nvm use v4.4.0'alias n6='nvm use v6.6.0' 모듈 설치NVM use 명령어를 통해 원하는 Node 버전을 선택 후 npm install 을 통해 필요한 모듈을 설치할 수 있습니다. 기존 사용법과 동일하나 NVM 은 /User에 설치되기 때문에 더이상 sudo 명령어를 사용하지 않아도 됩니다. 또한 하나의 Node 버전에서 필요한 모듈을 설치 후 새로운 Node 버전을 생성할 때 특정 버전 npm 패키지를 마이그레이션 할 수 있습니다.1$ nvm install v6.6.0 --reinstall-packages-from=4.4.0 기존에 설치되어 있던 Node 제거1$ sudo rm -rf /usr/local/lib/node /usr/local/lib/node_modules /var/db/receipts/org.nodejs.*","link":"/2016/09/20/Node/nvm-(Node-Version-Manager)/"},{"title":"Design Pattern - Adapter","text":"해당 포스팅은 Java 언어로 배우는 디자인 패턴 입문 책을 참고해 작성했습니다.사용된 코드는 jongmin92/Design-Pattern repository 에서 확인할 수 있습니다. Adapter 패턴이미 제공되어 있는 것을 그대로 사용할 수 없을 때, 필요한 형태로 교환하고 사용하는 일이 자주 있습니다. ‘이미 제공되어 있는 것’과 ‘필요한 것’ 사이(서로 다른 두 개)의 ‘차이’를 없애주는 디자인 패턴이 Adapter 패턴 입니다. Adapter 패턴은 Wrapper 패턴으로 불리기도 하며, 다음과 같은 두 가지 종류가 있습니다. 클래스에 의한 Adapter 패턴 (상속을 사용한 Adapter 패턴) 인스턴스에 의한 Adapter 패턴 (위임을 사용한 Adapter 패턴) 예제 프로그램(1) - 상속을 사용한 Adapter 패턴만들 예제 프로그램은 주어진 문자열을 아래와 같이 표시하는 간단한 것입니다. 12(Hello)*Hello* Banner 클래스에는 문자열을 괄호로 묶어서 표시하는 showWithParen 메소드와 문자열 전후에 *를 붙여 표시하는 showWithAster 메소드가 준비되어 있습니다. (이미 제공되어 있는 것) Print 인터페이스에는 문자열을 느슨하게(괄호 사용) 표시하기 위한 printWeak 메소드와 문자열을 강하게 표시하기 위한 (* 표시를 앞뒤에 붙여 강조) printStrong 메소드가 선언되어 있습니다. 지금 하고 싶은 일은 Banner 클래스를 사용해서 Print 인터페이스를 충족시키는 클래스를 만드는 일입니다. PrintBanner 클래스가 어댑터의 역할을 담당합니다. 이 클래스는 제공되어 있는 Banner 클래스를 상속해서, 필요로 하는 Print 인터페이스를 구현합니다. Banner 클래스123456789101112131415public class Banner { private String string; public Banner(String string) { this.string = string; } public void showWithParen() { System.out.println('(' + string + ')'); } public void showWithAster() { System.out.println('*' + string + '*'); }} Print 인터페이스12345public interface Print { void printWeak(); void printStrong();} PrintBanner 클래스123456789101112131415public class PrintBanner extends Banner implements Print { public PrintBanner(String string) { super(string); } @Override public void printWeak() { showWithParen(); } @Override public void printStrong() { showWithAster(); }} Main 클래스1234567public class Main { public static void main(String[] args) { Print p = new PrintBanner(\"Hello\"); p.printWeak(); p.printStrong(); }} Main 클래스는 Print 인터페이스를 사용하고 있습니다. Banner 클래스나 showWithParen 메소드나 showWithAster 메소드는 Main 클래스 소스 코드 상에서는 완전히 감추어져 있습니다. 예제 프로그램(2) - 위임을 사용한 Adapter 패턴Main 클래스, Banner 클래스, Print 인터페이스는 예제 프로그램(1)과 동일합니다. PrintBanner 클래스는 banner 필드에서 Banner 클래스의 인스턴스를 가집니다. 이 인스턴스는 PrintBanner 클래스의 생성자에서 생성합니다. 이전 예와는 달리, 이번에는 필드를 경우해서 호출하고 있습니다. 즉 위임을 하고 있습니다. PrintBanner 클래스1234567891011121314151617public class PrintBanner implements Print { private Banner banner; public PrintBanner(String string) { this.banner = new Banner(string); } @Override public void printWeak() { banner.showWithParen(); } @Override public void printStrong() { banner.showWithAster(); }} Adapter 패턴의 구성요소 Target(대상)의 역할지금 필요한 메소드를 결정합니다. 예제 프로그램에서 Print 인터페이스(상속의 경우)나 Print 클래스(위임의 경우)가 이 역할을 합니다. Client(의뢰자)의 역할Target 역할의 메소드를 사용해서 일을 합니다. 예제 프로그램에서 Main 클래스가 이 역할을 합니다. Adaptee(개조되는 쪽)의 역할Adaptee는 이미 준비되어 있는 메소드를 갖고 있는 역할입니다. Adaptee역의 메소드가 Target 역할의 메소드와 일치하면 다음 Adapter의 역할은 필요없습니다. Adapter의 역할Adapter 패턴의 주인공입니다. Adaptee 역할의 메소드를 사용해서 어떻게든 Target 역할을 만족시키기 위한 것이 Adapter 패턴의 목적이며, Adapter 역할의 임무입니다. 예제 프로그램에서는 PrintBanner 클래스가 Adapter의 역할을 합니다. 사고 넓히기어떤 경우에 사용할까?Adapter 패턴은 기존의 클래스를 개조해서 필요한 클래스를 만듭니다. 이 패턴으로 필요한 메소드를 빠르게 만들 수 있습니다. 이미 만들어진 클래스를 새로운 인터페이스(API)에 맞게 개조시킬 때 기존 클래스의 소스를 바꾸어서 ‘수정’하려고 합니다. 그러나 그렇게하면 테스트가 이미 끝난 기존의 클래스를 수정한 후에 다시 한 번 테스트 해야 합니다. Adapter 패턴은 기존의 클래스를 전혀 수정하지 않고 목적한 인터페이스(API)에 맞추려는 것입니다. 만약 버그가 발생해도 기존의 클래스(Adaptee의 역할)에는 버그가 없으므로 Adapter 역할의 클래스를 중점적으로 조사하면 되고, 프로그램 검사도 상당히 쉬워집니다.","link":"/2018/08/20/Java/design-pattern-adapter/"},{"title":"Sequelize 사용하기","text":"Index ORM 이란? Sequelize 설치하기 Sequelize CLI 사용하기 Sequelize config 설정하기 Model 정의하기 Sequelize Sync 사용하기 Sequelize 예제 (SELECT) Sequelize 예제 (INSERT) Sequelize 예제 (UPDATE) Sequelize 예제 (DELETE) ORM 이란?관계형 데이터베이스(RDB)를 사용할때 데이터베이스의 데이터 조작(CRUD)를 위해서는 SQL 문을 작성해야합니다. SQL 문은 비즈니스 로직을 구성하고 있는 코드와 함께 작성하게 되는데 이는 코드의 가독성을 떨어뜨릴뿐만 아니라, 사용하는 관계형 데이터베이스에 따라 조금씩의 차이가 존재하기 때문에 문제가 발생할 수 있습니다. 이를 해결하기 위해 ORM을 사용합니다. ORM(Object Relational Mapping)은 객체(Object)와 관계(Relation)를 맵핑(Mapping)하여 비즈니스 로직에 집중할 수 있도록 데이터 처리 로직을 추상화시킵니다. 객체와 관계를 매핑한다는 것은 데이터베이스에 저장된 레코드를 객체로 바꿔표현한다는 의미하며, 비즈니스 로직에 집중할 수 있도록 데이터 처리 로직을 추상화한다는 것은 쿼리를 사용하지 않고도 데이터베이스를 사용할 수 있음을 뜻합니다. ORM을 사용할 경우 특정 DBMS에 종속되지 않으며 생산성, 독립성, 가독성(SQL문이 코드에 들어가지 않기때문) 및 유지보수 측면에서의 장점이 있지만 반대로 RAW query에 비해 퍼포먼스가 떨어지고, query가 복잡해 질수록 오히려 생산성이 저하될 수 있다는 단점도 존재합니다. Sequelize 설치하기Sequelize는 Node에서 가장 많이 사용되는 ORM 입니다. RDS로 PostgresSQL, MySQL, MariaDB, SQLite, MSSQL을 지원하고 transaction, read replication등 다양한 기능을 제공하고 있으며. 또한 Promise를 기본으로 동작하기 때문에 비동기 코드를 보기좋게 작성할 수 있습니다. 실습을 위해 express-generator를 통해 Express 프로젝트를 생성후 sequelize와 mysql module을 설치합니다. (Express 프로젝트를 생성하는 부분은 생략합니다.) 1npm install --save sequelize mysql Sequelize Command Line Interface(CLI)를 사용하기 위해서 sequelize-cli module을 설치합니다. 1npm install -g sequelize-cli Sequelize CLI 사용하기sequelize cli를 통해서 migration(마이그레이션), seeder(시더), model(모델)의 초기 설정을 손쉽게 할 수 있습니다. 이번 포스팅에서는 model에 관해서 알아보겠습니다. RDB의 테이블을 model로 정의를 하면 해당 model을 통해 데이터 처리가 가능하게 됩니다.먼저 생성한 express 프로젝트에 sequelize cli 명령어를 통해 sequelize 설정 파일을 생성 후 model을 정의해 보겠습니다. 12sequelize init:config --config config/sequelize.jsonsequelize init:models sequelize cli의 sequelize init:config라는 명령어로 sequelize관련 config 파일을 자동으로 생성할 수 있습니다. 아무런 옵션을 주지 않는다면 config/config.json 파일이 생성됩니다. sequelize init:models 명령어를 통해서는 models 정의에 관련된 기본 구조를 생성할 수 있습니다. 위 2개의 명령어를 실행하면 다음과 같은 폴더와 파일이 생성됩니다.1234├── config/ └── sequelize.json├── models/ └── index.js Sequelize config 설정하기sequelize cli를 통해 생성한 config/sequelize.json파일에 데이터베이스에 관련된 설정 값을 입력합니다. NODE_ENV 에 따라 각기 다른 값을 사용하기 때문에 상황에 맞게 설정할 수 있습니다. NODE_ENV에 대해 잘 알지 못한다면 이곳을 참고하세요. 데이터베이스를 사용한 프로젝트 경험이 있다면 대부분의 config 값은 입력할 수 있습니다. config 값중 dialect에는 사용하는 RDB 이름을 입력해야 합니다. diaect에 사용 가능한 값은 sequelize docs를 참고하세요. 현재 사용 가능한 RDB 로는 ‘mysql’, ‘sqlite’, ‘postgress’, ‘mariadb’가 있습니다. 추가적으로 커넥션 풀과 로깅 기능을 사용한다면 해당 값을 추가합니다. 추가적으로 필요한 옵션은 docs를 참고하세요.123456\"pool\": { \"max\": 20, \"min\": 0, \"idle\": 5000},\"logging\": true # Model 정의하기Model을 생성하기 전 sequelize cli를 통해 생성한 models/index.js파일을 살펴보겠습니다. index.js 의 역할은 config/sequelize.json의 설정값을 읽어 sequelize를 생성한 후 models 폴더 아래에 정의한 model 관련 js 파일을 모두 로딩하여 db 객체에 Model을 정의한 후 반환합니다. sequelize config 관련 파일을 sequelize.json으로 생성하였다면 config 파일을 불러오는 require 부분의 경로를 수정해주어야 합니다. 이제 models 폴더 아래에 간단한 모델을 정의해 보겠습니다. user.js를 생성 후 다음의 코드를 입력합니다. 123456789101112131415161718192021222324252627module.exports = function (sequelize, DataTypes) { const user = sequelize.define('User', { userID: { field: 'user_id', type: DataTypes.STRING(50), unique: true, allowNull: false }, password: { field: 'password', type: DataTypes.STRING(30), allowNull: false }, }, { // don't use camelcase for automatically added attributes but underscore style // so updatedAt will be updated_at underscored: true, // disable the modification of tablenames; By default, sequelize will automatically // transform all passed model names (first parameter of define) into plural. // if you don't want that, set the following freezeTableName: true, // define the table's name tableName: 'user' }); return user;};/* Sequelize 참고 DataTypes =&gt; http://docs.sequelizejs.com/en/v3/api/datatypes/ Associations =&gt; http://docs.sequelizejs.com/en/v3/api/associations/ Model Function =&gt; http://docs.sequelizejs.com/en/v3/api/model/ */ Model을 생성하며 사용된 옵션은 주석과 docs를 참고합니다. 이제 모델에 대한 정의가 끝났습니다. 데이터베이스에 user라는 테이블은 User라는 Object로 매핑되었고 user_id, password라는 칼럼은 User Object의 속성으로 매핑되었습니다. Sequelize Sync 사용하기Sequeliz에서는 입력(INSERT), 수정(UPDATE), 조회(SELECT), 삭제(DELETE)의 데이터 조작(DML: Data Manipulation Language)뿐만 아니라 데이터베이스의 스키마 객체를 생성(CREATE), 변경(ALERT), 제거(DROP) 할 수 있는 데이터 정의(DDL: Data Definition Language)도 지원합니다.따라서 이미 만들어진 데이터베이스 테이블에 모델을 매핑할 수 있을 뿐만 아니라, 정의한 모델을 바탕으로 테이블을 생성할 수도 있습니다.(동기화) 해당 기능을 사용하기 위해서는 Sequelize의 sync 메서드를 사용합니다. app.js에 다음의 코드를 추가합니다.123456789101112// connect To DBconst models = require('./models');models.sequelize.sync() .then(() =&gt; { console.log('✓ DB connection success.'); console.log(' Press CTRL-C to stop\\n'); }) .catch(err =&gt; { console.error(err); console.log('✗ DB connection error. Please make sure DB is running.'; process.exit(); }); sync 메서드를 호출하여 실패했을 경우에는 에러 메시지를 출력 후 프로세스를 종료합니다. sync 메서드는 모델에서 정의한 이름의 테이블이 존재하지 않을 경우에만 동작합니다. 이미 테이블이 존재할 경우에는 models.sequelize.sync({force: true}) 과 같이 force 옵션을 주어 강제적으로 테이블을 제거 후 다시 생성이 가능하지만 매우 위험한 옵션이므로 주의를 기울여 사용해야 합니다. Sequelize 예제 (SELECT)이제 Sequelize를 사용하여 SELECT를 사용해보겠습니다. 유저 리스트를 가져오는 query는 다음과 같습니다.1234567models.User.findAll() .then(results) { res.json(results); }) .catch(err =&gt; { console.error(err); }); User 테이블에 있는 모든 row를 가져오는 query입니다. Sequelize는 결과를 Promise로 리턴하기 때문에 findAll 메서드 역시 Promise를 리턴합니다. 따라서 query의 결과는 then에서 받고, catch문에서 상황에 맞게 error 처리(handling)를 하면됩니다. findAll의 더 자세한 사용법은 Sequelize-model-findAll 설명을 참고합니다. Sequelize 예제 (INSERT)Sequelize를 사용하여 INSERT를 하는 방법은 다음과 같습니다.1234567models.User.create({userID: '유저ID', password: '유저PW'}) .then(result =&gt; { res.json(result); }) .catch(err =&gt; { console.error(err); }); create 메서드의 매개변수에 model에서 매핑한 내용을 토대로 데이터를 넣으면 query를 실행 후 insert된 row정보가 반환됩니다. create의 더 자세한 사용법은 Sequelize-model-create 설명을 참고합니다. Sequelize 예제 (UPDATE)User 테이블의 데이터를 수정할때는 다음과 같이 사용합니다.1234567models.User.update({password: '새로운 유저PW'}, {where: {userID: '유저ID'}}) .then(result =&gt; { res.json(result); }) .catch(err =&gt; { console.error(err); }); update 메서드의 매개변수에는 update할 데이터를 입력합니다. update 더 자세한 사용법은 Sequelize-model-update 설명을 참고합니다. Sequelize 예제 (DELETE)User 테이블의 데이터를 삭제할때는 다음과 같이 사용합니다.1234567models.User.destroy({where: {userID: '유저ID'}}) .then(result =&gt; { res.json({}); }) .catch(err =&gt; { console.error(err); }); destroy 메서드의 매개변수에는 where 조건을 입력합니다.(where 조건을 입력하지 않을 경우 테이블의 모든 row가 삭제되기 때문에 주의해야 합니다.) destroy 더 자세한 사용법은 Sequelize-model-update 설명을 참고합니다.","link":"/2017/04/08/Node/sequelize/"},{"title":"Design Pattern - Iterator","text":"해당 포스팅은 Java 언어로 배우는 디자인 패턴 입문 책을 참고해 작성했습니다.사용된 코드는 jongmin92/Design-Pattern repository 에서 확인할 수 있습니다. Iterator 패턴Java 언어에서 배열 arr의 모든 요소를 표시하기 위해서는 다음과 같이 for문을 사용합니다. 123for (int i = 0; i &lt; arr.length; i++) { System.out.println(arr[i]);} for문의 i++에서 i를 하나씩 증가시키면서 배열 arr의 요소 전체를 처음부터 차례대로 검색하게 됩니다. 여기서 사용되고 있는 변수 i의 기능을 추상화해서 일반화한 것을 디자인 패턴에서는 Iterator 패턴이라고 합니다. Iterator 패턴이란, 무엇인가 많이 모여있는 것들을 순서대로 지정하면서 전체를 검색하는 처리를 실행하기 위한 것입니다. Iterator는 무엇인가를 ‘반복한다’라는 의미이며, 반복자라고도 합니다. 예제 프로그램Iterator 패턴을 사용해 책장에 꽂혀 있는 책들을 하나씩 검색해 책 이름을 출력해보는 예제 프로그램을 작성해 보겠습니다. Aggregate 인터페이스Aggregate 인터페이스는 요소들이 나열되어 있는 ‘집합체’를 나타냅니다. 이 인터페이스를 구현하고 있는 클래스는 배열과 같이 무엇인가가 많이 모여 있습니다. 123public interface Aggregate { Iterator iterator();} Aggregate 인터페이스에 선언되어 있는 메소드는 iterator 메소드 하나뿐입니다. 이 메소드는 집합체에 대응하는 Iterator를 1개 작성하기 위한 것입니다. Iterator 인터페이스Iterator 인터페이스는 요소를 하나씩 나열하면서 루프 변수와 같은 역할을 수행합니다. 1234public interface Iterator() { boolean hasNext(); Object next();} hasNext 메소드는 다음 요소가 존재하는지를 조사하기 위한 메소드입니다. 다음 요소가 존재하면 true를 반환하고, 다음 요소가 존재하지 않는 마지막 요소라면 false를 반환합니다. 즉, hasNext는 루프의 종료 조건으로 사용됩니다. next 메소드는 집합체의 요소를 1개 반환합니다. 또한 next 메소드를 호출했을 때 다음 요소를 반환하도록 내부 상태를 다음으로 진행시켜 두는 역할도 함께합니다. Book 클래스Book 클래스는 책을 나타내는 클래스입니다. 1234567891011public class Book { private String name; public Book(String name) { this.name = name; } public String getName() { return name; }} BookShelf 클래스BookShelf 클래스는 책장을 나타내는 클래스입니다. 이 클래스를 집합체로 다루기 위해 Aggregate 인터페이스를 구현합니다. 1234567891011121314151617181920212223242526public class BookShelf implements Aggregate { private Book[] books; private int last = 0; public BookShelf(int maxsize) { this.books = new Book[maxsize]; } public Book getBookAt(int index) { return books[index]; } public void appendBook(Book book) { this.books[last] = book; last++; } public int getLength() { return last; } @Override public Iterator iterator() { return new BookShelfIterator(this); }} iterator 메소드는 BookShelf 클래스에 대응하는 Iterator로서, BookShelfIterator라는 클래스의 인스턴스를 생성해서 그것을 반환합니다. BookShelfIterator 클래스BookshelfIterator 를 Iterator로서 다루기 위해 Iterator 인터페이스를 구현합니다. bookShelf 필드는 BookShelfIterator가 검색할 책장이고, index 필드는 현재 가리키는 책을 가리키는 첨자입니다. 123456789101112131415161718192021 public class BookShelfIterator implements Iterator { private BookShelf bookShelf; private int index; public BookShelfIterator(BookShelf bookShelf) { this.bookShelf = bookShelf; this.index = 0; } @Override public boolean hasNext() { return index &lt; bookShelf.getLength(); } @Override public Object next() { Book book = bookShelf.getBookAt(index); index++; return book; }} Main 클래스123456789101112131415public class Main { public static void main(String[] args) { BookShelf bookShelf = new BookShelf(4); bookShelf.appendBook(new Book(\"Effective Java\")); bookShelf.appendBook(new Book(\"Head First Java\")); bookShelf.appendBook(new Book(\"Thinking In Java\")); bookShelf.appendBook(new Book(\"Agile Java\")); Iterator it = bookShelf.iterator(); while (it.hasNext()) { Book book = (Book) it.next(); System.out.println(book.getName()); } }} 12345// 실행결과Effective JavaHead First JavaThinking In JavaAgile Java Iterator 패턴의 구성요소 Iterator(반복자)의 역할요소를 순서대로 검색해가는 인터페이스(API)를 결정 (hasNext, next) ConcreteIterator(구체적인 반복자)의 역할Iterator가 결정한 인터페이스(API)를 실제로 구현 Aggregate(집합체)의 역할Iterator 역할을 만들어내는 인터페이스(API)를 결정 ConcreteAggregate(구체적인 집합체)의 역할Aggregate 역할이 결정한 인터페이스(API)를 실제로 구현 사고 넓히기구현에 상관 없이 Iterator를 사용할 수 있다.1234while (it.hasNext()) { Book book = (Book) it.next(); System.out.println(book.getName());} 여기서 사용되고 있는 것은 hasNext와 next라는 Iterator의 메소드 뿐입니다. BooShelf의 구현에서 사용되고 있는 메소드는 호출되고 있지 않습니다. 결국 위 코드의 while 루프는 BookShelf의 구현에 의존하지 않습니다. 그렇기 때문에 현재 배열을 사용해 구현하고 있는 BookShelf를 List를 사용하도록 수정해도, 위의 while 루프는 전혀 변경하지 않아도 동작합니다. Aggregate와 Iterator의 대응BookShelfIterator는 BookShelf가 어떻게 구현되고 있는지 알기 때문에, ‘다음 책’을 얻기 위해 getBookAt 메소드를 호출할 수 있었습니다. 만약 BookShelf의 구현을 전부 변경하고, getBookAt 메소드라는 인터페이스(API)도 변경된다면 BookShelfIterator의 수정이 필요하게 됩니다.","link":"/2018/08/18/Java/design-pattern-iterator/"},{"title":"AsyncRestTemplate의 콜백 헬과 중복 작업 문제","text":"해당 포스팅은 토비님의 토비의 봄 TV 10회 스프링 리액티브 프로그래밍 (6) AsyncRestTemplate의 콜백 헬과 중복 작업 문제 라이브 코딩을 보며 따라했던 실습 내용을 바탕으로 정리한 글입니다. 실습 코드들은 IntelliJ를 이용해 SpringBoot 2.1.3.RELEASE 버전 기반으로 프로젝트를 생성 후(web, lombok 포함) 진행했습니다. 이번에는 포스팅에서는 지난번 ListenableFuture를 사용하면서 발생한 콜백헬을 어떻게 개선할지에 대해서 이야기합니다. ListenableFuture를 Wrapping 하는 Completion이라는 클래스를 만들어, chainable하게 사용할 수 있는 방식으로 코드를 만들어봅니다.콜백헬의 문제로는 에러를 처리하는 코드가 중복이 된다는 것도 있는데, 이 부분도 해결해봅니다. Completion 클래스 추가123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @Autowired MyService myService; static final String URL1 = \"http://localhost:8081/service?req={req}\"; static final String URL2 = \"http://localhost:8081/service2?req={req}\"; @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); Completion .from(rt.getForEntity(URL1, String.class, \"hello\" + idx)) .andAccept(s -&gt; dr.setResult(s.getBody())); /* ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()); f2.addCallback(s2 -&gt; { ListenableFuture&lt;String&gt; f3 = myService.work(s2.getBody()); f3.addCallback(s3 -&gt; { dr.setResult(s3); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); */ return dr; } } public static class Completion { Consumer&lt;ResponseEntity&lt;String&gt;&gt; con; Completion next; public Completion() { } public Completion(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { this.con = con; } public static Completion from(ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf) { Completion c = new Completion(); lf.addCallback(s -&gt; { c.complete(s); }, e -&gt; { c.error(e); }); return c; } public void andAccept(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { Completion c = new Completion(con); this.next = c; } void complete(ResponseEntity&lt;String&gt; s) { if (next != null) next.run(s); } private void run(ResponseEntity&lt;String&gt; value) { if (con != null) con.accept(value); } private void error(Throwable e) { } } @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; work(String req) { return new AsyncResult&lt;&gt;(req + \"/asyncwork\"); } } @Bean public ThreadPoolTaskExecutor myThreadPool() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(1); te.setMaxPoolSize(1); te.initialize(); return te; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} andApply 메서드 추가123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @Autowired MyService myService; static final String URL1 = \"http://localhost:8081/service?req={req}\"; static final String URL2 = \"http://localhost:8081/service2?req={req}\"; @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); Completion .from(rt.getForEntity(URL1, String.class, \"hello\" + idx)) .andApply(s -&gt; rt.getForEntity(URL2, String.class, s.getBody())) .andAccept(s -&gt; dr.setResult(s.getBody())); /* ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()); f2.addCallback(s2 -&gt; { ListenableFuture&lt;String&gt; f3 = myService.work(s2.getBody()); f3.addCallback(s3 -&gt; { dr.setResult(s3); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); */ return dr; } } public static class Completion { Consumer&lt;ResponseEntity&lt;String&gt;&gt; con; Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn; Completion next; public Completion() { } public Completion(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { this.con = con; } public Completion(Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn) { this.fn = fn; } public static Completion from(ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf) { Completion c = new Completion(); lf.addCallback(s -&gt; { c.complete(s); }, e -&gt; { c.error(e); }); return c; } public Completion andApply(Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn) { Completion c = new Completion(fn); this.next = c; return c; } public void andAccept(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { Completion c = new Completion(con); this.next = c; } void complete(ResponseEntity&lt;String&gt; s) { if (next != null) next.run(s); } private void run(ResponseEntity&lt;String&gt; value) { if (con != null) con.accept(value); else if (fn != null) { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf = fn.apply(value); lf.addCallback(s -&gt; complete(s), e -&gt; error(e)); } } private void error(Throwable e) { } } @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; work(String req) { return new AsyncResult&lt;&gt;(req + \"/asyncwork\"); } } @Bean public ThreadPoolTaskExecutor myThreadPool() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(1); te.setMaxPoolSize(1); te.initialize(); return te; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} AcceptCompletion, AsyncCompletion 클래스 추가Completion을 결과를 받아서 사용만 하고 끝나는 Accept 처리를 하는 Completion과, 결과를 받아서 또 다른 비동기 작업을 수행하고 그 결과를 반환하는 Apply 용 Completion으로 분리합니다.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @Autowired MyService myService; static final String URL1 = \"http://localhost:8081/service?req={req}\"; static final String URL2 = \"http://localhost:8081/service2?req={req}\"; @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); Completion .from(rt.getForEntity(URL1, String.class, \"hello\" + idx)) .andApply(s -&gt; rt.getForEntity(URL2, String.class, s.getBody())) .andAccept(s -&gt; dr.setResult(s.getBody())); /* ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()); f2.addCallback(s2 -&gt; { ListenableFuture&lt;String&gt; f3 = myService.work(s2.getBody()); f3.addCallback(s3 -&gt; { dr.setResult(s3); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); */ return dr; } } public static class AcceptCompletion extends Completion { Consumer&lt;ResponseEntity&lt;String&gt;&gt; con; public AcceptCompletion(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { this.con = con; } @Override public void run(ResponseEntity&lt;String&gt; value) { con.accept(value); } } public static class AsyncCompletion extends Completion { Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn; public AsyncCompletion(Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn) { this.fn = fn; } @Override public void run(ResponseEntity&lt;String&gt; value) { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf = fn.apply(value); lf.addCallback(s -&gt; complete(s), e -&gt; error(e)); } } public static class Completion { Completion next; public static Completion from(ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf) { Completion c = new Completion(); lf.addCallback(s -&gt; { c.complete(s); }, e -&gt; { c.error(e); }); return c; } public Completion andApply(Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn) { Completion c = new AsyncCompletion(fn); this.next = c; return c; } public void andAccept(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { Completion c = new AcceptCompletion(con); this.next = c; } public void complete(ResponseEntity&lt;String&gt; s) { if (next != null) next.run(s); } public void run(ResponseEntity&lt;String&gt; value) { } public void error(Throwable e) { } } @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; work(String req) { return new AsyncResult&lt;&gt;(req + \"/asyncwork\"); } } @Bean public ThreadPoolTaskExecutor myThreadPool() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(1); te.setMaxPoolSize(1); te.initialize(); return te; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} ErrorCompletion 클래스 추가123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @Autowired MyService myService; static final String URL1 = \"http://localhost:8081/service?req={req}\"; static final String URL2 = \"http://localhost:8081/service2?req={req}\"; @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); Completion .from(rt.getForEntity(URL1, String.class, \"hello\" + idx)) .andApply(s -&gt; rt.getForEntity(URL2, String.class, s.getBody())) .andError(e -&gt; dr.setErrorResult(e)) .andAccept(s -&gt; dr.setResult(s.getBody())); /* ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()); f2.addCallback(s2 -&gt; { ListenableFuture&lt;String&gt; f3 = myService.work(s2.getBody()); f3.addCallback(s3 -&gt; { dr.setResult(s3); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); */ return dr; } } public static class AcceptCompletion extends Completion { Consumer&lt;ResponseEntity&lt;String&gt;&gt; con; public AcceptCompletion(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { this.con = con; } @Override public void run(ResponseEntity&lt;String&gt; value) { con.accept(value); } } public static class ErrorCompletion extends Completion { Consumer&lt;Throwable&gt; econ; public ErrorCompletion(Consumer&lt;Throwable&gt; econ) { this.econ = econ; } @Override public void run(ResponseEntity&lt;String&gt; value) { if (next != null) { next.run(value); } } @Override public void error(Throwable e) { econ.accept(e); } } public static class AsyncCompletion extends Completion { Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn; public AsyncCompletion(Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn) { this.fn = fn; } @Override public void run(ResponseEntity&lt;String&gt; value) { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf = fn.apply(value); lf.addCallback(s -&gt; complete(s), e -&gt; error(e)); } } public static class Completion { Completion next; public static Completion from(ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; lf) { Completion c = new Completion(); lf.addCallback(s -&gt; { c.complete(s); }, e -&gt; { c.error(e); }); return c; } public Completion andApply(Function&lt;ResponseEntity&lt;String&gt;, ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt;&gt; fn) { Completion c = new AsyncCompletion(fn); this.next = c; return c; } public Completion andError(Consumer&lt;Throwable&gt; econ) { Completion c = new ErrorCompletion(econ); this.next = c; return c; } public void andAccept(Consumer&lt;ResponseEntity&lt;String&gt;&gt; con) { Completion c = new AcceptCompletion(con); this.next = c; } public void complete(ResponseEntity&lt;String&gt; s) { if (next != null) next.run(s); } public void run(ResponseEntity&lt;String&gt; value) { } public void error(Throwable e) { if (next != null) next.error(e); } } @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; work(String req) { return new AsyncResult&lt;&gt;(req + \"/asyncwork\"); } } @Bean public ThreadPoolTaskExecutor myThreadPool() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(1); te.setMaxPoolSize(1); te.initialize(); return te; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} Generic 적용123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @Autowired MyService myService; static final String URL1 = \"http://localhost:8081/service?req={req}\"; static final String URL2 = \"http://localhost:8081/service2?req={req}\"; @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); Completion .from(rt.getForEntity(URL1, String.class, \"hello\" + idx)) .andApply(s -&gt; rt.getForEntity(URL2, String.class, s.getBody())) .andApply(s -&gt; myService.work(s.getBody())) .andError(e -&gt; dr.setErrorResult(e.toString())) .andAccept(s -&gt; dr.setResult(s)); /* ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()); f2.addCallback(s2 -&gt; { ListenableFuture&lt;String&gt; f3 = myService.work(s2.getBody()); f3.addCallback(s3 -&gt; { dr.setResult(s3); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); */ return dr; } } public static class AcceptCompletion&lt;S&gt; extends Completion&lt;S, Void&gt; { Consumer&lt;S&gt; con; public AcceptCompletion(Consumer&lt;S&gt; con) { this.con = con; } @Override public void run(S value) { con.accept(value); } } public static class ErrorCompletion&lt;T&gt; extends Completion&lt;T, T&gt; { Consumer&lt;Throwable&gt; econ; public ErrorCompletion(Consumer&lt;Throwable&gt; econ) { this.econ = econ; } @Override public void run(T value) { if (next != null) { next.run(value); } } @Override public void error(Throwable e) { econ.accept(e); } } public static class AsyncCompletion&lt;S, T&gt; extends Completion&lt;S, T&gt; { Function&lt;S, ListenableFuture&lt;T&gt;&gt; fn; public AsyncCompletion(Function&lt;S, ListenableFuture&lt;T&gt;&gt; fn) { this.fn = fn; } @Override public void run(S value) { ListenableFuture&lt;T&gt; lf = fn.apply(value); lf.addCallback(s -&gt; complete(s), e -&gt; error(e)); } } // S는 넘어온 파라미터, T는 결과 public static class Completion&lt;S, T&gt; { Completion next; public static &lt;S, T&gt; Completion&lt;S, T&gt; from(ListenableFuture&lt;T&gt; lf) { Completion&lt;S, T&gt; c = new Completion&lt;&gt;(); lf.addCallback(s -&gt; { c.complete(s); }, e -&gt; { c.error(e); }); return c; } public &lt;V&gt; Completion&lt;T, V&gt; andApply(Function&lt;T, ListenableFuture&lt;V&gt;&gt; fn) { Completion&lt;T, V&gt; c = new AsyncCompletion&lt;&gt;(fn); this.next = c; return c; } public Completion&lt;T, T&gt; andError(Consumer&lt;Throwable&gt; econ) { Completion&lt;T, T&gt; c = new ErrorCompletion&lt;&gt;(econ); this.next = c; return c; } public void andAccept(Consumer&lt;T&gt; con) { Completion&lt;T, Void&gt; c = new AcceptCompletion&lt;&gt;(con); this.next = c; } public void complete(T s) { if (next != null) next.run(s); } public void run(S value) { } public void error(Throwable e) { if (next != null) next.error(e); } } @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; work(String req) { return new AsyncResult&lt;&gt;(req + \"/asyncwork\"); } } @Bean public ThreadPoolTaskExecutor myThreadPool() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(1); te.setMaxPoolSize(1); te.initialize(); return te; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }}","link":"/2019/04/26/Java/java-async-3/"},{"title":"자바와 스프링의 비동기 기술","text":"해당 포스팅은 토비님의 토비의 봄 TV 8회 스프링 리액티브 프로그래밍 (4) 자바와 스프링의 비동기 기술 라이브 코딩을 보며 따라했던 실습 내용을 바탕으로 정리한 글입니다. 실습 코드들은 IntelliJ를 이용해 SpringBoot 2.1.3.RELEASE 버전 기반으로 프로젝트를 생성 후(web, lombok 포함) 진행했습니다. 자바의 비동기 기술ExecutorServiceExecutorService는 쉽게 비동기로 작업을 실행할 수 있도록 도와주는 JDK(1.5부터)에서 제공하는 interface입니다. 일반적으로 ExecutorService는 작업 할당을 위한 스레드 풀과 API를 제공합니다. 12345678910111213141516171819@Slf4jpublic class FutureEx { public static void main(String[] args) { ExecutorService es = Executors.newCachedThreadPool(); es.execute(() -&gt; { try { Thread.sleep(2000); } catch (InterruptedException e) {} log.info(\"Async\"); }); log.info(\"Exit\"); }}// 결과20:35:53.892 [main] INFO com.example.study.FutureEx - Exit20:35:55.888 [pool-1-thread-1] INFO com.example.study.FutureEx - Async FutureFuture는 자바 1.5에서 등장한 비동기 계산의 결과를 나타내는 Interface 입니다. 비동기적인 작업을 수행한다는 것은 현재 진행하고 있는 스레드가 아닌 별도의 스레드에서 작업을 수행하는 것을 말합니다. 같은 스레드에서 메서드를 호출할 때는 결과를 리턴 값을 받지만, 비동기적으로 작업을 수행할 때는 결과값을 전달받을 수 있는 무언가의 interface가 필요한데 Future가 그 역할을 합니다. 비동기 작업에서 결과를 반환하고 싶을 때는 runnable대신 callable interface를 이용하면 결과 값을 return 할 수 있습니다. 또한 예외가 발생했을 때 해당 예외를 비동기 코드를 처리하는 스레드 안에서 처리하지 않고 밖으로 던질 수 있습니다. 1234567891011121314151617181920@Slf4jpublic class FutureEx { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService es = Executors.newCachedThreadPool(); Future&lt;String&gt; f = es.submit(() -&gt; { Thread.sleep(2000); log.info(\"Async\"); return \"Hello\"; }); log.info(f.get()); log.info(\"Exit\"); }}// 결과20:43:11.704 [pool-1-thread-1] INFO com.example.study.FutureEx - Async20:43:11.706 [main] INFO com.example.study.FutureEx - Hello20:43:11.706 [main] INFO com.example.study.FutureEx - Exit Future를 통해서 비동기 결과의 값을 가져올 때는 get 메서드를 사용합니다. 그러나 get 메서드를 호출하게 되면 비동기 작업이 완료될 때까지 해당 스레드가 blocking됩니다. Future는 비동기적인 연산 혹은 작업을 수행하고 그 결과를 갖고 있으며, 완료를 기다리고 계산 결과를 반환(get)하는 메소드와 그 외에도 해당 연산이 완료되었는지 확인하는(isDone) 메소드를 제공합니다. 12345678910111213141516171819202122232425@Slf4jpublic class FutureEx { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService es = Executors.newCachedThreadPool(); Future&lt;String&gt; f = es.submit(() -&gt; { Thread.sleep(2000); log.info(\"Async\"); return \"Hello\"; }); log.info(String.valueOf(f.isDone())); Thread.sleep(2000); log.info(\"Exit\"); log.info(String.valueOf(f.isDone())); log.info(f.get()); }}// 결과00:26:00.501 [main] INFO com.example.study.FutureEx - false00:26:02.502 [pool-1-thread-1] INFO com.example.study.FutureEx - Async00:26:02.509 [main] INFO com.example.study.FutureEx - Exit00:26:02.509 [main] INFO com.example.study.FutureEx - true00:26:02.509 [main] INFO com.example.study.FutureEx - Hello FutureTaskFutureTask는 비동기 작업을 생성합니다. 지금까지 위의 코드는 비동기 작업 생성과 실행을 동시에 했다면 FutureTask는 비동기 작업 생성과 실행을 분리하여 진행할 수 있습니다. 123456789101112131415161718192021222324252627@Slf4jpublic class FutureEx { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService es = Executors.newCachedThreadPool(); FutureTask&lt;String&gt; f = new FutureTask&lt;&gt;(() -&gt; { Thread.sleep(2000); log.info(\"Async\"); return \"Hello\"; }); es.execute(f); log.info(String.valueOf(f.isDone())); Thread.sleep(2000); log.info(\"Exit\"); log.info(String.valueOf(f.isDone())); log.info(f.get()); }}// 결과00:28:39.459 [main] INFO com.example.study.FutureEx - false00:28:41.461 [pool-1-thread-1] INFO com.example.study.FutureEx - Async00:28:41.467 [main] INFO com.example.study.FutureEx - Exit00:28:41.467 [main] INFO com.example.study.FutureEx - true00:28:41.467 [main] INFO com.example.study.FutureEx - Hello 비동기 작업의 결과를 가져오는 방법은 Future와 같은 결과를 다루는 handler를 이용하거나 callback을 이용하는 2가지 방법이 있습니다.아래의 예시 코드는 FutureTask의 비동기 작업이 완료될 경우 호출되는 done() 메서드를 재정의하여 callback을 이용하는 방법입니다. 12345678910111213141516171819202122232425262728293031323334@Slf4jpublic class FutureEx { public static void main(String[] args) { ExecutorService es = Executors.newCachedThreadPool(); FutureTask&lt;String&gt; f = new FutureTask&lt;String&gt;(() -&gt; { Thread.sleep(2000); log.info(\"Async\"); return \"Hello\"; }) { @Override protected void done() { super.done(); try { log.info(get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } }; es.execute(f); es.shutdown(); log.info(\"EXIT\"); }}// 결과01:03:04.153 [main] INFO com.example.study.FutureEx - EXIT01:03:06.153 [pool-1-thread-1] INFO com.example.study.FutureEx - Async01:03:06.153 [pool-1-thread-1] INFO com.example.study.FutureEx - Hello 위 예시 코드의 callback 관련 부분을 FutureTask를 상속받아 done() 메서드를 재정의함으로써, 비동기 코드와 그 결과를 갖고 작업을 수행하는 callback을 좀 더 가독성이 좋게 작성할 수 있습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4jpublic class FutureEx { interface SuccessCallback { void onSuccess(String result); } public static class CallbackFutureTask extends FutureTask&lt;String&gt; { SuccessCallback sc; public CallbackFutureTask(Callable&lt;String&gt; callable, SuccessCallback sc) { super(callable); this.sc = Objects.requireNonNull(sc); } @Override protected void done() { super.done(); try { this.sc.onSuccess(get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } public static void main(String[] args) { ExecutorService es = Executors.newCachedThreadPool(); CallbackFutureTask f = new CallbackFutureTask(() -&gt; { Thread.sleep(2000); log.info(\"Async\"); return \"Hello\"; }, log::info); es.execute(f); es.shutdown(); }}// 결과01:05:01.978 [main] INFO com.example.study.FutureEx - EXIT01:05:03.977 [pool-1-thread-1] INFO com.example.study.FutureEx - Async01:05:03.978 [pool-1-thread-1] INFO com.example.study.FutureEx - Hello 위 예시 코드에 SuccessCallback을 추가한 것처럼 ExceptionCallback을 추가하여 비동기 코드에서 예외가 발생할 경우, 해당 예외를 처리하는 callback도 추가할 수 있습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Slf4jpublic class FutureEx { interface SuccessCallback { void onSuccess(String result); } interface ExceptionCallback { void onError(Throwable t); } public static class CallbackFutureTask extends FutureTask&lt;String&gt; { SuccessCallback sc; ExceptionCallback ec; public CallbackFutureTask(Callable&lt;String&gt; callable, SuccessCallback sc, ExceptionCallback ec) { super(callable); this.sc = Objects.requireNonNull(sc); this.ec = Objects.requireNonNull(ec); } @Override protected void done() { super.done(); try { this.sc.onSuccess(get()); /* InterruptedException은 예외긴 예외이지만, 현재 작업을 수행하지 말고 중단해라 라고 메시지를 보내는 용도이다. 따라서 현재 스레드에 interrupt를 체크하고 종료한다. */ } catch (InterruptedException e) { Thread.currentThread().interrupt(); } catch (ExecutionException e) { // 래핑된 에러를 빼내어 전달한다. ec.onError(e.getCause()); } } } public static void main(String[] args) { ExecutorService es = Executors.newCachedThreadPool(); CallbackFutureTask f = new CallbackFutureTask(() -&gt; { Thread.sleep(2000); if (1 == 1) throw new RuntimeException(\"Async ERROR!!!\"); log.info(\"Async\"); return \"Hello\"; }, s -&gt; log.info(\"Result: {}\", s), e -&gt; log.info(\"Error: {}\", e.getMessage())); es.execute(f); es.shutdown(); log.info(\"EXIT\"); }}// 결과01:11:53.460 [main] INFO com.example.study.FutureEx - EXIT01:11:55.463 [pool-1-thread-1] INFO com.example.study.FutureEx - Error: Async ERROR!!! 스프링의 비동기 기술@AsyncSpring MVC 3.2 부터 Servlet 3.0 기반의 비동기 요청 처리가 가능해졌습니다. @Async 어노테이션을 추가해 해당 메서드를 비동기적으로 호출할 수 있습니다. 해당 메서드를 호출한 호출자(caller)는 즉시 리턴하고 메소드의 실제 실행은 Spring TaskExecutor에 의해서 실행됩니다. 비동기로 실행되는 메서드는 Future 형식의 값을 리턴하고, 호출자는 해당 Future의 get() 메서드를 호출하기 전에 다른 작업을 수행할 수 있습니다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @Service public static class MyService { /* 내부적으로 AOP를 이용해 복잡한 로직이 실행된다. 비동기 작업은 return값으로 바로 결과를 줄 수 없다. (Future 혹은 Callback을 이용해야 한다.) */ @Async public Future&lt;String&gt; hello() throws InterruptedException { log.info(\"hello()\"); Thread.sleep(1000); return new AsyncResult&lt;&gt;(\"Hello\"); } } public static void main(String[] args) { // try with resource 블록을 이용해 빈이 다 준비된 후 종료되도록 설정 try (ConfigurableApplicationContext c = SpringApplication.run(StudyApplication.class, args)) { } } @Autowired MyService myService; // 모든 빈이 다 준비된 후 실행됨 (현재는 일종의 컨트롤러라고 생각) @Bean ApplicationRunner run() { return args -&gt; { log.info(\"run()\"); Future&lt;String&gt; res = myService.hello(); log.info(\"exit: {}\", res.isDone()); log.info(\"result: {}\", res.get()); }; }}// 결과2019-04-04 23:29:31.960 INFO 41618 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-04-04 23:29:31.960 INFO 41618 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 928 ms2019-04-04 23:29:32.161 INFO 41618 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'2019-04-04 23:29:32.337 INFO 41618 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2019-04-04 23:29:32.341 INFO 41618 --- [ main] com.example.study.StudyApplication : Started StudyApplication in 1.631 seconds (JVM running for 2.101)2019-04-04 23:29:32.343 INFO 41618 --- [ main] com.example.study.StudyApplication : run()2019-04-04 23:29:32.346 INFO 41618 --- [ main] com.example.study.StudyApplication : exit: false2019-04-04 23:29:32.350 INFO 41618 --- [ task-1] com.example.study.StudyApplication : hello()2019-04-04 23:29:33.351 INFO 41618 --- [ main] com.example.study.StudyApplication : result: Hello2019-04-04 23:29:33.354 INFO 41618 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' ListenableFuture스프링 4.0 부터 제공하는 Future 인터페이스를 확장한 ListenableFuture를 이용하면 비동기 처리의 결과 값을 사용할 수 있는 callback을 추가할 수 있습니다.@Async 어노테이션을 사용하는 메서드에서 스프링 4.1 부터 제공하는 ListenableFuture 인터페이스를 구현한 AsyncResult를 반환하면 됩니다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; hello() throws InterruptedException { log.info(\"hello()\"); Thread.sleep(1000); return new AsyncResult&lt;&gt;(\"Hello\"); } } public static void main(String[] args) { // try with resource 블록을 이용해 빈이 다 준비된 후 종료되도록 설정 try (ConfigurableApplicationContext c = SpringApplication.run(StudyApplication.class, args)) { } } @Autowired MyService myService; @Bean ApplicationRunner run() { return args -&gt; { log.info(\"run()\"); ListenableFuture&lt;String&gt; f = myService.hello(); f.addCallback(s -&gt; log.info(s), e-&gt; log.info(e.getMessage())); log.info(\"exit\"); Thread.sleep(2000); }; }}// 결과2019-04-04 23:42:46.348 INFO 44559 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-04-04 23:42:46.348 INFO 44559 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 959 ms2019-04-04 23:42:46.557 INFO 44559 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'2019-04-04 23:42:46.736 INFO 44559 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2019-04-04 23:42:46.740 INFO 44559 --- [ main] com.example.study.StudyApplication : Started StudyApplication in 1.779 seconds (JVM running for 2.306)2019-04-04 23:42:46.742 INFO 44559 --- [ main] com.example.study.StudyApplication : run()2019-04-04 23:42:46.748 INFO 44559 --- [ main] com.example.study.StudyApplication : exit2019-04-04 23:42:46.751 INFO 44559 --- [ task-1] com.example.study.StudyApplication : hello()2019-04-04 23:42:47.752 INFO 44559 --- [ task-1] com.example.study.StudyApplication : Hello2019-04-04 23:42:48.757 INFO 44559 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' ThreadPoolTaskExecutor@Async 어노테이션을 사용해 해당 메서드를 비동기적으로 호출할 경우 ThreadPool을 명시적으로 선언하지 않으면, 기본적으로 SimpleAsyncTaskExecutor를 사용합니다. SimpleAsyncTaskExecutor는 각 비동기 호출마다 계속 새로운 스레드를 만들어 사용하기 때문에 비효율적입니다. 이 경우 ThreadPoolTaskExecutor를 직접 만들어 사용하는게 효율적입니다. ThreadPoolTaskExecutor는 CorePool, QueueCapacity, MaxPoolSize를 직접 설정할 수 있습니다. 각 값에 대한 설명은 코드에 추가했습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @Service public static class MyService { /* 기본적으로 SimpleAsyncTaskExecutor를 사용한다. 스레드를 계속 새로 만들어 사용하기 때문에 비효율적이다. */ @Async // @Async(\"tp\") ThreadPool이 여러개일 경우 직접 지정 가능하다. public ListenableFuture&lt;String&gt; hello() throws InterruptedException { log.info(\"hello()\"); Thread.sleep(1000); return new AsyncResult&lt;&gt;(\"Hello\"); } } @Bean ThreadPoolTaskExecutor tp() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); // 1) 스레드 풀을 해당 개수까지 기본적으로 생성함. 처음 요청이 들어올 때 poll size만큼 생성한다. te.setCorePoolSize(10); // 2) 지금 당장은 Core 스레드를 모두 사용중일때, 큐에 만들어 대기시킨다. te.setQueueCapacity(50); // 3) 대기하는 작업이 큐에 꽉 찰 경우, 풀을 해당 개수까지 더 생성한다. te.setMaxPoolSize(100); te.setThreadNamePrefix(\"myThread\"); return te; } public static void main(String[] args) { // try with resource 블록을 이용해 빈이 다 준비된 후 종료되도록 설정 try (ConfigurableApplicationContext c = SpringApplication.run(StudyApplication.class, args)) { } } @Autowired MyService myService; // 모든 빈이 다 준비된 후 실행됨 (현재는 일종의 컨트롤러라고 생각) @Bean ApplicationRunner run() { return args -&gt; { log.info(\"run()\"); ListenableFuture&lt;String&gt; f = myService.hello(); f.addCallback(s -&gt; log.info(s), e-&gt; log.info(e.getMessage())); log.info(\"exit\"); Thread.sleep(2000); }; }}// 결과2019-04-05 00:03:11.304 INFO 47863 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-04-05 00:03:11.304 INFO 47863 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1061 ms2019-04-05 00:03:11.367 INFO 47863 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'tp'2019-04-05 00:03:11.677 INFO 47863 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2019-04-05 00:03:11.680 INFO 47863 --- [ main] com.example.study.StudyApplication : Started StudyApplication in 1.751 seconds (JVM running for 2.208)2019-04-05 00:03:11.681 INFO 47863 --- [ main] com.example.study.StudyApplication : run()2019-04-05 00:03:11.686 INFO 47863 --- [ main] com.example.study.StudyApplication : exit2019-04-05 00:03:11.687 INFO 47863 --- [ myThread1] com.example.study.StudyApplication : hello()2019-04-05 00:03:12.691 INFO 47863 --- [ myThread1] com.example.study.StudyApplication : Hello Servlet Async@Async 어노테이션을 설명할 때 말했던 것처럼, Spring MVC 3.2 부터 Servlet 3.0 기반의 비동기 요청 처리가 가능해졌습니다. 기존 Controller 메서드를 Callable로 변경함으로써 비동기로 만들 수 있습니다.Controller 메서드를 비동기로 변경해도 해당 처리가 서블릿 스레드가 아닌 다른 스레드에서 발생한다는 점을 제외하면 기존 Controller 메서드의 동작 방식과는 큰 차이가 없습니다.(참고 : Spring MVC 3.2 Preview: Making a Controller Method Asynchronous) Servlet 3.0 &amp; 3.1 Servlet 3.0: 비동기 서블릿 HTTP connection은 이미 논블록킹 IO 서블릿 요청 읽기, 응답 쓰기는 블록킹 비동기 작업 시작 즉시 서블릿 스레드 반납 비동기 작업이 완료되면 서블릿 스레드 재할당 비동기 서블릿 컨텍스트 이용 (AsyncContext) Servlet 3.1: 논블록킹 IO 논블록킹 서블릿 요청, 응답 처리 Callback 스레드가 블록되는 상황은 CPU와 메모리 자원을 많이 소모합니다. 컨텍스트 스위칭이 일어나기 때문입니다. 기본적으로 스레드가 블로킹되면 wating 상태로 변경되면서 컨텍스트 스위칭이 일어나고 추후 I/O 작업이 끝나 running 상태로 변경되면서 다시 컨텍스트 스위칭이 일어나 총 2번의 컨텍스트 스위칭이 일어납니다.Java InputStream과 OutputStream은 블록킹 방식이다. RequestHttpServletRequest, RequestHttpServletResponse는 InputSream과 OutputStream을 사용하기 때문에 서블릿은 기본적으로 블로킹 IO 방식이다. 1234567891011121314151617181920212223242526272829303132333435@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { @GetMapping(\"/callable\") public Callable&lt;String&gt; callable() { log.info(\"callable\"); return () -&gt; { log.info(\"async\"); Thread.sleep(2000); return \"hello\"; }; } } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }}// 결과2019-04-06 01:12:41.761 INFO 69216 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-04-06 01:12:41.762 INFO 69216 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1206 ms2019-04-06 01:12:41.993 INFO 69216 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'2019-04-06 01:12:42.182 INFO 69216 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2019-04-06 01:12:42.186 INFO 69216 --- [ main] com.example.study.StudyApplication : Started StudyApplication in 2.073 seconds (JVM running for 2.807)2019-04-06 01:12:44.161 INFO 69216 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'2019-04-06 01:12:44.162 INFO 69216 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'2019-04-06 01:12:44.169 INFO 69216 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 7 ms2019-04-06 01:12:44.190 INFO 69216 --- [nio-8080-exec-1] com.example.study.StudyApplication : callable2019-04-06 01:12:44.198 INFO 69216 --- [ task-1] com.example.study.StudyApplication : async 실제로 비동기 서블릿은 아래의 그림처럼 동작합니다. Client (For Load Test)지금부터는 Spring에서 Sync Servlet을 이용할 때와 Async Servlet을 이용했을 때의 차이점을 알아보기 위해 테스트를 할 수 있도록, 먼저 여러 Request를 동시에 생성하는 Client를 작성해봅니다.Spring에서 제공하는 RestTemplate을 이용해 100개의 Request를 동시에 호출합니다. 123456789101112131415161718192021222324252627282930313233343536@Slf4jpublic class LoadTest { private static AtomicInteger counter = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException { ExecutorService es = Executors.newFixedThreadPool(100); RestTemplate rt = new RestTemplate(); String url = \"http://localhost:8080/callable\"; StopWatch main = new StopWatch(); main.start(); for (int i = 0; i &lt; 100; i++) { es.execute(() -&gt; { int idx = counter.addAndGet(1); log.info(\"Thread {}\", idx); StopWatch sw = new StopWatch(); sw.start(); rt.getForObject(url, String.class); sw.stop(); log.info(\"Elapsed: {} -&gt; {}\", idx, sw.getTotalTimeSeconds()); }); } es.shutdown(); // 지정된 시간이 타임아웃 걸리기 전이라면 대기작업이 진행될 때까지 기다린다. // (100초안에 작업이 끝날때까지 기다리거나, 100초가 초과되면 종료) es.awaitTermination(100, TimeUnit.SECONDS); main.stop(); log.info(\"Total: {}\", main.getTotalTimeSeconds()); }} Change Tomcat Thread Count위의 비동기 서블릿 그림에서 볼 수 있듯이, Async Servlet은 클라이언트로부터 요청을 받은 후 실제 작업은 작업 스레드 풀에 위임하고 현재의 서블릿 스레드는 서블릿 스레드 풀에 반환 후, 다음 요청이 들어올 경우 사용할 수 있도록 합니다. 이에 반해, Sync Servlet은 요청을 받은 서블릿 스레드에서 실제 작업까지 전부 진행하기 때문에 요청에 대한 응답을 반환하기 전까지는 새로운 요청을 처리할 수 없는 상태입니다. 실제 이처럼 동작하는지 확인하기 위해서 application.properties 파일에서 다음과 같이 Tomcat의 스레드 개수를 1개로 설정합니다.1server.tomcat.max-threads=1 Sync vs AsyncSync먼저 아래와 같이 Sync Servlet을 이용해 서버를 띄운 후 위의 Client 코드를 이용해 테스트를 진행합니다. 12345678910111213141516171819@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { @GetMapping(\"/callable\") public String callable() throws InterruptedException { log.info(\"sync\"); Thread.sleep(2000); return \"hello\"; } } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} 해당 서버를 띄우고 Client(LoadTest) 코드를 사용해 테스트를 진행하면 결과는 다음과 같습니다. Tomcat의 스레드가 하나이며 Sync 방식으로 동작하기 때문에 한 번에 하나의 클라이언트 요청만 처리할 수 있습니다. 서버 로그를 확인하면 nio-8080-exec-1 라는 이름을 가진 한개의 스레드가 요청을 처리하고 있습니다. 이번에는 JMC(Java Mission Control)를 이용해 실제 서버의 스레드 상황을 살펴보겠습니다. JMC를 이용하기 위해서는 서버를 실행할 때 다음과 같은 JVM 옵션을 추가합니다.123456-XX:+UnlockCommercialFeatures-XX:+FlightRecorder-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false-Dcom.sun.management.jmxremote.ssl=false-Djava.rmi.server.hostname=localhost JMC를 이용해 클라이언트 요청이 들어올 때, Thread 상태를 보면 다음과 같습니다. 동시에 100개의 클라이언트 요청이 들어왔지만, 스레드 수는 그대로 유지되고 있으며, 여러 스레드 목록 중에 nio-8080-exec-1 스레드가 존재하고 있는것을 확인할 수 있습니다. Async이번에는 서버 코드를 아래와 같이 Async Servlet을 이용하도록 수정한 후 서버를 띄워 Client 코드를 이용해 테스트를 진행합니다. (작업 스레드 풀은 WebMvcConfigurer를 통해 설정해줍니다.) 1234567891011121314151617181920212223242526272829303132333435363738@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { @GetMapping(\"/callable\") public Callable&lt;String&gt; callable() { return () -&gt; { log.info(\"async\"); Thread.sleep(2000); return \"hello\"; }; } } @Bean WebMvcConfigurer configurer() { return new WebMvcConfigurer() { // 워커 스레드 풀 설정 @Override public void configureAsyncSupport(AsyncSupportConfigurer configurer) { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(100); te.setQueueCapacity(50); te.setMaxPoolSize(200); te.setThreadNamePrefix(\"workThread\"); te.initialize(); configurer.setTaskExecutor(te); } }; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} Client(LoadTest) 코드를 사용해 테스트를 진행하면 결과는 다음과 같습니다. Tomcat의 스레드가 하나이지만 Async 방식으로 동작하기 때문에 해당 요청에 대한 실제 처리는 워커 스레드 풀에서 사용되고 있지 않은 스레드를 이용해 처리합니다. 서버 로그를 확인하면 nio-8080-exec-1 라는 이름을 가진 한개의 Tomcat 스레드와 workThreadX라는 이름을 가진 100개의 워커 스레드를 확인할 수 있습니다. 이번에도 역시 JMC(Java Mission Control)를 이용해 실제 서버의 스레드 상황을 살펴보겠습니다. nio-8080-exec-1 라는 이름을 가진 한개의 Tomcat 스레드와 workThreadX라는 이름을 가진 100개의 워커 스레드를 확인할 수 있습니다. DeferredResultDeferredResult는 Spring 3.2 부터 사용 가능합니다. 비동기 요청 처리를 위해 사용하는 Callable의 대안을 제공합니다. “지연된 결과”를 의미하며 외부의 이벤트 혹은 클라이언트 요청에 의해서 지연되어 있는 HTTP 요청에 대한 응답을 나중에 써줄 수 있는 기술입니다. 별도로 워커 스레드를 만들어 대기하지 않고도 처리가 가능합니다. 123456789101112131415161718192021222324252627282930313233343536@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { Queue&lt;DeferredResult&lt;String&gt;&gt; results = new ConcurrentLinkedQueue&lt;&gt;(); @GetMapping(\"/dr\") public DeferredResult&lt;String&gt; dr() { log.info(\"dr\"); DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); results.add(dr); return dr; } @GetMapping(\"/dr/count\") public String drCount() { return String.valueOf(results.size()); } @GetMapping(\"/dr/event\") public String drEvent(String msg) { for (DeferredResult&lt;String&gt; dr : results) { dr.setResult(\"Hello \" + msg); results.remove(dr); } return \"OK\"; } } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} LoadTest 코드를 이용해 /dr로 100개의 요청을 보내고, 크롬에서 /dr/count로 DeferredResult가 담겨있는 큐의 사이즈를 확인해봅니다. 그리고 마지막으로 /dr/event로 큐에 담긴 DeferredResult 객체에 setResult로 결과를 반환합니다.100개의 요청이 동시에 완료되는 것을 확인할 수 있습니다. ResponseBodyEmitterResponseBodyEmitter는 Spring 4.2 부터 사용 가능합니다. 비동기 요청 처리의 결과로 하나 이상의 응답을 위해 사용되는 리턴 값 Type 입니다. DeferredResult가 하나의 결과를 생성해 요청을 처리했다면, ResponseBodyEmitter는 여러개의 결과를 만들어 요청을 처리할 수 있습니다. 123456789101112131415161718192021222324252627282930@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { @GetMapping(\"/emitter\") public ResponseBodyEmitter emitter() { ResponseBodyEmitter emitter = new ResponseBodyEmitter(); Executors.newSingleThreadExecutor().submit(() -&gt; { try { for (int i = 0; i &lt; 50; i++) { emitter.send(\"&lt;p&gt;Stream \" + i + \"&lt;/p&gt;\"); Thread.sleep(100); } } catch (Exception e) { } }); return emitter; } } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }} 후기우하한형제들 - 스프링 리액티브 프로그래밍 세미나를 다녀온 후 토비의 봄 TV 스프링 리액티브 프로그래밍 시리즈를 전부 보고있습니다. 토비님은 매 라이브 코딩마다 말씀하시길 단순히 코드를 보는 것과 실행 후 결과를 실제로 확인해보는 것은 또 다른 차이가 있을 수 있다고 말씀하십니다. 매우 공감합니다! 위의 내용들은 모두 라이브 코딩에 포함되어 있는 내용이지만 실제로 따라해보면서 해당 내용들을 정리하는 차원으로 작성해보았습니다. 따라하며 토비님이 라이브 코딩을 진행하셨을 때와 달라진 몇 가지를 수정한 부분도 있고, 서버의 스레드를 직접 확인해보고자 처음에는 VisualVM을 사용하려 했지만 계속 실패해 JMC을 이용해 진행했습니다. 라이브 코딩을 보며 자바와 스프링의 비동기 기술에 대해 개인적으로 궁금했던 부분들이 많이 해소되었습니다!! 앞으로 남은 내용들도 따라하며 정리해 보도록 하겠습니다.","link":"/2019/03/31/Java/java-async-1/"},{"title":"비동기 RestTemplate과 비동기 MVC/Serlvet","text":"해당 포스팅은 토비님의 토비의 봄 TV 9회 스프링 리액티브 프로그래밍 (5) 비동기 RestTemplate과 비동기 MVC/Serlvet 라이브 코딩을 보며 따라했던 실습 내용을 바탕으로 정리한 글입니다. 실습 코드들은 IntelliJ를 이용해 SpringBoot 2.1.3.RELEASE 버전 기반으로 프로젝트를 생성 후(web, lombok 포함) 진행했습니다. Thread Pool Hell스프링의 비동기 기술 을 이용해 클라이언트로부터 요청을 받은 후 실제 작업은 작업 스레드 풀에 위임하고 현재의 서블릿 스레드는 서블릿 스레드 풀에 반환 후, 다음 요청이 들어올 경우 바로 사용할 수 있게 효율적으로 처리하도록 만들었습니다.그러나 아직 문제가 있습니다. 아주 빠르게 무언가를 계산하고 해당 처리를 끝내는 경우라면 굳이 비동기 MVC(서블릿)를 사용하지 않아도 문제가 없지만, 하나의 요청에 대한 처리를 수행하면서 외부의 서비스들을 호출하는 작업이 많이 있는 경우, 문제는 단순히 비동기를 서블릿을 사용하는 것만으로 해결할 수 없는 경우가 많이 있습니다. (서블릿 요청은 바로 사용 가능하더라도 워커 스레드가 I/O 같은 작업으로 인해 블록되기 때문입니다.) Thread Pool Hell이란 풀 안에 있는 스레드에 대한 사용 요청이 급격하게 증가해 추가적인 요청이 들어올 때, 사용 가능한 스레드 풀의 스레드가 없기 때문에 대기 상태에 빠져 요청에 대한 응답이 느려지게 되는 상태를 말합니다. 최근 서비스들은 아래의 그럼처럼 하나의 요청을 처리함에 있어 다른 서버로의 요청(Network I/O)이 많아졌습니다. 조금전 설명한 것처럼 비동기 서블릿을 사용하더라도 하나의 요청을 처리하는 동안 하나의 작업(워커) 스레드는 그 시간동안 대기상태에 빠지게 되어 결국에는 스레드 풀의 가용성이 떨어지게 됩니다. 이번 포스팅에서는 해당 문제를 해결해가는 과정을 다루고 있습니다. Upgrade Client (For Load Test)지난 번에 작성했던 Client를 조금 수정하도록 합니다. 기존의 Client는 100개의 스레드를 순차적으로 만들면서 서버로의 Request를 만들었던 문제가 있었습니다. 이제는 100개의 스레드를 만들고 CyclicBarrier를 이용해 100개의 스레드에서 동시에 Request를 만들도록 변경해보겠습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4jpublic class LoadTest { static AtomicInteger counter = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException, BrokenBarrierException { ExecutorService es = Executors.newFixedThreadPool(100); RestTemplate rt = new RestTemplate(); String url = \"http://localhost:8080/rest?idx={idx}\"; CyclicBarrier barrier = new CyclicBarrier(101); for (int i = 0; i &lt; 100; i++) { // submit이 받는 callable은 return을 가질 수 있으며, exception도 던질 수 있다. es.submit(() -&gt; { int idx = counter.addAndGet(1); log.info(\"Thread {}\", idx); barrier.await(); StopWatch sw = new StopWatch(); sw.start(); String res = rt.getForObject(url, String.class, idx); sw.stop(); log.info(\"idx: {}, Elapsed: {} -&gt; res: {}\", idx, sw.getTotalTimeSeconds(), res); // IDE가 funtional interface가 callable임을 인식할 수 있도록 의미없는 return을 넣어준다. return null; }); } // await을 만난 스레드가 101번째가 될 때, 모든 스레드들도 await에서 풀려나 이후 로직을 수행한다. // 메인 스레드 1개, Executors.newFixedThreadPool로 생성한 스레드 100개 barrier.await(); StopWatch main = new StopWatch(); main.start(); es.shutdown(); // 지정된 시간이 타임아웃 걸리기 전이라면 대기작업이 진행될 때까지 기다린다. // (100초안에 작업이 끝날때까지 기다리거나, 100초가 초과되면 종료) es.awaitTermination(100, TimeUnit.SECONDS); main.stop(); log.info(\"Total: {}\", main.getTotalTimeSeconds()); }} 외부 서비스 호출 테스트클라이언트의 요청을 받아 외부 서비스를 호출하고 해당 결과를 이용해서 응답을 돌려주는 테스트를 진행합니다. 테스트를 진행하기 위해서는 2개의 스프링 애플리케이션이 필요합니다. 2개의 스프링 애플리케이션의 설정은 다음과 같습니다. Main Application port: 8080 tomcat-max-thread-count: 1 Remote Application port: 8081 tomcat-max-thread-count: 1000 Main Application먼저 하나의 스프링 애플리케이션에 컨트롤러를 하나 준비합니다. 이 컨트롤러는 클라이언트로부터 요청을 받아 해당 요청으로부터 받은 값을 이용해 다른 외부 서비스(http://localhost:8081/service?req={req})를 호출합니다. 결국 해당 서블릿은 클라이언트 요청을 처리하면서 외부 서비스로의 Networking I/O 작업을 수행하기 때문에 외부 서비스로부터의 요청에 대한 응답을 받기 전까지는 blocking 상태가 됩니다.1234567891011121314151617181920@SpringBootApplication@Slf4jpublic class MainApplication { @RestController public static class MainController { RestTemplate rt = new RestTemplate(); @GetMapping(\"/rest\") public String rest(int idx) { String res = rt.getForObject(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); return res; } } public static void main(String[] args) { SpringApplication.run(MainApplication.class, args); }} application.properties 파일에서 다음과 같이 Tomcat의 스레드 개수를 1개로 설정합니다.1server.tomcat.max-threads=1 Remote Application다른 하나의 스프링 애플리케이션을 생성하고 이전에 만들었던 스프링 애플리케이션의 컨트롤러 내부에서 만들었던 요청을 받아 처리할 수 있도록 컨트롤러 추가합니다. 8080 포트가 아닌 8081 포트를 사용하고 tomcat 스레드를 1000개로 설정합니다. RemoteApplication은 application.properties의 값을 사용하게 하지 않고 직접 프로퍼티를 설정해줍니다. 아래와 같이 설정하면 Intellij를 이용해서 하나의 프로젝트에서 2개의 스프링 애플리케이션을 실행할 수 있습니다.12345678910111213141516171819@SpringBootApplicationpublic class RemoteApplication { @RestController public static class RemoteController { @GetMapping(\"/service\") public String service(String req) { return req + \"/service\"; } } public static void main(String[] args) { // 하나의 프로젝트에서 2개의 스프링 애플리케이션을 띄우기 위해 외부 서비스 역할을 하는 RemoteApplication은 // application.properties가 아닌 별도의 프로퍼티를 이용하도록 직접 설정한다. System.setProperty(\"server.port\", \"8081\"); System.setProperty(\"server.tomcat.max-threads\", \"1000\"); SpringApplication.run(RemoteApplication.class, args); }} 결과 확인MainApplication과 RemoteApplication을 각각 실행하고 Client를 이용한 테스트 결과는 다음과 같습니다.100개의 클라이언트 요청을 처리하는데 0.4초 정도의 시간이 걸렸습니다.12345678910111213141516171819.........01:54:27.539 [pool-1-thread-40] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK01:54:27.539 [pool-1-thread-40] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"01:54:27.539 [pool-1-thread-40] INFO com.example.study.LoadTest - idx: 40, Elapsed: 0.4 -&gt; res: hello40/service01:54:27.541 [pool-1-thread-77] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK01:54:27.541 [pool-1-thread-77] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"01:54:27.541 [pool-1-thread-77] INFO com.example.study.LoadTest - idx: 77, Elapsed: 0.401 -&gt; res: hello77/service01:54:27.543 [pool-1-thread-48] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK01:54:27.543 [pool-1-thread-48] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"01:54:27.543 [pool-1-thread-48] INFO com.example.study.LoadTest - idx: 48, Elapsed: 0.403 -&gt; res: hello48/service01:54:27.545 [pool-1-thread-8] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK01:54:27.545 [pool-1-thread-8] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"01:54:27.546 [pool-1-thread-8] INFO com.example.study.LoadTest - idx: 8, Elapsed: 0.407 -&gt; res: hello8/service01:54:27.548 [pool-1-thread-33] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK01:54:27.548 [pool-1-thread-33] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"01:54:27.548 [pool-1-thread-33] INFO com.example.study.LoadTest - idx: 33, Elapsed: 0.409 -&gt; res: hello33/service01:54:27.548 [main] INFO com.example.study.LoadTest - Total: 0.407 이번에는 RemoteApplication의 요청 처리 부분에 2초간 Thread sleep을 주고 다시 한 번 클라이언트를 이용해 테스트를 진행해봅니다.12345678910// RemoteApplication@RestControllerpublic static class RemoteController { @GetMapping(\"/service\") public String service(String req) throws InterruptedException { Thread.sleep(2000); return req + \"/service\"; }} Thread sleep을 추가하고 다시 테스트를 해보면 결과는 다음과 같습니다. 100개의 요청을 약 0.4초만에 모두 처리하던 이전과 달리 매 요청을 처리하는데 약 2초의 시간이 증가하고 있습니다. 결국 마지막 요청은 약 2 * 100 = 200초 후에서야 응답을 받을 수 있기 때문에 모든 요청에 대한 처리는 200초 정도 걸릴 것 입니다.12345678910111213141516171819202102:25:22.056 [pool-1-thread-32] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK02:25:22.058 [pool-1-thread-32] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"02:25:22.061 [pool-1-thread-32] INFO com.example.study.LoadTest - idx: 32, Elapsed: 2.233 -&gt; res: hello32/service02:25:24.060 [pool-1-thread-56] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK02:25:24.060 [pool-1-thread-56] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"02:25:24.060 [pool-1-thread-56] INFO com.example.study.LoadTest - idx: 56, Elapsed: 4.231 -&gt; res: hello56/service02:25:26.068 [pool-1-thread-93] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK02:25:26.068 [pool-1-thread-93] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"02:25:26.068 [pool-1-thread-93] INFO com.example.study.LoadTest - idx: 93, Elapsed: 6.238 -&gt; res: hello93/service02:25:28.077 [pool-1-thread-31] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK02:25:28.077 [pool-1-thread-31] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"02:25:28.077 [pool-1-thread-31] INFO com.example.study.LoadTest - idx: 31, Elapsed: 8.249 -&gt; res: hello31/service02:25:30.081 [pool-1-thread-20] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK02:25:30.082 [pool-1-thread-20] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"02:25:30.082 [pool-1-thread-20] INFO com.example.study.LoadTest - idx: 20, Elapsed: 10.254 -&gt; res: hello20/service02:25:32.089 [pool-1-thread-46] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK02:25:32.089 [pool-1-thread-46] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"02:25:32.089 [pool-1-thread-46] INFO com.example.study.LoadTest - idx: 46, Elapsed: 12.26 -&gt; res: hello46/service......... 이런 결과가 나오게 된 이유는 클라이언트로부터의 요청을 받아 처리하는 Main Application의 tomcat thread가 1개이고, 1개의 서블릿 스레드를 이용해 클라이언트의 요청을 처리하는 과정에서 Remote Application에 대한 요청(Network I/O)에서 응답을 받기까지 약 2초간 스레드가 block되기 때문입니다. AsyncRestTemplate위의 문제는 MainApplication의 tomcat 스레드는 클라이언트의 요청을 처리하며 외부 서비스(RemoteApplication)로 요청(Network I/O)을 보낸 후, 응답이 올 때까지 대기하고 있는 상태라는 점입니다. 해당 시간동안 CPU는 아무 일을 처리하지 않기때문에 자원이 소모되고 있습니다. 이 문제를 해결하기 위해서는 API를 호출하는 작업을 비동기적으로 바꿔야합니다. tomcat 스레드는 요청에 대한 작업을 다 끝내기 전에 반환을 해서 바로 다음 요청을 처리하도록 사용합니다. 그리고 외부 서비스로부터 실제 결과를 받고 클라이언트의 요청에 응답을 보내기 위해서는 새로운 스레드를 할당 받아 사용합니다. (외부 서비스로부터 실제 결과를 받고 클라이언트에 응답을 보내기 위해서는 새로운 스레드를 할당 받아야 하지만, 외부 API를 호출하는 동안은 스레드(tomcat) 자원을 낭비하고 싶지 않다는 것이 목적이다.) 스프링 3.x 버전에서는 이 문제를 간단히 해결하기 어려웠지만 스프링 4 부터 제공하는 AsyncRestTemplate을 사용하면 이 문제를 쉽게 해결할 수 있습니다. AsyncRestTemplate은 비동기 클라이언트를 제공하는 클래스이며 ListenableFuture를 반환합니다. 스프링은 컨트롤러에서 ListenableFuture를 리턴하면 해당 스레드는 즉시 반납하고, 스프링 MVC가 자동으로 등록해준 콜백에 의해 결과가 처리됩니다. 1234567891011121314151617181920@SpringBootApplication@Slf4jpublic class MainApplication { @RestController public static class MainController { // asynchronous AsyncRestTemplate rt = new AsyncRestTemplate(); @GetMapping(\"/rest\") public ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; rest(int idx) { return rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); } } public static void main(String[] args) { SpringApplication.run(MainApplication.class, args); }} 실행 결과를 살펴보면 100개의 요청을 동시에 처리하는데 약 2.6초의 시간이 걸렸습니다.12345678910111213141516171819202122232425262728.........16:55:49.088 [pool-1-thread-4] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.089 [pool-1-thread-4] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.089 [pool-1-thread-4] INFO com.example.study.LoadTest - idx: 4, Elapsed: 2.658 -&gt; res: hello4/service16:55:49.090 [pool-1-thread-44] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.090 [pool-1-thread-44] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.090 [pool-1-thread-44] INFO com.example.study.LoadTest - idx: 44, Elapsed: 2.659 -&gt; res: hello44/service16:55:49.091 [pool-1-thread-93] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.091 [pool-1-thread-93] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.091 [pool-1-thread-93] INFO com.example.study.LoadTest - idx: 93, Elapsed: 2.658 -&gt; res: hello93/service16:55:49.095 [pool-1-thread-66] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.096 [pool-1-thread-66] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.096 [pool-1-thread-66] INFO com.example.study.LoadTest - idx: 66, Elapsed: 2.664 -&gt; res: hello66/service16:55:49.098 [pool-1-thread-16] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.098 [pool-1-thread-16] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.098 [pool-1-thread-16] INFO com.example.study.LoadTest - idx: 16, Elapsed: 2.667 -&gt; res: hello16/service16:55:49.101 [pool-1-thread-57] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.101 [pool-1-thread-57] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.101 [pool-1-thread-57] INFO com.example.study.LoadTest - idx: 57, Elapsed: 2.669 -&gt; res: hello57/service16:55:49.104 [pool-1-thread-2] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.104 [pool-1-thread-2] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.105 [pool-1-thread-2] INFO com.example.study.LoadTest - idx: 2, Elapsed: 2.674 -&gt; res: hello2/service16:55:49.105 [pool-1-thread-15] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK16:55:49.105 [pool-1-thread-15] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"16:55:49.105 [pool-1-thread-15] INFO com.example.study.LoadTest - idx: 15, Elapsed: 2.674 -&gt; res: hello15/service16:55:49.106 [main] INFO com.example.study.LoadTest - Total: 2.673 클라이언트의 요청이 들어 올 때, MainApplication의 스레드 상태를 살펴보면, tomcat 스레드는 그대로 1개 입니다.(http-nio-8080-exec-1) 그러나 비동기 작업을 처리하기 위해서 순간적으로 백그라운드에 100개의 스레드 새로 생성되는것을 확인할 수 있습니다. Netty non-blocking I/O지금까지 Tomcat의 스레드가 1개이지만 요청을 비동기적으로 처리함으로써 Tomcat의 스레드는 바로 반환이되어 다시 그 후의 요청에 Tomcat의 스레드를 이용해 요청을 받을 수 있었습니다. 그러나 결과적으로는 실제 비동기 요청을 처리하는 스레드는 요청의 수 만큼 계속 생성되는 것을 확인할 수 있었습니다. 이번에는 이렇게 비동기 요청을 처리하는 스레드의 수도 Netty의 non blocking I/O를 이용함으로써 비동기 요청을 처리하는 스레드도 줄여보고자 합니다. 그러면 결과적으로 tomcat의 스레드 1개, netty의 non blocking I/O를 이용하기위한 필요한 스레드의 수만큼만 생성되어 클라이언트의 요청을 모두 처리할 수 있을 것 입니다. 먼저 netty의 dependency를 build.gradle 혹은 pom.xml에 추가합니다. 저는 build.gradle에 의존성을 추가해 주었습니다.12345dependencies { ... implementation 'io.netty:netty-all:4.0.4.Final' ...} AsyncRestTemplate이 netty의 Netty4ClientHttpRequestFactory를 이용할 수 있도록 다음과 같이 설정합니다.1234567891011121314151617181920@SpringBootApplication@Slf4jpublic class MainApplication { @RestController public static class MainController { // asynchronous + netty non-blocking AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @GetMapping(\"/rest\") public ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; rest(int idx) { return rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); } } public static void main(String[] args) { SpringApplication.run(MainApplication.class, args); }} 다시 서버를 띄우고 테스트를 해보면 클라이언트의 요청을 전부 처리하는데 걸린 시간은 약 2.7초로 이전과 큰 차이가 없습니다.12345678910111213141516171819202122232425.........18:24:49.958 [pool-1-thread-65] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.958 [pool-1-thread-65] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.958 [pool-1-thread-65] INFO com.example.study.LoadTest - idx: 65, Elapsed: 2.744 -&gt; res: hello65/service18:24:49.964 [pool-1-thread-59] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.964 [pool-1-thread-59] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.964 [pool-1-thread-59] INFO com.example.study.LoadTest - idx: 59, Elapsed: 2.751 -&gt; res: hello59/service18:24:49.964 [pool-1-thread-14] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.965 [pool-1-thread-14] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.965 [pool-1-thread-14] INFO com.example.study.LoadTest - idx: 14, Elapsed: 2.752 -&gt; res: hello14/service18:24:49.968 [pool-1-thread-31] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.968 [pool-1-thread-31] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.968 [pool-1-thread-31] INFO com.example.study.LoadTest - idx: 31, Elapsed: 2.754 -&gt; res: hello31/service18:24:49.969 [pool-1-thread-63] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.969 [pool-1-thread-63] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.969 [pool-1-thread-63] INFO com.example.study.LoadTest - idx: 63, Elapsed: 2.755 -&gt; res: hello63/service18:24:49.969 [pool-1-thread-19] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.969 [pool-1-thread-19] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.969 [pool-1-thread-19] INFO com.example.study.LoadTest - idx: 19, Elapsed: 2.755 -&gt; res: hello19/service18:24:49.970 [pool-1-thread-62] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:24:49.970 [pool-1-thread-62] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:24:49.970 [pool-1-thread-62] INFO com.example.study.LoadTest - idx: 62, Elapsed: 2.756 -&gt; res: hello62/service18:24:49.970 [main] INFO com.example.study.LoadTest - Total: 2.755 스레드를 확인해보면 다음과 같이 tomcat 스레드 1개, netty가 non blocking I/O를 사용하는데 필요로 하는 몇개의 스레드가 추가된 것 말고는 스레드 수가 크게 증가하지 않은것을 확인할 수 있습니다. DeferredResult이전 포스팅에서 살펴 보았던 DeferredResult를 사용하면 AsyncRestTemplate을 사용하여 외부 서비스를 호출한 후, 그 결과를 다시 이용해 클라이언트의 요청에 응답하는 추가 로직 부분을 작성할 수 있습니다. 컨트롤러에서 DeferredResult 오브젝트를 반환하는 시점에는 바로 응답이 가지 않고, 추후 해당 DeferredResult 오브젝트에 값을 set(setResult, setErrorResult) 해줄 때, 클라이언트에게 응답이 가게 됩니다. 이를 이용하려면 ListenableFuture에 콜백을 추가해 해당 콜백 로직 안에서 결과를 이용해 DeferredResult 오브젝트의 set 메서드를 호출하면 됩니다. 1234567891011121314151617181920212223242526272829303132@SpringBootApplication@Slf4jpublic class MainApplication { @RestController public static class MainController { // asynchronous + netty non-blocking AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { // 오브젝트를 만들어서 컨트롤러에서 리턴하면 언제가 될지 모르지만 언제인가 DeferredResult에 값을 써주면 // 그 값을 응답으로 사용 DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { dr.setResult(s.getBody() + \"/work\"); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); return dr; } } public static void main(String[] args) { SpringApplication.run(MainApplication.class, args); }} 외부 서비스의 응답을 받아 “/work” 문자열이 추가되어 클라이언트에 전달된것을 확인할 수 있습니다.12345678910111213141516171819202122.........18:38:23.514 [pool-1-thread-33] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:38:23.514 [pool-1-thread-33] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:38:23.514 [pool-1-thread-33] INFO com.example.study.LoadTest - idx: 33, Elapsed: 2.345 -&gt; res: hello33/service/work18:38:23.515 [pool-1-thread-79] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:38:23.515 [pool-1-thread-79] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:38:23.515 [pool-1-thread-79] INFO com.example.study.LoadTest - idx: 79, Elapsed: 2.345 -&gt; res: hello79/service/work18:38:23.515 [pool-1-thread-80] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:38:23.515 [pool-1-thread-80] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:38:23.515 [pool-1-thread-80] INFO com.example.study.LoadTest - idx: 80, Elapsed: 2.345 -&gt; res: hello80/service/work18:38:23.516 [pool-1-thread-9] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:38:23.516 [pool-1-thread-9] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:38:23.516 [pool-1-thread-9] INFO com.example.study.LoadTest - idx: 9, Elapsed: 2.347 -&gt; res: hello9/service/work18:38:23.517 [pool-1-thread-60] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:38:23.517 [pool-1-thread-60] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:38:23.517 [pool-1-thread-60] INFO com.example.study.LoadTest - idx: 60, Elapsed: 2.347 -&gt; res: hello60/service/work18:38:23.517 [pool-1-thread-98] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK18:38:23.517 [pool-1-thread-98] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"18:38:23.518 [pool-1-thread-98] INFO com.example.study.LoadTest - idx: 98, Elapsed: 2.347 -&gt; res: hello98/service/work18:38:23.518 [main] INFO com.example.study.LoadTest - Total: 2.346 중첩된 Remote Service 사용이번에는 외부 서비스를 하나 더 추가해보겠습니다. 외부 서비스의 요청에 대한 결과를 다시 다른 서비스를 호출하는 요청의 파라미터로 사용하면서 콜백의 구조가 복잡해지는 문제가 생기게 되었습니다. 이런 문제를 콜백 헬이라고 합니다. 다음번 포스팅에서는 콜백 헬을 해결할 수 있는 방법에 대해서 알아보도록 하겠습니다. Remote Application“/service2”를 추가합니다. 1234567891011121314151617181920212223242526@SpringBootApplicationpublic class RemoteApplication { @RestController public static class RemoteController { @GetMapping(\"/service\") public String service(String req) throws InterruptedException { Thread.sleep(2000); return req + \"/service1\"; } @GetMapping(\"/service2\") public String service2(String req) throws InterruptedException { Thread.sleep(2000); return req + \"/service2\"; } } public static void main(String[] args) { // 하나의 프로젝트에서 2개의 스프링 애플리케이션을 띄우기 위해 외부 서비스 역할을 하는 RemoteApplication은 // application.properties가 아닌 별도의 프로퍼티를 이용하도록 직접 설정한다. System.setProperty(\"server.port\", \"8081\"); System.setProperty(\"server.tomcat.max-threads\", \"1000\"); SpringApplication.run(RemoteApplication.class, args); }} Main Application“/service”를 호출한 결과를 이용해 “/service2”를 호출하도록 합니다. 12345678910111213141516171819202122232425262728293031323334353637@SpringBootApplication@Slf4jpublic class MainApplication { @RestController public static class MainController { // asynchronous + netty non-blocking AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { // 오브젝트를 만들어서 컨트롤러에서 리턴하면 언제가 될지 모르지만 언제인가 DeferredResult에 값을 써주면 // 그 값을 응답으로 사용 DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f1 = rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx); f1.addCallback(s -&gt; { ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()); f2.addCallback(s2 -&gt; { dr.setResult(s2.getBody()); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); }, e -&gt; { dr.setErrorResult(e.getMessage()); }); return dr; } } public static void main(String[] args) { SpringApplication.run(MainApplication.class, args); }} 결과 확인100개의 클라이언트 요청을 처리하는데 약 4.3초의 시간이 걸렸습니다. 12345678910111213141516171819202122232425262728.........19:25:19.904 [pool-1-thread-17] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.904 [pool-1-thread-17] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.905 [pool-1-thread-17] INFO com.example.study.LoadTest - idx: 17, Elapsed: 4.338 -&gt; res: hello17/service1/service219:25:19.905 [pool-1-thread-87] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.905 [pool-1-thread-87] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.905 [pool-1-thread-87] INFO com.example.study.LoadTest - idx: 87, Elapsed: 4.337 -&gt; res: hello87/service1/service219:25:19.905 [pool-1-thread-14] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.906 [pool-1-thread-14] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.906 [pool-1-thread-14] INFO com.example.study.LoadTest - idx: 14, Elapsed: 4.339 -&gt; res: hello14/service1/service219:25:19.906 [pool-1-thread-74] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.906 [pool-1-thread-74] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.906 [pool-1-thread-74] INFO com.example.study.LoadTest - idx: 74, Elapsed: 4.338 -&gt; res: hello74/service1/service219:25:19.907 [pool-1-thread-60] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.907 [pool-1-thread-60] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.907 [pool-1-thread-60] INFO com.example.study.LoadTest - idx: 60, Elapsed: 4.339 -&gt; res: hello60/service1/service219:25:19.907 [pool-1-thread-38] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.907 [pool-1-thread-38] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.907 [pool-1-thread-38] INFO com.example.study.LoadTest - idx: 38, Elapsed: 4.34 -&gt; res: hello38/service1/service219:25:19.907 [pool-1-thread-78] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.908 [pool-1-thread-78] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.908 [pool-1-thread-78] INFO com.example.study.LoadTest - idx: 78, Elapsed: 4.34 -&gt; res: hello78/service1/service219:25:19.908 [pool-1-thread-5] DEBUG org.springframework.web.client.RestTemplate - Response 200 OK19:25:19.908 [pool-1-thread-5] DEBUG org.springframework.web.client.RestTemplate - Reading to [java.lang.String] as \"text/plain;charset=UTF-8\"19:25:19.909 [pool-1-thread-5] INFO com.example.study.LoadTest - idx: 5, Elapsed: 4.342 -&gt; res: hello5/service1/service219:25:19.909 [main] INFO com.example.study.LoadTest - Total: 4.338","link":"/2019/04/13/Java/java-async-2/"},{"title":"Collection Framework","text":"해당 포스팅의 내용은 Java의 정석 2권 - Chapter 11 컬렉션 프레임웍에 있는 내용을 요약한 것입니다. 해당 책으로 복습하며 정리한 내용이고 문제가 된다면 바로 해당 포스팅을 삭제하도록 하겠습니다. 컬렉션 프레임웍Java API 문서에서는 컬렉션 프레임웍을 ‘데이터 군(group)을 다루고 표현하기 위한 단일화된 구조’라고 정의하고 있다. JDK 1.2부터 컬렉션 프레임웍이 등장하면서 다양한 종류의 컬렉션 클래스가 추가되고 모든 컬렉션 클래스를 표준화된 방식으로 다룰 수 있도록 체계화되었다. 컬렉션 프레임웍의 핵심 인터페이스컬렉션 프리임웍에서는 컬렉션(데이터 그룹)을 크게 3가지 타입으로 구분하여 3가지 인터페이스를 정의했다. 그리고 인터페이스 중 List와 Set의 공통된 부분을 다시 뽑아서 새로운 인터페이스은 Collection을 추가로 정의하였다. 인터페이스 List와 Set을 구현한 컬렉션 클래스들은 서로 많은 공통부분이 있어서, 공통된 부분을 다시 뽑아 Collection 인터페이스를 정의할 수 있었지만 Map 인터페이스는 이들과는 전혀 다른 형태로 컬렉션을 다루기 때문에 같은 상속계층도에 포함되지 못했다. List : 순서가 있는 데이터의 집합. 데이터의 중복을 허용한다. 구현 클래스 : ArrayList, LinkedList, Stack, Vector 등 Set : 순서를 유지하지 않는 데이터의 집함. 데이터의 중복을 허용하지 않는다. 구현 클래스 : HashSet, TreeSet 등 Map : 키(key)와 값(value)의 쌍(pair)으로 이루어진 데이터의 집합. 순서는 유지되지 않으며, 키는 중복을 허용하지 않고, 값은 중복을 허용한다. 구현 클래스 : HashMap, TreeMap, Hashtable, Properties 등 Vector, Stack, Hashtable, Properties와 같은 클래스들은 컬렉션 프레임웍이 만들어지기 이전부터 존재하던 것이기 때문에 컬렉션 프레임웍의 명명법을 따르지 않는다. Vector나 Hashtable과 같은 기존의 컬렉션 클래스들은 호환을 위해, 설계를 변경해서 남겨두었지만 가능하면 사용하지 않는 것이 좋다. 그 대신 새로 추가된 ArrayList와 HashMap을 사용하자. Collection 인터페이스List와 Set의 조상인 Collection 인터페이스에는 다음과 같은 메서드들이 정의되어 있다. Collection 인터페이스는 컬렉션 클래스에 저장된 데이터를 읽고, 추가하고 삭제하는 등 컬렉션을 다루는데 가장 기본적인 메서드들을 정의하고 있다. boolean add(Object o) : 지정된 객체(o)를 Collection에 추가한다. boolean addAll(Collection c) : 지정된 Collection(c)의 객체들을 Collection에 추가한다. void clear() : Collection의 모든 객체를 삭제한다. boolean contains(Object o) : 지정된 객체(o)가 Collection에 포함되어 있는지 확인한다. boolean equals(Object o) : 동일한 Collection인지 비교한다. int hashCode() : Collection의 hash code를 반환한다. boolean isEmpty() : Collection이 비어있는지 확인한다. Iterator iterator() : Collection의 Iterator를 얻어서 반환한다. boolean remove(Object o) : 지정된 객체를 삭제한다. int size() : Collection에 저장된 객체의 개수를 반환한다. Object[] toArray() : Collection에 저장된 객체를 객체배열(Object[])로 반환한다. Object[] toArray(Object[] a) : 지정된 배열에 Collection의 객체를 저장해서 반환한다. List 인터페이스List 인터페이스는 중복을 허용하면서 저장순서가 유지되는 컬렉션을 구현하는데 사용된다. void add(int index, Object element) : 지정된 위치(index)에 객체(element) 또는 컬렉션에 포함된 객체들을 추가한다. Object get(int index) : 지정된 위치(index)에 있는 객체를 반환한다. int indexOf(Object o) : 지정된 객체의 위치(index)를 반환한다. (List의 첫 번째 요소부터 순방향으로 찾는다.) lastIndexOf(Object o) : 지정된 객체의 위치(index)를 반환한다. (List의 마지막 요소부터 역방향으로 찾는다.) ListIterator listIterator() : List의 객체에 접근할 수 있는 ListIterator를 반환한다. Object remove(int index) : 지정된 위치(index)에 있는 객체를 삭제하고 삭제된 객체를 반환한다. Object set(int index, Object element) : 지정된 위치(index)에 객체(element)를 저장한다. void sort(Comparator c) : 지정된 비교자(comparator)로 List를 정렬한다. List subList(int fromIndex, int toIndex) : 지정된 범위(fromIndex 부터 toIndex)에 있는 객체를 반환한다. Set 인터페이스Set 인터페이스는 중복을 허용하지 않고 저장순서가 유지되지 않는 컬렉션 클래스를 구현하는데 사용된다. Map 인터페이스Map 인터페이스는 키(key)와 값(value)을 하나의 쌍으로 묶어서 저장하는 컬렉션 클래스를 구현하는 데 사용된다. 키는 중복될 수 없지만 값은 중복을 허용한다. 구현 클래스로는 Hashtable, HashMap, LinkedHashMap, SortedMap, TreeMap 등이 있다. void clear() : Map의 모든 객체를 삭제한다. boolean containsKey(Object key) : 지정된 key객체와 일치하는 Map의 Key객체가 있는지 확인한다. boolean containsValue(Object value) : 지정된 value객체와 일치하는 Map의 Value객체가 있는지 확인한다. Set entrySet() : Map에 저장되어 있는 key-value 쌍을 Map.Entry 타입의 객체로 저장한 Set으로 반환한다. booelan equals(Object o) : 동일한 Map인지 비교한다. Object get(Object key) : 지정한 key객체에 대응하는 value객체를 찾아서 반환한다. int hashCode() : 해시코드를 반환한다. boolean isEmpty() : Map이 비어있는지 확인한다. Set keySet() : Map에 저장된 모든 Key객체를 반환한다. Object put(Object key, Object value) : Map에 value객체를 key객체에 연결(mapping)하여 저장한다. void putAll(Map t) : 지정된 Map의 모든 key-value 쌍을 추가한다. Object remove(Object key) : 지정한 key객체와 일치하는 key-value객체를 삭제한다. int size() : Map에 저장된 key-value 쌍의 개수를 반환한다. Collection values() : Map에 저장된 모든 value객체를 반환한다. Map 인터페이스에서 값(value)은 중복을 허용하기 때문에 Collection 타입으로 반환하고, 키(key)는 중복을 허용하지 않기 때문에 Set 타입으로 반환한다. Map.Entry 인터페이스Map.Entry 인터페이스는 Map 인터페이스의 내부 인터페이스이다. 내부 클래스와 같이 인터페이스도 인터페이스 안에 인터페이스를 정의하는 내부 인터페이스(inner interface)를 정의하는 것이 가능하다. Map에 저장되는 key-value 쌍을 다루기 위해 내부적으로 Entry 인터페이스를 정의해 놓았다. boolean equals(Object o) : 동일한 Entry인지 비교한다. Object getKey() : Entry의 key객체를 반환한다. Object getValue() : Entry의 value객체를 반환한다. int hashCode() : Entry의 해시코드를 반환한다. Object setValue(Object value) : Entry의 value객체를 지정된 객체로 바꾼다. ArrayListList 인터페이스를 구현하기 때문에 데이터의 저장순서가 유지되고 중복을 허용한다는 특징을 갖는다. ArrayList는 기존의 Vector를 개선한 것으로 Vector와 구현원리와 기능적인 측면은 동일하다. ArrayList는 Object배열을 이용해서 데이터를 순차적으로 저장한다. 계속 배열에 순서대로 저장되며, 배열에 더 이상 저장할 공간이 없으면 보다 큰 새로운 배열을 생성해서 기존의 배열에 저장된 내용을 새로운 배열로 복사한 다음에 저장된다. (Vector는 capacity가 부족할 경우 자동적으로 기존의 크기보다 2배의 크기로 증가된다. 그러나 생성자 Vector(int initialCapacity, int capacityIncrement)를 사용해서 인스턴스를 생성한 경우에는 지정해준 capacityIncrement만큼 증가하게 된다.) 배열은 크기를 변경할 수 없기 때문에 ArrayList나 Vector 같이 배열을 이용한 자료구조는 데이터를 읽어오고 저장하는 데는 효율이 좋지만, 용량을 변경해야 할 때는 새로운 배열을 생성한 후 기존의 배열로부터 새로 생성된 배열로 데이터를 복사해야하기 때문에 상당히 효율이 떨어진다는 단점을 가지고 있다. LinkedList배열은 가장 기본적인 형태의 자료구조로 구조가 간단하며 사용하기 쉽고 데이터를 읽어오는데 걸리는 시간(접근시간, access time)이 가장 빠르다는 장점을 가지고 있지만 다음과 같은 단점도 가지고 있다. 크기를 변경할 수 없다. 크기를 변경할 수 없으므로 새로운 배열을 생성해서 데이터를 복사하는 작업이 필요 하다. 실행속도를 향상시키기 위해서는 충분히 큰 크기의 배열을 생성해야 하므로 메모리가 낭비된다. 비순차적인 데이터의 추가 또는 삭제에 시간이 많이 걸린다. 차례대로 데이터를 추가하고 마지막에서부터 데이터를 삭제하는 것은 빠르지만, 배열의 중간에 데이터를 추가하려면, 빈자리를 만들기 위해 다른 데이터들을 복사해서 이동해야 한다. 이러한 배열의 단점을 보완하기 위해서 링크드 리스트(linked list)라는 자료구조가 고안되었다. 배열은 모든 데이터가 연속적으로 존재하지만 링크드 리스트는 불연속적으로 존재하는 데이터를 서로 연결(link)한 형태로 구성되어 있다. 링크드 리스트의 각 요소(node)들은 자신과 연결된 다음 요소에 대한 참조(주소값)와 데이터로 구성되어 있다. 1234class Node { Node next; // 다음 요소의 주소를 저장 Object obj; // 데이터를 저장} 링크드 리스트는 이동방향이 단방향이기 때문에 다음 요소에 대한 접근은 쉽지만 이전요소에 대한 접근은 어렵다. 이 점을 보완한 것이 더블 링크드 리스트(이중 연결리스트, doubly linked list)이다. 더블 링크드 리스트는 링크드 리스트보다 각 요소에 대한 접근과 이동이 쉽기 때문에 링크드 리스트보다 더 많이 사용된다. 12345class Node { Node next; // 다음 요소의 주소를 저장 Node previous; // 이전 요소의 주소를 저장 Object obj; // 데이터를 저장} 더블 링크드 리스트의 접근성을 보다 향상시킨 것이 ‘더블 써큘러 링크드 리스트(이중 연결형 연결 리스트)’이다. 단순히 더블 링크드 리스트의 첫 번째 요소와 마지막 요소를 서로 연결시킨 것이다. 실제로 LinkedList 클래스는 이름과 달리 ‘링크드 리스트’가 아닌 ‘더블 링크드 리스트’로 구현되어 있는데, 이는 링크드 리스트의 단점인 낮은 접근성(accessability)을 높이기 위한 것이다. 순차적으로 추가/삭제하는 경우에는 ArrayList가 LinkedList보다 빠르다.만약 ArrayList의 크기가 충분하지 않으면, 새로운 크기의 ArrayList를 생성하고 데이터를 복사하는 일이 발생하게 되므로 순차적으로 데이터를 추가해도 ArrayList보다 LinkedList가 더 빠를 수 있다.순차적으로 삭제한다는 것은 마지막 데이터부터 역순으로 삭제해나간다는 것을 의미하며, ArrayList는 마지막 데이터부터 삭제할 경우 각 요소들의 재배치가 필요하지 않기 때문에 상당히 빠르다. (단지 마지막 요소의 값을 null로만 바꾸면 되기 때문이다.) 중간 데이터를 추가/삭제하는 경우에는 LinkedList가 ArrayList보다 빠르다.LinkedList는 각 요소간의 연결만 변경해주면 되기 때문에 처리속도가 상당히 빠르다. 반면에 ArrayList는 각 요소들을 재배치하여 추가할 공간을 확보하거나 빈 공간을 채워야하기 때문에 처리속도가 늦다. 사실 데이터의 개수가 그리 크지 않다면 어느 것을 사용해도 큰 차이가 나지는 않는다. 데이터의 개수가 많아질수록 데이터를 읽어 오는 시간, 즉 접근시간(access time)은 ArrayList가 LinkedList보다 빠르다.배열의 경우 만일 n번째 원소의 값을 얻어 오고자 한다면 단순히 아래와 같은 수식을 계산함으로써 해결된다. (배열은 각 요소들이 연속적으로 메모리상에 존재하기 때문이다.) n번째 데이터의 주소 = 배열의 주소 + n * 데이터 타입의 크기 그러나, LinkedList는 불연속적으로 위치한 각 요소들이 서로 연결된 것이 아니기 때문에 처음부터 n번째 데이터까지 차례대로 따라가야만 원하는 값을 얻을 수 있다. Stack과 Queue순차적으로 데이터를 추가하고 삭제하는 스택에는 ArrayList와 같은 배열기반의 컬렉션 클래스가 적합하지만, 큐는 데이터를 꺼낼 때 항상 첫 번째 저장된 데이터를 삭제하므로, ArrayList와 같은 배열기반의 컬렉션 클래스를 사용한다면 데이터를 꺼낼 때마다 빈 공간을 채우기 위해 데이터의 복사가 발생하므로 비효율적이다. 그래서 큐는 ArrayList보다 데이터의 추가/삭제가 쉬운 LinkedList로 구현하는 것이 더 적합하다. Stack의 메서드 boolean empty() : Stack이 비어있는지 알려준다. Object peek() : Stack의 맨 위에 저장된 객체를 반환. pop()과 달리 Stack에서 객체를 꺼내지는 않음. Object pop() : Stack의 맨 위에 저장된 객체를 꺼낸다. Object push(Object item) : Stack에 객체(item)를 저장한다. int search(Object o) : Stack에서 주어진 객체(o)를 찾아서 그 위치를 반환. 못찾으면 -1을 반환. Queue의 메서드 boolean add(Object o) : 지정된 객체를 Queue에 추가한다. Object remove() : Queue에서 객체를 꺼내 반환. Object element() : 삭제없이 요소를 읽어온다. boolean offer(Object o) : Queue에 객체를 저장. Object poll() : Queue에서 객체를 꺼내서 반환. 비어있으면 null을 반환 Object peek() : 삭제없이 요소를 읽어 온다. Queue가 비어있으면 null을 반환 자바에서는 스택을 Stack클래스로 구현하여 제공하고 있지만 큐는 Queue인터페이스로만 정의해 놓았을 뿐 별도의 클래스를 제공하고 있지 않다. 대신 Queue인터페이스를 구현한 클래스들이 있어서 이 들 중의 하나를 선택해서 사용하면 된다. PriorityQueueQueue인터페이스의 구현체 중의 하나로, 저장한 순서에 관계없이 우선순위(priority)가 높은 것부터 꺼내게 된다는 특징이 있다. 그리고 null은 저장할 수 없다. Deque(Double-Ended Queue)Queue의 변형으로, 한 쪽 끝으로만 추가/삭제할 수 있는 Queue와 달리, Deque은 양쪽 끝에 추가/삭제가 가능하다. Deque의 조상은 Queue이며, 구현체로는 ArrayDeque와 LinkedList 등이 있다. 덱은 스택과 큐를 하나로 합쳐놓은 것과 같으며 스택으로 사용할 수도 있고, 큐로 사용할 수도 있다. Iterator, ListIterator, EnumerationIterator, ListIterator, Enumeration은 모두 컬렉션에 저장된 요소를 접근하는데 사용되는 인터페이스이다. Enumeration은 Iterator의 구버젼이며, ListIterator는 Iterator의 기능을 향상 시킨 것이다. Iterator컬렉션 프레임웍에서는 컬렉션에 저장된 요소들을 읽어오는 방법을 표준화하였다. 컬렉션에 저장된 각 요소에 접근하는 기능을 가진 Iterator인터페이스를 정의하고, Collection인터페이스에는 Iterator를 반환하는 iterator()를 정의하고 있다. iterator()는 Collection인터페이스에 정의된 메서드이므로 Collection인터페이스의 자손인 List와 Set에도 포함되어 있다. 그래서 List나 Set인터페이스를 구현하는 컬렉션은 iterator()가 각 컬렉션의 특징에 알맞게 작성되어 있다. boolean hasNext() : 읽어 올 요소가 남아있는지 확인한다. Object next() : 다음 요소를 읽어 온다. next()를 호출하기 전에 hasNext()를 호출해서 읽어 올 요소가 있는지 확인하는 것이 안전하다. void remove() : next()로 읽어 온 요소를 삭제한다. ListIterator와 EnumerationEnumeration은 컬렉션 프레임웍이 만들어지기 이전에 사용하던 것으로 Iterator의 구버젼이라고 생각하면 된다. ListIterator는 Iterator를 상속받아서 기능을 추가한 것으로, 컬렉션의 요소에 접근할 때 Iterator는 단방향으로만 이동할 수 있는 데 반해 ListIterator는 양방향으로의 이동이 가능하다. 다만 List인터페이스를 구현한 컬렉션에서만 사용할 수 있다. ArraysArrays클래스에는 배열을 다루는데 유용한 메서드가 정의되어 있다. Arrays에 정의된 메서드는 모두 static메서드이다. 배열의 복사 - copyOf(), copyOfRagne()copyOf()는 배열 전체를, copyOfRange()는 배열의 일부를 복사해서 새로운 배열을 만들어 반환한다. copyOfRange()에 지저왼 범위의 끝은 포함되지 안는다. 배열 채우기 - fill(), setAll()fill()은 배열의 모든 요소를 지정된 값으로 채운다. setAll()은 배열을 채우는데 사용할 함수형 인터페이스를 매개변수로 받는다. 이 메서드를 호출할 때는 함수형 인터페이스를 구현한 객체를 매개변수로 지정하던가 아니면 람다식을 지정해야 한다. 배열의 정렬과 검색 - sort(), binarySearch()sort()는 배열을 정렬할 때, 그리고 배열에 저장된 요소를 검색할 때는 binarySearch()를 사용한다. binarySearch()는 배열에서 지정된 값이 저장된 위치(index)를 찾아서 반환하는데, 반드시 배열이 정렬된 상태이어야 올바른 결과를 얻는다. (검색한 값과 일치하는 요소가 여러 개 있다면, 이 중 어떤 것의 위치가 반환될지는 알 수 없다.) 문자열의 비교와 출력 - equals(), toString(), deepEquals(), deepToString()toString()은 배열의 모든 요소를 문자열로 편하게 출력할 수 있다. toString은 일차원 배열에만 사용할 수 있으므로, 다차원 배열에서는 deepToString()을 사용해야 한다. deepToString()은 배열의 모든 요소를 재귀적으로 접근해서 문자열을 구성하므로 2차원뿐만 아니라 3차원 이상의 배열에 대해서도 동작한다. equals()는 두 배열에 저장된 모든 요소를 비교해서 같으면 true, 다르면 false를 반환한다. equals()도 일차원 배열에만 사용가능하므로, 다차원 배열의 비교에는 deepEquals()를 사용해야 한다. 배열을 List로 변환 - asList(Object… a)asList()는 배열을 List에 담아서 반환한다. 한 가지 주의할 점은 asList()가 반환한 List의 크기를 변경할 수 없다는 것이다. 저장된 내용은 변경 가능하나, 추가 또는 삭제가 불가능하다. 만약 크기를 변경할 수 있는 List가 필요하다면 다음과 같이 하면 된다. 1List list = new ArrayList(Arrays.asList(1, 2, 3, 4, 5)); parallelXXX(), spliterator(), stream()parallel로 시작하는 이름의 메서드는 빠른 결과를 얻기 위해 여러 쓰레드가 작업을 나누어 처리하도록 한다. spliterator()는 여러 쓰레드가 처리할 수 있게 하나의 작업을 여러 작업으로 나누는 Spliterator를 반환하며, stream()은 컬렉션을 스트림으로 변환한다. Comparator와 ComparableComparator와 Comparable은 모두 인터페이스로 컬렉션을 정렬하는데 필요한 메서드를 정의하고 있으며, Comparable을 구현하고 있는 클래스들은 같은 타입의 인터페이스끼리 서로 비교할 수 있는 클래스들(주로 wrapper클래스)이 있으며, 기본적으로 오름차순으로 구현되어 있다. 그래서 Comparable을 구현한 클래스는 정렬이 가능하다는 것을 의미한다. 12345678public interface Comparator { int compare(Object o1, Object o2); boolean equals(Object obj);}public interface Comparable { public int compareTo(Object o);} Comparator의 compare()와 Comparable의 compareTo()는 두 객체를 비교한다는 같은 기능을 목적으로 만들어 졌다. compareTo()는 반환값은 int지만 실제로는 비교하는 두 객체가 같으면 0, 비교하는 값보다 작으면 음수, 크면 양수를 반환하도록 구현해야한다. compare()도 객체를 비교해서 음수, 0, 양수 중의 하나를 반환하도록 구현해야한다. Comparable : 기본 정렬기준(오름차순)을 구현하는데 사용. Comparator : 기본 정렬기준 외에 다른 기준으로 정렬하고자할 때 사용 Arrays.sort()는 배열을 정렬할 때, Comparator를 지정해주지 않으면 저장하는 객체에 구현된 내용에 따라 정렬된다. 12static void sort(Object[] a) // 객체 배열에 저장된 객체가 구현한 Comparable에 의한 정렬static void sort(Object[] a, Comparator c) // 지정한 Comparator에 의한 정렬 HashSetHashSet은 Set인터페이스를 구현한 가장 대표적인 컬렉션이며, Set인터페이스의 특징대로 HashSet은 중복된 요소를 저장하지 않는다. ArrayList와 같이 List인터페이스를 구현한 컬렉션과 달리 HashSet은 저장순서를 유지하지 않으므로 저장순서를 유지하고자 한다면 LinkedHashSet을 사용해야 한다. HashSet은 내부적으로 HashMap을 이용해서 만들어졌으며, HashSet이란 이름은 해싱(hasing)을 이용해서 구현했기 때문에 붙여진 것이다. HashSet의 add메서드는 새로운 요소를 추가하기 전에 기존에 저장된 요소와 같은 것인지 판별하기 위해 추가하려는 요소의 equals()와 hashCode()를 호출하기 때문에 equals()와 hashCode()를 목적에 맞게 오버라이딩해야 한다. 오버라이딩을 통해 작성된 hashCode()는 다음의 세 가지 조건을 만족 시켜야 한다. 실행 중인 애플리케이션 내의 동일한 객체에 대해서 여러 번 hashCode()를 호출해도 동일한 int 값을 반환해야 한다. 하지만, 실행시마다 동일한 int값을 반환할 필요는 없다.(String 클래스는 문자열의 내용으로 해시코드를 만들어 내기 때문에 내용이 같은 문자열에 대한 hashCode() 호출은 항상 동일한 해시코드를 반환한다. 반면에 Object클래스는 객체의 주소로 해시코드를 만들어 내기 때문에 실행할 때마다 해시코드값이 달라질 수 있다.) equals메서드를 이용한 비교에 의해서 true를 얻은 두 객체에 대해 각각 hashCode()를 호출해서 얻은 결과는 반드시 같아야 한다. equals메서드를 호출했을 때 false를 반환하는 두 객체는 hashCode() 호출에 대해 같은 int값을 반환하는 경우가 있어도 괜찮지만, 해싱(hashing)을 사용하는 컬렉션의 성능을 향상시키기 위해서는 다른 int값을 반환하는 것이 좋다. TreeSetTreeSet은 이진 검색 트리(binary search tree)라는 자료구조의 형태로 데이터를 저장하는 컬렉션 클래스이다. 이진 검색 트리는 정렬, 검색, 범위검색(range search)에 노은 성능을 보이는 자료구조이며 TreeSet은 이진 검색 트리의 성능을 향상시킨 ‘레드-블랙 트리(Red-Black tree)’로 구현되어 있다. Set인터페이스를 구현했으므로 중복된 데이터의 저장을 허용하지 않으며 정렬된 위치에 저장하므로 저장순서를 유지하지도 않는다. HashMap과 HashtableHashtable과 HashMap의 관계는 Vector와 ArrayList의 관계와 같아서 Hashtable보다는 새로운 버전인 HashMap을 사용할 것을 권한다. HashMap은 Map을 구현했으므로 Map의 특징인 키(key)와 값(value)을 묶어서 하나의 데이터(entry)로 저장한다는 특징을 갖는다. 그리고 해싱(hashing)을 사용하기 때문에 많은 양의 데이터를 검색하는데 있어서 뛰어난 성능을 보인다. 123456789public class HashMap extends AbstractMap implements Map, Cloneable, Serializable { transient Entry[] table; //... static class Entry implements Map.Entry { final Object key; Object value; //... }} HashMap은 Entry라는 내부 클래스를 다시 정의하고, 다시 Entry타입의 배열을 선언하고 있다. 키(key)와 값(value)은 별개의 값이 아니라 서로 관련된 값이기 때문에 각각의 배열로 선언하기 보다는 하나의 클래스로 정의해서 하나의 배열로 다루는 것이 데이터의 무결성적인 측면에서 더 바람직하기 때문이다. HashMap은 키와 값을 각각 Object타입으로 저장한다. 즉 어떠한 객체도 저장할 수 있지만 키는 주로 String을 대문자 또는 소문자로 통일해서 사용하곤 한다. Set entrySet() : HashMap에 저장된 키와 값을 엔트리(키와 값의 결합)의 형태로 Set에 저장해서 반환 Object get(Object key) : 지정된 키(key)의 값(객체)을 반환. 못찾으면 null 반환 Set keySet() : HashMap에 저장된 모든 키가 저장된 Set을 반환 Object put(Object key, Object value) : 지정된 키와 값을 HashMap에 저장 Collection values() : HashMap에 저장된 모든 값을 컬렉션의 형태로 반환 해싱과 해시함수해싱이란 해시함수(hash function)을 이용해서 데이터를 해시테이블(hash table)에 저장하고 검색하는 기법을 말한다. 해시함수는 데이터가 저장되어 있는 곳을 알려주기 때문에 다량의 데이터 중에서도 원하는 데이터를 빠르게 찾을 수 있다. 해싱에서 사용하는 자료구조는 배열과 링크드 리스트의 조합으로 되어 있다. 저장할 데이터의 키를 해시함수에 넣으면 배열의 한 요소를 얻게 되고, 다시 그 곳에 연결되어 있는 링크드 리스트에 저장하게 된다. 검색하고자 하는 값의 키로 해시함수를 호출한다. 해시함수의 계산결과인 해시코드를 이용해서 해당 값이 저장되어 있는 링크드 리스트를 찾는다. 링크드 리스트에서 검색한 키와 일치하는 데이터를 찾는다. 링크드 리스트는 검색에 불리한 자료구조이기 때문에 링크드 리스트의 크기가 커질수록 검색속도가 떨어지게 된다. 하나의 링크드 리스트에 최소한의 데이터만 저장되려면, 저장될 데이터의 크기를 고려해서 HashMap의 크기를 적절하게 지정해주어야 하고, 해시함수가 서로 다른 키에 대해서 중복된 해시코드의 반환을 최소화해야 한다. 그래야 HashMap에서 빠른 검색시간을 얻을 수 있다. 실제로는 HashMap과 같이 해싱을 구현한 컬렉션 클래스에는 Object클래스에 정의된 hashCode()를 해시함수로 사용한다. Object클래스에 정의된 hashCode()는 객체의 주소를 이용하는 알고리즘으로 해시코드를 만들어 내기 때문에 모든 객체에 대헤 hashCode()를 호출한 결과가 서로 다른 좋은 방법이다. String클래스의 경우 Object로부터 상속받은 hashCode()를 오버라이딩해서 문자열의 내용으로 해시코드를 만들어 낸다. 그래서 서로 다른 String인스턴스일지라도 같은 내용의 문자열을 가졌다면 hashCode()를 호출하면 같은 해시코드를 얻는다. HashSet과 마찬가지로 HashMap에서도 서로 다른 두 객체에 대해 equals()로 비교한 결과가 true인 동시에 hashCode()의 반환값이 같아야 같은 객체로 인식한다. (이미 존재하는 키에 대한 값을 저장하면 기존의 값을 새로운 값으로 덮어쓴다.) 그래서 새로운 클래스를 정의할 때 equals()를 오버라이딩해다 한다면 hashCode()도 같이 오버라이딩해서 equals()의 결과가 true인 두 객체의 해시코드가 항상 같도록 해주어야 한다. 그렇지 않으면 HashMap과 같이 해싱을 구현한 컬렉션 클래스에서는 equals()의 호출결과가 true지만 해시코드가 다른 두 객체를 서로 다른 것으로 인식하고 따로 저장할 것이다. TreeMapTreeMap은 이진검색트리의 형태로 키와 값의 쌍으로 이루어진 데이터를 저장한다. 그래서 검색과 정렬에 적합한 컬렉션 클래스이다. 검색에 관한 대부분의 경우에서는 HashMap이 TreeMap보다 더 뛰어나므로 HashMap을 사용하는 것이 좋다. 다만 범위검색이나 정렬이 필요한 경우에는 TreeMap을 사용하자. PropertiesProperties는 HashMap의 구버전인 Hashtable을 상속받아 구현한 것으로, Hashtable은 키와 값을 (Object, Object)의 형태로 저장하는데 비해 Properties는 (String, String)의 형태로 저장하는 보다 단순화된 컬렉션클래스이다. 주로 애플리케이션의 환경설정과 관련된 속성(property)을 저장하는데 사용되며 데이터를 파일로부터 읽고 쓰는 편리한 기능을 제공한다. CollectionsArrays가 배열과 관련된 메서드를 제공하는 것처럼, Collections는 컬렉션과 관련된 메서드를 제공한다. fill(), copy(), sort(), binarySearch() 등의 메서드는 두 클래스에 포함되어 있으며 같은 기능을 한다. 컬렉션의 동기화멀티 쓰레드 프로그래밍에서는 하나의 객체를 여러 쓰레드가 동시에 접근할 수 있기 때문에 데이터의 일관성(consistency)을 유지하기 위해서는 공유되는 객체의 동기화(synchronization)가 필요하다. Vector와 Hashtable과 같은 구버전(JDK1.2 이전)의 클래스들은 자체적으로 동기화처리가 되어 있는데, 멀티쓰레드 프로그래밍이 아닌 경우에는 불필요한 기능이 되어 성능을 떨어뜨리는 요인이 된다. 그래서 새로 추가된 ArrayList와 HashMap과 같은 컬렉션은 동기화를 자체적으로 처리하지 않고 필요한 경우에만 java.util.Collections클래스의 동기화 메서드를 이용해서 동기화처리가 가능하도록 변경하였다. 123456static Collection synchronizedCollection(Collection c)static List synchronizedList(List list)static Set synchronizedSet(Set s)static Map synchronizedMap(Map m)static SortedSet synchronizedSortedSet(SortedSet s)static SortedMap synchronizedSortedMap(SortedMap m) 변경불가 컬렉션 만들기컬렉션에 저장된 데이터를 보호하기 위해서 컬렉션을 변경할 수 없게 읽기전용으로 만들어야 할 때가 있다. 123456static Collection unmodifiableCollection(Collection c)static List unmodifiableList(List list)static Set unmodifiableSet(Set s)static Map unmodifiableMap(Map m)static SortedSet unmodifiableSortedSet(SortedSet s)static SortedMap unmodifiableSortedMap(SortedMap m) 컬렉션 클래스 정리 &amp; 요약 ArrayList : 배열기반, 데이터의 추가와 삭제에 불리, 순차적인 추가/삭제는 제일 빠름. 임의의 요소에 대한 접근성이 뛰어남. LinkedList : 연결기반, 데이터의 추가와 삭제에 유리. 임의의 요소에 대한 접근성이 좋지 않다. HashMap : 배열과 연결이 결합된 형태. 추가, 삭제, 검색, 접근성이 모두 뛰어남. 검색에는 최고성능을 보인다. TreeMap : 연결기반, 정렬과 검색(특히 범위검색)에 적합. 검색성능은 HashMap보다 떨어짐. Stack : Vector를 상속받아 구현 Queue : LinkedList가 Queue인터페이스를 구현 Properties : Hashtable을 상속받아 구현(String, String) HashSet : HashMap을 이용해서 구현 TreeSet : TreeMap을 이용해서 구현 LinkedHashMap, LinkedHashSet : HashMap과 HashSet에 저장순서유지기능을 추가하였음.","link":"/2018/06/10/Java/java-collection-framework/"},{"title":"Hash - MD5와 SHA256","text":"해시(Hash)와 암호화(Encryption)의 차이먼저 혼동하기 쉬운 해시와 암호화의 차이에 대해서 알아보자. 해시해시는 가변 길이의 데이터를 해시 함수를 사용해 고정 길이의 해시 값을 만들어 내는 방법이다. 만약 해시 값이 다르면 그 해시 값을 만들기 위해 사용했던 원래의 데이터도 달라야한다. 또한 해시 값에서 원래의 데이터를 구하는 것은 매우 어렵다. 암호화암호화는 복호화(Decryption)을 할 수 있는 Key를 소유하고 있는 사람은 제외하고는 원래의 데이터를 읽어볼 수 없도록 암호화 알고리즘을 이용해 데이터를 전달하는 것이다. 암호화된 정보는 복호화하여 다시 원래의 데이터를 구할 수 있다. 즉, 암호화를 통해 생성된 값은 복호화를 통해 원래의 데이터를 알 수 있지만, 해시를 통해 만들어진 고정된 길이의 해시 값의 경우는 원래의 데이터를 알 수 없다. 해시이제 해시에 대해서 조금 더 자세히 알아보자. 해시 함수는 가변 길이의 데이터를 이용해 고정 길이의 해시 값을 생성하는데, 같은 입력 값에 대해서는 같은 출력 값을 보장한다. 해시는 보안 분야에서도 널리 사용된다. 해시 함수를 통해 생성된 해시 값을 이용해서 원래의 데이터를 알 수 없도록 만든다는 특성을 갖고 있기 때문이다. 해시 함수의 결과물은 고정된 길이의 숫자이므로, 원래의 정보는 손실된다. 또한 이런 특성 때문에 하나의 원본 데이터는 하나의 해시 값만 가지지만, 하나의 해시 값을 만들어낼 수 있는 원본 데이터는 매우 많다. 그렇기 때문에 해시 값만 가지고는 원본 데이터를 복원해내는 것은 불가능하다. 따라서 비밀번호, 전자서명, 전자투표, 전자상거래와 같은 민감한 입력의 무결성을 검증할 때 사용된다. 비밀번호: 보통 유저의 비밀번호를 암호화해서 저장한다고 한다. 그러나 암호화의 경우는 복호화를 통해 실제 비밀번호를 알아낼 수 있으므로 암호화가 아닌 해시 함수를 이용해 생성된 해시 값을 저장해야한다. MD5MD5(Message-Digest algorithm 5)는 128비트의 해시 값을 생성하는 해시 함수이다. 주로 프로그램이나 파일이 원본 그대로인지를 확인하는 무결성 검사 등에 사용된다. 이전에 쓰이던 MD4를 대체하기 위해 만들어졌다. 그러나 현재는 아래와 같은 결함이 발견되었기 때문에 사용하는 것을 권장하지 않는다. 1996년에 설계상 결함이 발견되었다. 이것은 매우 치명적인 결함은 아니었지만, 암호학자들은 해시 용도로 SHA-1과 같이 다른 안전한 알고리즘을 사용할 것을 권장하기 시작했다. 2004년에는 더욱 심한 암호화 결함이 발견되었고. 2006년에는 노트북 컴퓨터 한 대의 계산 능력으로 1분 내에 해시 충돌을 찾을 정도로 빠른 알고리즘이 발표되기도 하였다. 현재는 MD5 알고리즘을 보안 관련 용도로 쓰는 것은 권장하지 않으며, 심각한 보안 문제를 야기할 수도 있다. kotlin으로 작성한 코드를 통해 간단히 확인해보자. java에서 제공하는 MessageDigest를 사용하면 쉽게 MD5 해시 함수를 통한 해시 값을 만들 수 있다. 아래 코드에서는 MD5 해시 함수를 통해 해시 값(128비트)을 생성하고 Hex string으로 변환하였다. Online MD5 Hash Generator를 이용해서도 테스트할 수 있다. 1234567891011121314fun main() { val planText = \"password1!2@3#\" val md = MessageDigest.getInstance(\"MD5\") md.update(planText.toByteArray()) val digest = DatatypeConverter.printHexBinary(md.digest()) println(\"planText: ${planText}\") println(\"MD5 encoding result: ${digest}\")}----------실행 결과----------planText: password1!2@3#MD5 encoding result: E9C4736A0963EB81C0C85AF48CF2F3F2 SHA-256SHA-256은 SHA(Secure Hash Algorithm) 알고리즘의 한 종류로서 256비트의 해시 값을 생성하는 해시 함수이다. SHA-256은 미국의 국립표준기술연구소(NIST; National Institute of Standards and Technology)에 의해 공표된 표준 해시 알고리즘인 SHA-2 계열 중 하나이며 블록체인에서 가장 많이 채택하여 사용하고 있다. 개인용 컴퓨터로 무차별 대입을 수행해 해시 충돌 사례를 찾으려고 할 때 많은 시간이 소요될 정도로 큰 숫자이므로 충돌로부터 비교적 안전하다고 평가된다. 아래 코드에서는 SHA-256 해시 함수를 통해 해시 값(256비트)을 생성하고 Hex string으로 변환하였다. Online SHA-256 Hash Generator를 이용해서도 테스트할 수 있다. 1234567891011121314fun main() { val planText = \"password1!2@3#\" val md = MessageDigest.getInstance(\"SHA-256\") md.update(planText.toByteArray()) val digest = DatatypeConverter.printHexBinary(md.digest()) println(\"planText: ${planText}\") println(\"SHA-256 encoding result: ${digest}\")}----------실행 결과----------planText: password1!2@3#SHA-256 encoding result: 0979334AF544553966CB7AF741869C971C716A6879C562FDFE781B50F2F5862E","link":"/2019/12/18/Java/hash/"},{"title":"CompletableFuture","text":"해당 포스팅은 토비님의 토비의 봄 TV 11회 스프링 리액티브 프로그래밍 (7) CompletableFuture 라이브 코딩을 보며 따라했던 실습 내용을 바탕으로 정리한 글입니다. 실습 코드들은 IntelliJ를 이용해 SpringBoot 2.1.3.RELEASE 버전 기반으로 프로젝트를 생성 후(web, lombok 포함) 진행했습니다. 이번에는 자바8에 나온 CompletableFuture 라는 새로운 비동기 자바 프로그래밍 기술에 대해서 알아보고, 지난 3회 정도 동안 다루어 왔던 자바 서블릿, 스프링의 비동기 기술 발전의 내용을 자바 8을 기준으로 다시 재작성합니다. CompletableFuture먼저 간단한 코드를 통해서 CompletableFuture 사용법에 대해서 알아보겠습니다. runAsync &amp; thenRun12345678910111213141516171819202122@Slf4jpublic class CFuture { public static void main(String[] args) throws ExecutionException, InterruptedException { // Async 작업이 끝나고 해당 스레드에서 계속해서 작업을 수행한다. CompletableFuture .runAsync(() -&gt; log.info(\"runAsync\")) .thenRun(() -&gt; log.info(\"thenRun\")) .thenRun(() -&gt; log.info(\"thenRun\")); log.info(\"exit\"); // 별도의 pool을 설정하지 않으면 자바7 부터는 ForkJoinPool이 자동으로 사용된다. ForkJoinPool.commonPool().shutdown(); ForkJoinPool.commonPool().awaitTermination(10, TimeUnit.SECONDS); }}// 결과23:43:15.841 [main] INFO com.example.study.CFuture - exit23:43:15.841 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - runAsync23:43:15.845 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenRun23:43:15.845 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenRun supplyAsync, thenApply, thenAccept123456789101112131415161718192021222324252627282930@Slf4jpublic class CFuture { public static void main(String[] args) throws ExecutionException, InterruptedException { // Async 작업이 끝나고 해당 스레드에서 계속해서 작업을 수행한다. CompletableFuture .supplyAsync(() -&gt; { log.info(\"supplyAsync\"); return 1; }) // 앞의 비동기 작업의 결과를 받아 사용해 새로운 값을 return 한다. .thenApply(s -&gt; { log.info(\"thenApply {}\", s); return s + 1; }) // 앞의 비동기 작업의 결과를 받아 사용하며 return이 없다. .thenAccept(s -&gt; log.info(\"thenAccept {}\", s)); log.info(\"exit\"); // 별도의 pool을 설정하지않으면 자바7 부터는 ForkJoinPool이 자동으로 사용된다. ForkJoinPool.commonPool().shutdown(); ForkJoinPool.commonPool().awaitTermination(10, TimeUnit.SECONDS); }}// 결과23:50:00.650 [main] INFO com.example.study.CFuture - exit23:50:00.650 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - supplyAsync23:50:00.654 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenApply 123:50:00.656 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenAccept 2 thenCompose123456789101112131415161718192021222324252627282930313233343536@Slf4jpublic class CFuture { public static void main(String[] args) throws ExecutionException, InterruptedException { // Async 작업이 끝나고 해당 스레드에서 계속해서 작업을 수행한다. CompletableFuture .supplyAsync(() -&gt; { log.info(\"supplyAsync\"); return 1; }) // return이 CompletableFuture인 경우 thenCompose를 사용한다. .thenCompose(s -&gt; { log.info(\"thenApply {}\", s); return CompletableFuture.completedFuture(s + 1); }) // 앞의 비동기 작업의 결과를 받아 사용해 새로운 값을 return 한다. .thenApply(s -&gt; { log.info(\"thenApply {}\", s); return s + 1; }) // 앞의 비동기 작업의 결과를 받아 사용하며 return이 없다. .thenAccept(s -&gt; log.info(\"thenAccept {}\", s)); log.info(\"exit\"); // 별도의 pool을 설정하지않으면 자바7 부터는 ForkJoinPool이 자동으로 사용된다. ForkJoinPool.commonPool().shutdown(); ForkJoinPool.commonPool().awaitTermination(10, TimeUnit.SECONDS); }}// 결과23:50:35.893 [main] INFO com.example.study.CFuture - exit23:50:35.893 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - supplyAsync23:50:35.897 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenApply 123:50:35.899 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenApply 223:50:35.899 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenAccept 3 exceptionally1234567891011121314151617181920212223242526272829303132333435363738394041@Slf4jpublic class CFuture { public static void main(String[] args) throws ExecutionException, InterruptedException { // Async 작업이 끝나고 해당 스레드에서 계속해서 작업을 수행한다. CompletableFuture .supplyAsync(() -&gt; { log.info(\"supplyAsync\"); return 1; }) // return이 CompletableFuture인 경우 thenCompose를 사용한다. .thenCompose(s -&gt; { log.info(\"thenApply {}\", s); if (1 == 1) throw new RuntimeException(); return CompletableFuture.completedFuture(s + 1); }) // 앞의 비동기 작업의 결과를 받아 사용해 새로운 값을 return 한다. .thenApply(s -&gt; { log.info(\"thenApply {}\", s); return s + 1; }) .exceptionally(e -&gt; { log.info(\"exceptionally\"); return -10; }) // 앞의 비동기 작업의 결과를 받아 사용하며 return이 없다. .thenAccept(s -&gt; log.info(\"thenAccept {}\", s)); log.info(\"exit\"); // 별도의 pool을 설정하지않으면 자바7 부터는 ForkJoinPool이 자동으로 사용된다. ForkJoinPool.commonPool().shutdown(); ForkJoinPool.commonPool().awaitTermination(10, TimeUnit.SECONDS); }}// 결과23:51:31.255 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - supplyAsync23:51:31.257 [main] INFO com.example.study.CFuture - exit23:51:31.259 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenApply 123:51:31.261 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - exceptionally23:51:31.261 [ForkJoinPool.commonPool-worker-1] INFO com.example.study.CFuture - thenAccept -10 thenApplyAsync1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Slf4jpublic class CFuture { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService es = Executors.newFixedThreadPool(10); // Async 작업이 끝나고 해당 스레드에서 계속해서 작업을 수행한다. CompletableFuture .supplyAsync(() -&gt; { log.info(\"supplyAsync\"); return 1; }, es) // return이 CompletableFuture인 경우 thenCompose를 사용한다. .thenCompose(s -&gt; { log.info(\"thenApply {}\", s); return CompletableFuture.completedFuture(s + 1); }) // 앞의 비동기 작업의 결과를 받아 사용해 새로운 값을 return 한다. .thenApply(s -&gt; { log.info(\"thenApply {}\", s); return s + 2; }) // 이 작업은 다른 스레드에서 처리를 하려고 할 때, thenApplyAsync를 사용한다. // 스레드의 사용을 더 효율적으로 하고 자원을 더 효율적으로 사용한다. // 현재 스레드 풀의 정책에 따라서 새로운 스레드를 할당하거나 대기중인 스레드를 사용한다. (스레드 풀 전략에 따라 다르다.) .thenApplyAsync(s -&gt; { log.info(\"thenApply {}\", s); return s + 3; }, es) .exceptionally(e -&gt; { log.info(\"exceptionally\"); return -10; }) // 앞의 비동기 작업의 결과를 받아 사용하며 return이 없다. .thenAcceptAsync(s -&gt; log.info(\"thenAccept {}\", s), es); log.info(\"exit\"); // 별도의 pool을 설정하지않으면 자바7 부터는 ForkJoinPool이 자동으로 사용된다. ForkJoinPool.commonPool().shutdown(); ForkJoinPool.commonPool().awaitTermination(10, TimeUnit.SECONDS); }}// 결과23:54:00.043 [pool-1-thread-1] INFO com.example.study.CFuture - supplyAsync23:54:00.043 [main] INFO com.example.study.CFuture - exit23:54:00.047 [pool-1-thread-1] INFO com.example.study.CFuture - thenApply 123:54:00.048 [pool-1-thread-1] INFO com.example.study.CFuture - thenApply 223:54:00.049 [pool-1-thread-2] INFO com.example.study.CFuture - thenApply 423:54:00.049 [pool-1-thread-3] INFO com.example.study.CFuture - thenAccept 7 ListenableFuture에서 CompletableFuture로 변환Spring 4.0에 들어간 AsyncRestTemplate이 return하는 것은 CompletableFuture가 아닌 ListenableFuture입니다.Spring 4까지는 자바 6~8을 지원하기 때문에 CompletableFuture로 return을 만들지 못하고 계속 ListenableFuture를 유지했습니다. 따라서 ListenableFuture를 CompletableFuture로 만들어 체이닝하기 위해서는 유틸성 wrapper 메서드를 만들어 사용하면 됩니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@SpringBootApplication@EnableAsync@Slf4jpublic class StudyApplication { @RestController public static class MyController { AsyncRestTemplate rt = new AsyncRestTemplate(new Netty4ClientHttpRequestFactory(new NioEventLoopGroup(1))); @Autowired MyService myService; static final String URL1 = \"http://localhost:8081/service?req={req}\"; static final String URL2 = \"http://localhost:8081/service2?req={req}\"; @GetMapping(\"/rest\") public DeferredResult&lt;String&gt; rest(int idx) { DeferredResult&lt;String&gt; dr = new DeferredResult&lt;&gt;(); toCF(rt.getForEntity(\"http://localhost:8081/service?req={req}\", String.class, \"hello\" + idx)) .thenCompose(s -&gt; toCF(rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody()))) .thenCompose(s -&gt; toCF(myService.work(s.getBody()))) .thenAccept(s -&gt; dr.setResult(s)) .exceptionally(e -&gt; { dr.setErrorResult(e.getMessage()); return null; });// f1.addCallback(s -&gt; {// ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; f2 = rt.getForEntity(\"http://localhost:8081/service2?req={req}\", String.class, s.getBody());// f2.addCallback(s2 -&gt; {// ListenableFuture&lt;String&gt; f3 = myService.work(s2.getBody());// f3.addCallback(s3 -&gt; {// dr.setResult(s3);// }, e -&gt; {// dr.setErrorResult(e.getMessage());// });// }, e -&gt; {// dr.setErrorResult(e.getMessage());// });// }, e -&gt; {// dr.setErrorResult(e.getMessage());// }); return dr; } &lt;T&gt; CompletableFuture&lt;T&gt; toCF(ListenableFuture&lt;T&gt; lf) { CompletableFuture&lt;T&gt; cf = new CompletableFuture&lt;&gt;(); lf.addCallback(s -&gt; cf.complete(s), e -&gt; cf.completeExceptionally(e)); return cf; } } @Service public static class MyService { @Async public ListenableFuture&lt;String&gt; work(String req) { return new AsyncResult&lt;&gt;(req + \"/asyncwork\"); } } @Bean public ThreadPoolTaskExecutor myThreadPool() { ThreadPoolTaskExecutor te = new ThreadPoolTaskExecutor(); te.setCorePoolSize(1); te.setMaxPoolSize(1); te.initialize(); return te; } public static void main(String[] args) { SpringApplication.run(StudyApplication.class, args); }}","link":"/2019/05/05/Java/java-async-4/"},{"title":"자주 보지 않으면 잊게되는 Java 기초 정리","text":"매번 공부해도 너무 당연하다는 듯이 넘어가 잊게되거나, 기억해 두면 좋을것 같은 기초적인 문법과 개념들을 간단히 정리해보겠습니다. 변수덧셈 연산자(+)는 피연산자가 모두 숫자일 때는 두 수를 더하지만, 피연산자 중 어느 한쪽이 String이면 나머지 한 쪽을 먼저 String으로 변환한 다음 두 String을 결합한다. 참조변수의 출력이나 덧셈연산자를 이용한 참조변수와 문자열의 결합에는 toString()이 자동적으로 호출되어 참조변수를 문자열로 대치한 후 처리한다. 연산자 x &lt;&lt; 2 + 1 : 쉬프트연산자(&lt;&lt;)는 덧셈연산자보다 우선순위가 낮다. 그래서 해당 식은 ‘x &lt;&lt; (2 + 1)’ 과 같다. data &amp; 0xFF == 0 : 논리연산자(&amp;)는 비교연산자(==)보다 우선순위가 낮으므로 비교연산 후에 논리연산이 수행된다. 그래서 해당 식은 ‘data &amp; (0xFF == 0)’ 과 같다. x &lt; -1 || x &gt; 3 &amp;&amp; x &lt; 5 : 논리연산자 중에서 AND를 의미하는 ‘&amp;&amp;’가 OR을 의미하는 ‘||’보다 우선순위가 높다. 그래서 해당 식은 ‘x &lt; -1 || (x &gt; 3 &amp;&amp; x &lt; 5)’ 과 같다. 산술 변환 : 연산 전에 피연산자 타입의 일치를 위해 자동 형변환되는 것. 이 변환은 이항 연산에서 뿐만 아니라 단항 연산에서도 일어난다. ‘산술 변환’의 규칙은 다음과 같다. 두 피연산자의 타입을 같게 일치시킨다. (보다 큰 타입으로 일치) long + int -&gt; long + long -&gt; long float + int -&gt; float + float -&gt; float 피연산자의 타입이 int보다 작은 타입이면 int로 변환된다. byte + short -&gt; int + int -&gt; int char + short -&gt; int + int -&gt; int 첫 번째 규칙은 자동 형변환처럼 피연산자의 값손실을 최소화하기 위한 것이고, 두 번째 규칙은 정수형의 기본 타입인 int가 가장 효율적으로 처리할 수 있는 타입이기 때문에, 그리고 int보다 작은 타입, 예를 들면 char나 short의 표현범위가 좁아서 연산중에 오버플로우(overflow)가 발생할 가능성이 높기 때문에 만들어진 것이다. 12345678long a = 1000000 * 1000000;long b = 1000000 * 1000000L;System.out.println(\"a=\"+a);System.out.println(\"b=\"+b);// 결과a = -727379968b = 1000000000000 위의 예제에서 ‘1000000 1000000’의 결과가 1000000000000(2\\10의 12승)임에도 불구하고, -727379968라는 결과가 출력되었다. 그 이유는 int 타입과 int 타입의 연산 결과는 int 타입인데, 연산결과가 int 타입의 최대값인 1000000000(2*10의 9승)을 넘으므로 오버플로우(overflow)가 발생했기 때문이다. 이미 오버플로우가 발생한 값을 아무리 long 타입의 변수에 저장해도 소용이 없다. 123456789char c1 = 'a'; // c1에는 문자 'a'의 코드값은 97이 저장된다.char c2 = c1; // c1에 저장되어 있는 값이 c2에 저장된다.char c3 = ' '; // c3를 공백으로 초기화 한다.int i = c1 +1; // 'a' + 1 -&gt; 97 + 1 -&gt; 98c3 = (char)(c1 + 1);c2++;c2++; 위의 예제에서 c2++; 대신에 c2=c2+1;을 사용하면 에러가 발생할 것이다. c2+1의 연산결과는 int형이며, 그 결과를 다시 c2에 담으려면 형변환 연산자를 사용하여 char형으로 형변환해야 하기 때문이다. 123char c1 = 'a';char c2 = c1 + 1; // 컴파일 에러 발생 Ochar c2 = 'a' + 1; // 컴파일 에러 발생 X ‘a’ + 1은 리터럴 간의 연산이기 때문에 에러가 발생하지 않는다. 상수 또는 리터럴 간의 연산은 실행과정동안 변하는 값이 아니기 때문에, 컴파일 시에 컴파일러가 계산해서 그 결과로 대체함으로써 코드를 보다 효율적으로 만든다. 컴파일러가 미리 덧셈연산을 수행하기 때문에 실행 시에는 덧셈 연산이 수행되지 않는다. 수식에 변수가 들어가 있는 경우에는 컴파일러가 미리 계산을 할 수 없기 때문에 형변환을 해줘야한다. (char c2 = (char) (c1 + 1)) 그렇지 않으면 컴파일 에러가 발생한다. 12float f = 0.1f; // f에 0.10000000149011612로 저장된다.double d = 0.1; // d에 0.10000000000000001로 저장된다. float 타입의 값을 double 타입으로 형변환하면, 부호와 지수는 달라지지 않고 그저 기수의 빈자리를 0으로 채울 뿐이므로 0.1f를 double타입으로 형변환해도 그 값은 전혀 달라지지 않는다. 즉, float 타입의 값을 정밀도가 더 높은 double 타입으로 형변환했다고 해서 오차가 적어지는 것이 아니라는 말이다. 12345678910String str1 = \"abc\";String str2 = new String(\"abc\");\"abc\" == \"abc\" ? truestr1 == \"abc\" ? truestr2 == \"abc\" ? falsestr1.equals(\"abc\") ? truestr2.equals(\"abc\") ? truestr2.equals(\"ABC\") ? falsestr2.equalsIgnoreCase(\"ABC\") ? true str2와 “abc”의 내용이 같은데도 ‘==’로 비교하면, false를 결과로 얻는다. 내용은 같지만 서로 다른 객체이기 때문이다. 그러나 equals()는 객체가 달라도 내용이 같으면 true를 반환한다. 그래서 문자열을 비교할 때는 항상 equals()를 사용해야 한다. 효율적인 연산 OR 연산 ‘||’의 경우, 두 피연산자 중 어느 한 쪽만 ‘참’이어도 전체 연산결과가 ‘참’이므로 좌측 피연산자가 ‘true(참)’이면, 우측 피연산자의 값은 평가하지 않는다. AND 연산 ‘&amp;&amp;’의 경우, 어느 한쪽만 ‘거짓(0)’이어도 전체 연산결과가 ‘거짓(0)’이므로 좌측 피연산자가 ‘거짓(0)’이면, 우측 피연산자의 값은 평가하지 않는다. 비트 XOR 연산자 ‘^’는 두 피연산자의 비트가 다를 때만 1이 된다. 그리고 같은 값으로 두고 XOR 연산을 수행하면 원래의 값으로 돌아온다는 특징이 있어서 간단한 암호화에 사용된다. 비트 전환 연산자는 피연산자의 타입이 int보다 작으면 int로 자동 형변환(산술 변환) 후에 연산하기 때문에 연산결과는 32자리의 2진수이다. 쉬프트 연산자의 좌측 피연산자는 산술변환이 적용되어 int보다 작은 타입은 int타입으로 자동 변환되고 연산결과 역시 int타입이 된다. 그러나 쉬프트 연산자는 다른 이항연산자들과 달리 피연산자의 타입을 일치시킬 필요가 없기 때문에 우측 피연산자에는 산술변환이 적용되지 않는다. 변수 앞에 키워드 ‘final’을 붙이면 상수가 된다. 상수는 반드시 선언과 동시에 값을 저장해야하며, 한 번 저장된 값은 바꿀 수 없다. 조건문과 반복문JDK 1.5부터 배열과 컬렉션에 저장된 요소에 접근할 때 기존보다 편리한 방법으로 처리할 수 있도록 for문의 새로운 문법이 추가되었다. 123for (타입 변수명 : 배열 또는 컬렉션) { // 반복할 문장} 위의 문장에서 타입은 배열 또는 컬렉션의 요소의 타입이어야 한다. 배열 또는 컬렉션에 저장된 값이 매 반복마다 하나씩 순서대로 읽혀서 변수에 저장된다. 그러나 향상된 for문은 일반적인 for문과 달리 배열이나 컬렉션에 저장된 요소들을 읽어오는 용도로만 사용 수 있다는 제약이 있다. 반복문은 그저 같은 문장을 반복해서 수행하는 것이지만, 메서드를 호출하는 것은 반복문 보다 몇 가지 과정, 예를 들면 매개변수 복사와 종료 후 복귀할 주소저장 등, 이 추가로 필요하기 때문에 반복문보다 재귀호출의 수행시간이 더 오래 걸린다. 배열배열은 같은 타입의 여러 변수를 하나의 묶음으로 다루는 것이다.배열을 선언하는 것은 단지 생성된 배열을 다루기 위한 참조변수를 위한 공간이 만들어질 뿐이고, 배열을 생성해야만 비로소 값을 저장할 수 있는 공간이 만들어지는 것이다. Java에서는 배열의 길이가 0일 수도 있다. 배열이름.length - 자바에서는 JVM이 모든 배열의 길이를 별도로 관리하며, ‘배열이름.length’를 통해서 배열의 길이에 대한 정보를 얻을 수 있다. ‘배열이름.length’는 상수이다. 자바에서는 다음과 같이 배열을 간단히 초기화 할 수 있는 방법을 제공한다. 12int[] score1 = new int[]{50, 60, 70, 80, 90}; // 배열의 생성과 초기화를 동시에int[] score2 = {50, 60, 70, 80, 90} // new int[]를 생략할 수 있음 그러나 배열의 선언과 생성을 따로 하는 경우에는 생략할 수 없다. 123int [] score;score = new int[]{50, 60, 70, 80, 90}; // OKscore = {50, 60, 70, 80, 90}; // 에러. new int[]를 생략할 수 없음 만약 score의 값을 바로 출력하면 어떻게 될까? 타입@주소의 형식으로 출력된다. ‘[I’는 1차원 int 배열이라는 의미이고, ‘@’뒤에 나오는 16진수는 배열의 주소인데 실제 주소가 아닌 내부 주소이다. 12// 배열을 가리키는 참조변수 score의 값을 출력System.out.println(score); // [I@14318bb와 같은 형식의 문자열이 출력된다. 예외적으로 char배열은 println메서드로 출력하면 각 요소가 구분자없이 그대로 출력되는데, 이것은 println메서드가 char배열일 때만 이렇게 동작하도록 작성되었기 때문이다. for문 대신 System클래스의 arraycopy()를 사용하면 보다 간단하고 빠르게 배열을 복사할 수 있다. 자바에서 char배열이 아닌 String클래스를 이용해서 문자열을 처리하는 이유는 String클래스가 char배열에 여러 가지 기능을 추가하여 확장한 것이기 때문이다.char배열과 String클래스의 한 가지 중요한 차이는, String객체(문자열)는 읽을 수만 있을 뿐 내용을 변경할 수 없다. (변경 가능한 문자열을 다루려면, StringBuffer 클래스를 사용하면 된다.) JVM의 메모리구조JVM은 시스템으로부터 프로그램을 수행하는데 필요한 메모리를 할당받고 JVM은 이 메모리를 용도에 따라 여러 영역으로 나누어 관리한다. 메서드 영역 (method area)프로그램 실행 중 어떤 클래스가 사용되면, JVM은 해당 클래스의 클래스파일(*.class)을 읽어서 분석하여 클래스에 대한 정보(클래스 데이터)를 이곳에 저장한다. 그 클래스의 클래스변수도 이 영역에 함께 생성된다. 힙 (heap)인스턴스가 생성되는 공간. 프로그램 실행 중 생성되는 인스턴스는 모두 이곳에 생성된다. 즉, 인스턴스 변수들이 생성되는 곳이다. 호출스택 (call stack or execution stack)호출스택은 메서드의 작업에 필요한 메모리 공간을 제공한다. 메서드가 호출되면, 호출스택에 호출된 메서드를 위한 메모리가 할당되고, 이 메모리는 메서드가 작업을 수행하는 동안 지역변수(매개변수 포함)들과 연산의 중간결과 등을 저장하는데 사용된다. 메서드가 작업을 마치면 할당되었던 메모리공간은 반환되어 비워진다. 클래스인스턴스 메서드는 인스턴스 변수와 관련된 작업을 하는, 즉 메서드의 작업을 수행하는데 인스턴스 변수를 필요로 하는 메서드이다. 반면에 인스턴스와 관계없는(인스턴스 변수나 인스턴스 메서드를 사용하지 않는) 메서드를 클래스 메서드(static 메서드)로 정의한다. 가변인자기존에는 메서드의 매개변수 개수가 고정적이었으나 JDK1.5부터 동적으로 지정해 줄 수 있게 되었으며, 이 기능을 가변인자라고 한다. 가변인자는 ‘타입… 변수명’과 같은 형식으로 선언한다. PrintStream클래스의 printf()가 대표적인 예이다. 1public PrintStream printf(String format, Object... args); { ... } 가변인자 외에도 매개변수가 더 있으면, 가변인자를 매개변수 중에서 제일 마지막에 선언해야 한다. 그렇지 않으면, 컴파일 에러가 발생한다. 가변인자는 내부적으로 배열을 이용한다. 그래서 가변인자가 선언된 메서드를 호출할 때마다 배열이 새로 생성된다. 가변인자가 편리하지만, 이런 비효율이 숨어있기 때문에 꼭 필요한 경우에만 사용해야한다. 가변인자를 사용한 메서드를 호출할 때는 인자가 아예 없어도 되고 배열을 사용할 수도 있다. (C언어와 달리 자바에서는 길이가 0인 배열을 생성하는 것이 허용된다.) 생성자컴파일러가 자동적으로 기본 생성자를 추가해주는 경우는 ‘클래스 내에 생성자가 하나도 없을 때’ 뿐이다. 생성자에서 다른 생성자를 호출할 때에는 생성자의 이름으로 클래스이름 대신 this를 사용한다. ‘this’는 참조변수로 인스턴스 자신을 가리킨다. 또한 한 생성자에서 다른 생성자를 호출할 때는 반드시 첫 줄에서만 호출이 가능하다. this : 인스턴스 자신을 가리키는 참조변수, 인스턴스의 주소가 저장되어 있다. 모든 인스턴스 메서드에 지역변수에 숨겨진 채로 존재한다. this(), this(매개변수) : 생성자 같은 클래스의 다른 생성자를 호출할 때 사용한다. 변수의 초기화멤버변수는 초기화를 하지 않아도 자동적으로 변수의 자료형에 맞는 기본갑으로 초기화가 이루어지므로 초기화하지 않고 사용해도 되지만, 지역변수는 사용하기 전에 반드시 초기화해야 한다. (멤버변수(클래스변수와 인스턴스변수)와 배열의 초기화는 선택적이지만, 지역변수의 초기화는 필수적이다.) 멤버변수의 초기화는 지역변수와 달리 여러 가지 방법이 있다. 명시적 초기화 : 변수를 선언과 동시에 초기화하는 것 생성자 초기화 블럭 인스턴스 초기화 블럭 : 인스턴스변수를 초기화 하는데 사용 클래스 초기화 블럭 : 클래스 변수를 초기화 하는데 사용 1234567class testClass() { static { /* 클래스 초기화 블럭 */ } { /* 인스턴스 초기화 블럭 */ } // ...} 클래스 초기화 블럭은 클래스가 메모리에 처음 로딩될 때 한번만 수행되며, 인스턴스 초기화 블럭은 생성자와 같이 인스턴스를 생성할 때 마다 수행된다. (생성자보다 인스턴스 초기화 블럭이 먼저 수행된다.) 인스턴스 변수의 초기화는 주로 생성자를 사용하고, 인스턴스 초기화 블럭은 모든 생성자에서 공통으로 수행돼야 하는 코드를 넣는데 사용한다. 클래스변수의 초기화 시점 : 클래스가 처음 로딩될 때 단 한번 초기화 된다. 인스턴스변수의 초기화 시점 : 인스턴스가 생성될 때마다 각 인스턴스별로 초기화가 이루어진다. 클래스변수의 초기화 순서 : 기본값 -&gt; 명시적초기화 -&gt; 클래스 초기화 블럭 인스턴스변수의 초기화 순서 : 기본값 -&gt; 명시적초기화 -&gt; 인스턴스 초기화 블럭 -&gt; 생성자 프로그램 실행도중 클래스에 대한 정보가 요구될 때, 클래스에 로딩된다. 하지만, 해당 클래스가 이미 메모리에 로딩되어 있다면, 또 다시 로딩하지 않는다. 클래스의 로딩 시기는 JVM의 종류에 따라 좀 다를 수 있는데, 클래스가 필요할 때 바로 메모리에 로딩하도록 설계가 되어있는 것도 있고, 실행효율을 높이기 위해서 사용될 클래스들을 프로그램이 시작될 때 미리 로딩하도록 되어있는 것도 있다. 상속생성자와 초기화 블럭은 상속되지 않는다. 멤버만 상속된다. 오버라이딩의 조건오버라이딩시 접근 제어자와 예외는 제한된 조건 하에서만 다르게 변경할 수 있다. 접근 제어자는 조상 클래스의 메서드보다 좁은 범위로 변경 할 수 없다.접근범위는 public, protected, (default), private이다. 조상 클래스의 메서드보다 많은 수의 예외를 선언할 수 없다. Object 클래스를 제외한 모든 클래스의 생성자는 첫 줄에 반드시 자신의 다른 생성자 또는 조상의 생성자를 호출해야 한다. 그렇지 않으면 컴파일러는 생성자의 첫 줄에 ‘super();’를 자동적으로 추가한다. 어떤 클래스의 인스턴스를 생성하면, 클래스 상속관계의 최고조상인 Object 클래스까지 거슬러 올라가면서 모든 조상클래스의 생성자가 순서대로 호출된다. package와 import패키지(package)패키지란, 클래스의 묶음이다. 클래스의 실제 이름은 패키지명을 포함한 것이다. 클래스가 물리적으로 하나의 클래스파일(.class)인 것과 같이 패키지는 물리적으로 하나의 디렉토리이다. 디렉토리가 하위 디렉토리를 가질 수 있는 것처럼, 패키지도 다른 패키지를 포함할 수 있으며 점’.’으로 구분한다. 패키지 선언문은 반드시 소스파일에서 주석과 공백을 제외한 첫 번째 문장이어야 하며, 하나의 소스파일에 단 한번만 선언될 수 있다. 소스파일에 자신이 속할 패키지를 지정하지 않은 클래스는 자동적으로 ‘이름 없는 패키지’에 속하게 된다. 결국 패키지를 지정하지 않는 모든 클래스들은 같은 패키지에 속한다. 클래스패스(classpath)는 컴파일러(javac.exe)나 JVM 등이 클래스의 위치를 찾는데 사용되는 경로이다. import문클래스의 코드를 작성하기 전에 import문으로 사용하고자 하는 클래스의 패키지를 미리 명시해주면 소스코드에 사용되는 클래스이름에서 패키지명은 생략할 수 있다. import문의 역할은 컴파일러에게 소스파일에 사용된 클래스의 패키지에 대한 정보를 제공하는 것이다. import문에서 클래스의 이름 대신 ‘*’을 사용하는 것이 하위 패키지의 클래스까지 포함하는 것은 아니라는 것이다. import문으로 패키지를 지정하지 않으면 위와 같이 모든 클래스이름 앞에 패키지명을 반드시 붙여야 한다. 단, 같은 패키지 내의 클래스들은 import문을 지정하지 않고도 패키지명을 생략할 수 있다. 제어자생성자가 private인 클래스는 다른 클래스의 조상이 될 수 없다. 그래서 클래스 앞에 final을 더 추가하여 상속할 수 없는 클래스라는 것을 알려야 한다. 제어자를 조합해서 사용할 때 주의해야 할 사항 메서드에 static과 abstract를 함께 사용할 수 없다. (static 메서드는 몸통이 있는 메서드에만 사용할 수 있기 때문이다.) 클래스에 abstract와 final을 동시에 사용할 수 없다. 참조변수형변환컴파일 시에는 참조변수간의 타입만 체크하기 때문에 실행 시 생성될 인스턴스의 타입에 대해서는 전혀 알지 못한다. 그래서 컴파일 시에는 문제가 없었지만, 실행 시에는 에러가 발생하여 실행이 비정상적으로 종료될 수 있다. 참조변수가 참좋고 있는 인스턴스의 실제 타입을 알아보기 위해 instance 연산자를 사용한다. 실제 인스턴스와 같은 타입의 instanceof 연산 이외에 조상타입의 instance 연산에도 true를 결과로 얻으며, instanceof의 연산의 결과가 true라는 것은 검사한 타입으로의 형변환을 해도 아무런 문제가 없다는 뜻이다. 참조변수와 인스턴스의 연결멤버변수가 조상 클래스와 자손 클래스에 중복으로 정의된 경우, 조상 타입의 참조변수를 사용했을 때는 조상 클래스에 선언된 멤버변수가 사용되고, 자손타입의 참조변수를 사용했을 때는 자손 클래스에 선언된 멤버변수가 사용된다. 하지만 중복 정의되지 않은 경우, 조상타입의 참조변수를 사용했을 때와 자손타입의 참조변수를 사용했을 때의 차이는 없다. 인터페이스인터페이스는 일종의 추상클래스이다. 인터페이스는 추상클래스처럼 추상메서드를 갖지만 추상클래스보다 추상화 정도가 높아서 추상클래스와 달리 몸통을 갖춘 일반 메서드 또는 멤버변수를 구성원으로 가질 수 없다. 오직 추상메서드와 상수만을 멤버로 가질 수 있다. 모든 멤버변수는 public static final 이어야 하며, 이를 생략할 수 있다. 모든 메서드는 public abstract 이어야 하며, 이를 생략할 수 있다.단, static 메서드와 디폴트 메서드는 예외 원래는 인터페이스의 모든 메서드는 추상메서드이어야 하는데, JDK1.8부터 인터페이스에 static 메서드와 디폴트 메서드의 추가를 허용하는 방향으로 변경되었다. 디폴트 메서드조상 클래스에 새로운 메서드를 추가하는 것은 별 일이 아니지만, 인터페이스의 경우에는 보통 큰 일이 아니다. 인터페이스에 메서드를 추가한다는 것은, 추상 메서드를 추가한다는 것이고, 이 인터페이스를 구현한 기존의 모든 클래스들이 새로 추가된 메서드를 구현해야 하기 때문이다. 디폴트 메서드는 추상 메서드의 기본적인 구현을 제공하는 메서드로, 추상 메서드가 아니기 때문에 디폴트 메서드가 새로 추가되어도 해당 인터페이스를 구현한 클래스를 변경하지 않아도 된다. 디폴트 메서드는 메서드 앞에 키워드 default를 붙이며, 추상 메서드와 달리 일반 메서드처럼 몸통{}이 있어야 한다. 디폴트 메서드 역시 접근 제어자가 public 이며, 생략가능하다. 내부 클래스내부 클래스는 클래스 내에 선언된 클래스이다. 클래스에 다른 클래스를 선언하는 이유는 간단하다. 두 클래스가 서로 긴밀한 관계에 있기 때문이다. 내부 클래스의 장점 내부 클래스에서 외부 클래스의 멤버들을 쉽게 접근할 수 있다. 코드의 복잡성을 줄일 수 있다(캡슐화). 내부 클래스의 종류와 특징내부 클래스의 종류는 변수의 선언위치에 따른 종류와 같다. 내부 클래스는 마치 변수를 선언하는 것과 같은 위치에 선언할 수 있으며, 변수의 선언위치에 따라 인스턴스변수, 클래스변수(static 변수), 지역변수로 구분되는 것과 같이 내부 클래스도 선언위치에 따라 다음과 같이 구분된다. 인스턴스 클래스 (instance class)외부 클래스의 멤버변수 선언위치에 선언하며, 외부 클래스의 인스턴스 멤버처럼 다루어 진다. 주로 외부 클래스의 인스턴스멤버들과 관련된 작업에 사용될 목적으로 선언된다. 스태틱 클래스 (static class)외부 클래스의 멤버변수 선언위치에 선언하며, 외부 클래스의 static 멤버처럼 다루어진다. 주로 외부 클래스의 static 멤버, 특히 static 메서드에서 사용될 목적으로 선언된다. 지역 클래스 (local class)외부 클래스의 메서드나 초기화블럭 안에 선언하며, 선언된 영역 내부에서만 사용될 수 있다. 익명 클래스 (anonymous class)클래스의 선언과 객체의 생성을 동시에 하는 이름없는 클래스(일회용) 지역 클래스(LocalInner)는 외부 클래스의 인스턴스멤버와 static 멤버를 모두 사용할 수 있으며, 지역 클래스가 포함된 메서드에 정의된 지역변수도 사용할 수 있다. 단, final이 붙은 지역변수만 접근가능한데 그 이유는 메서드가 수행을 마쳐서 지역변수가 소멸된 시점에도, 지역 클래스의 인스턴스가 소멸된 지역변수를 참조하려는 경우가 발생할 수 있기 때문이다. JDK 1.8부터 지역 클래스에서 접근하는 지역 변수 앞에 final을 생략할 수 있게 바뀌었다. 대신 컴파일러가 자동으로 붙여준다. 즉, 편의상 final을 생략할 수 있게 한 것일 뿐 해당 변수의 값이 바뀌는 문장이 있으면 컴파일 에러가 발생한다. 내부 클래스는 컴파일 했을 때 생성되는 파일명은 외부 클래스명$내부 클래스명.class 형식으로 되어 있다. 익명 클래스 (anonymous class)익명클래스는 특이하게도 다른 내부 클래스들과는 달리 이름이 없다. 클래스의 선언과 객체의 생성을 동시에 하기 때문에 단 한번만 사용될 수 있고 오직 하나의 객체만을 생성할 수 있는 일회용 클래스이다. 1234567new 조상클래스이름() { // 멤버 선언} 또는new 구현인터페이스이름() { // 멤버 선언} 이름이 없기 때문에 생성자도 가질 수 없으며, 조상클래스의 이름이나 구현하고자 하는 인터페이스의 이름을 사용해서 정의하기 때문에 하나의 클래스로 상속받는 동시에 인터페이스를 구현하거나 둘 이상의 인터페이스를 구현할 수 있다. 오로지 단 하나의 클래스를 상속받거나 단 하나의 인터페이스만을 구현할 수 있다. 익명 클래스는 이름이 없기 때문에 외부 클래스명$숫자.class의 형식으로 클래스파일명이 결정된다. 예외처리프로그램이 실행 중 어떤 원인에 의해서 오작동을 하거나 비정상적으로 종료되는 경우가 있다. 이러한 결과를 초래하는 원인을 프로그램 에러 또는 오류라고 한다. 이를 발생시점에 따라 컴파일 에러와 런타임 에러로 나눌 수 있다. 컴파일 에러 - 컴파일 시에 발생하는 에러 런타임 에러 - 실행 시에 발생하는 에러 논리적 에러 - 실행은 되지만, 의도와 다르게 동작하는 것 컴파일은 잘되었어도 실행 중에 에러에 의해서 잘못된 결과를 얻거나 프로그램이 비정상적으로 종료될 수 있다. 자바에서는 실행 시(runtime) 발생할 수 있는 프로그램 오류를 에러(error)와 예외(exception) 두 가지로 구분하였다. 에러는 메모리 부족(OutOfMemoryError)이나 스택오버플로우(StackOverflowError)와 같이 일단 발생하면 복구할 수 없는 심각한 오류이고, 예외는 발생하더라도 수습될 수 있는 비교적 덜 심각한 것이다. 모든 예외의 최고 조상은 Exception 클래스이다. 예외 처리하기 - try-catch 문 예외처리의 정의 - 프로그램 실행 시 발생할 수 있는 예외의 발생에 대비한 코드를 작성하는 것 목적 - 프로그램의 비정상 종료를 막고, 정상적인 실행상태를 유지하는 것 에러와 예외는 모두 실행 시(runtime) 발생하는 오류이다. 발생한 예외를 처리하지 못하면, 프로그램은 비정상적으로 종료되며, 처리되지 못한 예외(uncaught exception)는 JVM의 ‘예외처리기(UncaughtExceptionHandler)’가 받아서 예외의 원인을 화면에 출력한다. 예외를 처리하기 위해서는 try-catch문을 사용한다. 하나의 try 블럭 다음에는 여러 종류의 예외를 처리할 수 있도록 하나 이상의 catch 블럭이 올 수 있으며, 이 중 발생한 예외의 종류와 일치하는 단 한 개의 catch 블럭만 수행된다. try 블럭 또는 catch 블럭에 또 다른 try-catch 문이 포함될 수 있다. catch 블럭 내의 코드에서도 예외가 발생할 수 있기 때문이다. catch 블럭 내에 또 하나의 try-catch 문이 포함된 경우, 같은 이름의 참조변수를 사용해서는 안 된다. 정수는 0으로 나누는 것이 금지되어 있지만, 실수를 0으로 나누는 것은 금지되어있지 않으며 예외가 발생하지 않는다. try 블럭에서 예외가 발생하면, 예외가 발생한 위치 이후에 있는 try 블럭의 문장들은 수행되지 않으므로, try 블럭에 포함시킬 코드의 범위를 잘 선택해야 한다. 예외가 발생한 문장이 try-catch 블럭부터 차례로 내려가면서 catch 블럭의 괄호()내에 선언된 참조변수의 종류와 생성된 예외클래스의 인스턴스에 instanceof 연산자를 이용해서 검사하게 되는데, 검사 결과가 true인 catch 블럭을 만날 때까지 검사는 계속된다. printStackTrace()와 getMessage()예외가 발생했을 때 생성되는 예외 클래스의 인스턴스에는 발생한 예외에 대한 정보가 담겨져 있으며, getMessage()와 printStackTrace()를 통해서 이 정보들을 얻을 수 있다. printStackTrace() - 예외발생 당시의 호출스택(Call Stack)에 있었던 메서드의 정보와 예외 메시지를 화면에 출력한다. getMessage() - 발생한 예외클래스의 인스턴스에 저장된 메시지를 얻을 수 있다. printStackTrace(PrintStream s) 또는 printStackTrace(PrintWriter s)를 사용하면 발생한 예외에 대한 정보를 파일에 저장할 수도 있다. 멀티 catch 블럭JDK 1.7부터 여러 catch 블럭을 ‘|’ 기호를 이용해서, 하나의 catch 블럭으로 합칠 수 있게되었으며, 이를 ‘멀티 catch 블럭’이라 한다. (멀티 catch 블럭에 사용되는 ‘|’는 논리 연산자가 아니라 기호이다.) 만일 멀티 catch 블럭의 ‘|’ 기호로 연결된 예외 클래스가 조상과 자손의 관계에 있다면 컴파일 에러가 발생한다. (그냥 조상 클래스만 써주는 것과 똑같기 때문이다.) 예외 발생시키기키워드 throw를 사용해서 프로그래머가 고의로 예외를 발생시킬 수 있다. 먼저, 연산자 new를 이용해서 발생시키려는 예외 클래스의 객체를 만든 다음 키워드 throw를 이용해서 예외를 발생시킨다. Exception 인스턴스를 생성할 때, 생성자에 String을 넣어 주면, 이 String이 Exception 인스턴스에 메시지로 저장된다. 이 메시지는 getMessage()를 이용해서 얻을 수 있다. RuntimeException을 발생시키는 코드는 이에 대한 예외 처리를 하지 않았음에도 불구하고 성공적으로 컴파일 된다. RuntimeException 클래스들과 그 자손 클래스에 해당하는 예외는 프로그래머가 실수로 발생하는 것들이기 때문에 예외처리를 강제하지 않는 것이다. 컴파일러가 예외처리를 확인하지 않는 RuntimeException 클래스들은 unchecked 예외라고 부르고, 예외처리를 확인하는 Exception 클래스들은 checked 예외라고 부른다. Error와 그 자손도 unchecked 예외이다. try-catch 블럭으로 처리할 수 없기 때문이다. 메서드에 예외 선언하기예외를 처리하는 방법에는 try-catch 문을 사용하는 것 외에, 예외를 메서드에 선언하는 방법이 있다. 메서드에 예외를 선언하려면, 메서드의 선언부에 키워드 throws를 사용해서 메서드 내에서 발생할 수 있는 예외를 적어주기만 하면 된다. (예외를 발생시키는 키워드 throw와 예외를 메서드에 선언할 때 쓰이는 throws를 구별해야 한다.) 메서드에 예외를 선언할 때 일반적으로 RuntimeException 클래스들은 적지 않는다. 예외를 메서드의 throws에 명시하는 것은 예외를 처리하는 것이 아니라, 자신(예외가 발생할 가능성이 있는 메서드)을 호출한 메서드에게 예외를 전달하여 예외처리를 떠맡기는 것이다. 예외를 전달받은 메서드가 또다시 자신을 호출한 메서드에게 전달할 수 있으며, 이런 식으로 계속 호출스택에 있는 메서드들을 따라 전달되다가 제일 마지막에 있는 main 메서드에서도 예외가 처리되지 않으면, main 메서드 마저 종료되어 프로그램이 전체가 종료된다. finally 블럭finally 블럭은 try-catch 문과 함께 예외의 발생여부에 상관없이 실행되어야할 코드를 포함시킬 목적으로 사용된다. try 블럭에서 return문이 실행되는 경우에도 finally 블럭의 문장들이 먼저 실행된 후에, 현재 실행 중인 메서드를 종료한다. 마찬가지로 catch 블럭의 문장 수행 중에 return 문을 만나도 finally 블럭의 문장들은 수행된다. 자원 자동 반환 - try-with-resources문JDK 1.7부터 try-with-resources문이라는 try-catch문의 변형이 새로 추가되었다. try-with-resources문의 괄호()안에 객체를 생성하는 문장을 넣으면, 이 객체는 따로 close()를 호출하지 않아도 try 블럭을 벗어나는 순간 자동적으로 close()가 호출된다. 그 다음에 catch 블럭 또는 finally 블럭이 수행된다. try-with-resources문에 의해 자동으로 객체의 close()가 호출될 수 있으려면, 클래스가 AuthCloseable이라는 인터페이스를 구현한 것이어야만 한다. 참고 Java의 정석 - 1","link":"/2018/04/07/Java/java-basic/"},{"title":"Java NIO와 멀티플렉싱 기반의 다중 접속 서버","text":"자바 NIO에 대한 소개와 NIO와 함께 도입된 자바에서 I/O 멀티플렉싱(multiplexing)을 구현한 selector에 대해 알아봅니다. I/O 멀티플렉싱(multiplexing)에 대한 개념에 대해 아직 잘 이해하지 못하고 있다면 먼저 &lt;멀티플렉싱 기반의 다중 접속 서버로 가기까지&gt; 포스팅을 읽어주세요. Overview자바 NIO (New IO)는 기존의 자바 IO API를 대체하기 위해 자바 1.4부터 도입이 되었습니다. 새롭게 변화된 부분에 대해서 간략히 요약해보면 다음과 같습니다. Channels and Buffers기존 IO API에서는 byte streams character streams 사용했지만, NIO에서는 channels(채널)과 buffers(버퍼)를 사용합니다. 데이터는 항상 채널에서 버퍼로 읽히거나 버퍼에서 채널로 쓰여집니다. Non-blocking IO자바 NIO에서는 non-blocking IO를 사용할 수 있습니다. 예를 들면, 하나의 스레드는 버퍼에 데이터를 읽도록 채널에 요청할 수 있습니다. 채널이 버퍼로 데이터를 읽는 동안 스레드는 다른 작업을 수행할 수 있습니다. 데이터가 채널에서 버퍼로 읽어지면, 스레드는 해당 버퍼를 이용한 processing(처리)를 계속 할 수 있습니다. 데이터를 채널에 쓰는 경우도 non-blocking이 가능합니다. Selectors자바 NIO에는 “selectors” 개념을 포함하고 있습니다. selector는 여러개의 채널에서 이벤트(연결이 생성됨, 데이터가 도착함)를 모니터링할 수 있는 객체입니다. 그래서 하나의 스레드에서 여러 채널에 대해 모니터링이 가능합니다. 자바 NIO는 다음과 같은 핵심 컴포넌트로 구성되어있습니다. Channels Buffers Selectors 실제로는 더 많은 클래스와 컴포넌트가 있지만 채널, 버퍼, 셀렉터가 API의 핵심을 구성합니다. Channels일반적으로 NIO의 모든 IO는 채널로 시작합니다. 채널 데이터를 버퍼로 읽을 수 있고, 버퍼에서 채널로 데이터를 쓸 수 있습니다. 채널은 스트림(stream)과 유사하지만 몇가지 차이점이 있습니다. 채널을 통해서는 읽고 쓸 수 있지만, 스트림은 일반적으로 단방향(읽기 혹은 쓰기)으로만 가능합니다. 채널은 비동기적(asynchronously)으로 읽고 쓸 수 있습니다. 채널은 항상 버퍼에서 부터 읽거나 버퍼로 씁니다. 채널에는 여러가지 타입이 있습니다. 다음은 자바 NIO에 기본적으로 구현되어 있는 목록입니다. Channels FileChannel: 파일에 데이터를 읽고 쓴다. DatagramChannel: UDP를 이용해 네트워크를 통해 데이터를 읽고 쓴다. SocketChannel: TCP를 이용해 네트워크를 통해 데이터를 읽고 쓴다. ServerSocketChannel: 들어오는 TCP 연결을 수신(listening)할 수 있다. 들어오는 연결마다 SocketChannel이 만들어진다. BuffersNIO의 버퍼는 채널과 상호작용할 때 사용됩니다. 데이터는 채널에서 버퍼로 읽혀지거나, 버퍼에서 읽혀 채널로 쓰여집니다. 버퍼에는 여러가지 타입이 있습니다. 다음은 자바 NIO에 기본적으로 구현되어 있는 목록입니다. Buffers ByteBuffer MappedByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 일반적으로 버퍼를 사용하여 데이터를 읽고 쓰는 것은 4단계 프로세스를 가집니다. 버퍼에 데이터 쓰기 buffer.flip() 호출 버퍼에서 데이터 읽기 buffer.clear() 혹은 buffer.compact() 호출 버퍼에 데이터를 쓸 때 버퍼는 쓰여진 데이터의 양을 기록합니다. 만약 데이터를 읽어야한다면 flip() 메서드를 호출해서 버퍼를 쓰기 모드에서 읽기 모드로 전환해야 합니다. 읽기 모드에서 버퍼를 사용하면 버퍼에 쓰여진 모든 데이터를 읽을 수 있습니다.모든 데이터를 읽은 후에는 버퍼를 지우고 다시 쓸 준비를 해야합니다. clear() 혹은 compact()를 호출함으로써 전체 버퍼를 지울 수 있습니다. (clear() 메서드는 버퍼 전체를 지우고, compact() 메서드는 이미 읽은 데이터만 지웁니다.) Selectors셀렉터를 사용하면 하나의 스레드가 여러 채널을 처리(handle)할 수 있습니다.셀렉터는 사용을 위해 하나 이상의 채널을 셀렉터에 등록하고 select() 메서드를 호출해 등록 된 채널 중 이벤트 준비가 완료된 하나 이상의 채널이 생길 때까지 봉쇄(block)됩니다. 메서드가 반환(return)되면 스레드는 채널에 준비 완료된 이벤트를 처리할 수 있습니다. 즉, 하나의 스레드에서 여러 채널을 관리할 수 있으므로 여러 네트워크 연결을 관리할 수 있습니다. (SocketChannel, ServerSocketChannel) Selector 생성Selector.open() 메서드를 통해 셀렉터를 생성할 수 있습니다.1Selector selector = Selector.open(); Channels 등록생성한 셀렉터에 채널을 등록하기 위해서는 다음과 같이 채널의 register() 메서드를 호출합니다.123channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 셀렉터에 채널을 등록하기 위해서는 반드시 해당 채널이 non-blocking 모드로 변환되어야 합니다. (FileChannel은 non-blocking 모드로 변경이 불가능하기 때문에 셀렉터에 등록이 불가능합니다.) register() 메서드의 두 번째 매개 변수는 셀렉터를 통해 채널에서 발생하는 이벤트 중 확인(알림)하고자 하는 이벤트의 집합을 의미합니다.이벤트에는 4가지 종류가 있으며, 이 4가지 이벤트는 SelectionKey 상수로 표시됩니다. SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 둘 이상의 이벤트 상수는 다음과 같이 사용 가능합니다.1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE SelectionKeyregister() 메서드를 이용해 채널을 셀렉터에 등록하면 SelectionKey 객체가 반환됩니다. 이 SelectionKey 객체에는 몇 가지 속성들이 있습니다. The interest set The ready set The Channel The Selector An attached object (optional) interest Setinterest set은 셀렉터에 등록된 채널이 확인하고자 하는 이벤트 집합(세트)입니다. 다음과 같이 SelectionKey를 이용해 해당 interest set을 확인할 수 있습니다.123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = interestSet &amp; SelectionKey.OP_ACCEPT;boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; Ready Setready set은 셀렉터에 등록된 채널에서 준비되어 처리(handle) 가능한 이벤트의 집합입니다.1int readySet = SelectionKey.readyOps(); 위와 같이 interest Set과 동일한 방식으로 확인할 수도 있지만 아래와 같이 4가지 메소드를 이용해서 확인할 수도 있습니다.1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel + SelectorSelectionKey를 이용해 채널과 셀렉터에 쉽게 접근할 수 있습니다.123Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); Attaching ObjectsSelectionKey에 객체를 첨부(attach)할 수 있습니다. 이 방법을 이용하면 채널에 추가 정보나 채널에서 사용하는 버퍼와 같은 객체들을 쉽게 첨부할 수 있습니다.123selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); selectionKey를 통해 직접 attach 하는 것 뿐만 아니라 셀렉터에 채널을 등록하면서 객체를 첨부할 수도 있습니다.1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 셀렉터를 이용해 채널 선택셀렉터에 하나 이상의 채널을 등록한 후에는 select() 메소드를 호출할 수 있습니다. select() 메소드는 accept, connect, read, write 이벤트에 대해 준비(ready) 되어 있는 채널을 반환합니다. select() 메소드는 다음과 같이 3가지 방식으로 사용 가능합니다. select(): 등록한 이벤트에 대해 하나 이상의 채널이 준비 될 때까지 봉쇄(block)됩니다. 몇개의 채널이 준비되었는지 준비된 채널의 수를 반환합니다. (마지막으로 select()를 호출한 이후 준비된 채널 수 입니다.) select(long timeout): 최대 timeout(ms) 동안만 봉쇄한다는 점을 제외하면 select()와 동일합니다. selectNow(): select와 달리 봉쇄하지 않습니다. 준비된 채널이 있으면 즉시 반환됩니다. selectedKeys()select() 메서드를 통해 하나 이상의 준비된 채널이 발생하면, selectedKeys() 메서드를 사용해 준비된 채널의 집합을 반환 받습니다.1Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); 반환된 SelectionKey set을 반복해 준비된 채널에 접근할 수 있습니다. 채널의 이벤트 처리가 끝나면 keyIterator.remove()를 통해 키 세트에서 제거해야 합니다.1234567891011121314151617181920212223Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if(key.isAcceptable()) { // a connection was accepted by a ServerSocketChannel. } else if (key.isConnectable()) { // a connection was established with a remote server. } else if (key.isReadable()) { // a channel is ready for reading } else if (key.isWritable()) { // a channel is ready for writing } keyIterator.remove();} ServerSocketChannelNIO ServerSocketChannel은 표준 자바 네트워킹의 ServerSocket과 마찬가지로 들어오는 TCP 연결을 수신 대기 할 수 있는 채널입니다.123456789ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true) { SocketChannel socketChannel = serverSocketChannel.accept(); // do something with socketChannel...} Non-blocking ModeServerSocketChannel은 non-blocking 모드로 설정이 가능합니다. non-blocking 모드에서는 accept() 메서드가 즉시 반환되므로 들어오는 연결이 없으면 null을 반환할 수 있습니다. 이에 따라 반환 된 ServerSocketChannel이 null인지 확인해야합니다.123456789101112ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));serverSocketChannel.configureBlocking(false);while(true){ SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel != null) { // do something with socketChannel... }} SocketChannelNIO SocketChannel은 TCP 네트워크 소켓에 연결된 채널입니다. 표준 자바 네트워킹의 Socket과 역할이 같습니다. Non-blocking ModeServerSocketChannel과 마찬가지로 SocketChannel을 non-blocking 모드로 설정할 수 있습니다. non-blocking 모드에서는 connect(), read(), write()를 호출할 수 있습니다. connect()SocketChannel이 non-blocking 모드일 때, connect()를 호출하면 메서드가 연결이 설정되기 전에 반환될 수 있습니다. 연결이 설정되었는지 확인하기 위해서 finishConnect() 메서드를 이용할 수 있습니다.123456socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress(\"http://naver.com\", 80));while(!socketChannel.finishConnect()) { // wait, or do something else... } read()non-blocking 모드일 때, read() 메서드는 데이터를 전혀 읽지 않고 반환 될 수 있습니다. 따라서 반환 된 결과(int)를 갖고 판단해야 합니다. 반환 된 결과(int)는 읽은 바이트 수를 나타냅니다. 멀티플렉싱 기반의 다중 접속 서버지금까지 살펴본 Channel, Buffer, Selector를 이용해 간단한 echo 서버를 만들어 보았습니다. EchoServer.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;import java.util.Set;public class EchoServer { private static final String EXIT = \"EXIT\"; public static void main(String[] args) throws IOException { Selector selector = Selector.open(); ServerSocketChannel serverSocket = ServerSocketChannel.open(); serverSocket.bind(new InetSocketAddress(\"localhost\", 3000)); serverSocket.configureBlocking(false); serverSocket.register(selector, SelectionKey.OP_ACCEPT); ByteBuffer buffer = ByteBuffer.allocate(256); while (true) { selector.select(); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iter = selectedKeys.iterator(); while (iter.hasNext()) { SelectionKey key = iter.next(); if (key.isAcceptable()) { register(selector, serverSocket); } if (key.isReadable()) { answerWithEcho(buffer, key); } iter.remove(); } } } private static void answerWithEcho(ByteBuffer buffer, SelectionKey key) throws IOException { SocketChannel client = (SocketChannel) key.channel(); client.read(buffer); if (new String(buffer.array()).trim().equals(EXIT)) { client.close(); System.out.println(\"Not accepting client messages anymore\"); } buffer.flip(); client.write(buffer); buffer.clear(); } private static void register(Selector selector, ServerSocketChannel serverSocket) throws IOException { SocketChannel client = serverSocket.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); System.out.println(\"new client connected...\"); }} 실행 결과 Java NIO vs IOStream Oriented vs Buffer Oriented스트림 지향의 IO는 스트림에서 한 번에 하나 이상의 바이트를 읽는 것을 의미합니다. 읽은 바이트를 이용해 유저가 데이터를 처리해야 하며 읽힌 바이트는 따로 캐시되지 않습니다. 또한 스트림의 데이터는 임의로 유저가 앞뒤로 이동할 수 없습니다. 스트림에서 읽은 데이터를 앞뒤로 이동해야 하는 경우는 먼저 스트림의 데이터를 읽어 버퍼에 캐시해야합니다. 버퍼 지향의 NIO 방식은 조금 다릅니다. 데이터는 나중에 처리되는 임의의 버퍼로 읽어집니다. 필요에 따라 버퍼에서 앞뒤로 이동할 수 있습니다. 이로 인해 버퍼를 이용한 처리 과정에서 좀 더 유연한 사용이 가능합니다. 그러나 버퍼를 이용해 완전히 처리하려면 필요한 모든 데이터가 버퍼에 들어있는지 확인해야합니다. 또한 버퍼에 더 많은 데이터를 읽을 때, 아직 처리하지 않은 버퍼의 데이터를 덮어 쓰지 않도록 주의해야합니다. Blocking vs Non-blocking IO자바 IO의 스트림을 이용하면 봉쇄(block)됩니다. 즉, 스레드가 read() 혹은 write()를 호출하면 읽은 데이터가 있거나 데이터가 완전히 쓰여질 때까지 해당 스레드가 차단되어 그 동안 스레드는 아무 것도 할 수 없습니다. 자바 NIO의 Non-blocking 모드는 스레드가 채널에서 데이터 읽기를 요청할 때, 현재 사용할 수 있는 데이터가 없는 경우 사용 가능한 데이터가 준비될 때까지 기다리지 않습니다. 때문에 해당 스레드는 봉쇄되지 않고 계속 진행될 수 있습니다. 쓰기 작업 또한 마찬가지 입니다. 스레드는 일부 데이터를 채널에 쓰도록 요청할 수 있지만 완전히 쓰여지기를 기다리지는 않습니다. Selectos자바 NIO의 셀렉터는 하나의 스레드에서 다중 입력 채널을 관리할 수 있습니다. 이 멀티플렉싱 메커니즘을 사용하면 단일 스레드에서 여러 채널의 입출력을 쉽게 관리할 수 있습니다. 참고 Java NIO Tutorial Introduction to the Java NIO Selector","link":"/2019/03/03/Java/java-nio/"},{"title":"날짜와 시간 & 형식화","text":"해당 포스팅의 내용은 Java의 정석 2권 - Chapter 10 날짜와 시간 &amp; 형식화에 있는 내용을 요약한 것입니다. 해당 책으로 복습하며 정리한 내용이고 문제가 된다면 바로 해당 포스팅을 삭제하도록 하겠습니다. 날짜와 시간 &amp; 형식화타임존 포함 ISO 8601 문자열의 표현날짜/시간 및 타임존을 다루는 국제적인 규약은 다양하다. RFC 822, 1036, 1123, 2822, 3339, ISO 8601 등이 있다. 여기서는 ISO 8601과 RFC 3339와 관련된 표기법을 알아본다. 12345678// 로컬 시간을 의미하는 ISO 8601 문자열2017-11-06T15:00:00.000// UTC(GMT) 시간을 의미하는 ISO 8601 문자열2017-11-06T06:00:00.000Z// 로컬 시간을 의미하면서 UTC(GMT) 대비 +09:00 임을 의미하는 ISO 8601 문자열2017-11-06T15:00:00.000+09:00 2017-11-06T15:00:00.000은 ISO 8601의 기본 형식이다. 해당 시간이 로컬 시간 임을 의미한다. 2017-11-06T06:00:00.000Z와 같이 뒤에 Z 식별자를 추가하면 해당 시간이 UTC(GMT) 시간 임을 의미한다. 2017-11-06T15:00:00.000+09:00와 같이 뒤에 Z 대신 +HH:mm 식별자를 추가하면 해당 시간이 로컬 시간이면서 UTC(GMT)와 09:00 만큼 차이가 남을 의미한다. 이 형식의 장점은 인간이 손쉽게 추가적인 계산 없이 로컬 시간을 인지하면서 추가적으로 타임존 정보까지 제공하기 때문에 가장 인간친화적이라고 할 수 있다. 날짜와 시간Date는 날짜와 시간을 다룰 목적으로 JDK 1.0부터 제공되어온 클래스이다. Date 클래스는 기능이 부족했기 때문에, Calendar라는 새로운 클래스를 그 다음 버젼인 JDK 1.1부터 제공하기 시작했다. Calendar는 Date보다는 훨씬 나았지만 몇 가지 단점들이 있었고, JDK 1.8부터 java.time 패키지로 기존의 단점들을 개선한 새로운 클래스들이 추가되었다. Date 클래스는 java.util 패키지에 속해있다. Date와 Calendar간의 변환 Calendar가 새로 추가되면서 Date는 대부분의 메서드가 ‘deprecated’되었으므로 잘 사용되지 않는다. 그럼에도 불구하고 여전히 Date를 필요로 하는 메서드들이 존재하기 때문에 Calendar를 Date로 또는 그 반대로 변환할 일이 생긴다. 1234567891. Calendar를 Date로 변환Calendar cal = Calendar.getInstance();Date d1 = new Date(cal.getTimeInMillis()); // Date(long date)Date d2 = cal.getTime();2. Date를 Calendar로 변환Date d = new Date();Calendar cal = Calendar.getInstance();cal.setTime(d); Calendar.getInstance()를 통해서 얻은 인스턴스는 기본적으로 현재 시스템의 날짜와 시간에 대한 정보를 담고 있다. (GregorianCalendar, BuddhistCalendar) 형식화 클래스자바의 형식화 클래스는 java.text 패키지에 포함되어 있으며 숫자, 날짜, 텍스트 데이터를 일정한 형식에 맞게 표현할 수 있는 방법을 객체지향적으로 설계하여 표준화하였다. 형식화 클래스는 형식화에 사용될 패턴을 정의하는데, 데이터를 정의된 패턴에 맞춰 형식화할 수 있을 뿐만 아니라 역으로 형식화된 데이터에서 원래의 데이터를 얻어낼 수도 있다. 즉, 형식화된 데이터의 패턴만 정의해주면 복잡한 문자열에서도 substring()을 사용하지 않고도 쉽게 원하는 값을 얻어낼 수 있다는 것이다. DecimalFormat형식화 클래스 중에서 숫자를 형식화 하는데 사용되는 것이 DecimalFormat이다. DecimalFormat을 이용하면 숫자 데이터를 정수, 부동소수점, 금액 등의 다양한 형식으로 표현할 수 있으며, 반대로 일정한 형식의 테스트 데이터를 숫자로 쉽게 변환하는 것도 가능하다. 123double number = 1234567.89;DecimalFormat df = new DecimalFormat(\"#.#E0\");String result = df.format(number); Number 클래스는 Integer, Double과 같은 숫자를 저장하는 래퍼 클래스의 조상이며, doubleValue()는 Number에 저장된 값을 double형의 값으로 변환하여 반환한다. 이 외에도 intValue(), floatValue()등의 메서드가 Number클래스에 정의되어 있다. SimpleDateFormatDate와 Calendar만으로는 날짜 데이터를 원하는 형태로 다양하게 출력하는 것은 불편하고 복잡하다. 그러나 SimpleDateFormat을 사용하면 이러한 문제들이 간단하게 해결된다. DateFormat은 추상클래스로 SimpleDateFormat의 조상이다. DateFormat는 추상클래스이므로 인스턴스를 생성하기 위해서는 getDateInstance()와 같은 static 메서드를 이용해야 한다. getDateInstance()에 의해서 반환되는 것은 DateFormat을 상속받아 완전하게 구현한 SimpleDateFormat 인스턴스이다. 12345Date today = new Date();SimpleDateFormat dt = new SimpleDateFormat(\"yyyy-MM-dd\");// 오늘 날짜를 yyyy-MM-dd 형태로 변환하여 반환한다.String result = df.format(today); Date 인스턴스만 format 메서드에 사용될 수 있다. 12DateFormat df = new SimpleDateFormat(\"yyyy년 MM월 dd일\");Date d = df.parse(\"2018년 6월 6일\"); parse(String source)를 사용하여 날짜 데이터의 출력형식을 변환하는 방법을 보여주는 예제이다. Integer의 parseInt()가 문자열을 정수로 변환하는 것처럼 SimpleDateFormat의 parse(String source)는 문자열(source)을 날짜(Date인스턴스)로 변환해주기 때문에 매우 유용하게 쓰일 수 있다. ChoiceFormatChoiceFormat은 특정 범위에 속하는 값을 문자열로 변환해준다. 연속적 또는 불연속적인 범위의 값들을 처리하는 데 있어서 if문이나 switch문은 적절하지 못한 경우가 많다. 이럴때 ChoiceFormat을 잘 사용하면 복잡하게 처리될 수밖에 없었던 코드를 간단하고 직관적으로 만들 수 있다. MessageFormatMessageFormat은 데이터를 정해진 양식에 맞게 출력할 수 있도록 도와준다. 데이터가 들어갈 자리를 마련해 놓은 양식을 미리 작성하고 프로그램을 이용해서 다수의 데이터를 같은 양식으로 출력할 때 사용하면 좋다. 하나의 데이터를 다양한 양식으로 출력할 때 사용한다. 그리고 SimpleDateFormat의 parse처럼 MessageFormat의 parse를 이용하면 지정된 양식에서 필요한 데이터만을 손쉽게 추출해 낼 수도 있다. 1234String msg = \"Name: {0} \\nTel: {1} \\nnAge:{2} \\nBirthday:{3}\";Object[] arguments = {\"이름\", \"01-234-5678\", \"27\", \"04-27\"};String result = MessageFormat.format(msg, arguments); MessageFormat에 사용될 양식인 문자열 msg를 작성할 때 ‘{숫자}’로 표시된 부분이 데이터가 출력될 자리이다. 데이터를 양식에 넣어서 출려하는것 뿐만 아니라, parse(String source)를 이용해서 출력된 데이터로부터 필요한 데이터만을 뽑아낼 수 있다. Java.time 패키지java의 탄생부터 지금까지 날짜와 시간을 다루는데 사용해왔던, Date와 Calendar가 가지고 있던 단점들을 해소하기 위해 JDK1.8부터 ‘java.time 패키지’가 추가되었다. 이 패키지는 다음과 같이 4개의 하위 패키지를 가지고 있다. java.time : 날짜와 시간을 다루는데 필요한 핵심 클래스들을 제공 java.time.chrono : 표준(ISO)이 아닌 달력 시스템을 위한 클래스들을 제공 java.time.format : 날짜와 시간을 파싱하고, 형식화하기 위한 클래스들을 제공 java.time.temporal : 날짜와 시간의 필드(field)와 단위(unit)를 위한 클래스들을 제공 java.time.zone : 시간대(time-zone)와 관련된 클래스들을 제공 위의 패키지들에 속한 클래스들의 가장 큰 특징은 String 클래스처럼 불변(immutable)이라는 것이다. 그래서 날짜나 시간을 변경하는 메서드들은 기존의 객체를 변경하는 대신 항상 변경된 새로운 객체를 반환한다. 기존 Calendar 클래스는 변경 가능하므로, 멀티 쓰레드 환경에서 안전하지 못하다. 멀티 쓰레드 환경에서는 동시에 여러 쓰레드가 같은 개겣에 접근할 수 있기 때문에, 변경 가능한 객체는 데이터가 잘못될 가능성이 있으며, 이를 쓰레드에 안전(thread-safe)하지 않다고 한다. java.time 패키지의 핵심 클래스날짜와 시간을 하나로 표현하는 Calendar 클래스와 달리, java.time 패키지에서는 날짜와 시간을 별도의 클래스로 분리해 놓았다. 시간을 표현할 때는 LocalTime 클래스를 사용하고, 날짜를 표현할 때는 LocalDate 클래스를 사용한다. 그리고 날짜와 시간이 모두 필요할 때는 LocalDateTime 클래스를 사용하면 된다. LocalDate + LocalTime -&gt; LocalDateTime 날짜 시간 날짜 &amp; 시간 여기에 시간대(time-zone)까지 다뤄야 한다면, ZonedDateTime 클래스를 사용한다. LocalDateTime + 시간대 -&gt; ZonedDateTime Calendar는 ZonedDateTime처럼, 날짜와 시간 그리고 시간대까지 모두 가지고 있다. Date와 유사한 클래스로는 Instant가 있는데, 이 클래스는 날짜와 시간을 초 단위(정확히는 나노초)로 표현한다. 날짜와 시간을 초단위로 표현한 값을 타임스탬프(time-stamp) 라고 부르는데, 이 값은 날짜와 시간을 하나의 정수로 표현할 수 있으므로 날짜와 시간의 차이를 계산하거나 순서를 비교하는데 유리해서 데이터베이스에 많이 사용한다. 객체 생성하기 - now(), of() java.time 패키지에 속한 클래스의 객체를 생성하는 가장 기본적인 방법은 now()와 of()를 사용하는 것이다. 1234LocalDate date = LocalDate.now(); // 2018-06-06LocalTime time = LocalTime.now(); // 02:34:50.223LocalDateTime dateTime = LocalDateTime.now(); // 2018-06-06T02:34:50.223ZonedDateTime dateTimeInKr = ZonedDateTime.now(); // 2018-06-06T02:34:50.223+09:00[Asia/Seoul] LocalDate와 LocalTimeLocalDate와 LocalTime은 java.time 패키지의 가장 기본이 되는 클래스이며, 나머지 클래스들은 이들의 확장이므로 이 두 클래스만 잘 이해하고 나면 나머지는 아주 쉬워진다. 객체를 생성하는 방법은 현재의 날짜와 시간을 LocalDate와 LocalTime으로 각각 반환하는 now()와 지정된 날짜와 시간으로 LocalDate와 LocalTime 객체를 생성하는 of()가 있다. 특정 필드의 값 가져오기 - get(), getXXX() 필드의 값 변경하기 - with(), plus(), minus() 날짜와 시간의 비교 - isAfter(), isBefore(), isEqual() InstantInstant는 에포크 타임(EPOCH TIME, 1970-01-01 00:00:00 UTC)부터 경과된 시간을 나노초 단위로 표현한다. 사람이 보기에는 불편하지만, 단일 진법으로 다루기 때문에 계산에는 편리하다. 사람이 사용하는 날짜와 시간에는 여러 진법이 섞여있어서 계산하기 어렵다. 123Instant now = Instant.now();Instant now2 = Instant.ofEpochSecond(now.getEpochSecond());Instant now3 = Instant.ofEpochSecond(now.getEpochSecond(), now.getNano()); Instant를 생성할 때는 위와 같이 now()와 ofEpochSecond()를 사용한다. 그리고 필드에 저장된 값을 가져올 때는 다음과 같이 한다. 12long epochSec = now.getEpochSecond();int nano = now.getNano(); 위의 코드처럼, Instant는 시간을 초 단위와 나노초 단위로 나누어 저장한다. 오라클 데이터베이스의 타임스탬프(timestamp)처럼 밀리초 단위의 EPOCH TIME을 필요로 하는 경우를 위해 toEpochMilli()가 정의되어 있다. 1long toEpochMilli() Instant는 항상 UTC(+00:00)를 기준으로 하기 때문에, LocalTime과 차이가 있을 수 있다. 예를 들어 한국은 시간대가 ‘+09:00’이므로 Instant와 LocalTime간에는 9시간의 차이가 있다. 시간대를 고려해야하는 경우 OffsetDateTime을 사용하는 것이 더 나은 선택일 수 있다. UTC는 ‘Coordinated Universal Time’의 약어로 ‘세계 협정시’이라고 하며, 1972년 1월 1일부터 시행된 국제 표준시이다. 이전에 사용되던 GMT(Greenwich Mean Time)와 UTC는 거의 같지만, UTC가 좀 더 정확하다. LocalDateTime과 ZonedDateTimeLocalDateTime에 시간대(time-zone)를 추가하면, ZonedDateTime이 된다. 기존에는 TimeZone클래스로 시간대를 다뤘지만 새로운 시간 패키지에서는 ZoneId라는 클래스를 사용한다. ZoneId는 일광 절약시간(DST, Daylight Saving Time)을 자동적으로 처리해주므로 더 편리하다. LocalDate에 시간 정보를 추가하는 atTime()을 쓰면 LocalDateTime을 얻을 수 있는 것처럼, LocalDateTime에 atZone()으로 시간대 정보를 추가하면, ZonedDateTime을 얻을 수 있다. 123ZoneId zid = ZoneId.of(\"Asia/Seoul\");zonedDateTime zdt = dateTime.atZone(zid);Syste.out.println(zdt); // 2018-06-06T14:23:50.235+09:00[Asia/Seoul] 만일 현재 특정 시간대의 시간, 예를 들어 뉴욕을 알고 싶다면 다음과 같이 하면 된다. 12ZoneId nyId = ZoneId.of(\"America/New_York\");ZonedDateTime nyTime = ZonedDateTime.now().withZoneSameInstant(nyId); ZoneOffSet UTC로부터 얼마만큼 떨어져 있는지를 ZoneOffSet으로 표현한다. 위의 결과에서 알 수 있듯이 서울은 ‘+9’이다. 즉, UTC보다 9시간(32400초=60*60*9)이 빠르다. 12ZoneOffset krOffset = ZonedDateTime.now().getOffset();int krOffsetInSec = KrOffset.get(ChronoField.OFFSET_SECONDS); // 32400초 OffsetDateTime ZonedDateTime은 ZoneId로 구역을 표현하는데, ZoneId가 아닌 ZoneOffset을 사용하는 것이 OffSetDateTime이다. ZoneId는 일광절약시간처럼 시간대와 관련된 규칙들을 포함하고 있는데, ZoneOffset은 단지 시간대를 시간의 차이로만 구분한다. 컴퓨터에게 일광절약시간처럼 계절별로 시간을 더했다 뺐다 하는 것과 같은 행위는 위험하다. 아무런 변화 없이 일관된 시간체계를 유지하는 것이 더 안전하다. 같은 지역 내의 컴퓨터 간에 데이터를 주고 받을 때, 전송시간을 표현하기에 LocalDateTime이면, 충분하겠지만, 서로 다른 시간대에 존재하는 컴퓨터간의 통신에는 OffsetDateTime이 필요하다. 일광 절약 시간제(Daylight saving time, DST) 또는 서머 타임(summer time)은 하절기에 표준시를 원래 시간보다 한 시간 앞당긴 시간을 쓰는 것을 말한다. 즉, 0시에 일광 절약 시간제를 실시하면 1시로 시간을 조정해야 하는 것이다. 실제 낮 시간과 사람들이 활동하는 낮 시간 사이의 격차를 줄이기 위해 사용한다. 12345ZonedDateTime zdt = ZondedDateTime.of(date, time, zid);OffsetDateTime odt = offsetDateTime.of(date, time, krOffset);// ZonedDatetime -&gt; OffsetDateTimeOffsetDateTime odt = zdt.toOffsetDateTime(); OffsetDateTime을 ZonedDateTime처럼, LocalDate와 LocalTime에 ZonedOffset을 더하거나, ZonedDateTime에 toOffsetDateTime()을 호출해서 얻을 수도 있다. 지금까지의 내용을 예제로 확인해보자. 123456789101112131415161718192021222324252627LocalDate ld = LocalDate.now();LocalTime lt = LocalTime.now();System.out.println(\"LocalDate : \" + ld);System.out.println(\"LocalTime : \" +lt);LocalDateTime dt = LocalDateTime.of(ld, lt);System.out.println(\"LocalDateTime : \" + dt);ZoneId zid = ZoneId.of(\"Asia/Seoul\");ZonedDateTime zdt = dt.atZone(zid);System.out.println(\"ZonedDateTime1 : \" + zdt);ZonedDateTime seoulTime = ZonedDateTime.now();System.out.println(\"ZonedDateTime2 : \" + seoulTime);// 특정 구역 시간의 다른 구역 시간 구하기ZoneId nyId = ZoneId.of(\"America/New_York\");ZonedDateTime nyTime = ZonedDateTime.now().withZoneSameInstant(nyId);System.out.println(\"ZonedDateTime3 : \" + nyTime);// 출력 결과LocalDate : 2018-06-06LocalTime : 10:28:37.743LocalDateTime : 2018-06-06T10:28:37.743ZonedDateTime1 : 2018-06-06T10:28:37.743+09:00[Asia/Seoul]ZonedDateTime2 : 2018-06-06T10:28:37.744+09:00[Asia/Seoul]ZonedDateTime3 : 2018-06-05T21:28:37.747-04:00[America/New_York] TemporalAdjustersplus(), minus()와 같은 메서드로 날짜와 시간을 계산하기에는 불편한 경우가 있다. (Ex. 이번 달의 3번째 금요일) 그래서 자주 쓰일만한 날짜 계산들을 대신 해주는 메서드를 정의해놓은 것이 TemporalAdjusters 클래스이다. 12LocalDate today = LocalDate.now();LocalDate nextMonday = today.with(TemporalAdjusters.next(DayofWeek.MONDAY))l with()는 LocalTime, LocalDateTime, ZonedDateTime, Instant 등 대부분의 날짜와 시간에 관련된 클래스에 포함되어 있다. Period와 DurationPeriod는 날짜의 차이를, Duration은 시간의 차이를 계산하기 위한 것이다. between() 두 날짜 date1과 date2의 차이를 나타내는 Period는 between()으로 얻을 수 있다. 123LocalDate date1 = LocalDate.of(2014, 1, 1);LocalDate date2 = LocalDate.of(2018, 6, 6);Period pe = Period.between(date1, date2) date1이 date2보다 날짜 상으로 이전이면 양수로, 이후면 음수로 Period에 저장된다. 그리고 시간차이를 구할 때는 Duration을 사용한다는 것을 제외하고는 Period와 똑같다. Period, Duration에서 특정 필드의 값을 얻을 때는 get()을 사용한다. 123456long year = pe.get(ChronoUnit.YEARS); // int getYears()long month = pe.get(ChronoUnit.MONTHS); // int getMonths()long day = pe.get(ChronoUnit.DAYS); // int getDays()long sec = du.get(ChronoUnit.SECONDS); // long getSeconds()long nano = du.get(ChronoUnit.NANOS); // int getNano() between()과 until() until()은 between()과 거의 같은 일을 한다. between()은 static 메서드이고, until()은 인스턴스 메서드라는 차이가 있다. Period는 년월일을 분리해서 저장하기 때문에, D-day를 구하려는 경우에는 두 개의 매개변수를 받는 until()을 사용하는 것이 낫다. 파싱과 포맷날짜와 시간을 원하는 형식으로 출력하고 해석(파싱)을 위한 형식화(formatting)와 관련된 클래스들은 java.time.format 패키지에 들어 있다. 그 중에서 DateTimeFormatter가 핵심이다. 이 클래스에는 자주 쓰이는 다양한 형식들을 기본적으로 정의하고 있으며, 그 외의 형식이 필요하다면 직접 정의해서 사용할 수도 있다. 123LocalDate date = LocalDate.of(2016, 6, 6);String yyyymmdd = DateTimeFormatter.ISO_LOCAL_DATE.format(date); // \"2016-06-06\"String yyyymmdd = date.format(DateTimeFormatter.ISO_LOCAL_DATE); // \"2018-06-06 날짜와 시간의 형식화에는 format()이 사용되는데, 이 메서드는 DateTimeFormatter뿐만 아니라 LocalDate나 LocalTime같은 클래스에도 있다. 같은 기능을 하기 때문에 상황에 따라 편한 쪽을 선택해서 사용하면 된다. 문자열을 날짜와 시간으로 파싱하기 문자열을 날짜 또는 시간으로 변환하려면 static 메서드 parse()를 사용하면 된다. 자주 사용되는 기본적인 형식의 문자열은 ISO_LOCAL_DATE와 같은 형식화 상수를 사용하지 않고도 파싱이 가능하다. 1234LocalDate date = LocalDate.parse(\"2018-06-06\", DateTimeFormatter.ISO_LOCAL_DATE);LocalDate newDate = LocalDate.parse(\"2018-06-06\");LocalTime newTime = LocalTime.parse(\"23:59:59\");LocalDateTime newDateTime = LocalDateTime.parse(\"2018-06-06T23:59:59\"); 참고 Java 8, 타임존이 포함된 ISO 8601 문자열을 LocalDateTime으로 변환하기 Java8에서 타임존(Time-Zone) 다루기 Java의 정석 - 2","link":"/2018/06/06/Java/java-date-time/"},{"title":"java.lang 패키지와 유용한 클래스","text":"java.lang 패키지와 유용한 클래스java.lang 패키지는 자바프로그래밍에 가장 기본이 되는 클래스들을 포함하고 있다. 그렇기 때문에 java.lang 패키지의 클래스들은 import문 없이도 사용할 수 있게 되어 있다. 그 동안 String 클래스나 System 클래스를 import문 없이 사용할 수 있었던 이유가 바로 java.lang 패키지에 속한 클래스들이기 때문이었던 것이다. java.lang 패키지Object 클래스Object 클래스는 멤버변수는 없고 오직 11개의 메서드만 가지고 있다. equals(Object obj)매개변수로 객체의 참조변수를 받아서 비교하여 그 결과를 booelan 값으로 알려주는 역할을 한다.* 아래의 코드는 Object 클래스에 정의되어 있는 equals 메서드의 실제 내용이다. 123public boolean equals(Object obj) { return (this==obj);} 두 객체의 같고 다름을 참조변수의 값으로 판단한다. String 클래스는 Object 클래스의 equals 메서드를 그대로 사용하는 것이 아니라 이처럼 오버라이딩을 통해서 String 인스턴스가 갖는 문자열 값을 비교하도록 되어있다. String 클래스 뿐만 아니라 Date, File, Wrapper 클래스(Integer, Double 등)의 equals 메서드도 주소값이 아닌 내용을 비교하도록 오버라이딩되어 있다. 그러나 StringBuffer 클래스는 오버라이딩되어 있지 않다. hashCode()이 메서드는 해싱(hashing)기법에 사용되는 ‘해시함수(hash function)’를 구현한 것이다. 해싱은 데이터관리기법 중의 하나인데 다량의 데이터를 저장하고 검색하는 데 유용하다.* 해시함수는 찾고자하는 값을 입력하면, 그 값이 저장된 위치를 알려주는 해시코드(hashcode)를 반환한다. Object 클래스에 정의된 hashCode 메서드는 객체의 주소값을 이용해서 해시코드를 만들어 반환하기 때문에 서로 다른 두 객체는 결코 같은 해시코드를 가질 수 없다. (해싱기법을 사용하는 HashMap이나 HashSet과 같은 클래스에 저장할 객체라면 반드시 hashCode 메서드를 오버라이딩해야 한다.) String 클래스는 문자열의 내용이 같으면, 동일한 해시코드를 반환하도록 hashCode 메서드가 오버라이딩되어 있기 때문에, 문자열의 내용이 같은 str1과 str2에 대해 hashCode()를 호출하면 항상 동일한 해시코드값을 얻는다. 반면에 System.identifyHashCode(Object x)는 Object 클래스의 hashCode 메서드처럼 객체의 주소값으로 해시코드를 생성하기 때문에 모든 객체에 대해 항상 다른 해시코드값을 반환할 것을 보장한다. 그래서 str1과 str2가 해시코드는 같지만 서로 다른 객체라는 것을 알 수 있다. toString()인스턴스에 대한 정보를 문자열(String)로 제공할 목적으로 정의한 것이다. 인스턴스의 정보를 제공한다는 것은 대부분의 경우 인스턴스 변수에 저장된 값들을 문자열로 표현한다는 뜻이다. Object클래스에 정의된 toString()은 아래와 같다. 123public String toString() { return getClass().getName() + \"@\" + Integer.toHexString(hashCode());} clone()자신을 복제하여 새로운 인스턴스를 생성하는 일을 한다. Object 클래스에 정의된 clone()은 단순히 인스턴스변수의 값만을 복사하기 때문에 참조 변수 타입의 인스턴스 변수가 정의되어 있는 클래스는 완전한 인스턴스 복제가 이루어지지 않는다. cloneable 인터페이스를 구현한 클래스에서만 clone()을 호출할 수 있다. 또한 clone()을 오버라이딩하면서 접근 제어자를 protected에서 public으로 변경해야 한다. clone()은 단순히 객체에 저장된 값을 그대로 복제할 뿐, 객체가 참조하고 있는 객체까지 복제하지는 않는다. 반면에 원본이 참조하고 있는 객체까지 복제하는 것을 ‘깊은 복사’라고 한다. 깊은 복사에서는 원본과 복사본이 서로 다른 객체를 참조하기 때문에 원본의 변경이 복사본에 영향을 미치지 않는다. 공변 반환타입 JDK 1.5부터 ‘공변 반환타입’ 이라는 것이 추가되었다. 이 기능은 오버라이딩할 때 조상 메서드의 반환타입을 자손 클래스의 타입으로 변경하는 것이다. 따라서 clone()의 반환타입을 Object가 아닌 자손의 타입으로 변경가능하다. ‘공변 반환타입’을 사용하면 조상의 타입이 아닌 실제로 반환되는 자손 객체의 타입으로 반환할 수 있어서 번거로운 형변환이 줄어든다는 장점이 있다. getClass()자신이 속한 클래스의 Class객체를 반환하는 메서드인데, Class 객체는 이름이 ‘Class’인 클래스의 객체이다. Class 객체는 아래와 같이 정의되어 있다. 123public final class Class implements ... { // Class 클래스 ...} Class 객체는 클래스의 모든 정보를 담고 있으며, 클래스당 단 1개만 존재한다. 그리고 클래스 파일이 ‘클래스 로더(ClassLoader)’에 의해서 메모리에 올라갈 때, 자동적으로 생성된다. 클래스 로더는 실행 시에 필요한 클래스를 동적으로 메모리에 로드하는 역할을 한다. 먼저 기존에 생성된 클래스 객체가 메모리에 존재하는지 확인하고, 있으면 객체의 참조를 반환하고 없으면 클래스 패스(classpath)에 지정된 경로를 따라서 클래스 파일을 찾는다. 못 찾으면 ClassNotFoundException이 발생하고, 찾으면 해당 클래스 파일을 읽어서 Class 객체로 변환한다. 파일 형태로 저장되어 있는 클래스를 읽어서 Class 클래스에 정의된 형식으로 변환하는 것이다. 즉, 클래스 파일을 읽어서 사용하기 편한 형태로 저장해 놓은 것이 클래스 객체이다. (클래스 파일을 메모리에 로드하고 변환하는 일은 클래스 로더가 한다.) Class 객체를 얻는 방법 Class 객체에 대한 참조를 얻는 방법은 여러 가지가 있다. 1234&gt; Class cObj = new Card().getClass(); // 생성된 객체로 부터 얻는 방법&gt; Class cObj = Card.class; // 클래스 리터럴(*.class)로 부터 얻는 방법&gt; Class cObj = Class.forName(\"Card\"); // 클래스 이름으로 부터 얻는 방법&gt; &gt; 특히 forName()은 특정 클래스 파일, 예를 들어 데이터베이스 드라이버를 메모리에 올릴 때 주로 사용한다. Class 객체를 이용하면 클래스에 정의된 멤버의 이름이나 개수 등, 클래스에 대한 모든 정보를 얻을 수 있기 때문에 Class 객체를 통해서 객체를 생성하고 메서드를 호출하는 등 보다 동적인 코드를 작성할 수 있다. String 클래스기존의 다른 언어에서는 문자열을 char형의 배열로 다루었으나 자바에서는 문자열을 위한 클래스를 제공한다. 변경 불가능한(immutable) 클래스String 클래스는 문자열을 저장하기 위해서 문자형 배열 변수(char[]) value를 인스턴스 변수로 정의해놓고 있다. 인스턴스 생성 시 생성자의 매개변수로 입력받는 문자열은 이 인스턴스변수(value)에 문자형 배열(char[])로 저장되는 것이다. 1234public final class String implements java.io.Serializable, Comparable { private char[] value; ...} 한번 생성된 String 인스턴스가 갖고 있는 문자열은 읽어 올 수만 있고, 변경할 수는 없다. 예를 들어 ‘+’ 연산자를 이용해서 문자열을 결합하는 경우 인스턴스내의 문자열이 바뀌는 것이 아니라 새로운 문자열이 담긴 String 인스턴스가 생성되는 것이다. 덧셈 연산자 ‘+’를 사용해서 문자열을 결합하는 것은 매 연산 시 마다 새로운 문자열을 가진 String 인스턴스가 생성되어 메모리공간을 차지하게 되므로 가능한 한 결합횟수를 줄이는 것이 좋다. 문자열을 다루는 작업이 많이 필요한 경우에는 String 클래스 대신 StringBuffer 클래스를 사용하는 것이 좋다. StringBuffer 인스턴스에 저장된 문자열은 변경이 가능하므로 하나의 StringBuffer 인스턴스만으로도 문자열을 다루는 것이 가능하다. 문자열의 비교문자열을 만들 때는 두 가지 방법, 문자열 리터럴을 지정하는 방법과 String 클래스의 생성자를 사용해서 만드는 방법이 있다. 1234Strig str1 = \"abc\"; // 문자열 리터럴 \"abc\"의 주소가 str1에 저장됨Strig str2 = \"abc\"; // 문자열 리터럴 \"abc\"의 주소가 str2에 저장됨Strig str3 = new String(\"abc\"); // 새로운 String 인스턴스를 생성Strig str4 = new String(\"abc\"); // 새로운 String 인스턴스를 생성 String 클래스의 생성자를 이용한 경우에는 new 연산자에 의해서 메모리할당이 이루어지기 때문에 항상 새로운 String 인스턴스가 생성된다. 그러나 문자열 리터럴은 이미 존재하는 것을 재사용하는 것이다. (문자열 리터럴은 클래스가 메모리에 로드될 때 자동적으로 미리 생성된다.) equals()를 사용했을 때는 두 문자열의 내용(“abc”)을 비교하기 때문에 두 경우 모두 true를 결과로 얻는다. 하지만, 각 String 인스턴스의 주소를 등가비교연산자 “==”로 비교했을 때는 결과가 다르다. 문자열 리터럴자바 소스파일에 포함된 모든 문자열 리터럴은 컴파일 시에 클래스 파일에 저장된다. 이대 같은 내용의 문자열 리터럴은 한번만 저장된다.* 문자열 리터럴도 String 인스턴스이고 한번 생성하면 내용을 변경할 수 없기 때문에 하나의 인스턴스를 공유하면 되기 때문이다. String 리터럴들은 컴파일 시에 클래스파일에 저장된다. 클래스 파일에는 소스파일에 포함된 모든 리터럴의 목록이 있다. 해당 클래스 파일이 클래스 로더에 의해 메모리에 올라갈 때, 이 리터럴의 목록에 있는 리터럴들이 JVM내에 있는 ‘상수 저장소(constant pool)’에 저장된다. 빈 문자열(empty string)길이가 0인 배열이 존재할 수 있다. char형 배열도 길이가 0인 배열을 생성할 수 있고, 이 배열을 내부적으로 가지고 있는 문자열이 바로 빈 문자열이다.* ‘String s = “”;’ 과 같은 문장이 있을 때, 참조변수 s가 참조하고 있는 String 인스턴스는 내부에 ‘new char[0]’과 같이 길이가 0인 char형 배열을 저장하고 있는 것이다. 그러나 ‘String s = “”;’과 같은 표현이 가능하다고 해서 ‘char c = ‘’;’와 같은 표현도 가능한 것은 아니다. char형 변수에는 반드시 하나의 문자를 지정해야한다. 일반적으로 변수를 선언할 때, 각 타입의 기본값으로 초기화 하지만 String은 참조형 타입의 기본값인 null 보다는 빈 문자열로, char형인 기본값은 ‘₩u0000’ 대신 공백으로 초기화 하는 것이 보통이다. (‘₩u0000’은 유니코드의 첫 번째 문자로써 아무런 문자도 지정되지 않은 빈 문자이다.) 문자 인코딩 변환getBytes(String charsetName)를 사용하면, 문자열의 문자 인코딩을 다른 인코딩으로 변경할 수 있다. 자바가 UTF-16을 사용하지만, 문자열 리터럴에 포함되는 문자들은 OS의 인코딩을 사용한다. 12byte[] utf8_str = \"가\".getBytes(\"UTF-8\"); // 문자열을 UTF-8로 분환String str = new String(utf8_str, \"UTF-8\"); // byte 배열을 문자열로 변환 서로 다른 문자 인코딩을 사용하는 컴퓨터 간에 데이터를 주고받을 때는 적절한 문자 인코딩이 필요하다. UTF-8은 한글 한 글자를 3 byte로 표현하고, CP949는 2 byte로 표현한다. 기본형 값을 String으로 변환기본형을 문자열로 변경하는 방법은 간단하다. 숫자에 빈 문자열””을 더해주기만 하면 된다. 이 외에도 valueOf()를 사용하는 방법도 있다. 성능은 valueOf()가 더 좋지만, 빈 문자열을 더하는 방법이 간단하고 편하기 때문에 성능향상이 필요한 경우에만 valueOf()를 쓰자. 참조변수에 String을 더하면, 참조변수가 가리키고 있는 인스턴스의 toString()을 호출하여 String을 얻은 다음 결합한다. String을 기본형 값으로 변환이전에는 parseInt()와 같은 메서드를 많이 섰는데, 메서드의 이름을 통일하기 위해 valueOf()가 나중에 추가되었다. valueOf(String s)는 메서드 내부에서 그저 parseInt(String s)를 호출할 뿐이므로, 두 메서드는 반환 타입만 다르지 같은 메서드이다. 123public static Integer valueOf(String s)throws NumberFormatException { return Integer.valueOf(ParseInt(s, 10));} StringBuffer 클래스와 StringBuilder 클래스String 클래스는 인스턴스를 생성할 때 지정된 문자열을 변경할 수 없지만 StringBuffer 클래스는 변경이 가능하다. 내부적으로 문자열 편집을 위한 버퍼(buffer)를 가지고 있으며, StringBuffer 인스턴스를 생성할 때 그 크기를 지정할 수 있다. StringBuffer 클래스는 String 클래스와 같이 문자열을 저장하기 위한 char형 배열의 참조변수 인스턴스로 선언해 놓고 있다. StringBuffer 인스턴스가 생성될 때, char형 배열이 생성되며 이 때 생성된 char형 배열을 인스턴스변수 value가 참조하게 된다. 1234public final class StringBuffer implements java.io.Serializable { private char[] value; ...} StringBuffer의 생성자StringBuffer 클래스의 인스턴스를 생성할 때, 적절한 길이의 char형 배열이 생성되고, 이 배열은 문자열을 저장하고 편집하기 위한 공간(buffer)으로 사용된다. StringBuffer 인스턴스를 생성할 때는 생성자 StringBuffer(int length)를 사용해서 StringBuffer 인스턴스에 저장될 문자열의 길이를 고려하여 충분히 여유있는 크기로 지정하는 것이 좋다. StringBuffer 인스턴스를 생성할 때, 버퍼의 크기를 지정해 주지 않으면 16개의 문자를 저장할 수 있는 크기의 버퍼를 생성한다. 12345678910111213public StringBuffer(int length) { value = new char[length]; shared = false;}public StringBuffer() { this(16);}public StringBuffer(String str) { this(str.length() + 16); append(str);} StringBuffer 인스턴스로 문자열을 다루는 작업을 할 때, 버퍼의 크기가 작업하려는 문자열의 길이보다 작을 때는 내부적으로 버퍼의 크기를 증가시키는 작업이 수행된다. 배열의 길이는 변경될 수 없으므로 새로운 길이의 배열을 생성한 후에 이전 배열의 값을 복사해야 한다. StringBuffer의 비교String 클래스에서는 equals메서드를 오버라이딩해서 문자열의 내용을 비교하도록 구현되어 있지만, StringBuffer 클래스는 equals메서드를 오버라이딩하지 않아서 StringBuffer클래스의 equals메서드를 사용해도 등가비교연산자(==)로 비교한 것과 같은 결과를 얻는다. 12345StringBuffer sb = new StringBuffer(\"abc\");StringBuffer sb2 = new StringBuffer(\"abc\");System.out.println(sb == sb2); // falseSystem.out.println(sb.equals(sb2)); // false 반면에 toString()은 오버라이딩되어 있어서 StringBuffer 인스턴스에 toString()을 호출하면, 담고있는 문자열을 String으로 변환한다. 그래서 StringBuffer 인스턴스에 담긴 문자열을 비교하기 위해서는 StringBuffer 인스턴스에 toString()을 호출해서 String 인스턴스를 얻은 다음, 여기에 equals 메서드를 사용해서 비교해야한다. StringBuilder란?StringBuffer는 멀티쓰레드에 안전(thread safe)하도록 동기화되어 있다. 멀티쓰레드로 작성된 프로그램이 아닌 경우, StringBuffer의 동기화는 불필요하게 성능만 떨어뜨리게 된다. 그래서 StringBuffer에서 쓰레드의 동기화만 뺀 StringBuilder가 새로 추가되었다. 래퍼(wrapper) 클래스경우에 따라 기본형(primitive type) 변수도 어쩔 수 없이 객체로 다뤄야 하는 경우가 있다. 예를 들면, 매개변수로 객체를 요구할 때, 기본형 값이 아닌 객체로 저장해야할 때, 객체 간의 비교가 필요할 때 등등의 경우에는 기본형 값들을 객체로 변환하여 작업을 수행해야 한다. 이 때 사용되는 것이 래퍼(wrapper)클래스이다. 8개의 기본형을 대표하는 8개의 래퍼클래스가 있는데, 이 클래스들을 이용하면 기본형 값을 객체로 다룰 수 있다. 래퍼 클래스들은 객체생성 시에 생성자의 인자로 주어진 각 자료형에 알맞은 값을 내부적으로 저장하고 있으며, 이에 관련된 여러 메서드가 정의되어 있다. 래퍼 클래스들은 모두 equals()가 오버라이딩되어 있어서 주소값이 아닌 객체가 가지고 있는 값을 비교한다. 오토박싱이 된다고 해도 Integer객체에 비교연산자를 사용할 수 없다. 대신 compareTo()를 제공한다. 그리고 toString()도 오버라이딩되어 있어서 객체가 가지고 있는 값을 문자열로 변환하여 반환한다. 문자열을 숫자로 변환하기123int i = new Integer(\"100\").intValue();int i2 = Integer.parseInt(\"100\");Integer i3 = Integer.valueOf(\"100\"); 타입.parse타입(String s) 의 반환값이 기본형(primitive type)이고, 타입.valueOf()는 반환값이 래퍼 클래스 타입이라는 차이가 있다. 문자열 -&gt; 기본형int i = Integer.parseInt(“100”); 문자열 -&gt; 래퍼 클래스Integer i = Integer.valueIf(“100”); JDK 1.5부터 도입된 ‘오토박싱(autoboxing)’ 기능 때문에 반환값이 기본형일 때와 래퍼 클래스일 때의 차이가 없어졌다. 그래서 그냥 구별없이 valueOf()를 쓰는 것도 괜찮은 방법이다. 단, 성능은 valueOf()가 조금 더 느리다. 오토박싱 &amp; 언박싱JDK 1.5 이전에는 기본형과 참조형 간의 연산이 불가능했기 때문에, 래퍼 클래스로 기본형을 객체로 만들어서 연산해야 했다. 그러나 이제는 기본형과 참조형 간의 덧셈이 가능하다. 자바 언어의 규칙이 바뀐 것은 아니고, 컴파일러가 자동으로 변환하는 코드를 넣어주기 때문이다. 기본형 값을 래퍼 클래스의 객체로 자동 변환해주는 것을 ‘오토박싱’이라고 하고, 반대로 변환하는 것을 ‘언박싱’이라고 한다. 1234ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(10); // 오토박싱int value = list.get(0); // 언박싱 ArrayList에 숫자를 저장하거나 꺼낼 때, 기본형 값을 래퍼클래스의 객체로 변환하지 않아도 되므로 편리하다. 유용한 클래스java.util.Objects 클래스Object 클래스의 보조 클래스로 Math 클래스처럼 모든 메서드가 ‘static’이다. 객체의 비교나 널 체크(null check)에 유용하다. IsNull()은 해당 객체가 널인지 확인해서 null이면 true를 반환하고 아니면 false를 반환한다. nonNull()은 isNull()과 정확히 반대의 일을 한다. 12static boolean isNull(object obj)static boolean nonNull(object obj) 그리고 requireNonNull()은 해당 객체가 널이 아니어야 하는 경우에 사용한다. 만일 객체가 널이면, NullPointerException을 발생시킨다. 두 번째 매개변수로 지정하는 문자열은 예외의 메시지가 된다. 12static &lt;T&gt; requireNonNull(T obj)static &lt;T&gt; requireNonNull(T obj, String message) Object 클래스에는 두 객체를 비교하는 메서드가 등가비교를 위한 equals()만 있고, 대소비교를 위한 compare()가 없는 것이 좀 아쉬웠다. 그래서인지 Objects에는 compare()가 추가되었다. compare()는 두 비교대상이 같으면 0, 크면 양수, 작으면 음수를 반환한다. 1static int compare(Object a, Object b, Comparator c) 이 메서드는 a와 b 두 객체를 비교하는데, 두 객체를 비교하는데 사용할 비교 기준이 필요하다. 그 역할을 하는 것이 Comparator이다. Objects 클래스의 equals()는 Object 클래스와는 달리, null 검사를 하지 않아도 된다. equals()의 내부에서 a와 b의 null 검사를 하기 때문에 따로 null 검사를 위한 조건식을 넣지 않아도 된다. 실제 메서드의 코드는 다음과 같다. 123public static boolean equals(Object a, Object b) { return (a == b) || (a != null &amp;&amp; a.equals(b));} a와 b가 모두 null인 경우에는 참을 반환한다는 점을 빼고는 특별한 것이 없다. deepEquals() 메서드는 객체를 재귀적으로 비교하기 때문에 다차원 배열의 비교도 가능하다. java.util.Scanner 클래스Scanner는 화면, 파일, 문자열과 같은 입력소스로부터 문자데이터를 읽어오는데 도움을 줄 목적으로 JDK 1.5부터 추가되었다. Scanner에는 다음과 같은 생성자를 지원하기 때문에 다양한 입력소스로부터 데이터를 읽을 수 있다. 123456Scanner(String source)Scanner(File source)Scanner(InputStream source)Scanner(Readable source)Scanner(ReadableByteChannel source)Scanner(Path source) .. JDK 1.7부터 추가 java.util.StringTokenizer 클래스StringTokenizer는 긴 문자열을 지정한 구분자(delimiter)를 기준으로 토큰(token)이라는 여러 개의 문자열로 잘라내는 데 사용된다. StringTokenizer를 이용하는 방법 이외에도 String의 split(String reges)이나 Scanner의 useDelimiter(Spring pattern)를 사용할 수도 있다. 위의 이 두 가지 방법은 정규식 표현(Regular expression)을 사용해야 하므로 정규식 표현에 익숙하지 않은 경우 StringTokenizer를 사용하는 것이 간단하면서도 명확한 결과를 얻을 수 있다. 그러나 StirngTokenizer는 구분자로 단 하나의 문자열 밖에 사용하지 못하기 때문에 복잡한 형태의 구분자로 문자열을 나누어야 하는 경우에는 정규식을 사용하는 메서드를 사용해야 한다. split()은 빈 문자열도 토큰으로 인식하는 반면 StringTokenizer는 빈 문자열을 토큰으로 인식하지 않기 때문에 인식하는 토큰의 개수가 서로 다른 것을 알 수 있다. 이 외에도 성능의 차이가 있는데, split()은 데이터를 토큰으로 잘라낸 결과를 배열에 담아서 반환하기 때문에 데이터를 토큰으로 바로바로 잘라서 반환하는 StringTokenizer보다 성능이 떨어질 수밖에 없다. 그러나 데이터의 양이 많은 경우가 아니라면 별 문제가 되지 않으므로 크게 신경 쓸 부분은 아니다. java.math.BigInteger 클래스정수형으로 표현할 수 있는 값의 한계가 있다. 가장 큰 정수형 타입인 long으로 표현할 수 있는 값은 10진수로 19자리 정도이다. 이 값도 상당히 큰 값이지만, 과학적 계산에서는 더 큰값을 다뤄야할 때가 있다. 그럴 때 사용하면 좋은 것이 BigIntenger이다. BigInteger는 내부적으로 int배열을 사용해서 값을 다룬다. 그래서 long 타입보다 훨씬 큰 값을 다룰 수 있는 것이다. 대신 성능은 long 타입보다 떨어질 수밖에 없다. 12final int signum; // 부호. 1(양수), 0, -1(음수) 셋 중의 하나final int[] mag; // 값 BigIntenger는 String처럼 불변(immutable)이다. 그리고 모든 정수형이 그렇듯이 BigInteger 역시 값을 ‘2의 보수’의 형태로 표현한다. 위의 코드에서 알 수 있듯이 부호를 따로 저장하고 배열에는 값 자체만 저장한다. 그래서 signum의 값이 -1, 즉 음수인 경우, 2의 보수법에 맞게 mag의 값을 변환해서 처리한다. 그래서 부호만 다른 두 값의 mag의 값을 변환해서 처리한다. 그래서 부호만 다른 두 값의 mag는 같고 signum은 다르다. BigInteger는 불변이므로, 반환타입이 BigInteger이란 얘기는 새로운 인스턴스가 반환된다는 뜻이다. 비트 연산 메서드워낙 큰 숫자를 다루기 위한 클래스이므로, 성능을 향상시키기 위해 비트단위로 연산을 수행하는 메서드들을 많이 갖고 있다. 따라서 가능하면 산술연산 대신 비트연산으로 처리하도록 노력해야 한다. java.math.BigDecimal 클래스double 타입으로 표현할 수 있는 값은 상당히 범위가 넓지만, 정밀도가 최대 13자리 밖에 되지 않고 실수형의 특성상 오차를 피할 수 없다. BigDecimal은 실수형과 달리 정수를 이용해서 실수를 표현한다. 실수의 오차는 10진 실수를 2진 실수로 정확히 변환할 수 없는 경우가 있기 때문에 발생하는 것이므로, 오차가 없는 2진 정수로 변환하여 다루는 것이다. 참고 Java의 정석 - 1","link":"/2018/04/07/Java/java-lang-package-and-useful-class/"},{"title":"람다 & 스트림","text":"해당 포스팅의 내용은 Java의 정석 2권 - Chapter 14 람다 &amp; 스트림에 있는 내용을 요약한 것입니다. 해당 책으로 복습하며 정리한 내용이고 문제가 된다면 바로 해당 포스팅을 삭제하도록 하겠습니다. 람다와 스트림람다식이란?람다식(Lambda expression)은 간단히 말해서 메서드를 하나의 ‘식(expression)’으로 표현한 것이다. 람다식은 함수를 간략하면서도 명확한 식으로 표현할 수 있게 해준다. 메서드를 람다식으로 표현하면 메서드의 이름과 반환값이 없어지므로, 람다식을 ‘익명 함수(annonymous function)’이라고도 한다. 12int[] arr = new int[5];Arrays.setAll(arr, i -&gt; (int)(Math.random()*5)+1); // arr=[1,5,2,1,1] 위의 문장에서 ‘i -&gt; (int)(Math.random()*5)+1)’이 람다식이다. 이 람다식이 하는 일을 메서드로 표현하면 다음과 같다. 123int method(int i) { return (int)(Math.random()*5) + 1;} 위의 메서드보다 람다식이 간결하고 이해하기 쉽다. 게다가 모든 메서드는 클래스에 포함되어야 하므로 클래스도 새로 만들어야 하고, 객체도 생성해야만 비로소 이 메서드를 호출할 수 있다. 그러나 람다식은 이 모든 과정없이 오직 람다식 자체만으로도 이 메서드의 역할을 대신할 수 있다. 또한, 람다식은 메서드의 매개변수로 전달되어지는 것이 가능하고, 메서드의 결과로 반환될 수도 있다. 람다식으로 인해 메서드를 변수처럼 다루는 것이 가능해진 것이다. 람다식 작성하기랃마식은 ‘익명 함수’답게 메서드에서 이름과 반환타입을 제거하고 매개변수 선언부와 몸통{} 사이에 ‘-&gt;’를 추가한다. 반환값이 있는 경우, return문 대신 ‘식(expression)’으로 대신 할 수 있다. 식의 연산결과가 자동으로 반환값이 된다. 이때는 ‘문장(statement)’이 아닌 ‘식’이므로 끝에 ‘;’을 붙이지 않는다. 람다식에 선언된 매개변수의 타입은 추론이 가능한 경우는 생략할 수 있는데, 대부분의 경우에 생략가능하다. 람다식에 반환타입이 없는 이유도 항상 추론이 가능하기 때문이다. 매개변수가 하나뿐인 경우에는 괄호()를 생략할 수 있다. 단, 매개변수의 타입이 있으면 괄호()를 생략할 수 없다. 마찬가지로 괄호{}안의 문장이 하나일 때는 괄호{}를 생략할 수 있다. 이 때 문장의 끝에 ‘;’를 붙이지 않아야 한다. 그러나 괄호{} 안의 문장이 return문일 경우 괄호{}를 생략할 수 없다. 함수형 인터페이스(Funtional Interface)자바에서 모든 메서드는 클래스 내에 포함되어야 한다. 사실 람다식은 익명 클래스의 객체와 동일하다. 하나의 메서드가 선언된 인터페이스를 정의해서 람다식을 다루는 것은 기존의 자바의 규칙들을 어기지 않으면서도 자연스럽다. 그래서 인터페이스를 통해 람다식을 다루기로 결정되었으며, 람다식을 다루기 위한 인터페이스를 함수형 인터페이스(functional interface)라고 부른다. 단, 함수형 인터페이스에는 오직 하나의 추상 메서드만 정의되어 있어야 한다는 제약이 있다. 그래야 람다식과 인터페이스의 메서드가 1:1로 연결 될 수 있기 때문이다. 반면에 static 메서드와 default 메서드의 개수에는 제약이 없다. @FunctionalInterface를 붙이면, 컴파일러가 함수형 인터페이스를 올바르게 정의했는지 확인해주므로, 꼭 붙이는 것이 좋다. 함수형 인터페이스 타입의 매개변수와 반환타입함수형 인터페이스 MyFunction이 아래와 같이 정의되어 있을 때, 1234@FunctionalInterfaceinterface MyFunction { void myMethod(); // 추상 메서드} 메서드의 매개변수가 MyFunction 타입이면, 이 메서드를 호출할 때 람다식을 참조하는 참조변수를 매개변수로 지정해야한다는 뜻이다. 123456void aMethod(MyFunction f) { f.myMethod();}// ...MyFunction f = () -&gt; System.out.println(\"myMethod()\");aMethod(f); 또는 참조변수 없이 직접 람다식을 매개변수로 지정하는 것도 가능하다. 1aMethod(() -&gt; System.out.println(\"myMethod()\")); 메서드의 반환타입이 함수형 인터페이스라면, 이 함수형 인터페이스의 추상 메서드와 동등한 람다식을 가리키는 참조변수를 반환하거나 람다식을 직접 반환할 수 있다. 1234MyFunction mymethod() { MyFunction f = () -&gt; {}; return f;} 람다식을 참조변수로 다룰 수 있다는 것은 메서드를 통해 람다식을 주고받을 수 있다는 것을 의미한다. 즉, 변수처럼 메서드를 주고받는 것이 가능해진 것이다. (사실상 메서드가 아니라 객체를 주고받는 것이라 달라진 것은 없다.) 람다식의 타입과 형변환함수형 인터페이스로 람다식을 참조할 수 있는 것일 뿐, 람다식의 타입이 함수형 인터페이스의 타입과 일치하는 것은 아니다. 람다식은 익명 객체이고 익명 객체는 타입이 없다. 정확히는 타입은 있지만 컴파일러가 임의로 이름을 정하기 때문에 알 수 없는 것이다. 그래서 대입 연산자의 양변의 타입을 일치시키기 위해 형변환이 필요하다. 1MyFunction f = (Myfunction)(() -&gt; {}); 람다식은 MyFunction 인터페이스를 직접 구현하지 않았지만, 이 인터페이스를 구현한 클래스의 객체와 완전히 동일하기 때문에 위처럼 형변환을 허용한다. 그리고 이 형변환은 생략가능하다. 람다식은 이름이 없을 뿐 객체인데도, Object 타입으로 형변환 할 수 없다. 람다식은 오직 함수형 인터페이스로만 형변환이 가능하다. 일반적인 익명 객체라면, 객체의 타입이 ‘외부클래스이름$번호’와 같은 형식으로 타입이 결정되었을 텐데, 람다식의 타입은 ‘외부클래스이름$$Lambda$번호’와 같은 형식으로 되어 있다. 외부 변수를 참조하는 람다식람다식도 익명 객체, 즉 익명 클래스의 인스턴스이므로 람다식에서 외부에 선언된 변수에 접근하는 규칙은 익명 클래스와 동일하다. 람다식 내에서 참조하는 지역변수는 final이 붙지 않았어도 상수로 간주한다.(인스턴스 변수는 변경 가능) 람다식 내에서 지역변수를 참조하면 람다식 내에서나 다른 어느 곳에서도 이 변수의 값을 변경할 수 없다. java.util.function 패키지java.util.function 패키지에 일반적으로 자주 쓰이는 형식의 메서드를 함수형 인터페이스로 미리 정의해 놓았다. 매번 새로운 함수형 인터페이스를 정의하지 말고, 가능하면 이 패키지의 인터페이스를 활용하는 것이 좋다. 그래야 함수형 인터페이스에 정의된 메서드 이름도 통일되고, 재사용성이나 유지보수 측면에서도 좋다. 자주 쓰이는 가장 기본적인 함수형 인터페이스는 다음과 같다. java.lang.Runnable 메서드 : void run() 매개변수도 없고, 반환값도 없음. Supplier&lt;T&gt; 메서드 : T get() 매개변수는 없고, 반환값만 있음. Consumer&lt;T&gt; 메서드 : void accept(T t) Supplier와 반대로 매개변수만 있고, 반환값이 없음 Function&lt;T, R&gt; 메서드 : R apply(T t) 일반적인 함수, 하나의 매개변수를 받아서 결과를 반환 Predicate&lt;T&gt; 메서드 : boolean test(T t) 조건식을 표현하는데 사용됨. 타입 문자 ‘T’는 ‘Type’을, ‘R’은 ‘Return Type’을 의미한다. 인터페이스 이름 앞에 접두사 ‘Bi’가 붙으면 매개변수가 두 개인 함수형 인터페이스이다. 3개 이상의 매개변수를 갖는 함수형 인터페이스를 선언한다면 직접 만들어서 서야한다. 컬렉션 프레임웍의 인터페이스에 디폴트 메서드가 추가되었다. Collection boolean removeIf(Predicate&lt;E&gt; filter): 조건에 맞는 요소를 삭제 List void replaceAll(UnaryOperator&lt;E&gt; operator): 모든 요소를 변환하여 대체 Iterable void forEach(Consumer&lt;T&gt; action): 모든 요소에 작업 action을 수행 Map V compute(K key, BiFunction&lt;K,V,V&gt; f): 지정된 키의 값에 작업 f를 수행 V computeIfAbsent(K key, BiFunction&lt;K,V&gt; f): 키가 없으면, 작업 f 수행 후 추가 V computeIfPresentt(K key, BiFunction&lt;K,V,V&gt; f): 지정된 키가 있을 때, 작업 f 수행 V merge(K key, V value, BiFunction&lt;V,V,V&gt; f): 모든 요소에 병합작업 f를 수행 void forEach(BiConsumer&lt;K,V&gt; action): 모든 요소에 작업 action을 수행 void replaceAll(BiFunction&lt;K,V,V&gt; f): 모든 요소에 치환작업 f를 수행 래퍼클래스를 사용하는 것은 비효율적이다. 그래서 보다 효율적으로 처리할 수 있도록 기본형을 사용하는 함수형 인터페이스들이 제공된다. DoubleToIntfunction : AToBFunction은 입력이 A타입 출력이 B타입 ToIntFunction&lt;T&gt; : ToBFunction은 출력이 B타입이다. 입력은 generic 타입 intFunction&lt;R&gt; : AFunction은 입력이 A타입이고 출력은 generic 타입 ObjintConsumer&lt;T&gt; : ObjAFunction은 입력이 T, A타입이고 출력은 없다. Function의 합성과 Predicate의 결합java.util.function 패키지의 함수형 인터페이스에는 추상형메서드 외에도 디폴트 메서드와 static 메서드가 정의되어 있다. Function의 합성함수 f, g가 있을 때, f.andThen(g)는 함수 f를 먼저 적용하고, 그 다음에 함수 g를 적용한다. 그리고 f.compose(g)는 반대로 g를 먼저 적용하고 f를 적용한다. 1234Function&lt;String, Integer&gt; f = (s) -&gt; Integer.parseInt(s, 16);Function&lt;Integer, String&gt; g = (i) -&gt; Integer.toBinaryString(i);Function&lt;String, String&gt; h = f.andThen(g);Function&lt;Integer, Integer&gt; i = f.compose(g); Predicate의 결합여러 조건식을 논리 연산자로 연결해서 하나의 식을 구성할 수 있는 것처럼, 여러 Predicate를 and(), or(), negate()로 연결해서 하나의 새로운 Predicate를 결합할 수 있다. 메서드 참조람다식을 더욱 간결하게 표현할 수 있는 방법이 있다. 람다식이 하나의 메서드만 호출하는 경우에는 메서드 참조라는 방법으로 람다식을 간략히 할 수 있다. 12345/// 변환 전Function&lt;String, Integer&gt; f = (String s) -&gt; Integer.parseInt(s);/// 변환 후Function&lt;String, Integer&gt; f = Integer::parseInt; 하나의 메서드만 호출하는 람다식은 ‘클래스이름::메서드이름’ 또는 ‘참조변수::메서드이름’ 으로 바꿀 수 있다. 메서드 참조는 람다식을 마치 static 변수처럼 다룰 수 있게 해준다. 메서드 참조는 코드를 간략히 하는데 유용해서 많이 사용된다. 스트림(stream)스트림이란?스트림은 데이터 소스를 추상화하고, 데이터를 다루는데 자주 사용되는 메서드들을 정의해 놓았다. 데이터 소스를 추상화했다는 것은, 데이터 소스가 무엇이던 간에 같은 방식으로 다룰 수 있게 되었다는 것과 코드의 재사용성이 높아진다는 것을 의미한다. 12345678String[] strArr = {\"aaa\", \"bbb\", \"ccc\"};List&lt;String&gt; strList = Arrays.asList(strArr);stream&lt;String&gt; strStream1 = strList.stream();stream&lt;String&gt; strStream2 = Arrays.stream(strArr);strStream1.sorted().forEach(System.out::println);strStream2.sorted().forEach(System.out::println); 스트림은 데이터 소스를 변경하지 않는다.스트림은 데이터 소스로부터 데이터를 읽기만할 뿐, 데이터 소스를 변경하지 않는다. 필요하다면, 결과를 컬렉션이나 배열에 담아서 반환할 수도 있다. 1List&lt;String&gt; sortedList = strStream2.sorted().collect(Collectors.toList()); 스트림은 일회용이다.스트림은 Iterator처럼 일회용이다. 한번 사용하면 닫혀서 다시 사용할 수 없다. 필요하다면 스트림을 다시 생성해야 한다. 스트림은 작업을 내부 반복으로 처리한다.내부 반복이라는 것은 반복문을 메서드의 내부에 숨길 수 있다는 것을 의미한다. forEach()는 스트림에 정의된 메서드 중의 하나로 매개변수에 대입된 람다식을 데이터 소스의 모든 요소에 적용한다. (forEach()는 메서드 안에 for문을 넣어버린 것이다.) 스트림의 연산스트림이 제공하는 다양한 연산을 이용해서 복잡한 작업들을 간단히 처리할 수 있다. 중간 연산 : 연산 결과가 스트림인 연산. 스트림에 연속해서 중간 연산을 할 수 있음 최종 연산 : 연산 결과가 스트림이 아닌 연산. 스트림의 요소를 소모하므로 단 한번만 가능 지연된 연산스트림 연산에서 한 가지 중요한 점은 최종 연산이 수행되기 전까지는 중간 연산이 수행되지 않는다는 것이다. 중간 연산을 호출하는 것은 단지 어떤 작업이 수행되어야하는지를 지정해주는 것일 뿐이다. 최종 연산이 수행되어야 비로소 스트림의 요소들이 중간 연산을 거쳐 최종 연산에서 소모된다. 병렬 스트림스트림으로 데이터를 다룰 때의 장점 중 하나가 병렬 처리가 쉽다는 것이다. 병렬 스트림은 내부적으로 fork&amp;join을 이용해서 자동적으로 연산을 병렬로 수행한다. 모든 스트림은 기본적으로 병렬 스트림이 아니므로 병렬 스트림을 사용하려면 parallelStream() 메서드를 사용해 병렬 스트림으로 전환해야 한다. 스트림 만들기스트림의 소스가 될 수 있는 대상은 배열, 컬렉션, 임의의 수 등 다양하다. 컬렉션컬렉션의 최고 조상인 Collection에 stream()이 정의되어 있다. 그래서 Collection의 자손인 List와 Set을 구현한 컬렉션 클래스들은 모두 이 메서드로 스트림을 생성할 수 있다. stream()은 해당 컬렉션을 소스로 하는 스트림을 반환한다. 1Stream&lt;T&gt; Collection.stream() 배열배열을 소스로 하는 스트림을 생성하는 메서드는 다음과 같이 Stream과 Arrays에 static 메서드로 정의되어 있다. 1234Stream&lt;T&gt; Stream.of(T... values)Stream&lt;T&gt; Stream.of(T[])Stream&lt;T&gt; Arrays.stream(T[])Stream&lt;T&gt; Arrays.stream(T[] array, int startInclusive, int endExclusive) 그리고 int, long, double과 같은 기본형 배열을 소스로 하는 스트림을 생성하는 메서드도 있다. 1234IntStream IntStream.of(int ...values) // 가변인자IntStream IntStream.of(int[])IntStream Arrays.stream(int[])IntStream Arrays.stream(int[] array, int startInclusive, int endExclusive) 특정 범위의 정수IntStream과 LongStream은 지정된 범위의 연속된 정수를 스트림으로 생성해서 반환하는 range()와 rangeClosed()를 가지고 있다. 임의의 수난수를 생성하는데 사용하는 Random 클래스에는 해당 타입의 난수들로 이루어지는 스트림을 반환하는 인스턴스 메서드들이 포함되어 있다. 스트림의 중간연산스트림 자르기 - skip(), limit()skip()과 limit()은 스트림의 일부를 잘라낼 때 사용한다. 스트림의 요소 걸러내기 - filter(), distinct()distinct()는 스트림에서 중복된 요소들을 제거하고, filter()는 주어진 조건(Predicate)에 맞지 않는 요소를 걸러낸다. 정렬 - sorted()스트림을 정렬할 때는 sorted()를 사용하면 된다. sorted()는 지정된 Comparator로 스트림을 정렬하는데, Comparator대신 int값을 반환하는 람다식을 사용하는 것도 가능하다. Comparator를 지정하지 않으면 스트림 요소의 기본 정렬 기준(Comparable)으로 정렬한다. 단, 스트림의 요소가 Comparable을 구현한 클래스가 아니면 예외가 발생한다. JDK 1.8부터 Comparator 인터페이스에 static 메서드와 디폴트 메서드가 많이 추가되었는데, 이 메서드들을 이용하면 정렬이 쉬워진다. 이 메서드들은 모두 Comparator&lt;T&gt;를 반환한다. 변환 - map()스트림의 요소에 저장된 값 중에서 원하는 필드만 뽑아내거나 특정 형태로 변환해야 할 때가 있다. 이 때 사용하는 것이 바로 map()이다. 이 메서드의 선언부는 아래와 같으며, 매개변수로 T타입을 R타입으로 변환해서 반환하는 함수를 지정해야한다. 1Stream&lt;R&gt; map(Function&lt;? super T,? extends R&gt; mapper) 조회 - peek()연산과 연산 사이에 올바르게 처리되었는지 확인하고 싶다면, peek()를 사용한다. forEach()와 달리 스트림의 요소를 소모하지 않으므로 연산 사이에 여러 번 끼워 넣어도 문제가 되지 않는다. filter()나 map()의 결과를 확인할 때 유용하게 사용될 수 있다. mapToInt(), mapToLong(), mapToDouble()map()은 연산의 결과로 Stream&lt;T&gt; 타입의 스트림을 반환하는데, 스트림의 요소를 숫자로 변환하는 경우 IntStream과 같은 기본형 스트림으로 변환하는 것이 더 유용할 수 있다. count()만 지원하는 Stream&lt;T&gt;와 달리 IntStream과 같은 기본형 스트림은 아래와 같이 숫자를 다루는데 편리한 메서드들을 제공한다. Int sum() : 스트림의 모든 요소의 총합 OptionalDouble average() : sum() / (double)count() OptionalInt max() : 스트림의 요소 중 제일 큰 값 OptionalInt min() : 스트림의 요소 중 제일 작은 값 위의 메서드들은 최종연산이기 때문에 호출 후 스트림이 닫힌다는 점을 주의해야 한다. sum()과 average()를 모두 호출해야할 때, 스트림을 또 생성해야하므로 불편하다. 그래서 summaryStatistics()라는 메서드가 따로 제공된다. 반대로 IntStream을 Stream&lt;T&gt;로 변환할 때는 mapToObj()를, Stream&lt;Integer&gt;로 변환할 때는 boxed()를 사용한다. 123IntStream intStream = new Random().ints(1, 46); // 1~45 사이의 정수Stream&lt;String&gt; lottoStream = intStream.distinct().limit(6).sorted().mapToObj(i -&gt; i + \",\");lottoStream.forEach(System.out::print); flatMap() - Stream&lt;T[]&gt;를 Stream&lt;T&gt;로 변환스트림의 요소가 배열이거나 map()의 연산결과가 배열인 경우, 즉 스트림의 타입이 Stream&lt;T[]&gt;인 경우, Stream&lt;T&gt;로 다루는 것이 더 편리할 때가 있다. 그럴 때는 map()대신 flatMap()을 사용하면 된다. 1234Stream&lt;String[]&gt; strArrStrm = Stream.of( new String[]{\"abc\", \"def\", \"ghi\"}, new String[]{\"ABC\", \"GHI\", \"JKLMN\"}); 1Stream&lt;String&gt; strStrm = strArrStrm.flatMap(Arrays::stream); 요소의 타입이 Stream&lt;String&gt;인 스트림(Stream&lt;Stream&lt;String&gt;&gt;)이 있을때, 이 스트림을 Stream&lt;T&gt;으로 변환하려면 다음과 같이 map()과 flatMap()을 함께 사용해야 한다. 123Stream&lt;String&gt; strStream = strStrm .map(s -&gt; s.toArray(String[]::new)) // Stream&lt;Stream&lt;String&gt;&gt; -&gt; Stream&lt;String[]&gt; .flatMap(Arrays::stream); // Stream&lt;String[]&gt; -&gt; Stream&lt;String&gt; toArray()는 스트림을 배열로 변환해서 반환한다. 매개변수를 지정하지 않으면 Object[]을 반환하므로 특정 타입의 생성자를 지정해줘야 한다. 위에서는 String배열의 생성자(String[]::new)를 지정하였다. Optional&lt;T&gt;와 OptionalInt최종 연산의 결과 타입이 Optional인 경우가 있다. Optional&lt;T&gt;은 지네릭 클래스로 ‘T타입의 객체’를 감싸는 래퍼 클래스이다. 그래서 Optional타입의 객체에는 모든 타입의 참조변수를 담을 수 있다. 1234public final class Optional&lt;T&gt; { private final T value; // T타입의 참조변수 ...} 최종 연산의 결과를 그냥 반환하는게 아니라 Optional 객체에 담아서 반환한다. 이처럼 객체에 담아서 반환을 하면, 반환된 결과가 null인지 매번 if문으로 체크하는 대신 Optional에 정의된 메서드를 통해서 간단히 처리할 수 있다. Objects클래스에 isNull(), nonNull(), requireNonNull()과 같은 메서드가 있는 것도 널 체크를 위한 if문을 메서드 안으로 넣어서 코드의 복잡도를 낮추기 위한 것이다. Optional 객체 생성하기Optional 객체를 생성할 때는 of() 또는 ofNullable()을 사용한다. 12String str = \"abc\";Optional&lt;String&gt; optVal = Optional.of(str); 만일 참조변수의 값이 null일 가능성이 있으면, of()대신 ofNullable()을 사용해야 한다. of()는 매개변수의 값이 null이면 NullPointerException을 발생하기 때문이다. Optional&lt;T&gt;타입의 참조변수를 기본값으로 초기화 할 때는 empty()를 사용한다. null로 초기화하는 것이 가능하지만, empty()로 초기화하는 것이 바람직하다. 12Optional&lt;String&gt; optVal = null; // null로 초기화Optional&lt;String&gt; optVal = Optional.&lt;String&gt;empty(); // 빈 객체로 초기화 Optional 객체의 값 가져오기123Optional&lt;String&gt; optVal = Optional.of(\"abc\");String str1 = optVal.get(); // optVal에 저장된 값을 반환. null이면 예외 발생String str2 = optVal.orElse(\"\"); // optVal에 저장된 값이 null일 때는, \"\"을 반환 orElse()의 변형으로 null을 대체할 값을 반환하는 람다식을 지정할 수 있는 orElseGet()과 null일 때 지정된 예외를 발생시키는 orElseThrow()가 있다. 12String str3 = optVal2.orElseGet(String::new); // () -&gt; new String()과 동일String str4 = optVal2.orElseThrow(NullPointerException::new); // null이면 예외 발생 Stream처럼 Optional 객체에도 filter()와 map(), 그리고 flatMap()을 사용할 수 있다. isPresent()는 Optional 객체의 값이 null이면 false를, 아니면 true를 반환한다. ifPresent()은 값이 있으면 주어진 람다식을 실행하고 , 없으면 아무 일도 하지 않는다. ifPresent()는 Optional&lt;T&gt;를 반환하는 findAny()나 findFirst()와 같은 최종 연산과 잘 어울린다. 스트림의 최종 연산최종 연산은 스트림의 요소를 소모해서 결과를 만들어낸다. 그래서 최종 연산후에는 스트림이 닫히게 되고 더 이상 사용할 수 없다. 최종 연산의 결과는 스트림 요소의 합과 같은 단일 값이거나, 스트림의 요소가 담긴 배열 또는 컬렉션일 수 있다. forEach()반환 타입이 void이므로 스트림의 요소를 출력하는 용도로 많이 사용된다. 1void forEach(Consumer&lt;? super T&gt; action) 조건 검사 - allMatch(), anyMatch(), noneMatch(), findFirst(), findAny()스트림의 요소에 대해 지정된 조건에 모든 요소가 일치하는지, 일부가 일치하는지 아니면 어떤 요소도 일치하지 않는지 확인하는데 사용할 수 있는 메서드들이다. 이 메서드들은 모두 매개변수로 Predicate를 요구하며, 연산결과로 boolean을 반환한다. 통계 - count(), sum(), average(), max(), min()IntStream과 같은 기본형 스트림에는 스트림의 요소들에 대한 통계 정보를 얻을 수 있는 메서드들이 있다. 대부분의 경우 위의 메서드를 사용하기보다 기본형 스트림으로 변환하거나 reduce()와 collect()를 사용해 통계 정보를 얻는다. 리듀싱 - reduce()스트림의 요소를 줄여나가면서 연산을 수행하고 최종결과를 반환한다. 처음 두 요소를 가지고 연산한 결과를 가지고 그 다음 요소와 연산한다. 그래서 매개변수의 타입이 BinaryOperator&lt;T&gt;인 것이다. 이 과정에서 스트림의 요소를 하나씩 소모하게 되며, 스트림의 모든 요소를 소모하게 되면 그 결과를 반환한다. 최종 연산 count()와 sum() 등은 내부적으로 모두 reduce()를 이용해서 작성되어 있다. 1234int count = intStream.reduce(0, (a,b) -&gt; a + 1); // count()int sum = intStream.reduce(0, (a,b) -&gt; a + b); // sum()int max = intStream.reduce(Integer.MIN_VALUE, (a,b) -&gt; a&gt;b ? a:b); // max()int min = intStream.reduce(Integer.MAX_VALUE, (a,b) -&gt; a&lt;b ? a:b); // min() Collect()collect()는 스트림의 요소를 수집하는 최종 연산으로 리듀싱(reducing)과 유사하다. collect()가 스트림의 요소를 수집하려면, 어떻게 수집할 것인가에 대한 방법이 정의되어 있어야 하는데, 이 방법을 정의한 것이 바로 컬렉터(collector)이다. 컬렉터는 Collector 인터페이스를 구현한 것으로, 직접 구현할 수도 있고 미리 작성된 것을 사용할 수도 있다. Collectors 클래스는 미리 작성된 다양한 종류의 컬렉터를 반환하는 static 메서드를 갖고 있다. collect() : 스트림의 최종연산, 매개변수로 컬렉터를 필요로 한다. Collector : 인터페이스, 컬렉터는 이 인터페이스를 구현해야 한다. Collectors : 클래스, static 메서드로 미리 작성된 컬렉터를 제공한다. 스트림을 컬렉션과 배열로 변환 - toList(), toSet(), toMap(), toCollection(), toArray()List나 Set이 아닌 특정 컬렉션을 지정하려면, toCollection()에 해당 컬렉션의 생성자 참조를 매개변수로 넣어주면 된다. 1234List&lt;String&gt; names = stuStream.map(Student::getName) .collect(Collectors.toList());ArrayList&lt;String&gt; list = names.stream() .collect(Collectors.toCollection(ArrayList::new)); Map은 키와 값의 쌍으로 저장해야하므로 객체의 어떤 필드를 키로 사용할지와 값으로 사용할지를 지정해줘야 한다. 1Map&lt;String, Person&gt; map = personStream.collect(Collectors.toMap(p-&gt;p.getRegId(), p-&gt;p)); 스트림에 저장된 요소들을 ‘T[]’ 타입의 배열로 변환하려면, toArray()를 사용하면 된다. 단, 해당 타입의 생성자 참조를 매개변수로 지정해줘야 한다. 만일 매개변수를 지정하지 않으면 반환되는 배열의 타입은 ‘Object[]’이다. 123Student[] stuNames = studentStream.toArray(Student[]::new); // OKStudent[] stuNames = studentStream.toArray(); // 에러Object[] stuNames = studentStream.toArray(); // OK 통계 - countint(), summingInt(), averagingInt(), maxBy(), minBy()최종 연산들이 제공하는 통계 정보를 collect()로 똑같이 얻을 수 있다. 리듀싱 - reducing()리듀싱 역시 collect()로 가능하다. 1234567IntStream intStream = new Random().ints(1, 46).distinct().limit(6);OptionalInt max = intStream.reduce(Integer::max);Optional&lt;Integer&gt; max = intStream.boxed().collect(reducing(Integer::max));long sum = intStream.reduce(0, (a, b) -&gt; a + b);long sum = intStream.boxed().collect(reducing(0, (a, b) -&gt; a + b)); 12int grandTotal = stuStream.map(Student::getTotalScore).reduce(0, Integer::sum);int grandTotal = stuStream.collect(reducing(0, Student::getTotalScore, Integer::sum)); 문자열 결합 - joining()문자열 스트림의 모든 요소를 하나의 문자열로 연결해서 반환한다. 구분자를 지정해줄 수도 있고, 접두사와 접미사도 가능하다. 스트림의 요소가 String이나 StringBuffer처럼 CharSequence의 자손인 경우에만 결합이 가능하므로 스트림의 요소가 문자열이 아닌 경우에는 먼저 map()을 이용해서 스트림의 요소를 문자열로 변환해야 한다. 만일 map()없이 스트림에 바로 joining()하면, 스트림의 요소에 toString()을 호출한 결과를 결합한다. 그룹화와 분할 - groupingBy, partitioningBy()그룹화는 스트림의 요소를 특정 기준으로 그룹화하는 것을 의미하고, 분할은 스트림의 요소를 두 가지, 지정된 조건에 일치하는 그룹과 일치하지 않는 그룹으로의 분할을 의미한다. 스트림을 두 개의 그룹으로 나눠야 한다면, partitioningBy()로 분할하는 것이 더 빠르다. 그 외에는 groupingBy()를 쓰면 된다. 그룹화와 분할의 결과는 Map에 반환된다. 참고 Java의 정석 - 2","link":"/2018/07/03/Java/java-lambda-stream/"},{"title":"멀티플렉싱 기반의 다중 접속 서버로 가기까지","text":"소켓이란?소켓은 네트워크 상에서 서버와 클라이언트 두개의 프로그램이 특정 포트를 통해 양방향 통신이 가능하도록 만들어주는 추상화된 장치입니다. 메모리의 유저 공간에 존재하는 프로세스(서버, 클라이언트)는 커널 공간에 생성된 소켓을 통해 데이터를 송수신할 수 있습니다. 소켓은 아래와 같이 지역(로컬) IP 주소, Port 번호와 상대방의 IP 주소와 Port 번호, 그리고 수신 버퍼와 송신 버퍼가 존재합니다. 서버와 클라이언트의 소켓이 서로 연결된 후, 데이터가 들어오면 수신 버퍼로 수신 데이터가 쓰이고, 반대로 데이터를 내 보낼 때는 송신 버퍼에 데이터가 쓰입니다. C언어로 간단한 서버 &amp; 클라이언트 구현C언어를 이용해 linux와 window에서 간단하게 소켓을 이용해 echo server와 client를 만들어 보겠습니다.코드 한줄 한줄을 전부 해석하기 보다는 주석을 참고해 server와 client에서 어떤 순서로 소켓이 만들어지고 통신이 이루어지는지에 중점을 두어 보겠습니다. linux“Everything is a File”라는 말이 있습니다. linux에서는 소켓도 하나의 파일(File), 더 정확히는 파일 디스크립터(File descriptor)로 생성되어 관리됩니다. 그러므로 저 수준 파일 입출력 함수를 기반으로 소켓 기반의 데이터 송수신이 가능합니다. 파일 디스크립터(File descriptor) 운영체제가 만든 파일을 구분하기 위한 일종의 숫자 저 수준 파일 입출력 함수는 입출력을 목적으로 파일 디스크립터를 요구한다. 저 수준 파일 입출력 함수에 소켓의 파일 디스크립터를 전달하면, 소켓을 대상으로 입출력을 진행한다. echo_server.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#define BUF_SIZE 1024void error_handling(char *message);int main(int argc, char *argv[]) { // 파일 디스크립터를 위한 변수 int serv_sock, clnt_sock; char message[BUF_SIZE]; int str_len, i; struct sockaddr_in serv_adr; struct sockaddr_in clnt_adr; socklen_t clnt_adr_sz; if (argc != 2) { printf(\"Usage : %s &lt;port&gt;\\n\", argv[0]); exit(1); } // 1. socket 하나를 생성한다. serv_sock = socket(PF_INET, SOCK_STREAM, 0); if (serv_sock == -1) error_handling(\"socket() error\"); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family = AF_INET; serv_adr.sin_addr.s_addr = htonl(INADDR_ANY); serv_adr.sin_port = htons(atoi(argv[1])); // 2. socket에 IP와 Port 번호를 할당한다. if (bind(serv_sock, (struct sockaddr*)&amp;serv_adr, sizeof(serv_adr)) == -1) error_handling(\"bind() error\"); // 3. server socket(listen socket)을 통해 클라이언트의 접속 요청을 대기한다. // 5개의 수신 대기열(큐)을 생성한다. if (listen(serv_sock, 5) == -1) error_handling(\"listen() error\"); clnt_adr_sz=sizeof(clnt_adr); for (i=0; i&lt;5; i++) { // 4. 클라이언트 접속 요청을 수락한다. (클라이언트와 연결된 새로운 socket이 생성된다.) clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_adr, &amp;clnt_adr_sz); if (clnt_sock == -1) error_handling(\"accept() error\"); else printf(\"Connected client %d \\n\", i+1); // 5. 클라이언트와 연결된 socket을 통해 데이터를 송수신한다. while((str_len=read(clnt_sock, message, BUF_SIZE)) != 0) write(clnt_sock, message, str_len); close(clnt_sock); } close(serv_sock); return 0;}void error_handling(char *message) { fputs(message, stderr); fputc('\\n', stderr); exit(1);} echo_client.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#define BUF_SIZE 1024void error_handling(char *message);int main(int argc, char *argv[]) { // 파일 디스크립터를 위한 변수 int sock; char message[BUF_SIZE]; int str_len; struct sockaddr_in serv_adr; if (argc != 3) { printf(\"Usage : %s &lt;IP&gt; &lt;port&gt;\\n\", argv[0]); exit(1); } // 1. socket 하나를 생성한다. sock = socket(PF_INET, SOCK_STREAM, 0); if (sock == -1) error_handling(\"socket() error\"); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family = AF_INET; serv_adr.sin_addr.s_addr = inet_addr(argv[1]); serv_adr.sin_port = htons(atoi(argv[2])); // 2. socket을 이용해 server의 server socket(listen socket)에 연결을 요청한다. if (connect(sock, (struct sockaddr*)&amp;serv_adr, sizeof(serv_adr)) == -1) error_handling(\"connect() error!\"); else puts(\"Connected...........\"); while(1) { fputs(\"Input message(Q to quit): \", stdout); fgets(message, BUF_SIZE, stdin); if (!strcmp(message,\"q\\n\") || !strcmp(message,\"Q\\n\")) break; // 3. 연결된 socket을 통해 server로부터 데이터를 송수신한다. write(sock, message, strlen(message)); str_len = read(sock, message, BUF_SIZE-1); message[str_len] = 0; printf(\"Message from server: %s\", message); } close(sock); return 0;}void error_handling(char *message) { fputs(message, stderr); fputc('\\n', stderr); exit(1);} 결과 확인gcc로 컴파일 후 실행하면 결과는 다음과 같습니다. windowwindow는 linux와 달리 파일이 아닌 별도의 소켓 구조체가 존재합니다. 별도의 소켓 구조체를 이용한 함수를 기반으로 소켓 기반의 데이터 송수신이 가능합니다.window 코드의 결과는 위의 linux 코드의 결과와 같으므로 생략합니다. echo_server_win.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;// window socket#include &lt;winsock2.h&gt;#define BUF_SIZE 1024void ErrorHandling(char *message);int main(int argc, char *argv[]) { WSADATA wsaData; SOCKET hServSock, hClntSock; char message[BUF_SIZE]; int strLen, i; SOCKADDR_IN servAdr, clntAdr; int clntAdrSize; if (argc != 2) { printf(\"Usage : %s &lt;port&gt;\\n\", argv[0]); exit(1); } if (WSAStartup(MAKEWORD(2, 2), &amp;wsaData) != 0) ErrorHandling(\"WSAStartup() error!\"); // 1. socket 하나를 생성한다. hServSock = socket(PF_INET, SOCK_STREAM, 0); if (hServSock == INVALID_SOCKET) ErrorHandling(\"socket() error\"); memset(&amp;servAdr, 0, sizeof(servAdr)); servAdr.sin_family = AF_INET; servAdr.sin_addr.s_addr = htonl(INADDR_ANY); servAdr.sin_port = htons(atoi(argv[1])); // 2. 생성한 socket을 server socket(listen socket)으로 등록한다. if (bind(hServSock, (SOCKADDR*)&amp;servAdr, sizeof(servAdr)) == SOCKET_ERROR) ErrorHandling(\"bind() error\"); // 3. server socket을 통해 클라이언트의 접속 요청을 확인한다. if (listen(hServSock, 5) == SOCKET_ERROR) ErrorHandling(\"listen() error\"); clntAdrSize=sizeof(clntAdr); for (i=0; i&lt;5; i++) { // 4. 클라이언트 접속 요청 대기 및 허락 (클라이언트와 연결된 새로운 socket이 생성된다.) hClntSock = accept(hServSock, (SOCKADDR*)&amp;clntAdr, &amp;clntAdrSize); if (hClntSock == -1) ErrorHandling(\"accept() error\"); else printf(\"Connected client %d \\n\", i+1); // 5. 클라이언트와 연결된 socket을 통해 데이터를 송수신한다. while((strLen=recv(hClntSock, message, BUF_SIZE, 0)) != 0) send(hClntSock, message, strLen, 0); closesocket(hClntSock); } closesocket(hServSock); WSACleanup(); return 0;}void ErrorHandling(char *message) { fputs(message, stderr); fputc('\\n', stderr); exit(1);} echo_client_win.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;// window socket#include &lt;winsock2.h&gt;#define BUF_SIZE 1024void ErrorHandling(char *message);int main(int argc, char *argv[]) { WSADATA wsaData; SOCKET hSocket; char message[BUF_SIZE]; int strLen; SOCKADDR_IN servAdr; if (argc != 3) { printf(\"Usage : %s &lt;IP&gt; &lt;port&gt;\\n\", argv[0]); exit(1); } if (WSAStartup(MAKEWORD(2, 2), &amp;wsaData) != 0) ErrorHandling(\"WSAStartup() error!\"); // 1. socket 하나를 생성한다. hSocket = socket(PF_INET, SOCK_STREAM, 0); if (hSocket == INVALID_SOCKET) ErrorHandling(\"socket() error\"); memset(&amp;servAdr, 0, sizeof(servAdr)); servAdr.sin_family = AF_INET; servAdr.sin_addr.s_addr = inet_addr(argv[1]); servAdr.sin_port = htons(atoi(argv[2])); // 2. socket을 이용해 server의 server socket(listen socket)에 연결을 요청한다. if (connect(hSocket, (SOCKADDR*)&amp;servAdr, sizeof(servAdr)) == SOCKET_ERROR) ErrorHandling(\"connect() error!\"); else puts(\"Connected...........\"); while(1) { fputs(\"Input message(Q to quit): \", stdout); fgets(message, BUF_SIZE, stdin); if (!strcmp(message,\"q\\n\") || !strcmp(message,\"Q\\n\")) break; // 3. 연결된 socket을 통해 server로부터 데이터를 송수신한다. send(hSocket, message, strlen(message), 0); strLen = recv(hSocket, message, BUF_SIZE-1, 0); message[strLen] = 0; printf(\"Message from server: %s\", message); } closesocket(hSocket); WSACleanup(); return 0;}void ErrorHandling(char *message) { fputs(message, stderr); fputc('\\n', stderr); exit(1);} 고찰linux와 window의 서버 &amp; 클라이언트 소켓 생성과 연결 과정은 다음과 같습니다. 서버 클라이언트로부터의 연결요청도 일종의 데이터 전송입니다. 따라서 연결 요청을 받아들이기 위해서도 하나의 소켓이 필요하고, 이 소켓을 가리켜 서버소켓 또는 리스닝 소켓이라고 합니다. listen 함수의 호출은 소켓을 리스닝 소켓으로 만듭니다. accept 함수의 결과로 서버소켓을 통해 클라이언트로부터의 연결요청을 받으면, 연결요청 정보를 참조하여 클라이언트 소켓과의 통신을 위한 별도의 소켓을 추가로 하나 더 생성합니다. 그리고 이렇게 생성된 소켓을 대상으로 데이터의 송수신이 진행됩니다. 클라이언트 소켓을 생성하고 연결 요청을 위해서 connect 함수를 호출하는 것이 전부입니다. 서버의 listen 함수호출 이후에야(서버소켓이 준비된 이후) connect 함수 호출이 유효합니다. 문제점위 예제의 경우 반복적(Iterable)으로 accept 함수를 호출하면, 계속해서 클라이언트의 연결요청을 수락할 수 있습니다. 그러나, 동시에 둘 이상의 클라이언트에게 서비스를 제공할 수 있는 상태는 아닙니다. (처음 소켓 연결을 맺은 클라이언트가 종료하기 전까지는 다른 클라이언트의 연결은 listen 큐에 들어가 대기해야합니다.) 이 문제를 해결하기 위해 둘 이상의 클라이언트들이 동시에 접속해 서버로부터 서비스를 제공받을 수 있는 여러 다중 접속 서버의 구현 방법들에 대해 알아보겠습니다. 다중 접속 서버 구현 방법 멀티프로세스 기반 서버 : 다수의 프로세스를 생성하는 방식으로 서비스를 제공한다. 멀티스레드 기반 서버 : 클라이언트의 수만큼 스레드를 생성하는 방식으로 서비스를 제공한다. 멀티플렉싱 기반 서버 : 입출력 대상을 묶어서 관리하는 방식으로 서비스를 제공한다. 멀티프로세스 기반의 다중 접속 서버멀티프로세스 기반의 다중 접속 서버는 다수의 프로세스를 생성하는 방식으로 서비스를 제공합니다. 부모 프로세스는 리스닝 소켓으로 accept 함수 호출을 통해서 연결요청을 수락합니다. 이때 얻게 되는 소켓의 파일 디스크립터(클라이언트와 연결된 연결 소켓)를 자식 프로세스를 생성해 넘겨줍니다. 자식 프로세스는 전달받은 파일 디스크립터를 바탕으로 서비스를 제공합니다. 핵심은 연결이 하나 생성될 때마다 프로세스를 생성해서 해당 클라이언트에 대해 서비스를 제공하는 것입니다. echo_multi_process_server.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#define BUF_SIZE 30void error_handling(char *message);void read_childproc(int sig);int main(int argc, char *argv[]) { int serv_sock, clnt_sock; struct sockaddr_in serv_adr, clnt_adr; pid_t pid; struct sigaction act; socklen_t adr_sz; int str_len, state; char buf[BUF_SIZE]; if (argc != 2) { printf(\"Usage : %s &lt;port&gt;\\n\", argv[0]); exit(1); } act.sa_handler = read_childproc; sigemptyset(&amp;act.sa_mask); act.sa_flags = 0; state = sigaction(SIGCHLD, &amp;act, 0); // 1. socket 하나를 생성한다. serv_sock = socket(PF_INET, SOCK_STREAM, 0); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family = AF_INET; serv_adr.sin_addr.s_addr = htonl(INADDR_ANY); serv_adr.sin_port = htons(atoi(argv[1])); // 2. socket에 IP와 Port 번호를 할당한다. if (bind(serv_sock, (struct sockaddr*) &amp;serv_adr, sizeof(serv_adr)) == -1) error_handling(\"bind() error\"); // 3. 생성한 socket을 server socket(listen socket)으로 등록한다. if (listen(serv_sock, 5) == -1) error_handling(\"listen() error\"); while(1) { adr_sz = sizeof(clnt_adr); // 4. 부모 프로세스는 리스닝 소켓으로 accept 함수 호출을 통해서 연결요청을 수락한다. clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_adr, &amp;adr_sz); if (clnt_sock == -1) continue; else puts(\"new client connected...\"); // 5. 이때 얻게 되는 소켓의 파일 디스크립터(클라이언트와 연결된 연결 소켓)를 자식 프로세스를 생성해 넘겨준다. pid = fork(); if (pid == -1) { close(clnt_sock); continue; } if (pid == 0) { close(serv_sock); // 6. 자식 프로세스는 전달받은 파일 디스크립터를 바탕으로 서비스를 제공한다. while((str_len = read(clnt_sock, buf, BUF_SIZE)) != 0) write(clnt_sock, buf, str_len); close(clnt_sock); puts(\"client disconnected...\"); return 0; } else close(clnt_sock); } close(serv_sock); return 0;}void read_childproc(int sig) { pid_t pid; int status; pid = waitpid(-1, &amp;status, WNOHANG); printf(\"removed proc id: %d \\n\", pid);}void error_handling(char *message) { fputs(message, stderr); fputc('\\n', stderr); exit(1);} 결과 확인위에서 Iterable하게 구현했을때 발생했던 문제를 각 클라이언트 요청마다 별도의 프로세스를 생성함으로써 문제를 해결한 것을 확인할 수 있습니다. 고찰 장점 프로그램 흐름이 단순하기 때문에 이해하기 쉽습니다. 안정적인 동작이 가능합니다. 운영체제에서 프로세스는 서로 독립된 실행 객체로 존재합니다. 서로 독립된 메모리 공간을 갖고 서로 다른 프로세스끼리 서로 영향을 미치지 않고 독립적으로 수행이 가능합니다. 단점 프로세스 복사에 따른 성능 문제가 있습니다. 병렬 처리해야 하는 만큼의 프로세스를 생성해야 합니다. fork에 의해 자식 프로세스가 생성될 경우, 부모 프로세스의 자원이 복사됩니다. (코드, 소켓을 포함한 모든 열린 파일들(파일 디스크립터)) 부모 프로세스로부터 accept되어 생성된 하나의 소켓에 대해 부모 프로세스와 자식 프로세스 모두에서 한 소켓에 대한 파일 디스크립터가 존재합니다. 따라서 두 파일 디스크립터를 모두 종료해야 해당 소켓을 제거할 수 있습니다. 서로 다른 독립적인 메모리 공간을 갖기 때문에 프로세스간 정보 교환이 어렵다. 위의 단점들은 각 클라이언트의 요청마다 프로세스가 아닌 스레드를 생성함으로써 해결할 수 있습니다.다음으로 멀티프로세스 기반의 다중 접속 서버의 단점을 개선할 수 있는 멀티스레드 기반의 다중 접속 서버에 대해 알아보겠습니다. 멀티스레드 기반의 다중 접속 서버멀티스레드 기반의 다중 접속 서버는 다수의 스레드를 생성하는 방식으로 서비스를 제공합니다. 메인 스레드는 리스닝 소켓으로 accept 함수 호출을 통해서 연결요청을 수락합니다. 이때 얻게 되는 소켓의 파일 디스크립터(클라이언트와 연결된 연결 소켓)를 별도의 워커 스레드를 생성해 넘겨줍니다. 워커 스레드는 전달받은 파일 디스크립터를 바탕으로 서비스를 제공합니다. 핵심은 연결이 하나 생성될 때마다 프로세스가 아닌 스레드를 생성해서 해당 클라이언트에 대해 서비스를 제공하는 것입니다. echo_multi_thread_server.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;signal.h&gt;#include &lt;sys/wait.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#include &lt;pthread.h&gt;#define BUF_SIZE 30void * handle_clnt(void * arg);void error_handling(char * msg);int main(int argc, char *argv[]) { int serv_sock, clnt_sock; struct sockaddr_in serv_adr, clnt_adr; pthread_t t_id; socklen_t adr_sz; int str_len, state; char buf[BUF_SIZE]; if (argc != 2) { printf(\"Usage : %s &lt;port&gt;\\n\", argv[0]); exit(1); } // 1. socket 하나를 생성한다. serv_sock = socket(PF_INET, SOCK_STREAM, 0); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family = AF_INET; serv_adr.sin_addr.s_addr = htonl(INADDR_ANY); serv_adr.sin_port = htons(atoi(argv[1])); // 2. socket에 IP와 Port 번호를 할당한다. if (bind(serv_sock, (struct sockaddr*) &amp;serv_adr, sizeof(serv_adr)) == -1) error_handling(\"bind() error\"); // 3. 생성한 socket을 server socket(listen socket)으로 등록한다. if (listen(serv_sock, 5) == -1) error_handling(\"listen() error\"); while(1) { adr_sz = sizeof(clnt_adr); // 4. 메인 스레드는 리스닝 소켓으로 accept 함수 호출을 통해서 연결요청을 수락한다. clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_adr, &amp;adr_sz); if (clnt_sock == -1) continue; puts(\"new client connected...\"); // 5. 클라이언트와 연결된 소켓의 파일 디스크립터를 워커 스레드를 생성해 넘겨준다. pthread_create(&amp;t_id, NULL, handle_clnt, (void*)&amp;clnt_sock); pthread_detach(t_id); } close(serv_sock); return 0;}void * handle_clnt(void * arg) { int clnt_sock=*((int*)arg); int str_len=0, i; char buf[BUF_SIZE]; // 6. 워커 스레드는 전달받은 파일 디스크립터를 바탕으로 서비스를 제공한다. while((str_len = read(clnt_sock, buf, BUF_SIZE)) != 0) write(clnt_sock, buf, str_len); close(clnt_sock); return NULL;}void error_handling(char * msg) { fputs(msg, stderr); fputc('\\n', stderr); exit(1);} 결과 확인처음 Iterable하게 구현했을때 발생했던 문제를 각 클라이언트 요청마다 별도의 스레드를 생성함으로써 문제를 해결했으며, 클라이언트의 요청마다 각 프로세스를 할당해서 해결한 방법보다 스레드를 생성해 할당함으로써 리소스 소모를 줄였습니다. 고찰 장점 프로세스 복사에 따른 비용보다 스레드 생성에 대한 비용이 적다. 스레드간 서로 공유하는 메모리를 갖기 때문에, 스레드간 정보 교환이 쉽다. 단점 하나의 프로세스 내의 다수의 스레드가 존재하기 때문에 하나의 스레드에서 문제가 생긴다면 프로세스에 영향을 미쳐 나머지 다수의 스레드에도 영향을 끼칠 수 있다. 각 클라이언트 요청마다 별도의 스레드를 생성함으로써 프로세스를 생성하던 방법보다 리소스의 비용을 줄일 수 있었고, 스레드들이 서로 공유하는 메모리를 가질 수 있는 환경이 되었습니다.그러나 I/O 멀티플렉싱(multiplexing) 기법을 사용한다면, 각 클라이언트 마다 별도의 스레드를 생성하는 것이 아닌 하나의 스레드에서 다수의 클라이언트에 연결된 소켓(파일 디스크립터)을 괸리하고 소켓에 이벤트(read/write)가 발생할 경우에만 별도의 스레드를 만들어 해당 이벤트를 처리하도록 구현할 수 있습니다. 멀티플렉싱 기반의 다중 접속 서버입출력 다중화란 하나의 프로세스 혹은 스레드에서 입력과 출력을 모두 다룰 수 있는 기술을 말합니다. 커널(kernel)에서는 하나의 스레드가 여러 개의 소켓(파일)을 핸들링 할 수 있는 select, poll, epoll과 같은 시스템 콜(system call)을 제공하고 있습니다. 한개의 프로세스 혹은 스레드에서 한개의 클라이언트에 대한 입출력만 처리할 수 있었던 이유는 입출력 함수가 봉쇄(block)되었기 때문에, 입출력 데이터가 준비될때까지 무한정 봉쇄되어 여러 클라이언트의 입출력을 처리할 수 없었기 때문입니다. 그러나 I/O 멀티플렉싱 기법을 사용하면 입출력 다중화에서도 입출력 함수는 여전히 봉쇄로 작동하지만, 입출력 함수를 호출하기전에 어떤 파일에서 입출력이 준비가 되었는지 확인할 수가 있습니다. 봉쇄 (block) 봉쇄를 이해하기 위해 먼저 두가지 짚고 넘어가야할 사항이 있습니다. 애플리케이션에서 I/O 작업을 하는 경우, 스레드는 데이터 준비가 완료될 때까지 대기합니다. 예를 들어 소켓을 통해 read(recvfrom)를 수행하는 경우 데이터가 네트워크를 통해 도착하는 것을 기다립니다. 패킷이 네트워크를 통해 도착하면 커널 내의 버퍼에 복사됩니다. (처음에 커널 공간에 생성된 소켓의 구조에서 송신 버퍼와 수신 버퍼가 있는 것을 보았습니다.) 커널 내의 버퍼에 복사된 데이터를 애플리케이션에서 사용하기 위해서는 커널 버퍼(kernel space)에서 유저 버퍼(user space)로 복사 후 이용해야 합니다. 애플리케이션은 유버 모드에서 유저 버퍼에만 접근이 가능하기 때문입니다. Blocking I/O Model프로세스(스레드)는 하나의 소켓에 대해 recvfrom을 호출하고 데이터가 kernel space 도착해 user space의 프로세스 버퍼에 복사 될 때까지 시스템 호출이 반환되지 않습니다. 즉 recvfrom은 kernel space에 데이터가 도착하길 기다리는것 부터 시작됩니다. 프로세스는 recvfrom을 호출할 때부터 반환 할 때까지 전체 프로세스가 봉쇄됩니다. I/O Multiplexing Model멀티플렉싱 모델에서는 select 함수를 호출해, 여러개의 소켓들 중 recvfrom이 가능한 소켓이 생길 때까지 대기합니다. select의 결과로 recvfrom을 호출할 수 있는 소켓의 목록이 반환되면, 해당 소켓들에 대해 recvfrom을 호출합니다. 봉쇄 모델(Blocking I/O model)에서는 하나의 프로세스(스레드)에서 하나의 소켓(파일 디스크립터)에 대해 recvfrom을 호출해 데이터가 kernel space에 도착했는지 확인하고 현재 읽을 수 있는 데이터가 없다면 봉쇄되어 대기했다면, 멀티플렉싱 모델(I/O Multiplexing Model)에서는 하나 이상의 소켓(파일 디스크립터)이 준비 될 때까지 대기할 수 있습니다. selectselect 방식은 이벤트(입력|출력|에러) 별로 감시할 파일들을 fd_set 이라는 파일 상태 테이블(fd 비트 배열)에 등록하고, 등록된 파일(파일 디스크립터)에 어떠한 이벤트가 발생했을 경우 fd_set을 확인하는 방식으로 동작합니다.예를 들어 위와 같이 6개의 파일을 다루어야 한다고 했을 때, 6개의 파일에 대해 입출력 데이터가 준비될 때까지 이벤트를 기다리는 파일 상태 테이블을 준비합니다. 그 후 6개의 파일 중 입출력이 준비된 파일에 대해서 이벤트가 발생하면 이벤트가 발생한 파일 디스크립터의 수를 반환합니다. 이후 이벤트가 준비된 파일에 대해 입출력을 수행하는데 이미 데이터가 준비된 파일에 대해 입출력을 수행하기 때문에 봉쇄가 발생하지 않을 것이라는게 보장됩니다. int select(int nfds, fd_set readfds, fd_set writefds, fd_set exceptfds, struct timeval timeout) nfds: 검사 대상이 되는 파일 디스크립터의 수 readfs: 읽기 이벤트를 검사할 파일 디스크립터의 목록 writefds: 쓰기 이벤트를 검사할 파일 디스크립터의 목록 exceptfds: 예외 이벤트를 검사할 파일 디스크립터의 목록 timeout: 이벤트를 기다릴 시간 제한 반환 값: 이벤트가 발생한 파일의 갯수 반환 값이 이벤트가 발생한 파일의 디스크립터 목록이 아닌 파일의 갯수임에 주의해야합니다. echo_select_server.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/time.h&gt;#include &lt;sys/select.h&gt;#define BUF_SIZE 100void error_handling(char *buf);int main(int argc, char *argv[]) { int serv_sock, clnt_sock; struct sockaddr_in serv_adr, clnt_adr; struct timeval timeout; // 파일 상태 테이블 선언 fd_set reads, cpy_reads; socklen_t adr_sz; int fd_max, str_len, fd_num, i; char buf[BUF_SIZE]; if (argc != 2) { printf(\"Usage : %s &lt;port&gt;\\n\", argv[0]); exit(1); } serv_sock = socket(PF_INET, SOCK_STREAM, 0); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family = AF_INET; serv_adr.sin_addr.s_addr = htonl(INADDR_ANY); serv_adr.sin_port = htons(atoi(argv[1])); if (bind(serv_sock, (struct sockaddr*) &amp;serv_adr, sizeof(serv_adr)) == -1) error_handling(\"bind() error\"); if (listen(serv_sock, 5) == -1) error_handling(\"listen() error\"); FD_ZERO(&amp;reads); // fd_set 테이블을 초기화한다. FD_SET(serv_sock, &amp;reads); // 서버 소켓(리스닝 소켓)의 이벤트 검사를 위해 fd_set 테이블에 추가한다. fd_max = serv_sock; while(1) { cpy_reads = reads; timeout.tv_sec = 5; timeout.tv_usec = 5000; // result // -1: 오류 발생 // 0: 타임 아웃 // 1 이상 : 등록된 파일 디스크립터에 해당 이벤트가 발생하면 이벤트가 발생한 파일 디스크립터의 수를 반환한다. if ((fd_num = select(fd_max+1, &amp;cpy_reads, 0, 0, &amp;timeout)) == -1) break; if (fd_num == 0) continue; for (i=0; i&lt;fd_max+1; i++) { if (FD_ISSET(i, &amp;cpy_reads)) { // fd_set 테이블을 검사한다. // 서버 소켓(리스닝 소켓)에 이벤트(연결 요청) 발생 if (i == serv_sock) { // connection request! adr_sz = sizeof(clnt_adr); clnt_sock= accept(serv_sock, (struct sockaddr*)&amp;clnt_adr, &amp;adr_sz); FD_SET(clnt_sock, &amp;reads); // fd_set 테이블에 클라이언트 소켓 디스크립터를 추가한다. if (fd_max &lt; clnt_sock) fd_max = clnt_sock; printf(\"connected client: %d \\n\", clnt_sock); } // 클라이언트와 연결된 소켓에 이벤트 발생 else { // read message! str_len = read(i, buf, BUF_SIZE); if (str_len == 0) { // close request! FD_CLR(i, &amp;reads); // fd_set 테이블에서 파일 디스크립터를 삭제한다. close(i); printf(\"closed client: %d \\n\", i); } else { write(i, buf, str_len); // echo! } } } } } close(serv_sock); return 0;}void error_handling(char *buf) { fputs(buf, stderr); fputc('\\n', stderr); exit(1);} 결과 확인 고찰 장점 단일 프로세스(스레드)에서 여러 파일의 입출력 처리가 가능합니다. 지원 하는 OS가 많아 이식성이 좋습니다. (POSIX 표준) 단점 커널에 의해서 완성되는 기능이 아닌, 순수하게 함수에 의해 완성되는 기능이다. select 함수의 호출을 통해서 전달된 정보는 커널에 등록되지 않은 것이며, 그래서 select 함수를 호출할 때마다 매번 관련 정보를 전달해야 합니다. select 함수의 호출 결과가 이벤트가 발생한 파일 디스크립터의 개수이기 때문에 어떤 파일 디스크립터에서 이벤트가 발생했는지 확인하기 위해서는 fd_set 테이블 전체를 검사해야 합니다. (속도가 느립니다) 검사할 수 있는 fd 개수에 제한이 있습니다. (최대 1024개) select 호출 때마다 데이터를 복사해야합니다. (select 함수를 호출한 후 이벤트를 처리할 때 fd_set 테이블 변경이 필요하기 때문에 미리 복사가 필요합니다) POSIX란? POSIX(Portable Operating System Interface)는 이식 가능 운영 체제 인터페이스의 약자로, 서로 다른 UNIX OS의 공통 API를 정리하여 이식성이 높은 유닉스 응용 프로그램을 개발하기 위한 목적으로 IEEE가 책정한 애플리케이션 인터페이스 규격입니다. pollpoll도 select와 마찬가지로 멀티플렉싱을 구현하기 위한 방법입니다. poll이 여러 개의 파일을 다루는 방법은 select와 마찬가지로 fd(파일 디스크립터)의 이벤트를 기다리다가 이벤트가 발생하면, poll에서의 block이 해제되고, 다음 루틴에서 어떤 fd에 이벤트가 발생했는지 검사하는 방식을 사용합니다. poll의 동작 원리는 select와 비슷하므로 생략합니다. 간단히 select와 비교해 차이점에 대해서만 알아보겠습니다. 장점 select와 단일 프로세스(스레드)에서 여러 파일의 입출력 처리가 가능합니다. select 방식처럼 표준 입력|출력|에러을 따로 감시할 필요가 없습니다. select는 timeval이라는 구조체를 사용해 타임아웃 값을 세팅하지만, poll은 별다른 구조체 없이 타임아웃 기능을 지원합니다. 단점 일부 unix 시스템에서는 poll을 지원하지 않습니다. epollepoll은 select 함수의 단점 극복을 위해 커널 레벨멀티플렉싱을 지원해줍니다. 커널에 관찰대상에 대한 정보를 한 번만 전달하고, 관찰대상의 범위, 또는 내용에 변경이 있을 때만 변경 사항을 알려줍니다. 리눅스에서는 epoll, 윈도우에서는 IOCP, 맥에서는 Kqueue가 이에 해당합니다. 12345678910111213141516int epoll_create(int size); //size는 epoll_fd의 크기정보를 전달한다.// 반환 값 : 실패 시 -1, 일반적으로 epoll_fd의 값을 리턴int epoll_ctl(int epoll_fd, // epoll_fd int operate_enum, // 어떤 변경을 할지 결정하는 enum값 int enroll_fd, // 등록할 fd struct epoll_event* event // 관찰 대상의 관찰 이벤트 유형 ); // 반환 값 : 실패 시 -1, 성공시 0int epoll_wait(int epoll_fd, // epoll_fd struct epoll_event* event, // event 버퍼의 주소 int maxevents, // 버퍼에 들어갈 수 있는 구조체 최대 개수 int timeout // select의 timeout과 동일 단위는 1/1000 );// 성공시 이벤트 발생한 파일 디스크립터 개수 반환, 실패시 -1 반환 epoll_create : epoll 파일 디스크립터 저장소 생성 epoll_ctl : 저장소에 파일 디스크립터 등록 및 삭제 epoll_wait : select 함수와 마찬가지로 파일 디스크립터의 변화를 대기한다. epoll_create를 통해 생성된 epoll 인스턴스에 관찰대상을 저장 및 삭제하는 함수가 epoll_ctl이고, epoll 인스턴스에 등록된 파일 디스크립터를 대상으로 이벤트의 발생 유무를 확인하는 함수가 epoll_wait이다. echo_epoll_server.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;// 리눅스에서만 사용 가능#include &lt;sys/epoll.h&gt;#define BUF_SIZE 100#define EPOLL_SIZE 50void error_handling(char *buf);int main(int argc, char *argv[]) { int serv_sock, clnt_sock; struct sockaddr_in serv_adr, clnt_adr; socklen_t adr_sz; int str_len, i; char buf[BUF_SIZE]; struct epoll_event *ep_events; struct epoll_event event; int epfd, event_cnt; if (argc != 2) { printf(\"Usage : %s &lt;port&gt;\\n\", argv[0]); exit(1); } serv_sock = socket(PF_INET, SOCK_STREAM, 0); memset(&amp;serv_adr, 0, sizeof(serv_adr)); serv_adr.sin_family = AF_INET; serv_adr.sin_addr.s_addr = htonl(INADDR_ANY); serv_adr.sin_port = htons(atoi(argv[1])); if (bind(serv_sock, (struct sockaddr*) &amp;serv_adr, sizeof(serv_adr)) == -1) error_handling(\"bind() error\"); if (listen(serv_sock, 5) == -1) error_handling(\"listen() error\"); // 커널이 관리하는 epoll 인스턴스라 불리는 파일 디스크립터의 저장소 생성 // 성공 시 epoll 파일 디스크립터, 실패시 -1 반환 epfd = epoll_create(EPOLL_SIZE); ep_events = malloc(sizeof(struct epoll_event)*EPOLL_SIZE); event.events = EPOLLIN; event.data.fd = serv_sock; // 파일 디스크립터(serv_sock)를 epoll 인스턴스에 등록한다. (관찰대상의 관찰 이벤트 유형은 EPOLLIN) epoll_ctl(epfd, EPOLL_CTL_ADD, serv_sock, &amp;event); while(1) { // 성공 시 이벤트가 발생한 파일 디스크립터이ㅡ 수, 실패 시 -1 반환 // 두 번째 인자로 전달된 주소의 메모리 공간에 이벤트 발생한 파일 디스크립터에 대한 정보가 들어있다. event_cnt = epoll_wait(epfd, ep_events, EPOLL_SIZE, -1); if (event_cnt == -1) { puts(\"epoll_wait() error\"); break; } for (i=0; i&lt;event_cnt; i++) { if (ep_events[i].data.fd == serv_sock) { adr_sz = sizeof(clnt_adr); clnt_sock= accept(serv_sock, (struct sockaddr*)&amp;clnt_adr, &amp;adr_sz); event.events = EPOLLIN; event.data.fd = clnt_sock; // 파일 디스크립터(clnt_sock)를 epoll 인스턴스에 등록한다. (관찰대상의 관찰 이벤트 유형은 EPOLLIN) epoll_ctl(epfd, EPOLL_CTL_ADD, clnt_sock, &amp;event); printf(\"connected client: %d \\n\", clnt_sock); } else { str_len = read(ep_events[i].data.fd, buf, BUF_SIZE); if (str_len == 0) { // close request! epoll_ctl(epfd, EPOLL_CTL_DEL, ep_events[i].data.fd, NULL); close(ep_events[i].data.fd); printf(\"closed client: %d \\n\", ep_events[i].data.fd); } else { write(ep_events[i].data.fd, buf, str_len); // echo! } } } } close(serv_sock); close(epfd); return 0;}void error_handling(char *buf) { fputs(buf, stderr); fputc('\\n', stderr); exit(1);} 결과 확인 고찰 장점 상태변화의 확인을 위한, 전체 파일 디스크립터를 대상으로 하는 반복문이 필요 없습니다. select 함수에 대응하는 epoll_wait 함수호출 시, 커널에서 상태정보를 유지하기 때문에 관찰대상의 정보를 매번 전달할 필요가 없습니다. 단점 리눅스의 select 기반 서버를 윈도우의 select 기반 서버로 변경하는 것은 간단하나, 리눅스의 epoll 기반의 서버를 윈도우의 IOCP 기반으로 변경하는 것은 select를 이용하는 것보다 번거롭습니다. 참고 I/O Models I/O Multiplexing: The select and poll Functions 뇌를 자극하는 TCP/IP 소켓 프로그래밍","link":"/2019/02/28/Java/java-with-non-blocking-io/"},{"title":"[번역] Java Reactor Pattern","text":"해당 글은 아래의 Reactor Pattern Explained 시리즈를 번역하였습니다. Reactor Pattern Explained - Part 1 Reactor Pattern Explained - Part 2 Reactor Pattern Explained - Part 3 Part 1서버가 동시에 요청(이벤트)을 받을 때, 보통 요청을 처리하기 위한 이벤트 리스너를 각 스레드마다 할당해 처리하곤 합니다.123456789101112131415161718192021222324class Server implements Runnable { public void run() { try { ServerSocket ss = new ServerSocket(PORT); while (!Thread.interrupted()) new Thread(new Handler(ss.accept())).start(); // or, single-threaded, or a thread pool } catch (IOException ex) { } }} class Handler implements Runnable { final Socket socket; Handler(Socket s) { socket = s; } public void run() { try { byte[] input = new byte[MAX_INPUT]; socket.getInputStream().read(input); byte[] output = process(input); socket.getOutputStream().write(output); } catch (IOException ex) { } } private byte[] process(byte[] cmd) { }} 요청마다 처리를 위해 이벤트 리스너를 별도의 스레드로 만들어 사용하는 것의 단점은 컨텍스트 전환(context switching)의 오버 헤드가 크다는 것입니다. 최악의 경우, 데이터를 자주 읽거나 쓰지 않는 이벤트 리스너를 처리하는 일부 스레드는 유용한 작업을 하지 않고 주기적으로 컨텍스트를 전환할 것입니다. 스케줄러가 이러한 스레드를 CPU에 디스패치(dispatch) 할 때마다 I/O 이벤트가 발생할 때까지 스레드는 차단되어 I/O 이벤트를 기다리는 데 소비되는 모든 시간이 낭비됩니다. 위의 코드에서 ss.accept()는 클라이언트가 연결될 때까지 서버 스레드를 차단하는 블로킹 호출입니다. 서버 스레드는 ss.accept() 호출이 반환 될 때까지 이벤트 리스너를 위한 새로운 스레드의 start() 메서드를 호출 할 수 없습니다. 불필요한 컨텍스트 전환으로 인한 CPU 시간 낭비를 줄이기 위해 non-blocking I/O 개념이 탄생했습니다. Reactor Pattern은 이 문제를 해결하기 위한 이벤트 처리(event handling) 디자인 패턴입니다. 하나의 Reactor가 계속 이벤트를 찾고 이벤트가 발생(trigger)하면 해당 이벤트 처리기(event handler)에게 이를 알립니다. 자바는 non-blocking 시스템을 설계하는 데 사용할 수 있는 표준 API (java.nio)를 제공합니다. 클라이언트가 서버로 이름(데이터)을 보내면 서버는 Hello 메시지로 응답하는 간단한 예제를 통해 Reactor 패턴에 대해서 알아보겠습니다. Reactor 패턴의 아키텍처에는 두 가지 중요한 참여자가 있습니다. Reactor: Reactor는 별도의 스레드에서 실행되며 발생한 I/O 이벤트는 dispatching되어 해당 이벤트 처리기로 보내 처리합니다. Handlers: Handler는 Reactor로부터 I/O 이벤트를 받아 실제 작업을 수행합니다. java.nio 패키지를 이용해서 Reactor 패턴을 구현할 것이기 때문에 nio 패키지에 속한 몇가지 class에 대한 이해가 필요합니다. Channels: 소켓을 통해 non-blocking read를 할 수 있도록 지원하는 connection. Buffers: 채널에 의해 직접 read되거나 write될 수 있는 배열과 같은 객체. Selectors: Selector 는 어느 channel set 이 IO event 를 가지고 있는지를 알려준다. Selector.select() 는 I/O 이벤트가 발생한 채널 set을 return한다. return할 channel이 없다면 계속 기다리게(block) 된다. 이 block된 것을 바로 return 시켜주는 것이 Selector.wakeup()이다.Selector.selectedKeys()는 Selection Key 를 return 해 준다. Reactor는 이 Selection Key를 보고 어떤 handler로 넘겨줄 지를 결정한다. Selection Keys: Selector와 Channel간의 관계를 표현해주는 객체이다. Selector가 제공한 Selection Key를 이용해 Reactor는 채널에서 발생하는 I/O 이벤트로 수행할 작업을 선택할 수 있다. ServerSocketChannel에 selector를 등록하면 key를 준다. 이 key가 SelectionKey 이다. Selector는 계속해서 I/O 이벤트가 발생하기를 대기합니다. Reactor가 Selector.select() 메소드를 호출하면 Selector는 등록된 채널에 대해서 발생한 이벤트 정보가 들어있는 SelectionKey Set을 반환합니다. (SelectionKey는 해당 채널과 Selector와의 관계에 대한 모든 정보를 갖고 있습니다. 또한 Handler에 대한 정보도 갖고 있습니다.) Selector에 등록된 하나의 ServerSocketChannel이 있습니다. ServerSocketChannel은 클라이언트에서 들어오는 연결 요청으로부터 이벤트를 수신해야합니다. 클라이언트가 연결을 요청할 때, ServerSocketChhannel은 I/O 이벤트를 받아 클라이언트에 SocketChannel을 할당해야 합니다. SelectionKey0은 ServerSocketChannel을 가지고 무엇을 해야하는지에 대한 이벤트 정보를 갖고 있습니다. SocketChhannel을 만들기 위해서는 Reactor가 SelectionKey0의 이벤트를 Acceptor에 전달해 Acceptor가 클라이언트와의 연결 요청을 수락하고 SocketChannel을 만들도록 해야합니다. Acceptor가 클라이언트1의 연결을 수락하면 클라이언트1에 대한 SocketChannel이 생성됩니다. 이 SocketChannel역시 Selector에 등록되고 해당 채널에서 이벤트가 발생하면 해당 이벤트에 대한 정보를 포함한 SelectionKey1을 반환합니다. 이 SelectionKey1을 이용해서 해당 채널로부터 데이터를 읽고 쓸 수 있습니다. 따라서 SelectionKey1은 읽기와 쓰기를 처리하는 Handler1 객체에 바인딩 됩니다. 이후로 Reactor가 Selector.selector()를 호출했을 때 반환된 SelectionKey Set에 SelectionKey1이 있으면 SocketChannel1이 이벤트와 함께 트리거됨을 의미합니다. 이제 SelectionKey1을 보면, Reactor는 Handler1이 SelectionKey1에 바인딩되어 있으므로 Handler1에 이벤트를 전달해야한다는 것을 알고 있습니다. 반환 된 SelectionKey Set에 SelectionKey0이 있으면 ServerSocketChannel이 다른 클라이언트에서 이벤트를 수신했으며 SelectionKey0을 보고 Reactor는 해당 이벤트를 다시 Acceptor에 전달해야 함을 알고 있습니다. 이벤트가 Acceptor에 전달되면 클라이언트2에 대해 SocketChannel2를 만들고 SelectionKey2로 Selector로 SocketChannel2를 등록합니다. 따라서 이 시나리오에서는 3가지 유형의 이벤트에 관심이 있습니다. accept 해야하는 ServerSocketChannel에서 트리거되는 연결 요청 이벤트. 클라이언트로 부터 송신된 데이터를 수신할 수 있을 때, SocketChannel로부터 트리거 되는 이벤트. 서버에서 클라이언트로 데이터를 송신할 때, 송신할 수 있는 준비가 되면 SocketChannel로부터 트리거 되는 이벤트. 그럼 스레드 풀은 이 작업과 어떤 관련이 있을까요? non-blocking 아키텍처의 장점은 클라이언트의 모든 요청을 처리하는 동시에 단일 스레드에서 실행되도록 서버를 작성할 수 있다는 것입니다. 서버를 설계하는 데 동시성 개념을 적용하지 않으면 이벤트에 대한 반응성이 떨어집니다. 단일 스레드일 때는 reactor가 이벤트를 handler에 전달해 처리될 때 까지는 다른 이벤트에 응답할 수 없기 때문입니다. 왜냐하면 하나의 스레드를 사용하여 모든 이벤트를 처리하기 때문입니다. 위의 아키텍처에 동시성을 추가해서 시스템의 응답 속도를 향상시킬 수 있습니다. Reactor가 이벤트를 Handler에 전달하고 새로운 Thread에서 Handler를 이용해 이벤트를 처리하면 Reacgtor는 계속해서 다른 이벤트에 응답할 수 있습니다. 또한 스레드 풀을 이용하면 시스템의 스레드 수를 제한하면서 더 효율적으로 사용할 수 있을 것 입니다. Part 2간단한 Reactor 패턴의 예시를 살펴보겠습니다. 클라이언트는 서버로 이름을 넣은 메시지를 전송하고 서버는 클라이언트에 Hello 메시지로 응답합니다. 스레드 풀은 Part3에서 살펴보겠습니다. 클라이언트는 java.nio를 사용하여 Socket을 생성하지 않고 java.net.Socket을 사용합니다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Client { String hostIp; int hostPort; public Client(String hostIp, int hostPort) { this.hostIp = hostIp; this.hostPort = hostPort; } public void runClient() throws IOException { Socket clientSocket = null; PrintWriter out = null; BufferedReader in = null; try { clientSocket = new Socket(hostIp, hostPort); out = new PrintWriter(clientSocket.getOutputStream(), true); in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); } catch (UnknownHostException e) { System.err.println(\"Unknown host: \" + hostIp); System.exit(1); } catch (IOException e) { System.err.println(\"Couldn't connect to: \" + hostIp); System.exit(1); } BufferedReader stdIn = new BufferedReader(new InputStreamReader(System.in)); String userInput; System.out.println(\"Client connected to host : \" + hostIp + \" port: \" + hostPort); System.out.println(\"Type (\\\"Bye\\\" to quit)\"); System.out.println(\"Tell what your name is to the Server.....\"); while ((userInput = stdIn.readLine()) != null) { out.println(userInput); // Break when client says Bye. if (userInput.equalsIgnoreCase(\"Bye\")) break; System.out.println(\"Server says: \" + in.readLine()); } out.close(); in.close(); stdIn.close(); clientSocket.close(); } public static void main(String[] args) throws IOException { Client client = new Client(\"127.0.0.1\", 9900); client.runClient(); }} 서버는 Reactor 패턴을 이용해 구현합니다.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Reactor implements Runnable { final Selector selector; final ServerSocketChannel serverSocketChannel; final boolean isWithThreadPool; Reactor(int port, boolean isWithThreadPool) throws IOException { this.isWithThreadPool = isWithThreadPool; selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(port)); serverSocketChannel.configureBlocking(false); SelectionKey selectionKey0 = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); selectionKey0.attach(new Acceptor()); } public void run() { System.out.println(\"Server listening to port: \" + serverSocketChannel.socket().getLocalPort()); try { while (!Thread.interrupted()) { selector.select(); Set selected = selector.selectedKeys(); Iterator it = selected.iterator(); while (it.hasNext()) { dispatch((SelectionKey) (it.next())); } selected.clear(); } } catch (IOException ex) { ex.printStackTrace(); } } void dispatch(SelectionKey k) { Runnable r = (Runnable) (k.attachment()); if (r != null) { r.run(); } } class Acceptor implements Runnable { public void run() { try { SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel != null) { if (isWithThreadPool) new HandlerWithThreadPool(selector, socketChannel); else new Handler(selector, socketChannel); } System.out.println(\"Connection Accepted by Reactor\"); } catch (IOException ex) { ex.printStackTrace(); } } }} Reactor는 Runnable을 구현하고 있으며, run() 메서드에서는 while 루프를 돌며 selector.select()를 호출하여 처리할 수 있는 이벤트 정보가 담긴 SelectionKey Set을 가져옵니다. SelectionKey에 바인드 되어있는 Handler를 가져와 dispatch합니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class Handler implements Runnable { final SocketChannel socketChannel; final SelectionKey selectionKey; ByteBuffer input = ByteBuffer.allocate(1024); static final int READING = 0, SENDING = 1; int state = READING; String clientName = \"\"; Handler(Selector selector, SocketChannel c) throws IOException { socketChannel = c; c.configureBlocking(false); selectionKey = socketChannel.register(selector, 0); selectionKey.attach(this); selectionKey.interestOps(SelectionKey.OP_READ); selector.wakeup(); } public void run() { try { if (state == READING) { read(); } else if (state == SENDING) { send(); } } catch (IOException ex) { ex.printStackTrace(); } } void read() throws IOException { int readCount = socketChannel.read(input); if (readCount &gt; 0) { readProcess(readCount); } state = SENDING; // Interested in writing selectionKey.interestOps(SelectionKey.OP_WRITE); } /** * Processing of the read message. This only prints the message to stdOut. * * @param readCount */ synchronized void readProcess(int readCount) { StringBuilder sb = new StringBuilder(); input.flip(); byte[] subStringBytes = new byte[readCount]; byte[] array = input.array(); System.arraycopy(array, 0, subStringBytes, 0, readCount); // Assuming ASCII (bad assumption but simplifies the example) sb.append(new String(subStringBytes)); input.clear(); clientName = sb.toString().trim(); } void send() throws IOException { System.out.println(\"Saying hello to \" + clientName); ByteBuffer output = ByteBuffer.wrap((\"Hello \" + clientName + \"\\n\").getBytes()); socketChannel.write(output); selectionKey.interestOps(SelectionKey.OP_READ); state = READING; }} Handler에는 READING, SENDING 2가지 상태가 있습니다. 채널은 한 번에 하나의 작업만 지원하기 때문에 동시에 처리할 수 없습니다. Handler가 SelectionKey에 어떻게 attach 되는지와 관심있는 연산이 OP_READ로 설정되는 부분에 유의해야합니다. Selector는 Read 이벤트가 발생할 때만 SelectionKey를 select해야 합니다. READ 프로세스가 완료되면 Handler는 상태를 SENDING으로 변경하고 관심 대상 연산을 OP_WRITE로 변경합니다. 이제 Selector는 채널이 데이터를 전송할 준비가 되었을 때 SelectionKey를 select 합니다. Write 이벤트가 Handler에 dispatch될 때, 상태가 SENDING이므로 Hello 메시지를 출력 버퍼에 씁니다. 전송이 완료되면 관심있는 작업을 OP_READ로 다시 변경하면서 Handler의 상태가 READING으로 변경됩니다. 결과적으로 서버는 단일 스레드에서 실행되지만 서버에 연결하는 클라이언트 수에 상관없이 응답합니다. Part 3이번 파트에서는 Handler의 스레드 풀에 대해서 설명합니다. HandlerWithThreadPool은 Handler 클래스의 확장 버전입니다. 123456789101112131415161718192021222324252627282930313233343536public class HandlerWithThreadPool extends Handler { static ExecutorService pool = Executors.newFixedThreadPool(2); static final int PROCESSING = 2; public HandlerWithThreadPool(Selector sel, SocketChannel c) throws IOException { super(sel, c); } void read() throws IOException { int readCount = socketChannel.read(input); if (readCount &gt; 0) { state = PROCESSING; pool.execute(new Processer(readCount)); } // We are interested in writing back to the client soon after read processing is done. selectionKey.interestOps(SelectionKey.OP_WRITE); } // Start processing in a new Processer Thread and Hand off to the reactor thread. synchronized void processAndHandOff(int readCount) { readProcess(readCount); // Read processing done. Now the server is ready to send a message to the client. state = SENDING; } class Processer implements Runnable { int readCount; Processer(int readCount) { this.readCount = readCount; } public void run() { processAndHandOff(readCount); } }} PROCESSING이 새로 도입되었으며 read() 메서드가 override 되었습니다. 이제 Read 이벤트가 Handler에 dispatch되면 데이터를 읽지만 상태를 SENDING으로 변경하지는 않습니다. 메시지를 처리하고 스레드 풀의 다른 스레드에서 실행하고 관련 작업을 OP_WRITE로 설정하는 Processer를 생성합니다. 이 시점에서 채널에 Write 준비가 되어 있더라도 Handler는 아직 PROCESSING 상태이기 때문에 write하지 않습니다. 참고Reactor Pattern 에 대해 알아보자","link":"/2019/03/05/Java/java-reactor-pattern/"},{"title":"NoSuchMethodException & NoSuchMethodError 해결하기","text":"애플리케이션에서 사용하는 라이브러리의 버전을 업데이트하거나 혹은 새로운 라이브러리를 추가하는 과정에서 종종 NoSuchMethodError을 마주하게 된다.이번에는 NoSuchMethodErrors 대한 내용과 해결하는 방법에 대해서 알아보자. NoSuchMethodErrorsNoSuchMethodErrors는 런타임(runtime) 시점에 존재하지 않는 메서드(method)를 호출하는 경우에 발생한다.일반적으로 존재하지 않는 메서드를 사용하려는 경우 컴파일(compile) 시점에 컴파일러가 에러를 발생시킨다. 그런데 런타임 시점에 에러가 발생했다는 말은 즉, 컴파일때는 해당 메서드가 존재했지만 런타임 시점에 찾을 수 없었다는 것을 의미한다. 원인NoSuchMethodErrors가 발생하는 일반적인 상황에 대해서 좀 더 알아보자. 라이브러리 Breaking ChangeNoSuchMethodErrors가 발생하는 원인 중 하나는 애플리케이션에서 사용하는 라이브러리 중 하나가 한 버전에서 다음 버전으로 변경될 때, Breaking Change를 포함하는 경우이다.Breaking Change란 라이브러리가 제공하던 API에 변경 사항이 있음을 의미한다. API가 사라진다던가 return type 혹은 parameters가 변경되는 경우들이 있다. 그러나, 위에서도 이야기한 것처럼 일반적으로 존재하지 않는 메서드를 사용하려는 경우 컴파일 시점에 컴파일러가 에러를 발생시키는데 어떻게 런타임 시점에 에러가 발생할 수 있는 것일까? 최근에는 SpringBoot로 애플리케이션을 개발하고 Tomcat 자체를 포함해 fatjar(uberjar)로 패키징(packaging) 후 배포해서 jar 파일을 실행하는 것으로 애플리케이션을 실행하는 것이 자연스럽게 여겨진다. Embeded Tomcat을 사용하지 않았던 때를 생각해보자. Spring 애플리케이션을 개발하고 war로 패키징한 후, Tomcat이 설치된 폴더 아래의 webapps에 war를 배포 후 Tomcat을 재기동 하는 것으로 애플리케이션을 실행했었다. 이것이 의미하는 것이 무엇일까? Servlet Container인 Tomcat과 함게 애플리케이션이 실행되고 있는 런타임 시점에 HTTP 요청이 들어오면 Tomcat은 해당 요청에 대한 HttpServletRequest와 HttpServletResponse를 만들고 우리가 작성한 Spring 애플리케이션 코드를 실행한다.우리는 애플리케이션 코드에서 Tomcat으로부터 전달받은 HttpServletRequest와 HttpServletResponse를 사용하는데, 개발하는 시점에 Spring 애플리케이션에서는 HttpServletRequest와 HttpServletResponse를 어떻게 사용할 수 있는 것일까? Gradle을 사용한다면 build.gradle을, Maven을 사용하고 있다면 pom.xml을 확인해보자. 다음과 같이 HttpServletRequest와 HttpServletResponse를 포함하고 있는 javax.servlet-api 라이브러리를 포함하고 있을 것이다. 12// ex) build.gradlecompileOnly(&quot;javax.servlet:javax.servlet-api:3.0.1&quot;) 다만 implementation 혹은 api가 아닌 compileOnly를 사용해서 의존성을 선언하고 있다. 이것이 의미하는 것은 애플리케이션을 작성하고 컴파일 시점까지만3.0.1 버전의 javax.servlet-api를 사용하겠다는 것이다. 그 후 컴파일이 완료되고 Tomcat에 의해서 애플리케이션이 실행되는 런타임 시점에는 Tomcat에 의해 classpath에 포함된 javax.servlet-api를 사용하게 된다. Tomcat은 버전에 따라 사용하는 Servlet 버전이 다르다. 따라서 Spring 애플리케이션에서 compileOnly 의존성으로 사용하고 있는 Servlet 라이브러리의 버전과 실제 애플리케이션이 구동되는 Tomcat에서 사용하는 버전에 차이가 있다면 생각과는 다르게 동작할 수 있는 가능성이 있는 것이다. Apache Tomcat Versions 만약 Spring 애플리케이션의 Servlet 버전을 3.0 버전에 맞춰 개발하고 있었는데 애플리케이션이 실행되는 Tomcat이 6.0.x(Servlet 버전 2.5) 혹은 8.0.x(Servlet 버전 3.1)이라면 의도치 않은 Breaking Change를 겪게될 수 있는 것이다. 라이브러리 버전 Overriding다른 원인으로는 라이브러리 버전 Overriding 문제가 있다. 다음을 가정해보자. 애플리케이션에서 라이브러리 A를 사용하고 있다. 라이브러리 A는 다른 라이브러리 B에 대해 의존성(dependency)를 갖고 있다. 애플리케이션에서 라이브러리 B를 직접 호출하지는 않지만 라이브러리 B를 사용하기 때문에 A까지 포함되게 되는데 이때, 라이브러리 B는 해당 애플리케이션에 대해 전이 의존성(transitive dependency)이라고 부른다. 이 경우, 만약 라이브러리 B를 이용하는 또 다른 라이브러리 C가 있고 이를 애플리케이션에서 사용하고 있다면 build system에 의해 버전 충돌로 인한 문제가 발생할 수 있다. 애플리케이션 &lt;- 라이브러리 A &lt;- 라이브러리 B (버전 1.x) 애플리케이션 &lt;- 라이브러리 C &lt;- 라이브러리 B (버전 2.x) Gradle과 Maven 같은 빌드 시스템은 이와 같은 버전 충돌 문제가 발생했을 때, 두 버전 중 하나를 선택하게 된다. 위의 예시에서 라이브러리 B의 2.x 버전을 선택하게 되었을 때, 라이브러리 C에서는 문제가 발생하지 않지만 라이브러리 A에서는 문제가 발생할 수 있다. (라이브러리 B가 버전 1.x와 2.x 사이에 Breaking Change가 존재할 수 있기 때문이다.) 해결책크게 3단계로 해결할 수 있다. 문제의 Class 찾기먼저 문제의 메서드를 포함하는 클래스를 찾아야한다. NoSuchMethodError 로그로부터 쉽게 찾을 수 있다.12Exception in thread \"main\" java.lang.NoSuchMethodError: com.jongmin.example.Service.hello(Ljava/lang/String;)Ljava/lang/String; 클래스를 찾았다면 검색 혹은 사용하고 있는 IDE를 통해서 해당 클래스가 포함된 JAR(라이브러리)를 찾을 수 있다. Class 호출하는 곳 찾기다음으로 메서드를 호출하는 위치를 찾아야 한다. 이 정보는 에러 로그의 stack trace를 이용해 찾을 수 있다.123Exception in thread \"main\" java.lang.NoSuchMethodError: com.jongmin.example.Service.hello(Ljava/lang/String;)Ljava/lang/String; at com.jongmin.example.NoSuchMethod.main(ProvokeNoSuchMethodError.java:7) 위의 로그에서는 NoSuchMethod 클래스가 런타임에 존재하지 않는 hello 메서드를 호출하려고 하는 것을 확인할 수 있다. 이제 해당 클래스가 속한 라이브러리를 찾아야한다. 버전 확인이제 NoSuchMethodError가 발생하는 위치와 런타임 시점에 존재하지 않는 메서드를 알았으므로 해결할 수 있다. 현재 프로젝트의 모든 dependency를 출력해보자. Gradle을 사용하고 있다면 다음의 명령어를 사용한다.1./gradlew dependencies &gt; dependencies.txt Maven을 사용한다면 다음의 명령어를 사용한다.1mvn dependency:list &gt; dependencies.txt dependencies.txt 파일을 확인하면 런타임 시점에 존재하지 않는 메서드와 이를 호출하는 클래스가 포함 된 라이브러리를 찾을 수 있다. 예를 들면, 다음과 같은 출력 결과를 확인할 수 있다.12\\--- org.springframework.data:spring-data-commons:1.8.2.RELEASE| \\--- org.springframework:spring-core:3.2.10.RELEASE -&gt; 4.3.20.RELEASE (*) 위의 결과를 보면 spring-data-commons 라이브러리가 3.2.10 버전의 spring-core에 의존하지만 다른 라이브러리도 버전 4.3.20의 spring-core에 의존하고 있어 3.2.10 버전이 4.3.2 버전으로 Overriding된 것이다. 그럼 이제 어떤 라이브러리가 spring-core 4.3.2 버전 라이브러리에 의존하고 있는지 찾을 수 있다. 마지막으로 spring-core 라이브러리의 두 버전 중 어떤 버전이 spring-core를 필요로하는 두 라이브러리의 종속성을 만족시키는지 확인하고 결정해야 한다. 일반적이라면 안정적인 라이브러리라면 업데이트 되더라도 하위 호환성(backward compatibility)를 유지하기 때문에 최신 버전을 사용하면 될 것이다. NoSuchMethodExceptionNoSuchMethodException은 NoSuchMethodError와 관련이 있지만 다른 context에서 발생한다. NoSuchMethodError는 JAR 파일이 컴파일 시점과 런타임 시점에 다른 버전을 갖는 경우 발생한다. 반면 NoSuchMethodException은 reflection을 이용해 존재하지 않는 메서드를 사용하려고하면 발생한다. 예를 들면, 다음과 같은 코드이다.1String.class.getMethod(\"notExist\");","link":"/2019/12/05/Java/nosuchmethod/"},{"title":"Mockito annotation을 사용하는 field 초기화 하기","text":"Mockito JUnit ruleMockito에서 제공하는 @Mock, @Spy, @InjectMocks과 같은 annotation을 사용하는 field를 초기화 하는 방법으로는 2가지가 제공되고 있었다. JUnit test class에 @RunWith(MockitoJUnitRunner.class)를 추가하는 방법 1234567891011@RunWith(MockitoJUnitRunner.class)public class MockitoTest { @Mock private List list; @Test public void shouldDoSomething() { list.add(100); }} MockitoAnnotations.initMocks(Object)을 @Before 메서드에서 실행하는 방법 123456789101112131415public class MockitoTest { @Before public void setup() { MockitoAnnotations.initMocks(this); } @Mock private List list; @Test public void shouldDoSomething() { list.add(100); }} 그리고 추가로 Mockito 1.10.17 버전부터 제공하는 JUnit rule을 이용하는 방법이 있다.12345678910111213public class MockitoTest { @Rule public MockitoRule mockito = MockitoJUnit.rule(); @Mock private List list; @Test public void shouldDoSomething() { list.add(100); }} 그럼 위의 3가지 방법 중 어떤 방법을 사용하는 것이 좋을까? 먼저, 3가지 방식들을 비교하기전에 Test Runner, @RunWith, Rule에 대해서 간단하게 알아보자. Test RunnerJUnit 프레임워크에서 테스트 클래스 내에 존재하는 각각의 테스트 메소드 실행을 담 당하고 있는 클래스를 Test Runner라고 한다. Test Runner는 테스트 클래스의 구조에 맞게 테스트 메소드들을 실행하고 결과를 표시하는 역할을 수행한다. 우리 눈에는 보이지 않지만, 테스트 케이스를 IDE에서 실행하면 내부적으로 는 JUnit의 BlockJUnit4ClassRunner라는 Test Runner 클래스가 실행되고, IDE는 그 결과를 해석해서 우리에게 보기 편한 화면으로 보여준다. 대부분의 Java 통합개발환경(IDE)은 JUnit 프레임워크를 내장 지원하고 있다. 그래서 종종 JUnit이 독립적인 프레임워크라기보다는 하나의 기능처럼 생각될 수 있다. 하지만 JUnit 프레임워크는 분명 독립적인 소프트웨어이고, 애초부터 그렇게 만들어 졌다. 그렇기 때문에 명령행 프롬프트에서 실행하거나 셸 스크립트 등을 이용해서 실행할 수도 있다. @RunWith@RunWith annotation은 JUnit에 내장된 기본 테스트 러너인 BlockJUnit4ClassRunner 대신에 @RunWith(클래스이름.class)를 이용해 JUnit Test 클래스를 실행하기 위한 Test Runner를 명시적으로 지정할 수 있다. 지정된 클래스를 이용해 테스트 클래스 내의 테스트 메소드들을 수행하도록 지정해주는 annotation이다. 일종의 JUnit 프레임워크의 확장지점이다. 이런 구조를 이용해서 많은 애플리케이션이나 프레임워크가 자신에게 필요한 Test Runner를 직접 만들어 자신만의 고유한 기능을 추가해 테스트를 수행하고 있다. 예를 들면, 스프링 프레임워크에서 제공하는 SpringJUnit4ClassRunner, SpringRunner같은 클래스는 이 확장 기능을 이용한 대표적인 사례 중 하나다. RuleJUnit 4.7 버전부터 추가된 기능으로 하나의 테스트 클래스 내에서 각 테스트 메소드의 동작 방식을 재정의하거나 추가하기 위해 사용하는 기능이다. 테스트 케이스 수행을 좀 더 세밀하게 조작할 수 있게 된다. 결론MockitoJUnit의 rule을 사용하면 MockitoJUnitRunner와 똑같은 기능을 수행하면서, 다른 Test Runner를 사용할 수 있다. 사용하고 있는 Mockito의 버전이 1.10.17, JUnit 버전이 4.7 이상이라면 @RunWith가 아닌 MockitoJUnit의 rule을 사용해서 Mockito annotation을 사용하는 field를 초기화 하자 참고 @RunWith(MockitoJUnitRunner.class) vs MockitoAnnotations.initMocks(this)","link":"/2019/02/10/Java/mockito-anotation-field-initialize/"},{"title":"Reactive Streams (1)","text":"Reactive Streams 란?reactive-streams.org 에서는 Reactive Streams를 다음과 같이 정의하고 있다. Reactive Streams is an initiative to provide a standard for asynchronous stream processing with non-blocking back pressure. Reactive Streams란 non-blocking과 back pressure를 이용한 asynchronous 스트림 처리의 표준이다. 중요한 키워드가 여러개 등장 했는데, 먼저 back pressure에 대해서 알아보자. Back PressureBack Pressure는 Reactive Streams에서 가장 중요한 요소라고 할 수 있다. Back Pressure가 등장하게 된 배경을 이해하기 위해서 먼저 옵저버 패턴을 이해하고 옵저버 패턴이 갖고 있는 문제점을 인식할 수 있어야한다. Observable &amp; Observer 옵저버 패턴(observer pattern) 은 객체의 상태 변화를 관찰하는 관찰자들, 즉 옵저버들의 목록을 객체에 등록하여 상태 변화가 있을 때마다 메서드 등을 통해 객체가 직접 목록의 각 옵저버에게 통지하도록 하는 디자인 패턴이다. 주로 분산 이벤트 핸들링 시스템을 구현하는 데 사용된다. 발행/구독 모델로 알려져 있기도 하다. 옵저버 패턴 - 위키백과 예를 들면, 안드로이드에서 Button이 클릭되었을 때 실행할 함수를 onclicklistener에 추가하는데 이와 같이 이벤트 핸들링 처리를 위해 사용되는 패턴이다. 이 패턴에는 Observable과 Observer가 등장한다. Osbservable: 등록된 Observer들을 관리하며, 새로운 데이터(이벤트)가 들어오면 등록된 Observer에게 데이터를 전달한다. 데이터를 생성해서 전달하기 때문에 Publisher(발행)라고 부른다. Observer: Observable로 부터 데이터(이벤트)를 받을 수 있다. 데이터를 전달 받기 때문에 Subscriber(구독)라고 부른다. Java는 이미 JDK 1.0 부터 옵저버 패턴을 쉽게 구현할 수 있는 인터페이스를 제공하고 있다. 아래의 코드는 JDK 1.0에 포함된 Observable과 Observer 인터페이스를 사용해 만든 간단한 예시 코드이다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4jpublic class Ob { // Source -&gt; Event/Data -&gt; Observer static class IntObservable extends Observable implements Runnable { @Override public void run() { for (int i = 1; i &lt;= 10; i++) { setChanged(); notifyObservers(i); // push } } } public static void main(String[] args) { Observer ob = new Observer() { @Override public void update(Observable o, Object arg) { log.info(\"{}\", arg); } }; IntObservable io = new IntObservable(); io.addObserver(ob); ExecutorService es = Executors.newSingleThreadExecutor(); es.execute(io); log.info(\"EXIT\"); es.shutdown(); }}- 실행결과01:47:30.715 [main] INFO com.jongmin.reactive.practice.Ob - EXIT01:47:30.715 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 101:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 201:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 301:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 401:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 501:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 601:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 701:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 801:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 901:47:30.719 [pool-1-thread-1] INFO com.jongmin.reactive.practice.Ob - 10 문제점옵저버 패턴에서는 Publisher(Observable)이 Subscriber(Observer)에게 데이터(이벤트)를 Push(notifyObservers)하는 방식으로 전달한다. 이때, Publisher는 Subscriber의 상태에 상관없이 데이터를 전달하는데만 집중한다. 만약, Subscriber는 1초에 10개의 데이터를 처리할 수 있는데 Publisher가 1초에 20개의 데이터를 전달(Push)한다면 어떤 문제가 발생할까? 다음과 같은 문제가 발생할 수 있다. Subscriber에 별도의 queue(버퍼)를 두고 처리하지 않고 대기중인 데이터를 저장할 수 있다. 하지만, queue의 사용 가능한 공간도 전부 금방 소모될 것이다. queue의 크기를 넘어가게 되면 데이터는 소실될 것이다. queue의 크기를 너무 크게 생성하면 OOM(Out Of Memory) 문제가 발생할 수 있다. 해결 방법Observable과 Observer의 문제를 어떻게 해결할 수 있을까? Publisher가 Subscriber에게 데이터를 Push 하던 기존의 방식을 Subscriber가 Publisher에게 자신이 처리할 수 있는 만큼의 데이터를 Request하는 방식으로 해결할 수 있다. 필요한(처리할 수 있는) 만큼만 요청해서 Pull하는 것이다. 데이터 요청의 크기가 Subscriber에 의해서 결정되는 것이다. 이를 dynamic pull 방식이라 부르며, Back Pressure의 기본 원리이다. Reactive Streams APIReactive Streams는 표준화된 API이다. 2013년 netflix, pivotal, lightbend의 엔지니어들에 의해서 처음 시작되어, 2015 4월에 JVM에 대한 1.0.0 스펙이 릴리즈 되었다.Java 9부터는 reactive streams이 java.util.concurrent의 패키지 아래 Flow라는 형태로 JDK에 포함되었다. 기존에 reactive streams가 가진 API와 스펙, pull방식을 사용하는 원칙을 그대로 수용하였다. 아래는 Reactive Streams API이다.123456789101112131415public interface Publisher&lt;T&gt; { public void subscribe(Subscriber&lt;? super T&gt; s);}public interface Subscription { public void request(long n); public void cancel();}public interface Subscriber&lt;T&gt; { public void onSubscribe(Subscription s); public void onNext(T t); public void onError(Throwable t); public void onComplete();} 실제로 보면 굉장히 간단한 API들의 조합으로 이루어져 있다. Publisher: Subscriber를 받아들이는 subscribe 메서드 하나만 갖는다. Subscriber: 데이터를 받아 처리할 수 있는 onNext, 에러를 처리하는 onError, 모든 데이터를 받아 완료되었을 때는 onComplete, 그리고 Publisher로부터 Subscription을 전달 받는 onSubscribe 메서드로 이루어진다. Subscription: n개의 데이터를 요청하는 request와 구독을 취소하는 cancel을 갖는다. 전체적인 흐름은 다음과 같다. Subscriber가 Publisher에게 구독을 요청한다. Publisher는 Subscriber의 onSubscribe 메서드를 통해 Subscription을 전달한다. Subscriber는 Publisher에게 직접 데이터를 요청하지 않고 Subscription을 통해 요청한다. Publisher는 Subscription을 통해 onNext에 데이터를 전달하고 완료되면 onComplete, 에러가 발생하면 onError에 전달한다. Example마지막으로 Reactive Streams API를 간단하게 구현해 테스트 해보자. Reactive Streams API의 Interface는 간단해 보이지만 이를 구현한 구현체는 Reactive Streams Specification을 만족해야만 한다. 구현체가 Specification을 만족하는지는 Reactive Streams TCK(Technology Compatibility Kit)라는 도구를 이용해 검증할 수 있다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Slf4jpublic class PubSub { public static void main(String[] args) { Iterable&lt;Integer&gt; iter = Arrays.asList(1, 2, 3, 4, 5); Publisher p = new Publisher() { @Override public void subscribe(Subscriber subscriber) { Iterator&lt;Integer&gt; it = iter.iterator(); subscriber.onSubscribe(new Subscription() { @Override public void request(long n) { while(n-- &gt; 0) { if (it.hasNext()) { subscriber.onNext(it.next()); } else { subscriber.onComplete(); break; } } } @Override public void cancel() { log.info(\"cancel\"); } }); } }; Subscriber&lt;Integer&gt; s = new Subscriber&lt;Integer&gt;() { Subscription subscription; @Override public void onSubscribe(Subscription subscription) { log.info(\"onSubscribe\"); this.subscription = subscription; this.subscription.request(1); } @Override public void onNext(Integer item) { log.info(\"onNext: {}\", item); this.subscription.request(1); } @Override public void onError(Throwable t) { log.info(\"onError\"); } @Override public void onComplete() { log.info(\"onComplete\"); } }; p.subscribe(s); }}- 실행결과00:19:08.655 [main] INFO com.jongmin.reactive.practice.PubSub - onSubscribe00:19:08.660 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 100:19:08.662 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 200:19:08.663 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 300:19:08.663 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 400:19:08.663 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 500:19:08.663 [main] INFO com.jongmin.reactive.practice.PubSub - onComplete","link":"/2019/11/05/Java/reactive-1/"},{"title":"Reactive Streams (2)","text":"지난번 Reactive Streams API를 구현한 예제를 바탕으로 간단한 Operator를 만들어보자. Operator라 함은 Stream의 map연산 처럼 Publisher가 제공하는 data를 가공할 수 있도록 하는 것이다. 먼저 간단한 Publisher와 Subscriber 코드이다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Slf4jpublic class PubSub { public static void main(String[] args) { Publisher&lt;Integer&gt; pub = iterPub(Stream.iterate(1, a -&gt; a + 1) .limit(5) .collect(Collectors.toList())); pub.subscribe(logSub()); } private static Publisher&lt;Integer&gt; iterPub(List&lt;Integer&gt; iter) { return new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber sub) { sub.onSubscribe(new Subscription() { @Override public void request(long n) { iter.forEach(i -&gt; sub.onNext(i)); sub.onComplete(); } @Override public void cancel() { } }); } }; } private static Subscriber&lt;Integer&gt; logSub() { return new Subscriber&lt;Integer&gt;() { @Override public void onSubscribe(Subscription s) { log.info(\"onSubscribe\"); s.request(Long.MAX_VALUE); } @Override public void onNext(Integer i) { log.info(\"onNext: {}\", i); } @Override public void onError(Throwable t) { log.info(\"onError\", t); } @Override public void onComplete() { log.info(\"onComplete\"); } }; }}- 실행결과23:32:28.255 [main] INFO com.jongmin.reactive.practice.PubSub - onSubscribe23:32:28.260 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 123:32:28.262 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 223:32:28.262 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 323:32:28.262 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 423:32:28.262 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 523:32:28.262 [main] INFO com.jongmin.reactive.practice.PubSub - onComplete OperatorPublisher -&gt; [Data1] -&gt; Operator -&gt; [Data2] -&gt; Subscriber 위와 같이 Data1을 Data2로 변환하는 Operator를 만들어보자. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Slf4jpublic class PubSub { public static void main(String[] args) { Publisher&lt;Integer&gt; pub = iterPub(Stream.iterate(1, a -&gt; a + 1) .limit(5) .collect(Collectors.toList())); Publisher&lt;Integer&gt; mapPub = mapPub(pub, s -&gt; s * 10); // iterrPub -&gt; [Data1] -&gt; mapPub -&gt; [Data2] -&gt; logSub mapPub.subscribe(logSub()); } private static Publisher&lt;Integer&gt; mapPub(Publisher&lt;Integer&gt; pub, Function&lt;Integer, Integer&gt; f) { return new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { pub.subscribe(new Subscriber&lt;Integer&gt;() { @Override public void onSubscribe(Subscription s) { sub.onSubscribe(s); } @Override public void onNext(Integer i) { sub.onNext(f.apply(i)); } @Override public void onError(Throwable t) { sub.onError(t); } @Override public void onComplete() { sub.onComplete(); } }); } }; } private static Publisher&lt;Integer&gt; iterPub(List&lt;Integer&gt; iter) { ... ... ... } private static Subscriber&lt;Integer&gt; logSub() { ... ... ... }}- 실행결과23:45:19.758 [main] INFO com.jongmin.reactive.practice.PubSub - onSubscribe23:45:19.764 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 1023:45:19.767 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 2023:45:19.767 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 3023:45:19.767 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 4023:45:19.767 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 5023:45:19.767 [main] INFO com.jongmin.reactive.practice.PubSub - onComplete mapPub 메서드가 추가되었다. Data를 제공하는 Publisher와 가공에 사용할 Function을 받아 Operator(새로운 Publisher)를 반환한다. 실제 하는 일은 단순하다. 기존 Publisher와 Subscriber를 이어준다. Operator가 기존 Publisher를 subscribe하고, 받게되는 Subscription을 기존 Subscriber에게 전달한다. DelegateSubOperator가 하는 일은 기존 Publisher와 Subscriber를 이어주면서, onNext 부분에서 전달받은 Function을 적용해주는 것 뿐이다. onNext를 제외하고는 Operator 마다 코드가 반복될 수 있기 때문에 해당 부분을 DelegateSub으로 분리해보자. 12345678910111213141516171819202122232425262728public class DelegateSub implements Subscriber&lt;Integer&gt; { Subscriber sub; public DelegateSub(Subscriber sub) { this.sub = sub; } @Override public void onSubscribe(Subscription s) { sub.onSubscribe(s); } @Override public void onNext(Integer i) { sub.onNext(i); } @Override public void onError(Throwable t) { sub.onError(t); } @Override public void onComplete() { sub.onComplete(); }} DelegateSub을 사용해서 기존 코드를 다음과 같이 수정할 수 있다. 필요한 onNext 메서드만 오버라이딩해서 사용한다.123456789101112131415161718192021222324252627282930313233343536@Slf4jpublic class PubSub2 { public static void main(String[] args) { Publisher&lt;Integer&gt; pub = iterPub(Stream.iterate(1, a -&gt; a + 1) .limit(5) .collect(Collectors.toList())); Publisher&lt;Integer&gt; mapPub = mapPub(pub, s -&gt; s * 10); mapPub.subscribe(logSub()); } private static Publisher&lt;Integer&gt; mapPub(Publisher&lt;Integer&gt; pub, Function&lt;Integer, Integer&gt; f) { return new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { pub.subscribe(new DelegateSub(sub) { @Override public void onNext(Integer i) { sub.onNext(f.apply(i)); } }); } }; } private static Publisher&lt;Integer&gt; iterPub(List&lt;Integer&gt; iter) { ... ... ... } private static Subscriber&lt;Integer&gt; logSub() { ... ... ... }} SubPub이번에는 Publisher로부터 전달받은 Data를 전부 더하는 sum operation을 만들어보자. 기존 Publisher와 Subscriber를 onNext로 이어주지 않고, onComplete이 호출되었을 때, sum 값을 onNext로 전달한 뒤 onComplete을 호출해 종료한다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Slf4jpublic class PubSub2 { public static void main(String[] args) { Publisher&lt;Integer&gt; pub = iterPub(Stream.iterate(1, a -&gt; a + 1) .limit(5) .collect(Collectors.toList())); Publisher&lt;Integer&gt; sumPub = sumPub(pub); sumPub.subscribe(logSub()); } private static Publisher&lt;Integer&gt; sumPub(Publisher&lt;Integer&gt; pub) { return new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { pub.subscribe(new DelegateSub(sub) { int sum = 0; @Override public void onNext(Integer i) { sum += i; } @Override public void onComplete() { sub.onNext(sum); sub.onComplete(); } }); } }; } private static Publisher&lt;Integer&gt; iterPub(List&lt;Integer&gt; iter) { ... ... ... } private static Subscriber&lt;Integer&gt; logSub() { ... ... ... }}- 실행결과00:30:48.643 [main] INFO com.jongmin.reactive.practice.PubSub - onSubscribe00:30:48.648 [main] INFO com.jongmin.reactive.practice.PubSub - onNext: 1500:30:48.650 [main] INFO com.jongmin.reactive.practice.PubSub - onComplete","link":"/2019/11/07/Java/reactive-2/"},{"title":"0. 라즈베리파이 강의 소개","text":"오랜만에 포스팅을 하는 것 같습니다. 그간 회사에서 운이 좋게 3주간 보조 강사로 강의를 할 수 있는 기회를 얻어 강의를 하고 있습니다. 신기하게도 제가 졸업한 인천대학교에서 강의를 하고있습니다. 강의 주제는 라즈베리파이에 음성인식 서비스(STT, TTS)와 GPIO를 활용해 나만의 비서를 만들기 입니다. 라즈베리파이 같은 경우 이전에 친구들과 스마트미러를 만들며 사용했던 경험이 있었기에 낯설지 않았지만, 강의를 준비하고 강의자료를 만들면서 생각보다 여러가지로 고난을 겪었습니다… 단순히 발표자료가 아닌 누군가에게 지식을 잘 전달할 수 있도록 만들어야 하다보니 생각보다 만드는게 쉽지 않았습니다. 그래도 혹시나 필요하신 분이 있을까 하여 만들었던 강의자료를 공개합니다. 파이썬 관련된 부분은 책을 많이 참고하였기에 생략하고 라즈베리파이와 GPIO, 그리고 음성인식 프레임워크로 사용했던 Jasper에 대한 강의자료를 업로드하겠습니다. 다음은 강의 목차입니다. - 라즈베리파이 강의 목차 - 라즈베리파이 OS 설치 &amp; 설정 Unix / Linux 소개 사용자 관리, 원격접속 vi 편집기 bash 설정, vim 설정, gist 사용하기 GPIO, LED, BreadBoard Extra GPIO Jasper 앞으로 강의에 대한 간단한 내용정리와 사용한 pdf 파일을 업로드하도록 하겠습니다.","link":"/2017/07/06/RaspberryPi/0-Intro/"},{"title":"2. Unix / Linux 소개","text":"강의 내용 훑어보기이번 강의는 운영체제(OS), 커널, 쉘, Unix &amp; Linux, 간단한 명령어 실습에 대한 내용을 다루고 있습니다. 1. 운영체제(OS), 커널, 쉘Unix와 Linux에 대해 알아보기 전 간단히 운영체제(OS), 커널, 쉘의 역할과 정의에 대해서 알아봅니다. 2. Unix &amp; LinuxUnix의 역사와 Linux가 만들어지게 된 배경에 대해 설명하고, 리눅스의 특징에 대해 설명합니다. 3. 간단한 명령어 실습Unix와 Linux의 디렉터리 계층 구조를 살펴보고 terminal을 통해 자주 사용되는 명령어를 실습합니다.","link":"/2017/07/09/RaspberryPi/2-unix-linux/"},{"title":"3. 사용자 관리, 원격접속 vi 편집기","text":"강의 내용 훑어보기이번 강의는 사용자 관리(추가 &amp; 삭제), 원격접속(VNC, SSH), vi 편집기에 대한 내용을 다루고 있습니다. 1. 사용자 관리(추가 &amp; 삭제)Unix와 Linux에서 사용자를 추가하고 삭제해보며, sudoers 파일을 수정해 root 권한을 사용할 수 있도록 수정해 봅니다. 2. 원격접속(VNC, SSH)GUI 환경으로 작업이 가능한(VNC)와 CUI 환경인 SSH 접속을 통해 원격으로 라즈베리파이를 다룰 수 있는 실습을 합니다. 3. vi 편집기IDE(통합 개발 환경)와 vi(편집기)의 공통점과 차이점에 대해 알아보고 vimtutor.txt 파일을 통해 vi 실습을 합니다.","link":"/2017/07/10/RaspberryPi/3-user-management/"},{"title":"5. GPIO, LED, BreadBoard","text":"강의 내용 훑어보기이번 강의는 GPIO, LED, BreadBoard에 대한 내용을 다루고 있습니다. 1. GPIOGPIO의 정의와 작동원리에 대해 알아봅니다. 2. LED파이썬을 이용해서 간단하게 LED를 켜고 끄는 실습을 합니다. 3. BreadBoard(빵판)BreadBoard(빵판)의 원리에 대해 알아본 후 여러개의 LED를 갖고 실습을 합니다.","link":"/2017/07/10/RaspberryPi/5-gpio_led_breadboard/"},{"title":"1. 라즈베리파이 OS 설치 & 설정","text":"강의 내용 훑어보기이번 강의는 아두이노와 라즈베리파이 비교, 라즈베리파이에 OS(라즈비안) 설치, 라즈베리파이 설정(인터넷, 한글)에 대한 내용을 다루고 있습니다. 1. 아두이노와 라즈베리파이 비교아두이노와 라즈베리파이는 서로의 연관검색어 상단에서 볼 수 있는 만큼 유사한점이 많지만 다른점이 분명히 있습니다. 아두이노와 라즈베리파이의 다른점에 대해 알아보고 언제 어떤것을 사용하는것이 효율적일지 알아봅니다. 2. 라즈베리파이에 OS(라즈비안) 설치라즈베리파이에 라즈비안을 설치합니다. 설치 시 NOOBS 프로그램을 통해 더욱 간편하게 OS를 설치할 수 있습니다. 3. 라즈베리파이 설정(인터넷, 한글)라즈베리파이3는 라즈베리파이2와 달리 무선 LAN 카드를 내장하고 있기 때문에 기존 모델과 달리 Wifi 동글을 사용하지 않아도 Wifi 사용이 가능합니다. 간편하게 GUI 상에서 Wifi 설정하는 법을 알아보고 학교와 같은 고정IP를 사용해야 하는 경우에도 대비해 고정IP 설정하는 법을 알아봅니다. 추가적으로 라즈비안을 처음 설치했을 경우 한글폰트가 설치되어있지 않기 때문에 한글 폰트 설치 및 언어 설정을 합니다.","link":"/2017/07/07/RaspberryPi/1-os-install/"},{"title":"Reactive Streams (3)","text":"“Reactive Streams란 non-blocking과 back pressure를 이용한 asynchronous 스트림 처리의 표준이다.” 라고 지난 글에서 이야기 했다. 이번에는 asynchronous(비동기 처리)에 대해서 이야기해보자. 먼저 아래 간단한 코드를 실행해보자. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Slf4jpublic class SchedulerEx { public static void main(String[] args) { Publisher&lt;Integer&gt; pub = new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { sub.onSubscribe(new Subscription() { @Override public void request(long n) { sub.onNext(1); sub.onNext(2); sub.onNext(3); sub.onNext(4); sub.onNext(5); sub.onComplete(); } @Override public void cancel() { } }); } }; Subscriber&lt;Integer&gt; sub = new Subscriber&lt;Integer&gt;() { @Override public void onSubscribe(Subscription s) { log.info(\"onSubscribe\"); s.request(Long.MAX_VALUE); } @Override public void onNext(Integer integer) { log.info(\"onNext: {}\", integer); } @Override public void onError(Throwable t) { log.info(\"onError\", t); } @Override public void onComplete() { log.info(\"onComplete\"); } }; pub.subscribe(sub); log.info(\"Exit)\"; }}- 실행결과23:27:45.475 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onSubscribe23:27:45.480 [main] INFO com.jongmin.reactive.practice.SchedulerEx - request: 922337203685477580723:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 123:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 223:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 323:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 423:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 523:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - onComplete23:27:45.484 [main] INFO com.jongmin.reactive.practice.SchedulerEx - exit subscriber를 publisher에 등록(subscribe)하고 처리(onSubscribe -&gt; request -&gt; next)가 끝나면 exit 로그를 마지막으로 종료된다. 이때 subscriber와 publisher의 진행은 모두 main 스레드에서 진행된다.즉, subscriber를 등록 후 publisher가 데이터를 push하고 처리할 때까지 main 스레드를 붙잡고 있게 된다.만약 publisher 혹은 subscriber의 처리가 지연된다면 main 스레드는 더욱 오래 사용해야 할 것이다. 결국 publisher에 subscriber를 등록하면 별도의 스레드에서 진행하고 main 스레드는 계속해서 다른 작업을 진행하기를 원하는 것이다. publishOn먼저 publisher가 main 스레드가 아닌 별도의 스레드에서 동작하도록 만들어보자.12345678910private static Publisher&lt;Integer&gt; publishOn(Publisher&lt;Integer&gt; pub) { return new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { Executors.newSingleThreadExecutor().execute(() -&gt; { pub.subscribe(sub); }); } };} 파라미터로 전달받은 publisher의 subscribe 메서드를 별도의 스레드에서 실행하도록 하는 publisher를 새로 만들어서 반환한다. publishOn 메서드를 기존의 publisher에 적용해 실행하면 다음과 같이 실행결과를 확인할 수 있다. 12345678910- 실행결과23:55:57.820 [main] INFO com.jongmin.reactive.practice.SchedulerEx - exit23:55:57.820 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onSubscribe23:55:57.824 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - request: 922337203685477580723:55:57.827 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 123:55:57.827 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 223:55:57.827 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 323:55:57.827 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 423:55:57.827 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 523:55:57.827 [pool-1-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onComplete main 스레드는 바로 해제되어 이후의 일을 진행할 수 있게 되었고 onSubscribe 이후의 처리는 모두 별도의 스레드에서 진행된다. 그러나 아직 “빠른 프로듀서”와 “느린 컨슈머”의 문제가 남아있다. publisher가 데이터를 빠르게 생산하지만 subscriber의 onNext에서 데이터를 소비하는 작업에 시간이 오래 걸리는 경우인 것이다.이때는 subscriber 또한 별도의 스레드에서 onNext 처리를 하도록 함으로써 해결할 수 있다. subscribeOnsubscriber도 별도의 스레드에서 동작하도록 만들어보자.1234567891011121314151617181920212223private static Subscriber&lt;Integer&gt; subscriberOn(Subscriber&lt;Integer&gt; sub) { return new Subscriber&lt;Integer&gt;() { @Override public void onSubscribe(Subscription s) { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onSubscribe(s)); } @Override public void onNext(Integer i) { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onNext(i)); } @Override public void onError(Throwable t) { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onError(t)); } @Override public void onComplete() { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onComplete()); } };} 파라미터로 전달받은 subscriber의 onSubscribe, onNext, onError, onComplete 메서드를 별도의 스레드에서 실행하도록 하는 subscriber를 새로 만들어서 반환한다. subscriberOn 메서드를 기존의 subscriber에 적용해 실행하면 다음과 같이 실행결과를 확인할 수 있다. 12345678910- 실행결과00:14:53.604 [main] INFO com.jongmin.reactive.practice.SchedulerEx - exit00:14:53.604 [pool-2-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onSubscribe00:14:53.607 [pool-2-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - request: 922337203685477580700:14:53.609 [pool-3-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 100:14:53.609 [pool-4-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 200:14:53.609 [pool-5-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 300:14:53.609 [pool-6-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 400:14:53.610 [pool-7-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onNext: 500:14:53.610 [pool-8-thread-1] INFO com.jongmin.reactive.practice.SchedulerEx - onComplete 이제는 main 스레드는 subscriber를 publisher에 등록(subscribe)까지만 하고 그 이후의 작업은 publisher와 subscriber 모두 별도의 스레드에서 동작하게 되었다. 전체 코드는 다음과 같다.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Slf4jpublic class SchedulerEx { public static void main(String[] args) { Publisher&lt;Integer&gt; pub = new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { sub.onSubscribe(new Subscription() { @Override public void request(long n) { log.info(\"request: {}\", n); sub.onNext(1); sub.onNext(2); sub.onNext(3); sub.onNext(4); sub.onNext(5); sub.onComplete(); } @Override public void cancel() { } }); } }; Subscriber&lt;Integer&gt; sub = new Subscriber&lt;Integer&gt;() { @Override public void onSubscribe(Subscription s) { log.info(\"onSubscribe\"); s.request(Long.MAX_VALUE); } @Override public void onNext(Integer integer) { log.info(\"onNext: {}\", integer); } @Override public void onError(Throwable t) { log.info(\"onError\", t); } @Override public void onComplete() { log.info(\"onComplete\"); } }; publishOn(pub).subscribe(subscriberOn(sub)); log.info(\"exit\"); } private static Publisher&lt;Integer&gt; publishOn(Publisher&lt;Integer&gt; pub) { return new Publisher&lt;Integer&gt;() { @Override public void subscribe(Subscriber&lt;? super Integer&gt; sub) { Executors.newSingleThreadExecutor().execute(() -&gt; { pub.subscribe(sub); }); } }; } private static Subscriber&lt;Integer&gt; subscriberOn(Subscriber&lt;Integer&gt; sub) { return new Subscriber&lt;Integer&gt;() { @Override public void onSubscribe(Subscription s) { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onSubscribe(s)); } @Override public void onNext(Integer i) { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onNext(i)); } @Override public void onError(Throwable t) { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onError(t)); } @Override public void onComplete() { Executors.newSingleThreadExecutor().execute(() -&gt; sub.onComplete()); } }; }}","link":"/2019/11/10/Java/reactive-3/"},{"title":"Encryption - RSA","text":"이전에 에서 해시(Hash)에 대해 설명하며 암호화(Encryption)와 다른점에 대해 간략히 알아보았다.이번에는 암호화에 대해서 조금 더 자세히 알아보자. 암호화 (Encryption)암호화(Encryption)은 평문(PlanText)을 암호문(CipherText)으로 변환하는 과정을 말한다. 반대로 복호화(Decryption)은 암호문을 평문으로 변환하는 과정을 말한다. 암호화: 평문 -&gt; 암호문 복호화: 암호문 -&gt; 평문 이 과정에서 암호화와 복호화에 사용하는 키(Key)를 같은 것을 사용하는 경우를 대칭키 암호화(Symmetric Key Encryption)라 부르고, 암호화와 복호화에 서로 다른 키(공개키, 비공개키)를 사용하는 경우는 비대칭키 암호화(Asymmetric Key Encryption)라고 부른다. 대칭키 암호화: 암호화와 복호화에 같은 키를 사용 비대칭키 암호화: 암호화와 복호화에 서로 다른 키를 사용 (공개캐, 비공개키) 대칭키 암호화 (Symmetric Key Encryption)대칭키 암호화는 오래전부터 사용되어온 방식이다. 암호화와 복호화에 같은 키를 사용하는데 보통 PSK(Pre-Shared Key)라고도 표현한다. 영문 그대로 미리 공유된 키를 말한다. 대칭키 암호화를 위해서는 평문을 암호화해서 전달하는 송신자와 암호문을 받아 평문으로 복호화하려는 수신자가 서로 동일한 키를 암호화가 시작되기 전에 서로 공유해야 한다. 대칭키 암호화에는 DES(Data Encryption Standard), AES(Advanced Encryption Standard)와 같은 알고리즘이 대표적으로 사용된다. 그러나 대칭키 암호화 방식에는 문제가 있다. 처음 서로 키를 공유하는 과정에서 만약 누군가 중간에서 이 키를 가로챌 수 있다면, 그 후에 해당 키를 이용해 암호화되어 전달되는 암호문들은 중간에서 쉽게 복호화되어 그 내용이 전부 노출될 수 있다. 이런 문제를 근본적으로 해결하고 암호키를 쉽게 전달하기 위해 나온 방법이 비대칭키 암호화이다. 비대칭키 암호화 (Asymmetric Key Encryption)비대칭키 암호화는 암호화와 복호화에 서로 다른 키(공개캐, 비공개키)를 사용 한다. 비대칭키 알고리즘에는 대표적으로 RSA(Rivest–Shamir–Adleman)가 사용된다. RSA (Rivest–Shamir–Adleman)RSA는 수학적인 기법을 통해 한 쌍의 키를 생성한다. 보통 한 쌍의 키를 각각 공개키와 비공개키라고 부르며 다음과 같은 용도로 사용된다. 공개키(Publick Key): 누구에게나 공개될 수 있으며 데이터를 보내는 발신자는 공개키를 통해 정보를 암호화한다. 비공개키(Private Key, 비밀키): 수신자는 비밀키를 암호화된 메세지를 복호화 하는데 사용한다. 외부에 노출되지 않도록 안전하게 보관해야 한다. 이와 같이 RSA를 이용한 공개키 암호화 방식은 비공개키를 외부에 노출할 위험이 없어 기존의 대칭키 암호화 방식의 문제를 해결하고 있다. 일반적으로는 공개키는 암호화에만 사용되고 비밀키는 복호화에만 사용된다고 잘못 알려져 있다. 공개키로 암호화된 것을 비밀키로 복호화할 수 있을 뿐만 아니라, 비밀키로 암호화된 것을 공개키를 이용해서도 복호화할 수 있다. 이러한 한 쌍의 암호화 키를 이용하는 방식이 RSA 알고리즘인 것이다. RSA가 사용되고 있는 사례는 주변에서 생각보다 쉽게 찾을 수 있다. SSL/TLS가 통신을 암호화하기 위해 사용하는 대칭키를 교환하기 위해서 RSA(비대칭키)를 사용하고 있다. SSL/TLS에서 암호화에 사용하려는 대칭키를 전달(공유) 할 때, 이 대칭키를 RSA의 공개키로 암호화 하여 상대방에게 전달하고, 비밀키를 가지고 있는 상대방만 이 암호화 내용을 복호화 하여 대칭키를 획득할 수 있게 하는 것이 SSL/TLS에서 RSA를 통해 대칭키를 공유하는 방식인 것이다. 이후로는 이렇게 공유된 대칭키를 이용하여 송수신자는 암호화 통신을 하게 된다. 한 가지 의문이 있을 수 있다. 처음부터 대칭키가 아닌 비대칭키 이용해서 모든 통신을 암복호화 하여 통신하면 간단하고 좋겠지만, RSA와 같은 비대칭키 암호화 방식은 복잡한 수학적 원리로 이루어져 있어 많은 CPU 리소스를 소모하게 된다. 따라서 대칭키를 공유 할 때만 비대칭키 암호화 방식으로 대칭키를 공유하고, 그 후로는 공유된 대칭키를 이용해서 CPU 리소스를 덜 소모하는 암호화 방식을 사용해서 통신하는 것이다. RSA는 암호화뿐만 아니라 전자서명이 가능한 최초의 알고리즘으로 알려져 있다. RSA가 갖는 전자서명 기능은 인증을 요구하는 전자 상거래와 같은 곳에서 사용된다. 예제kotlin을 이용해 간단히 RSA(public key, private key) 키를 생성하고, 이를 이용해 암복호화를 해보자. 키 생성java.security.KeyPairGenerator를 이용하면 쉽게 RSA 키를 생성할 수 있다. The KeyPairGenerator class is used to generate pairs of public and private keys. Key pair generators are constructed using the getInstance factory methods (static methods that return instances of a given class).A Key pair generator for a particular algorithm creates a public/private key pair that can be used with this algorithm. It also associates algorithm-specific parameters with each of the generated keys.There are two ways to generate a key pair: in an algorithm-independent manner, and in an algorithm-specific manner. The only difference between the two is the initialization of the object: 공개키는 X.509 형식으로 생성된다. X.509는 공개키 인증서와 인증알고리즘의 표준 가운데에서 공개 키 기반(PKI)의 ITU-T 표준이다. 비공개키(개인키)는 PKCS #8(Public-Key Cryptography Standard) 형식으로 생성된다. PKCS #8는 개인키 정보 문법 표준으로 RFC 5208에 기술되었다. 공개키 암호에서 사용되는 비밀키 값에 대한 문법을 정의한다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344class RSAKeyPairGenerator { private val privateKey: PrivateKey private val publicKey: PublicKey init { val keyGen = KeyPairGenerator.getInstance(\"RSA\") keyGen.initialize(1024) val keyPair = keyGen.generateKeyPair() this.privateKey = keyPair.private this.publicKey = keyPair.public } fun writeToFile(path: String, key: String) { val file = File(path) file.parentFile.mkdir(); file.bufferedWriter().use { it.write(key) } } fun getPrivateKey(): PrivateKey { return privateKey } fun getPublicKey(): PublicKey { return publicKey }}fun main() { val keyPairGenerator = RSAKeyPairGenerator() val publicKey = keyPairGenerator.getPublicKey().encoded val privateKey = keyPairGenerator.getPrivateKey().encoded val base64PublicKey = Base64.getEncoder().encodeToString(publicKey) val base64PrivateKey = Base64.getEncoder().encodeToString(privateKey) keyPairGenerator.writeToFile(\"RSA/publicKey\", base64PublicKey) keyPairGenerator.writeToFile(\"RSA/privateKey\", base64PrivateKey) println(\"public key: $base64PublicKey\") println(\"private key: $base64PrivateKey\")} privateKey1MIICdwIBADANBgkqhkiG9w0BAQEFAASCAmEwggJdAgEAAoGBAKxfz0f6BTZVergW5tZxHgUIbVmApXb01ozq11fukFsJx2WbfvxddyxU3P6NEZjoSYCM5NPjvtscMtvfErL93qa3cVrKgBXumclfMAe7ijHeesiC/0RUnSoV7ytdz9AXn0TvjzIxAibGL8HxdGGMgAtYERM7/NYJ/JU7o7jYWhKFAgMBAAECgYBIiwXUF8+rvyunX9QEOZTVr2c9vJtmRcIpigfYtMjB14q4I0m88aTe3lQnOL1IKbINTL5cwkMnOWXaDLZ058yUkfDdahjaCxg9z9/jY2cxREvMR/oWtY5FwrodDKvoTURC8Hz+TZg4a9S1NofKY8W4YBqxpW3PKvBkIVl6beECfQJBAOEW9VdkwT/zgXwUXvivZAqlbFkOkr9zBE+tvQ+QEY6rLMgIoEa1NK/xx1gWt+c6xLMjE8f7GS7HEkCbQOtlvXcCQQDEC6MnswfK7arpv02odhc92ViHCGI1W8rvFlG4SL0RHI+VxAIBaEL+1RN9k4aCSWLrCLtLzaSa+8ArFp2r0f7jAkEA3Ck+k9qjAtBEqH6sXgX/jkI7dehBNS1k3CKNt/kskyVuycFWM5LuE+IjH1ApVOwwlR8MLCC4gv6IJdU1bIm5BQJBAIr/PUSueL32WJG2Y1cnsz7U1SGYXhk65d0yU+p3GCYDvAIRoOJii+2mIVWNvXaulYXTAQiz2xtPl2Z1eIEUOMUCQEdR7nswIOfV71fp1sTngUM3GpLDrT3uA9M8/2ND3QnfrVDc+gFWkj+OmKeDsLx7Rhs+liVP9qgFppC9IJxcmyI= publicKey1MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCsX89H+gU2VXq4FubWcR4FCG1ZgKV29NaM6tdX7pBbCcdlm378XXcsVNz+jRGY6EmAjOTT477bHDLb3xKy/d6mt3FayoAV7pnJXzAHu4ox3nrIgv9EVJ0qFe8rXc/QF59E748yMQImxi/B8XRhjIALWBETO/zWCfyVO6O42FoShQIDAQAB 암복호화X.509 형식의 데이터를 다시 RSA 공개키로 변환하기 위해서는 X509EncodedKeySpec을 사용한다.PKCS #8 형식의 데이터를 RSA 비공개키로 변환하기 위해서는 PKCS8EncodedKeySpec를 사용한다. 공개키: X.509 -&gt; X509EncodedKeySpec 비공개키: PKCS #8 -&gt; PKCS8EncodedKeySpec 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647object RSAUtil { private val keyFactory = KeyFactory.getInstance(\"RSA\") private fun getPublicKey(base64PublicKey: String): PublicKey { val keySpec = X509EncodedKeySpec(Base64.getDecoder().decode(base64PublicKey.toByteArray())) return keyFactory.generatePublic(keySpec) } private fun getPrivateKey(base64PrivateKey: String): PrivateKey { val keySpec = PKCS8EncodedKeySpec(Base64.getDecoder().decode(base64PrivateKey.toByteArray())) return keyFactory.generatePrivate(keySpec) } fun encrypt(data: String, base64PublicKey: String): ByteArray { val cipher = Cipher.getInstance(\"RSA/ECB/PKCS1Padding\") cipher.init(Cipher.ENCRYPT_MODE, getPublicKey(base64PublicKey)) return cipher.doFinal(data.toByteArray()) } private fun decrypt(data: ByteArray, privateKey: PrivateKey): String { val cipher = Cipher.getInstance(\"RSA/ECB/PKCS1Padding\") cipher.init(Cipher.DECRYPT_MODE, privateKey) return String(cipher.doFinal(data)) } fun decrypt(data: String, base64PrivateKey: String): String { return decrypt(Base64.getDecoder().decode(data.toByteArray()), getPrivateKey(base64PrivateKey)) }}fun main() { val publicKey = \"MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCya66h9+mG6z3/3lSV/IjfXFxH/Y0CPgc+YLIjui5JmbNgPC2EQ4GJPsT0CbxjcMTnrSvyj7JzBbJhzmsTBD+HuKEiQOOlGNhPS0HIDvpk+J4DDyuGoTVHnWkuxNC9+IlbkWZQMWHcQ42VCFJwvduESOhs01vSFQCRBYNzYL54HQIDAQAB\" val privateKey = \"MIICeAIBADANBgkqhkiG9w0BAQEFAASCAmIwggJeAgEAAoGBALJrrqH36YbrPf/eVJX8iN9cXEf9jQI+Bz5gsiO6LkmZs2A8LYRDgYk+xPQJvGNwxOetK/KPsnMFsmHOaxMEP4e4oSJA46UY2E9LQcgO+mT4ngMPK4ahNUedaS7E0L34iVuRZlAxYdxDjZUIUnC924RI6GzTW9IVAJEFg3NgvngdAgMBAAECgYEAmAd/Z03ac/dQ/gxRYPgtHL4Td9hJ5eY6v+EfCahkNpy8Jr1AP5pR70NICXWeS9FURuDdOLNO6AmrpQGBZVPSWQODDXq47CJO4bHMk55DXzPue31jva7Kk7l2ydmm2K6h3s9b+4pkYOtN3f/8tnQsbundqIXI2Uz6E8LP8ksGilUCQQDjZt8sMa9nkZ7RC5SqF8QecMKXErsf5iZroYHt+2HHaakoV+Exy+eXBgREPO7cZMC+BIglTciHFD5grCrdwQBLAkEAyNvgViJI0XUsiLlsg9RHA0DciErEkjzXMd6LcND1KspXFM6y484uN6B07SDeqG1Dyn/C+pQarpt5xER9UEU4NwJBAIiqe7fYyH0rJFKobhlnnSNaS2h2BmYecLrA3xCCwvoQw2wOnLXLwQyfvhKwuDFWkAvjN1uMCtc70F1TO5P4eU8CQGJof8ATqhOdUgVmu4jXPzeT1rib0TVIw7I2M6FBb2zYl9Ok9bZw9OniHodzfEOOzRDwianVWEFGAWGsoKzsTP8CQQDZrzW16AnCQrmr1ENCQoQonEZTAAS5FI1XhfIH4VvGq+yCyYMdB7WtQ0kUS3Qm20VfDhim55NjlZd2BPpPBmxL\" val text = \"Please encrypt this data\" val encryptedString = Base64.getEncoder().encodeToString(RSAUtil.encrypt(text, publicKey)) println(\"encryptedString: $encryptedString\") val decryptedString = RSAUtil.decrypt(encryptedString, privateKey) println(\"decryptedString: $decryptedString\")}","link":"/2020/01/02/Java/rsa/"},{"title":"6. Extra GPIO","text":"강의 내용 훑어보기이번 강의는 카메라(V2), 온습도(SZH-EK024), 조도(BH1750), 초음파(HC-SR04) 센서에 대한 내용을 다루고 있습니다. 1. 카메라(V2)간단하게 카메라(V2) 모듈에 대해 알아보고 사진 캡쳐, 영상 촬영, 효과 주기, 웹 서버를 통해 스트리밍해보는 실습을 합니다. 2. 온습도(SZH-EK024)온습도 센서를 통해 온도와 습도를 측정하고 이전 시간에 배운 LED를 통해 현재의 온습도 상태를 표시하는 실습을 합니다. 3. 조도(BH1750)I2C 버스 인터페이스를 사용하기 위한 설정을 하고 센서를 사용합니다. 4. 초음파(HC-SR04)초음파 센서가 거리를 측정하는 방법에 대해 알아보고 LED를 통해 현재의 거리 정도를 표시하는 실습을 합니다.","link":"/2017/07/10/RaspberryPi/6-extra-gpio/"},{"title":"4. bash 설정, vim 설정, gist 사용하기","text":"강의 내용 훑어보기이번 강의는 bash 설정, vim 설정, gist 사용하기에 대한 내용을 다루고 있습니다. 1. bash 설정bash 쉘에 대해 간단하게 알아본 후 .bashrc 파일을 수정하여 프롬프트(prompt)의 색상 정보를 변경하고, .dircolors 파일을 수정하여 터미널의 폴더 색상을 변경하는 실습을 합니다. 2. vim 설정apt를 사용하여 vim을 설치하고 .vimrc 파일을 수정하여 vi 편집기를 좀 더 편리하게 사용할 수 있도록 설정을 추가합니다. 3. gist 사용하기gist에 대해 알아본 후 지금까지 실습한 자신만의 설정파일을 gist에 업로드 합니다.","link":"/2017/07/10/RaspberryPi/4-bash_vim_gist/"},{"title":"Retrofit2 네트워크 타임아웃 시간 설정하기","text":"Retrofit은 기본적인 네트워크 타임아웃 시간 설정을 사용하고 있습니다. 그러나 여러 상황으로 인해 기본적으로 설정된 타임아웃 시간을 변경할 필요가 생기기도 합니다.이번 포스팅에서는 3가지의 네트워크 타임아웃 시간 설정에 대해 알아보고 변경해보겠습니다. 타임아웃 시간 설정Retrofit에서는 기본적으로 다음의 3가지 타임아웃 시간 설정 값을 갖고 있습니다. Connection timeout : 10초 Read timeout : 10초 Write timeout : 10초 Connection Timeout요청을 시작한 후 서버와의 TCP handshake가 완료되기까지 지속되는 시간이다. 즉, Retrofit이 설정된 연결 시간 제한 내에서 서버에 연결할 수없는 경우 해당 요청을 실패한 것으로 계산한다.따라서 사용자의 인터넷 연결 상태가 좋지 않을때 기본 시간 제한인 10초를 더 높은 값으로 설정하면 좋다. Read Timeout읽기 시간 초과는 연결이 설정되면 모든 바이트가 전송되는 속도를 감시한다. 서버로부터의 응답까지의 시간이 읽기 시간 초과보다 크면 요청이 실패로 계산된다.LongPolling을 위해 변경해 주어야 하는 설정값이다. Write Timeout쓰기 타임 아웃은 읽기 타임 아웃의 반대 방향이다. 얼마나 빨리 서버에 바이트를 보낼 수 있는지 확인한다. 코드12345678910OkHttpClient okHttpClient = new OkHttpClient.Builder() .connectTimeout(1, TimeUnit.MINUTES) .readTimeout(30, TimeUnit.SECONDS) .writeTimeout(15, TimeUnit.SECONDS) .build();Retrofit.Builder builder = new Retrofit.Builder() .baseUrl(\"http://localhost:3000/\") .client(okHttpClient) .addConverterFactory(GsonConverterFactory.create());","link":"/2018/01/31/Programming/android-customize-network-timeouts/"},{"title":"7. Jasper","text":"강의 내용 훑어보기이번 강의는 음성인식 &amp; IPA, Jasper, Jasper (hardware), Jasper (software), Jasper (configure), Jasper (write your apps)에 대한 내용을 다루고 있습니다. 1. 음성인식 &amp; IPAIPA(Intelligent Personal Assistant)에 대해 알아보고 그 중 많이 사용되는 Jasper가 음성을 인식하는 과정에 대해 설명합니다. 2. Jasper음성으로 제어하는 오픈 소스 플랫폼 Jasper에 대해 간략하게 설명합니다. 3. Jasper (haredware)Jasper를 사용하기 위해 하드웨어 설정을 진행합니다. 음성을 듣기 위해 이어폰 설정과 음성을 녹음하기 위해 마이크 설정을 합니다. 4. Jasper (software)github에서 Jasper를 다운로드 한 후 추가적으로 STT와 TTS 엔진을 설치합니다. 5. Jasper (configure)Jasper의 기본 환경설정 파일을 생성하고 STT 사용을 위해 Google Speech API Key를 발급받습니다.Jasper에서 사용하는 Google STT와 TTS의 기본 언어를 한글로 변경한 후 예시로 Time과 Weather 모듈을 한글로 변경합니다. 6. Jasper (write your apps)Jasper의 구조를 알아본 후 표준 모듈(Standard module)과 알림 모듈(Notification module)에 대해 알아 본 후 음성으로 LED를 키고 끌 수 있는 LED 표준 모듈을 만드는 실습을 합니다.","link":"/2017/07/10/RaspberryPi/7-jasper/"},{"title":"2년차 LINE 서버 개발자의 2019년 회고","text":"벌써 LINE에 입사한지 2년이 다 되어간다. 올해는 정말 시간이 어떻게 지나갔는지 모르겠다. 정신 차리고 보니 2020년이 코앞이다. 올해는 작년에 하지 못했던 회고를 해보려한다. 블로그 포스팅어떻게 회고를 시작할까 생각하다가 올해 포스팅한 글들을 확인해보았다. 올해는 26개의 글을 포스팅을 했다. 올해 작성한 글들을 통해서 어떤 일들이 있었고 무엇을 느끼고 배우게 되었는지 정리해보려 한다. Non-blocking / Asynchronous 관련 기술 공부사내에서 팀원분들의 PR을 리뷰하면서 Non-blocking/Asynchronous에 관련된 내용을 많이 접하게 되었다. Webflux나 Armeria와 같은 프레임워크들을 처음 공부하면서 Reactive라는 용어와 함께 그 기반이 되는 Non-blocking/Asynchronous에 대한 내용을 접하게 되었고, Netty를 거쳐 Java NIO와 멀티플렉싱까지 관심을 갖고 공부하게된 계기가 되었다. 개인적으로 무언가 새로운 기술을 접하고 사용하게 될 때, 그 기술이 만들어지게 된 배경과 기반이 되는 기술 또한 공부하는 것을 매우 중요하게 생각한다.실제로는 하나의 흐름으로 이어질 수 있는 내용들인데 매번 새로운 기술이 등장할때면 그 기술 자체에 집중하느라 흐름을 따라 파악하기가 쉽지 않은 것 같다. 또한 이러한 부분을 정리하는 것도 갈수록 어려워지는것 같다. 결과적으로 이와 관련된 내용은 후에 팀내에서 Webflux 관련 스터디를 진행하면서도 개인적으로 큰 도움이 되었다. 오픈소스 첫 컨트리뷰트올해는 처음으로 오픈소스에 컨트리뷰트를 해보았다. Armeria는 Java 개발자라면 누구나 한번 쯤 들어보았을 Netty를 만드신 희승님께서 개발하고 계신 오픈소스이다. 어느날 사내에서 Armeria Sprint라는 행사를 진행하게 되었고 이 행사에 참여해 처음으로 오픈소스에 기여하는 경험을 하게 되었다. (자세한 내용이 궁금하다면 &lt;오픈소스 컷 컨트리뷰트 경험기&gt;를 보면 좋을 것 같다!) 평소 오픈소스에 컨트리뷰트를 해보고 싶었지만 어떻게 해야하는 것인지, 내가 할 수 있을까에 대한 막연한 두려움이 있었다면, 이번 첫 컨트리뷰트를 통해 이러한 부분들을 많이 해소할 수 있었던 것 같다. 첫 컨트리뷰트 이후로도 꾸준히 해보겠다고 다짐했지만 실행에 옮기지는 못했다. 내년에는 꾸준히 하지는 못하더라도 오픈소스에 관심 갖고 기여하는 시간을 조금 더 가져보려고 한다. 공부 방식의 변화작년에는 32개의 글을 포스팅을 했는데, 올해 작성했던 글들은 작년에 작성했던 글들과 조금 차이가 있다. 작년에 작성했던 글들은 대부분이 회사에 입사해 처음으로 접하는 기술들을 공부하며 관련된 내용을 정리하는 내용의 글들이었다. 말로만 듣다가 처음 접하게 된 Spring과 학부생 수업때 이후로 사용하지 않던 Java 뿐만 아니라 Gradle, Jenkins, SonarQube와 같은 것들에 대해서 전반적으로 다루었다. 각각에 대해서 깊은 내용을 다루기 보다는 당장 회사에서 사용하는 기술들에 대해 파악하고 업무를 진행할 수 있는 정도로 공부하고 정리하며 글을 작성했던것 같다. 이에 반해, 올해 작성했던 글들은 회사에서 업무를 진행하며 겪었던 문제에 대한 내용 혹은 PR review에서 받았던 코멘트들에 대한 내용을 위주로 작성했다. 앞으로도 업무를 하면서 새로 알게된 내용들 위주로 작성하게 될 것 같다. 또한, 한가지 더 변한 것이 있다면 작년에는 기술 서적을 최대한 많이 읽기 위해 노력했지만 올해는 조금이라도 직접 코드를 작성하는 시간을 더 많이 갖기위해 노력하고 있다. 확실히 책을 여러번 아무리 많이 보아도 직접 코딩하는게 학습에는 제일 효과가 좋은 것 같다. 실무에서 배운 것근무하고 있는 LINE의 개발 문화에 대해서는 동기가 잘 작성한 글로 대신한다. (2년차 서버 개발자가 바라본 LINE의 개발 문화) 올해는 기존의 feature 하나를 새롭게 리뉴얼하면서(설계부터 릴리즈까지) 정말 너무나도 많은 것들을 배웠다. 아주 간략히 정리하면 아래와 같다. 기존 legacy 코드의 문제점을 파악하고 개선 다른 부서(기획팀, 클라이언트 개발팀, 서버팀)와의 협업 이미 서비스 되고 있는 client에 대해서는 어떻게 다룰 것인지 backward compatibility (하위 호환성) 지원 릴리즈 후 모니터링 개발 후 릴리즈까지가 끝이라고 생각했지만 모니터링 또한 매우 중요했다. feature가 문제없이 잘 동작하고 있는지, 그리고 장애 상황을 미리 감지할 수 있도록 의미있는 metric들을 잘 정의하고 대시보드로 만드는 것까지 함으로써 feature에 대한 개발을 마무리 할 수 있었다. 릴리즈 후 모니터링을 하면서 몇일간 기존의 API에서 리뉴얼 된 API로 사용량이 증가하면서 이로 인해 변경된 지표들을 확인할 수 있었고, API 디자인의 변경으로 인해 애플리케이션 지표에 미치는 영향들 또한 확인할 수 있었다. 어디가서 쉽게 해볼 수 없는 값진 경험이었다. 그러나 많은 준비를 했음에도 불구하고 릴리즈 후 예상하지 못한 부분에서 장애가 발생했었고 LINE의 장애 보고와 후속 절차 문화에 따라 어떻게 하면 앞으로 같은 장애를 겪지 않을 수 있을지에 대해서도 생각해보게 되었다. 약 6개월간 진행했던 feature 리뉴얼을 진행하며 배운것을 아주 간략히 정리해보았다. 지나고나니 아쉬웠던 부분들도 생각이 난다. 다음번에는 이런 부분들도 잘 고려해서 문제없이 마무리할 수 있도록 노력하자.","link":"/2019/12/26/Programming/2019-retrospect/"},{"title":"OAuth 2.0과 네이버로 로그인","text":"안드로이드에서 &lt;네이버 아이디로 로그인&gt; 기능을 구현하며 OAuth 2.0에 대해 알아보고, 라이브러리를 적용하는 방법에 대해 알아보겠습니다. OAuth 2.0OAuth는 인증(Authentication)과 허가(Authorization)을 위한 표준 프로토콜로, 사용자가 Facebook이나 트위터 같은 인터넷 서비스의 기능을 다른 애플리케이션(데스크톱, 웹, 모바일 등)에서도 사용할 수 있게 한 것입니다. Facebook이나 트위터의 기능을 이용하기 위해 사용자가 반드시 Facebook이나 트위터에 로그인해야 하는 것이 아니라, 별도의 인증 절차를 거치면 다른 서비스에서 Facebook과 트위터의 기능을 이용할 수 있게 됩니다. 이런 방식은 Facebook이나 트위터 같은 서비스 제공자뿐만 아니라 사용자와 여러 인터넷 서비스 업체 모두에 이익이 되는 생태계를 구축하는데 기여했습니다.이 방식에서 사용하는 인증 절차가 OAuth입니다. OAuth를 이용하면 이 인증을 공유하는 애플리케이션끼리는 별도의 인증이 필요없습니다. 따라서 여러 애플리케이션을 통합하여 사용하는 것이 가능하게 됩니다. OAuth 2.0은 authorization(허가, 승인)을 위한 산업 표준 프로토콜입니다. OAuth 2.0 전에 OAuth 1.0이 만들어져 사용되었지만 웹, 데스크탑, 모바일 등의 어플리케이션의 authorization flow(권한 흐름)을 보다 단순화 하는데 초점이 맞춰졌습니다.(OAuth 1.0에서는 Acess Token을 받으면 계속 사용이 가능했습니다. 그러나 OAuth 2.0에서는 보안 강화를 위해 Access Token의 Life-time을 지정할 수 있게됐고, Life-time이 만료되면 Refresh Token을 통해 Access Token을 재발급을 받아야 합니다.) 주의사항로그인과 OAuth는 반드시 분리해서 이해해야 합니다. 아래의 예시를 통해 그 이유를 생각해봅시다. 사원증을 이용해 출입할 수 있는 회사를 생각해 보자. 그런데 외부 손님이 그 회사에 방문할 일이 있다. 회사 사원이 건물에 출입하는 것이 로그인이라면 OAuth는 방문증을 수령한 후 회사에 출입하는 것에 비유할 수 있다. 방문증이란 사전에 정해진 곳만 다닐 수 있도록 하는 것이니, ‘방문증’을 가진 사람이 출입할 수 있는 곳과 ‘사원증’을 가진 사람이 출입할 수 있는 곳은 다르다. 역시 직접 서비스에 로그인한 사용자와 OAuth를 이용해 권한을 인증받은 사용자는 할 수 있는 일이 다르다. 구성요소 사용자(Resource Owner) : Service Provider에 계정을 가지고 있으면서, Client를 이용하려는 사용자 소비자(Client) : OAuth 인증을 사용해 Service Provider의 기능을 사용하려는 애플리케이션이나 웹 서비스 API 서버(Resource Server) : OAuth를 사용하는 Open API를 제공하는 서비스 권한 (Authroization Server) : OAuth 인증 서버 접근 토큰(Access Token) : 인증 후 Client가 Resource Server의 자원에 접근하기 위한 키를 포함한 값 갱신 토큰(Refresh Token) : 유효기간이 지난 Access Token을 갱신하기 위해 사용되는 값 인증과정 네이버 아이디로 로그인&lt;네이버 아이디로 로그인&gt;은 OAuth 2.0 기반의 사용자 인증 기능을 제공해 네이버가 아닌 다른 서비스에서 네이버의 사용자 인증 기능을 이용할 수 있게 하는 서비스입니다. 별도의 아이디나 비밀번호를 기억할 필요 없이 네이버 아이디로 간편하고 안전하게 서비스에 로그인할 수 있어, 가입이 귀찮거나 가입한 계정이 생각나지 않아 서비스를 이탈하는 사용자를 잡을 수 있습니다. &lt;네이버 아이디로 로그인&gt;을 통해 로그인하는 기본 절차는 다음과 같습니다. 로그인 (네이버 앱이 설치되어 있다면 네이버 앱의 간편 로그인 기능으로 로그인, 네이버 앱이 설치되지 않았다면 애플리케이션에서 인앱 브라우저가 실행되고 네이버 로그인 화면으로 이동한다.) 사용자가 네이버 아이디로 로그인하면 사용자 정보에 동의하는 화면으로 이동한다. 사용자가 정보 제공에 동의하면 콜백 URL로 애플리케이션에 접근 토큰(access token)이 발급된다. 발급받은 접근 토큰을 이용해 OAuth 2.0을 지원하는 네이버의 오픈 API를 사용하거나 사용자의 정보를 얻어 올 수 있다. 특징네이버 아이디로 로그인한 사용자의 이름, 메일 주소, 별명, 프로필 사진, 생일, 연령대, 성별 등을 API로 간단하게 조회할 수 있습니다. 적용 칠자 애플리케이션 등록네이버 아이디로 로그인을 적용하기 위해 애플리케이션을 등록하고 클라이언트 아이디와 클라이언트 시크릿 키를 발급받는다. 애플리케이션 개발네이버 아이디로 로그인을 이용하기 위한 정보를 확인하고 등록한 환경에 맞는 개발가이드를 참고해 애플리케이션을 개발한다.- Android 튜토리얼 참고 서비스 적용개발을 완료하면 서비스에 네이버 아이디로 로그인을 적용한다. 결과","link":"/2018/01/20/Programming/android-naver-login/"},{"title":"Uniton 후기","text":"2017.07.28(금) ~ 07.30(일) 2박3일간 유니톤에 참여했습니다. 아래의 사진에서 볼 수 있듯이, 이번 유니톤은 UNIT, NEXTERS, REAL, YAPP 4개의 연합 IT 단체에서 주관하고 있습니다. 여러 기업의 후원을 받으며 각 IT 단체의 학생들이 모여 진행하는 모습이 멋있었습니다. 어떠한 이익을 추구하지 않으며 자신들이 재밌게 즐겼던 이 유니톤 행사가 계속 이어지길 바라는 마음을 갖고 있으셔서 인지 2박3일간 관리하느라 그 어떤 사람들보다 힘들었을 텐데 다들 즐거워 보이셨습니다. 먼저 유니톤 행사를 잘 진행해주셔서 감사합니다! 해커톤이나 유니톤에 참여하는건 이번이 처음이었습니다. 2월에 졸업하고 지금은 직장인이지만 이전에 SOPT에서 동아리 활동했던 경험이 있기에 신청을 했는데 운이좋게 참여할 수 있게되었습니다. 이번 유니톤의 전체적인 행사는 다음과 같았습니다. 먼저 2박3일간의 유니톤을 진행하기 일주일 전 네트워킹 데이를 통해서 유니톤에서 활용 가능한 후원사들의 서비스와 기술들을 세미나를 통해 배우고 심화시킬 수 있는 시간을 가졌습니다. 저는 회사 일로 인해 참여할 수 없어 아쉬웠지만, 세미나 뿐만 아니라 여러 이벤트도 하며 선물도 나눠주는 시간이였다고 합니다. 네트워킹 데이는 유니톤에 참여하지 않는 분들도 참여할 수 있다고 합니다. (다음에는 꼭 참여해보겠습니다!) 그렇게 네트워킹 데이가 끝나고 일주일 후에 본격적인 유니톤이 시작됩니다! 장소는 공덕역 근처의 서울창업허브 였는데, 시설이 매우매우 좋았습니다. 약 100명정도의 참가자가 미리 정해진 조에 따라 모여 사전 행사 (세미나, 후원사 대표자 분들과 네트워킹)를 가진 후 아이디어 회의를 시작합니다. 사실 시작하기전 사전 행사가 매우 길었는데… 후원을 받는만큼 어쩔 수 없다고 생각합니다. 그래도 AWS 크래딧, 개발 서적, 목배게 등 여려가지 선물을 많이 받아서 좋았습니다! 사전행사를 하며 여러가지 팀게임을 하고 선물도 받으니 조금은 어색한게 풀려 여러가지 아이디어 회의를 했습니다. 오히려 주제가 정해지지 않고 자유이다 보니 아이디어를 정해는데 애먹긴했지만, 대부분 다른조와 마찬가지로 첫날(금요일)은 아이디어 주제를 정한 후 각자 집으로 갔습니다. 둘째날!! 저희 조는 11시에 모여 첫날 다하지 못한 아이디어 회의를 마무리 한 후 바로 개발과 디자인을 시작했습니다. 개발자(안드로이드3, 서버2)5명, 디자인 1명으로 구성되었고 저는 서버 개발로 참여했으나, 구현하고자 하는 앱은 서버 개발보다는 프론트에서 해야할 일이 훨씬 많았기에 프론트를 개발하게되었습니다. 그간 회사에서 사용했던 ReactNative에 미리 만들어 놓은 boilerplate를 사용해서 개발했습니다. 정말 잠 한숨 안자며 죽어라 개발했지만 원래 계획했던 것중 한개의 엑티비티를 완성하지 못했지만, 그래도 만족할만큼 개발한것 같습니다. 간단하게 앱에 대해 설명하면, 한국관광공사에서 제공하는 Tour Api 3.0을 사용해 지역기반의 여행 정보를 제공하는 앱을 만들었습니다. 다음은 안성된 앱의 엑티비티 입니다. 발표자료와 서버, 클라이언트 코드는 UNITON-5TH Git-Hub 에서 확인 가능합니다. 비록 수상은 못해 조금은 아쉽지만 간만에 오랜시간 집중해 즐겁게 코딩한건 오랜만인것 같습니다. 팀원들과도 더 친해졌으면 좋았겠지만 개발하기에도 짧은 시간이 아쉬웠습니다. 다음 UNITON에도 참여할 것이며, 종종 다른 해커톤과 같은 행사가 있으면 참여할 생각입니다. 마지막으로 단체사진 투척하며 UNITON에 참여하신 모든분들 고생하셨습니다!","link":"/2017/08/01/Programming/5th-uniton/"},{"title":"컴퓨터 구조와 I/O","text":"Computer system일반적인 컴퓨터 시스템은 CPU, 메모리, 외부 장치(ex. 하드디스크, 키보드, 모니터, 마우스)로 구성된다. CPU와 장치 컨트롤러들은 메모리 사이클을 두고 경쟁하며 동시에 실행된다. 경쟁상황에서 공유하는 메모리에 순차적으로 접근할 수 있도록 메모리 컨트롤러가 메모리에 대한 접근을 제어한다. 장치 컨트롤러: 컴퓨터 내의 각 하드웨어 장치에는 컨트롤러(Controller: 제어기)가 존재한다. 컨트롤러는 일종의 작은 CPU로서, 컴퓨터 전체에 CPU라는 중앙 처리 장치가 있듯이 컨트롤러는 각 하드웨어 장치마다 존재하면서 이들을 제어하는 작은 CPU라고 할 수 있다.로컬 버퍼: 장치 컨트롤러에는 장치로부터 들어오고 나가는 데이터를 임시로 저장하기 위한 작은 메모리를 가지고 있다. 이를 로컬 버퍼(local buffer)라고 부른다.디스크나 키보드 등에서 데이터를 읽어오는 경우, 우선 로컬 버퍼에 데이터가 임시로 저장된 후 메모리에 전달된다. 이 때, 장치에서 로컬 버퍼로 읽어오는 일은 컨트롤러가 담당한다. I/O (Input/Output)컴퓨터는 목적을 달성하기 위해 CPU/메모리와 외부 장치간에 정보를 주고 받는다. 이를 I/O라고 말할 수 있다.컴퓨터에서 연산을 한다는 것은 CPU가 무언가 일을 한다는 뜻이다. 입출력 장치들의 I/O 연산은 I/O 컨트롤러가 담당하고, 컴퓨터 내에서 수행되는 연산은 메인 CPU가 담당한다. CPU context어느 시점에나 CPU의 모든 레지스터 값은 CPU 컨텍스트를 정의한다. CPU 컨텍스트라 하면 프로세스 혹은 스레드에서 사용되는 데이터의 집합으로, 진행중이던 작업을 중단하고 나중에 같은 지점에서 다시 계속할 수 있도록 필요한 내용들을 포함하고 있다. Dual mode operation사용자 프로세스에서 운영체제(OS)를 보하하기 위해 하드웨어는 사용자 모드(user mode)와 커널 모드(kernel mode)라는 두 가지 모드를 제공한다. 두 가지 모드 작동은 CPU가 실행할 수 있는 작업의 유형과 범위에 제한을 둔다. (운영 체제 커널이 사용자 응용 프로그램 프로세스보다 많은 권한을 갖고 있다.) System call사용자 프로그램은 시스템 호출(System call)을 사용해서 운영 체제에게 서비스를 요청한다. 시스템 호출은 특별한 시스템 호출 예외를 사용하여 구현되어 있으며, 시스템 호출은 트랩(trap)이라고도 불린다. 시스템 호출(System call)은 운영 체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스이다. 보통 C나 C++과 같은 고급 언어로 작성된 프로그램들은 직접 시스템 호출을 사용할 수 없기 때문에 API를 통해 시스템 호출에 접근하게 하는 방법이다.하드웨어 제어를 하는 모든 권한을 커널에서 가지고 있기 때문에 파일 시스템 같은 경우 응용 프로그램에서는 직접 제어할 수 없다. 따라서 응용 프로그램에서 하드웨어의 데이터를 가져오거나 쓰려면 커널의 장치 드라이버와 연동되어 실행되어야 한다. 결국 응용 프로그램이 파일 시스템을 이용하려면 커널의 파일 시스템 드라이버로 넘어가 실행되어야 하므로 시스템 호출 방법을 사용한다. Exceptions and Interrupt예외(Exception)와 인터럽트(Interrupt)는 즉각 실행되어야 하는 이벤트를 CPU에게 알리는데 사용된다. 인터럽트는 컨트롤러가 CPU에게 이벤트를 알리기 위해 사용한다. CPU 옆에는 인터럽트 라인(interrupt line)이 있어서, CPU가 자신의 작업을 하던 중간에 인터럽트 라인에 신호가 들어오면 하던 일을 멈추고, 인터럽트와 관련된 일을 처리한다. 좀더 정확히 CPU는 명령 하나를 수행할 때마다 인터럽트가 발생했는지를 체크하고, 인터럽트가 발생했으면 다음 명령을 수행하기 전에 인터럽트 처리를 하게 되고 그렇지 않으면 다음 명령을 계속 수행하게 된다. Exception and Interrupt handler예외 혹은 인터럽트가 발생하면 사용자 모드에서 커널 모드로 실행이 전환된다. 예외 혹은 인터럽트가 처리된 후 다시 사용자 모드로 전환된다. 조금 더 상세하게는 다음과 같은 과정을 거친다. 커널에 들어가는 동안 현재 실행중인 프로세스의 컨텍스트(CPU의 모든 레지스터의 값)가 먼저 메모리에 저장된다. 예외 / 인터럽트를 처리한다. 복원 및 재개할 프로세스를 선택한다. 선택한 프로세스의 컨텍스트를 복구한다. 선택한 프로세스의 실행을 재개한다. Read string system call design문자열(String)을 입력받는 System call을 디자인 해보자. Input buffer &amp; Memory safety 사용자 프로세스가 커널에 저장된 임의의 데이터를 읽을 수 있는 것은 바람직하지 않다. 사용자 프로세스가 입력 버퍼 외부에 데이터를 기록하여 커널을 손상시킬 수 있다. 이를 Buffer overflow라고 한다. 메모리 보안을 위해 사용자 프로세스는 커널 데이터에 읽고 쓸 수 없지만, 커널은 사용자 공간에 데이터를 읽고 쓸 수 있다. Buffer pointer커널은 사용자 공간에서 입력 버퍼에 대한 주소(pointer)를 알아야 한다. Buffer size커널은 입력 버퍼의 크기를 알아야하고 버퍼가 꽉 찼을 때 수행 할 작업을 결정해야한다. Read string system call example","link":"/2019/02/18/Programming/computer-structure/"},{"title":"크롬 확장프로그램 구글 번역기 활용하기","text":"많은 분들이 여러 필요에 의해 Google 번역을 사용하고 있습니다. 대부분의 개발자는 영어 문서를 많이 읽게 되는데, 이해하기 어려운 부분에서는 Google 번역의 도움을 받아 조금 더 쉽게 일을 진행할 수 있습니다. 그러나 Google 번역을 사용하기 위해 따로 인터넷 창 탭에 페이지를 띄워놓고 번역이 필요한 부분을 복사 붙여넣기 해가며 사용하기에는 분명 번거로운 점이 있습니다. 이때 크롬 확장프로그램으로 제공되는 Google 번역을 사용하면 편리하게 사용할 수 있습니다. 먼저 다음과 같이 Chrome 웹 스토어에서 다운로드를 받습니다. 다운로드 후 다음과 같이 옵션을 통해 설정을 변경합니다. Google 번역 크롬 확장프로그램을 다운로드 받고 설정까지 마쳤다면 다음과 같이 번역하고자 하는 부분을 드래그했을 때 크롬 확장프로그램을 통해 자동으로 변역된 결과를 볼 수 있습니다. 만약 번역하고자 하는 부분의 범위가 크다면 드래그 한 후 상단 우측(주소창 우측)에 있는 크롬 확장프로그램 목록 중 Google 번역 아이콘을 클릭하면 다음과 같이 번역된 결과를 확인할 수 있습니다. 간단하게 크롬 확장프로그램 Google 번역을 설치한 후 활용해보았습니다. 앞으로 번역이 필요한 부분은 이제 복사 붙여넣기와 같은 번거로운 과정없이 크롬 확장프로그램 Google 번역을 통해서 진행해보세요!","link":"/2017/07/18/Tip/google-translator/"},{"title":"Retrofit2 + OkHttp3 사용하기","text":"신입사원 프로젝트로 간만에 안드로이드 개발을 하게됐습니다. 서버와 통신하기위해 Square에서 만든 Retrofit 라이브러리를 사용했는데, 기존에 사용하던 버전(1.x)과 변경된 부분이 많아 새롭게 사용법을 알아보고자 합니다.Retrofit 테스트는 API 테스트 사이트를 통해서 Fake data를 가져오는 실습을 해보겠습니다. 해당 글의 대부분은 Retrofit 2.0 Example을 참고했습니다. Retrofit2Retrofit 의외에 다른 라이브러리도 있지만, Retrofit을 사용하기로 한 이유는 성능과 간단한 구현방법 때문입니다. 아래 보시는것과 같이 응답속도가 매우 빠른것으로 나와있습니다. 더 자세한 비교는 Android Async HTTP Clients: Volley vs Retrofit에서 볼 수 있습니다. Retrofit2는 기본적으로 OkHttp를 네트워킹 계층으로 활용하며 그 위에 구축됩니다. Retrofit은 자동적으로 JSON 응답을 사전에 정의된 POJO를 통해 직렬화 할 수 있습니다. JSON을 직렬화 하기 위해서는 먼저 Gson converter가 필요합니다. build.gradle에 다음의 dependencies를 추가합니다.123compile 'com.squareup.retrofit2:retrofit:2.3.0'compile 'com.google.code.gson:gson:2.8.0'compile 'com.squareup.retrofit2:converter-gson:2.1.0' OkHttp는 이미 Retrofit2 모듈의 종속성에 포함되어 있어, 별도의 OkHttp 설정이 필요하다면 다음과 같이 Retrofit2에서 OkHttp 종속성을 제외해야 합니다.12345678compile('com.squareup.retrofit2:retrofit:2.3.0') { exclude module: 'okhttp'}compile 'com.google.code.gson:gson:2.8.0'compile 'com.squareup.retrofit2:converter-gson:2.1.0'compile 'com.squareup.okhttp3:okhttp:3.9.1'compile 'com.squareup.okhttp3:logging-interceptor:3.9.1'// logging-interceptor는 반환된 모든 응답에 대해 로그 문자열을 생성합니다. 네트워크 사용을 위해서 AndroidManifest.xml에서 Internet Permission을 추가합니다.123&lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"&gt; &lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;&lt;/manifest&gt; OkHttp InterceptorsInterceptor는 OkHttp에 있는 강력한 메커니즘으로 호출을 모니터, 재 작성 및 재 시도를 할 수 있습니다. Interceptor는 크게 두 가지 카테고리로 분류할 수 있습니다. Application Interceptors : Application Interceptor를 등록하려면 OkHttpClient.Builder에서 addInterceptor()를 호출해야 합니다. Network Interceptors : Network Interceptor를 등록하려면 addInterceptor() 대신 addNetworkInterceptor()를 추가해야 합니다. Retrofit Interface 설정APIClient.java12345678910111213141516171819202122232425package com.journaldev.retrofitintro;import okhttp3.OkHttpClient;import okhttp3.logging.HttpLoggingInterceptor;import retrofit2.Retrofit;import retrofit2.converter.gson.GsonConverterFactory;class APIClient { private static Retrofit retrofit = null; static Retrofit getClient() { HttpLoggingInterceptor interceptor = new HttpLoggingInterceptor(); interceptor.setLevel(HttpLoggingInterceptor.Level.BODY); OkHttpClient client = new OkHttpClient.Builder().addInterceptor(interceptor).build(); retrofit = new Retrofit.Builder() .baseUrl(\"https://reqres.in/\") .addConverterFactory(GsonConverterFactory.create()) .client(client) .build(); return retrofit; }} getClient() 메서드는 Retrofit 인터페이스를 설정할 때마다 호출됩니다. Retrofit은 @GET, @POST, @PUT, @DELETE, @PATCH or @HEAD와 같은 annotation을 통해 HTTP method를 이용합니다. APIInterface.java1234567891011121314151617181920212223242526272829package com.journaldev.retrofitintro;import com.journaldev.retrofitintro.pojo.MultipleResource;import com.journaldev.retrofitintro.pojo.User;import com.journaldev.retrofitintro.pojo.UserList;import retrofit2.Call;import retrofit2.http.Body;import retrofit2.http.Field;import retrofit2.http.FormUrlEncoded;import retrofit2.http.GET;import retrofit2.http.POST;import retrofit2.http.Query;interface APIInterface { @GET(\"api/unknown\") Call&lt;MultipleResource&gt; doGetListResources(); @POST(\"api/users\") Call&lt;User&gt; createUser(@Body User user); @GET(\"api/users?\") Call&lt;UserList&gt; doGetUserList(@Query(\"page\") String page); @FormUrlEncoded @POST(\"api/users?\") Call&lt;UserList&gt; doCreateUserWithField(@Field(\"name\") String name, @Field(\"job\") String job);} 위의 클래스에서 Annotation을 통해 테스트 HTTP request를 작성했습니다. 해당 API로 이곳을 통해 테스트 할 것입니다. @GET(&quot;api/unknown&quot;)은 doGetListResources()를 호출합니다.doGetListResources()은 메서드 이름입니다. MultipleResource.java는 응답 객체의 Model POJO 클래스로서 Response parameter를 각각의 변수에 매핑하는 데 사용됩니다. 이러한 POJO 클래스는 메소드 리턴 유형으로 동작합니다. MultipleResources.java123456789101112131415161718192021222324252627282930313233package com.journaldev.retrofitintro.pojo;import com.google.gson.annotations.SerializedName;import java.util.ArrayList;import java.util.List;public class MultipleResource { @SerializedName(\"page\") public Integer page; @SerializedName(\"per_page\") public Integer perPage; @SerializedName(\"total\") public Integer total; @SerializedName(\"total_pages\") public Integer totalPages; @SerializedName(\"data\") public List&lt;Datum&gt; data = null; public class Datum { @SerializedName(\"id\") public Integer id; @SerializedName(\"name\") public String name; @SerializedName(\"year\") public Integer year; @SerializedName(\"pantone_value\") public String pantoneValue; }} @SerializedName 어노테이션은 JSON 응답에서 각각의 필드를 구분하기 위해 사용합니다. # Tip) jsonschema2pojo 에서 json 응답의 구조를 바탕으로 해당 응답에 대한 POJO 클래스를 쉽게 만들 수 있습니다. POJO 클래스는 Retrofit Call 클래스로 래핑됩니다. (JSONArray는 POJO 클래스의 객체 목록으로 직렬화됩니다.) Method Parameters : 메서드 내에서 전달할 수 있는 다양한 매개 변수 옵션이 있습니다. @Body - request body로 Java 객체를 전달합니다. @Url - 동적인 URL이 필요할때 사용합니다. @Query - 쿼리를 추가할 수 있으며, 쿼리를 URL 인코딩하려면 다음과 같이 작성합니다.@Query(value = “auth_token”,encoded = true) String auth_token @Field - POST에서만 동작하며 form-urlencoded로 데이터를 전송합니다. 이 메소드에는 @FormUrlEncoded 어노테이션이 추가되어야 합니다. Android Retrofit 예제 프로젝트 구조 pojo 패키지는 APIInterface.java 클래스에 정의된 각각의 API 요청 응답에 대한 4가지 모델 클래스를 정의하고 있습니다. User.java1234567891011121314151617181920package com.journaldev.retrofitintro.pojo;import com.google.gson.annotations.SerializedName;public class User { @SerializedName(\"name\") public String name; @SerializedName(\"job\") public String job; @SerializedName(\"id\") public String id; @SerializedName(\"createdAt\") public String createdAt; public User(String name, String job) { this.name = name; this.job = job; }} 위 클래스는 createUser() 메서드에 대한 응답을 위해 사용합니다. UserList.java123456789101112131415161718192021222324252627282930313233package com.journaldev.retrofitintro.pojo;import com.google.gson.annotations.SerializedName;import java.util.ArrayList;import java.util.List;public class UserList { @SerializedName(\"page\") public Integer page; @SerializedName(\"per_page\") public Integer perPage; @SerializedName(\"total\") public Integer total; @SerializedName(\"total_pages\") public Integer totalPages; @SerializedName(\"data\") public List&lt;Datum&gt; data = new ArrayList(); public class Datum { @SerializedName(\"id\") public Integer id; @SerializedName(\"first_name\") public String first_name; @SerializedName(\"last_name\") public String last_name; @SerializedName(\"avatar\") public String avatar; }} CreateUserResponse.java123456789101112131415package com.journaldev.retrofitintro.pojo;import com.google.gson.annotations.SerializedName;public class CreateUserResponse { @SerializedName(\"name\") public String name; @SerializedName(\"job\") public String job; @SerializedName(\"id\") public String id; @SerializedName(\"createdAt\") public String createdAt;} MainActivity.javaMainActivity.java는 Interface 클래스에 정의된 각각의 API를 호출하고 그 결과를 Toast와 TextView를 통해 표시하고 있습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144package com.journaldev.retrofitintro;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.util.Log;import android.widget.TextView;import android.widget.Toast;import com.journaldev.retrofitintro.pojo.CreateUserResponse;import com.journaldev.retrofitintro.pojo.MultipleResource;import com.journaldev.retrofitintro.pojo.User;import com.journaldev.retrofitintro.pojo.UserList;import java.util.List;import retrofit2.Call;import retrofit2.Callback;import retrofit2.Response;public class MainActivity extends AppCompatActivity { TextView responseText; APIInterface apiInterface; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); responseText = (TextView) findViewById(R.id.responseText); apiInterface = APIClient.getClient().create(APIInterface.class); /** GET List Resources **/ Call&lt;MultipleResource&gt; call = apiInterface.doGetListResources(); call.enqueue(new Callback&lt;MultipleResource&gt;() { @Override public void onResponse(Call&lt;MultipleResource&gt; call, Response&lt;MultipleResource&gt; response) { Log.d(\"TAG\",response.code()+\"\"); String displayResponse = \"\"; MultipleResource resource = response.body(); Integer text = resource.page; Integer total = resource.total; Integer totalPages = resource.totalPages; List&lt;MultipleResource.Datum&gt; datumList = resource.data; displayResponse += text + \" Page\\n\" + total + \" Total\\n\" + totalPages + \" Total Pages\\n\"; for (MultipleResource.Datum datum : datumList) { displayResponse += datum.id + \" \" + datum.name + \" \" + datum.pantoneValue + \" \" + datum.year + \"\\n\"; } responseText.setText(displayResponse); } @Override public void onFailure(Call&lt;MultipleResource&gt; call, Throwable t) { call.cancel(); } }); /** Create new user **/ User user = new User(\"morpheus\", \"leader\"); Call&lt;User&gt; call1 = apiInterface.createUser(user); call1.enqueue(new Callback&lt;User&gt;() { @Override public void onResponse(Call&lt;User&gt; call, Response&lt;User&gt; response) { User user1 = response.body(); Toast.makeText(getApplicationContext(), user1.name + \" \" + user1.job + \" \" + user1.id + \" \" + user1.createdAt, Toast.LENGTH_SHORT).show(); } @Override public void onFailure(Call&lt;User&gt; call, Throwable t) { call.cancel(); } }); /** GET List Users **/ Call&lt;UserList&gt; call2 = apiInterface.doGetUserList(\"2\"); call2.enqueue(new Callback&lt;UserList&gt;() { @Override public void onResponse(Call&lt;UserList&gt; call, Response&lt;UserList&gt; response) { UserList userList = response.body(); Integer text = userList.page; Integer total = userList.total; Integer totalPages = userList.totalPages; List&lt;UserList.Datum&gt; datumList = userList.data; Toast.makeText(getApplicationContext(), text + \" page\\n\" + total + \" total\\n\" + totalPages + \" totalPages\\n\", Toast.LENGTH_SHORT).show(); for (UserList.Datum datum : datumList) { Toast.makeText(getApplicationContext(), \"id : \" + datum.id + \" name: \" + datum.first_name + \" \" + datum.last_name + \" avatar: \" + datum.avatar, Toast.LENGTH_SHORT).show(); } } @Override public void onFailure(Call&lt;UserList&gt; call, Throwable t) { call.cancel(); } }); /** POST name and job Url encoded. **/ Call&lt;UserList&gt; call3 = apiInterface.doCreateUserWithField(\"morpheus\",\"leader\"); call3.enqueue(new Callback&lt;UserList&gt;() { @Override public void onResponse(Call&lt;UserList&gt; call, Response&lt;UserList&gt; response) { UserList userList = response.body(); Integer text = userList.page; Integer total = userList.total; Integer totalPages = userList.totalPages; List&lt;UserList.Datum&gt; datumList = userList.data; Toast.makeText(getApplicationContext(), text + \" page\\n\" + total + \" total\\n\" + totalPages + \" totalPages\\n\", Toast.LENGTH_SHORT).show(); for (UserList.Datum datum : datumList) { Toast.makeText(getApplicationContext(), \"id : \" + datum.id + \" name: \" + datum.first_name + \" \" + datum.last_name + \" avatar: \" + datum.avatar, Toast.LENGTH_SHORT).show(); } } @Override public void onFailure(Call&lt;UserList&gt; call, Throwable t) { call.cancel(); } }); }} apiInterface = APIClient.getClient().create(APIInterface.class);는 APIClient를 인스턴스화 하기위해 사용됩니다.API 응답에 Model 클래스를 매핑하기 위해서는 다음과 같이 사용합니다.MultipleResource resource = response.body(); 이제 앱을 실행하면 각 API를 호출하고 이에 따라 토스트 메시지를 표시합니다. 참고 Volley vs Retrofit OkHttp Example","link":"/2018/01/29/Programming/android-retrofit2-okhttp3/"},{"title":"크롬에서 방문한 링크 색상 변경하기","text":"이번 포스팅에서는 크롬 브라우저에서 방문했던 페이지의 링크 색상을 디폴트 색상보다 조금 더 보기 쉬운 색상으로 변경해보려 합니다. 먼저 이해하기 쉽게 변경 전의 화면과 변경 후의 화면을 스크린샷을 통해 보겠습니다. 위와 같이 방문했던 페이지의 링크 색상을 변경함으로써 조금 더 쉽게 자신이 방문했던 페이지를 식별할 수 있습니다. 그럼 지금부터 위와 같이 색상을 변경하기 위한 작업을 진행해보겠습니다. 먼저, 검색을 통해 크롬 웹 스토어에서 Stylish라고 하는 확장도구(chrome extension)를 설치합니다. Stylish를 설치한 후 Create New Style을 클릭해 새로운 Style을 생성합니다. 다음과 같이 방문했던 링크의 색상을 변경하는 css 코드를 작성하고 Applies to에 변경된 해당 css 코드를 적용하고 싶은 사이트를 기재합니다. (색상은 원하시는 색으로 변경이 가능합니다. 저는 구글과 네이버 검색결과에 적용되도록 설정했습니다.)123a:visited { color: red !important} 작성이 완료되면 SAVE 버튼을 통해 저장을 합니다. 이제 해당 커스텀 style이 적용된 결과를 확인할 수 있습니다.","link":"/2017/07/13/Tip/change-visited-link-color/"},{"title":"(객체지향의 사실과 오해) 정리","text":"객체지향의 사실과 오해 (역할, 책임, 협력 관점에서 본 객체지향) 협력하는 객체들의 공동체 객체지향의 목표는 실세계를 모방하는 것이 아니다. 오히려 새로운 세계를 창조하는 것이다. 객체를 스스로 생각하고 스스로 결정하는 현실 세계의 생명체에 비유하는 것은 상태와 행위를 ‘캡슐화’하는 소프트웨어 객체의 ‘자율성’을 설명하는 데 효과적이다. 현실 세계의 사람들이 암묵적인 약속과 명시적인 계약을 기반으로 목표를 달성해 나가는 과정은 ‘메시지’를 주고받으며 공동의 목표를 달성하기 위해 ‘협력’하는 객체들의 관계를 설명하는 데 적합하다. 실세계의 모방이라는 객체지향의 개념은 훌륭한 프로그램을 설계하고 구현하는 실무적인 관점에서는 부적합하지만 객체지향이라는 용어에 담긴 기본 사상을 이해하고 학습하는 데는 매우 효과적이다. 역할은 관련성 높은 책임의 집합이다. 객체의 역할은 사람의 역할과 유사하게 다음과 같은 특징을 지닌다. 여러 객체가 동일한 역할을 수행할 수 있다. 역할은 대체 가능성을 의미한다. 각 객체는 책임을 수행하는 방법을 자율적으로 선택할 수 있다. 하나의 객체가 동시에 여러 역할을 수행할 수 있다. 객체를 상태와 행동을 함께 지닌 실체라고 정의한다. 이 말은 객체가 협력에 참여하기 위해 어떤 행동을 해야 한다면 그 행동을 하는 데 필요한 상태도 함께 지니고 있어야 한다는 것을 의미한다. 과거의 전통적인 개발 방법은 데이터와 프로세스를 엄격하게 구분한다. 이에 반해 객체지향에서는 데이터와 프로세스를 객체라는 하나의 틀 안에 함께 묶어 놓음으로써 객체의 자율성을 보장한다. 이것이 전통적인 개발 방법과 객체지향을 구분 짓는 가장 핵심적인 차이다. 객체지향의 세계에서는 오직 한 가지 의사소통 수단만이 존재한다. 이를 메시지라고 한다. 객체지향이란? 객체지향이란 시스템을 상호작용하는 자율적인 객체들의 공동체로 바라보고 객체를 이용해 시스템을 분할하는 방법이다. 자율적인 객체란 상태와 행위를 함께 지니며 스스로 자기 자신을 책임지는 객체를 의미한다. 객체는 시스템의 행위를 구현하기 위해 다른 객체와 협력한다. 각 객체는 협력 내에서 정해진 역할을 수행하며 역할은 관련된 책임의 집합이다. 객체는 다른 객체와 협력하기 위해 메시지를 전송하고, 메시지를 수신한 객체는 메시지를 처리하는 데 적합한 메서드를 자율적으로 선택한다. 이상한 나라의 객체 인간은 행동의 과정과 결과를 단순하게 기술하기 위해 상태라는 개념을 고안했다. 상태를 이용하면 과거에 얽매이지 않고 현재를 기반으로 객체의 행동 방식을 이해할 수 있다. 객체와 객체 사이의 의미 있는 연결을 링크라고 한다. 객체와 객체 사이에는 링크가 존재해야만 요청(메시지)을 보내고 받을 수 있다. 객체 간의 선으로 표현되는 링크와 달리 객체를 구성하는 단순한 값은 속성이라고 한다. 객체는 자율적인 존재이다. 객체지향의 세계에서 객체는 다른 객체의 상태에 직접적으로 접근할 수도, 상태를 변경할 수도 없다. 자율적인 객체는 스스로 자신의 상태를 책임져야 한다. 객체의 상태는 저절로 변경되지 않는다. 객체의 상태를 변경하는 것은 객체의 자발적인 행동뿐이다. 객체는 협력에 참여하는 과정에서 자기 자신의 상태뿐만 아니라 다른 객체의 상태 변경을 유발할 수도 있다. 객체의 행동으로 인해 발생하는 결과는 두 가지 관점에서 설명할 수 있다. 객체 자신의 상태 변경 행동 내에서 협력하는 다른 객체에 대한 메시지 전송 현실 세계의 객체와 객체지향 세계의 객체 사이에는 중요한 차이점이 있다. 현실과 달리 객체지향의 세계에서 모든 객체는 자신의 상태를 스스로 관리하는 자율적인 존재다. 객체는 상태를 캡슐 안에 감춰둔 채 외부로 노출하지 않는다. 객체가 외부에 노출하는 것은 행동뿐이며, 외부에서 객체에 접근할 수 있는 유일한 방법 역시 행동뿐이다. 객체의 행동을 유발하는 것은 외부로부터의 전달된 메시지지만 객체의 상태를 변경할지 여부는 객체 스스로 결정한다. 사실 객체에게 메시지를 전달하는 외부의 객체는 메시지를 수신하는 객체의 상태가 변경된다는 사실조차 알지 못한다. 상태를 외부에 노출시키지 않고 행동을 경계로 캡슐화하는 것은 결과적으로 객체의 자율성을 높인다. 상태를 잘 정의된 행동 뒤로 캡슐화하는 것은 객체의 자율성을 높이고 협력을 단순하고 유연하게 만든다. 상태를 먼저 결정하고 행동을 나중에 결정하는 방법은 설계에 나쁜 영향을 끼친다. 상태를 먼저 결정할 경우 캡슐화가 저해된다. 객체를 협력자가 아닌 고립된 섬으로 만든다. 객체의 재사용성이 저하된다. 객체지향 설계는 애플리케이션에 필요한 협력을 생각하고 협력에 참여하는 데 필요한 행동을 생각한 후 행동을 수행할 객체를 선택하는 방식으로 수행된다. 행동을 결정한 후에야 행동에 필요한 정보가 무엇인지를 고려하게 되며 이 과정에서 필요한 상태가 결정된다. 객체지향 세계는 현실 세계의 단순한 모방이 아니다. 소프트웨어 안에 구현된 상품 객체는 실제 세계의 상품과는 전혀 다른 양상을 띤다. 현실 속에서는 수동적인 존재가 소프트웨어 객체로 구현될 때는 능동적으로 변한다. 소프트웨어 객체가 현실 객체의 부분적인 특징을 모방하는 것이 아니라 현실 객체가 가지지 못한 추가적인 능력을 보유하게 된다. 현실 세계와 객체지향 세계 사이의 관계를 좀 더 정확하게 설명할 수 있는 단어는 은유다. 현실 속의 객체의 의미 일부가 소프트웨어 객체로 전달되기 때문에 프로그램 내의 객체는 현실 속의 객체에 대한 은유다. 역할, 책임, 협력 객체의 세계에서는 협력이라는 문맥이 객체의 행동 방식을 결정한다. 중요한 것은 개별 객체가 아니라 객체들 사이에 이뤄지는 협력이다. 객체지향 개발에서 가장 중요한 능력은 책임을 능숙하게 소트웨어 객체에 할당하는 것이다. 책임을 어떻게 구현할 것인가 하는 문제는 객체와 책임이 제자리를 잡은 후에 고려해도 늦지 않다. 객체와 책임이 이리저리 부유하는 상황에서 성급하게 구현에 뛰어드는 것은 변경에 취약하고 다양한 협력에 참여할 수 없는 비자율적인 객체를 낳게 된다. 객체의 책임은 크게 ‘하는 것’과 ‘아는 것’의 두 가지 범주로 분류된다. 하는 것 객체를 생성하거나 계산을 하는 등의 스스로 하는 것 다른 객체의 행동을 시작시키는 것 다른 객체의 활동을 제어하고 조절하는 것 아는 것 개인적인 정보에 관해 아는 것 관련된 객체에 관해 아는 것 자신이 유도하거나 계산할 수 있는 것에 관해 아는 것 책임은 객체의 외부에 제공해 줄 수 있는 정보(아는 것의 측면)와 외부에 제공해 줄 수 있는 서비스(하는 것의 측면)의 목록이다. 따라서 책임은 객체의 공용 인터페이스를 구성한다. 객체가 다른 객체에게 주어진 책임을 수행하도록 요청을 보내는 것을 메시지 전송이라고 한다. 따라서 두 객체 간의 협력은 메시지를 통해 이뤄진다. 객체지향 설계는 협력에 참여하기 위해 어떤 객체가 어떤 책임을 수행해야 하고 어떤 객체로부터 메시지를 수신할 것인지를 결정하는 것으로부터 시작된다. 어떤 클래스가 필요하고 어떤 메서드를 포함해야 하는지를 결정하는 것은 책임과 메시지에 대한 대략적인 윤곽을 잡은 후에 시작해도 늦지 않다. 역할은 협력 내에서 다른 객체로 대체할 수 있음을 나타내는 일종의 표식이다. 협력 안에서 역할은 “이 자리는 해당 역할을 수행할 수 있는 어떤 객체라도 대신할 수 있습니다”라고 말하는 것과 같다. 역할을 대체하기 위해서는 각 역할이 수신할 수 있는 메시지를 동일한 방식으로 이해해야 한다. 역할은 객체지향 설계의 단순성, 유연성, 재사용성을 뒷받침하는 핵심 개념이다. 역할의 대체 가능성은 행위 호환성을 의미하고, 행위 호환성은 동일한 책임의 수행을 의미한다. 객체지향 설계 기법 책임-주도 설계(Responsibility-Driven Design) 객체지향 설계란 애플리케이션의 기능을 구현하기 위한 협력 관계를 고안하고, 협력에 필요한 역할과 책임을 식별한 후 이를 수행할 수 있는 적절한 객체를 식별해 나가는 과정이다. 객체지향 설계의 핵심은 올바른 책임을 올바른 객체에게 할당하는 것이다. 책임-주도 설계에서는 시스템의 책임을 객체의 책임으로 변환하고, 각 객체가 책임을 수행하는 중에 필요한 정보나 서비스를 제공해줄 협력자를 찾아 해당 협력자에게 책임을 할당하는 순차적인 방식으로 객체들의 협력 공동체를 구축한다. 책임-주도 설계는 개별적인 객체의 상태가 아니라 객체의 책임과 상호작용에 집중한다. 디자인 패턴(Design Pattern) 디자인 패턴은 책임-주도 설계의 결과를 표현한다. 패턴은 모범이되는 설계다. 패턴은 반복해서 일어나는 특정한 상황에서 어떤 설계가 왜 더 효과적인지에 대한 이유를 설명한다. 특정 상황에 적용 가능한 디자인 패턴을 잘 알고 있다면 책임-주도 설계의 절차를 순차적으로 따르지 않고도 시스템 안에 구현할 객체들의 역할과 책임, 협력 관계를 빠르고 손 쉽게 포착할 수 있을 것이다. 테스트-주도 개발(Test-Driven Development) 테스트-주도 개발의 기본 흐름은 실패하는 테스트를 작성하고, 테스트를 통과하는 가장 간단한 코드를 작성한 후, 리팩터링을 통해 중복을 제거하는 것이다. 테스트-주도 개발은 객체가 이미 존재한다고 가정하고 객체에게 어떤 메시지를 전송할 것인지에 관해 먼저 생각하라고 충고한다. 그러나 이 같은 종류의 충고는 역할, 책임, 협력의 관점에서 객체를 바라보지 않을 경우 무의미하다. 테스트-주도 개발은 테스트를 작성하는 것이 아니라 책임을 수행할 객체 또는 클라이언트가 기대하는 객체의 역할이 메시지를 수신할 때 어떤 결과를 반환하고 그 과정에서 어떤 객체와 협력할 것인지에 대한 기대를 코드의 형태로 작성하는 것이다. 테스트를 작성하기 위해 객체의 메서드를 호출하고 반환값을 검증하는 것은 순간적으로 객체가 수행해야 하는 책임에 관해 생각한 것이다. 테스트에 필요한 간접 입력 값을 제공하기 위해 스텁(stub)을 추가하거나 간접 출력 값을 검증하기 위해 목 객체(mock object)를 사용하는 것은 객체와 협력해야 하는 협력자에 관해 고민한 결과를 코드로 표현한 것이다. 책임과 메시지 객체가 어떤 행동을 하는 유일한 이유는 다른 객체로부터 요청을 수신했기 때문이다. 요청을 처리하기 위해 객체가 수행하는 행동을 책임이라고 한다. 따라서 자율적인 객체란 스스로의 의지와 판단에 따라 각자 맡은 책임을 수행하는 객체를 의미한다. 적절한 책임이 자율적인 객체를 낳고, 자율적인 객체들이 모여 유연하고 단순한 협력을 낳는다. 따라서 협력에 참여하는 객체가 얼마나 자율적인지가 전체 애플리케이션의 품질을 결정한다. 추상적이고 포괄적인 책임은 협력을 좀 더 다양한 환경에서 재사용할 수 있도록 유연성이라는 축복을 내려준다. 그러나 책임은 협력에 참여하는 의도를 명확하게 설명할 수 있는 수준 안에서 추상적이어야 한다. 객체가 다른 객체에게 접근할 수 있는 유일한 방법은 요청을 전송하는 것뿐이다. 그리고 이 요청을 메시지라고 부른다. 메시지는 객체로 하여금 자신의 책임, 즉 행동을 수행하게 만드는 유일한 방법이다. 메시지를 처리할 수 있다는 것은 객체가 해당 메시지에 해당하는 행동을 수행해야 할 책임이 있다는 것을 의미한다. 따라서 메시지의 개념은 책임의 개념과 연결된다. 송신자는 메시지 전송을 통해서만 다른 객체의 책임을 요청할 수 있고, 수신자는 오직 메시지 수신을 통해서만 자신의 책임을 수행할 수 있다. 따라서 객체가 수신할 수 있는 메시지의 모양이 객체가 수행할 책임의 모양을 결정한다. 객체가 유일하기 이해할 수 있는 의사소통 수단은 메시지 뿐이며 객체는 메시지를 처리하기 위한 방법을 자율적으로 선택할 수 있다. 외부의 객체는 메시지에 관해서만 볼 수 있고 객체 내부는 볼 수 없기 때문에 자연스럽게 객체의 외부와 내부가 분리된다. 메시지를 수신한 객체가 실행 시간에 메서드를 선택할 수 있다는 사실은 다른 프로그래밍 언어와 객체지향 프로그래밍 언어를 구분 짓는 핵심적인 특징 중 하나다. 이것은 프로시저 호출에 대한 실행 코드를 컴파일 시간에 결정하는 절차적인 언어와 확연히 구분되는 특징이다. 다형성이란 서로 다른 유형의 객체가 동일한 메시지에 대해 서로 다르게 반응하는 것을 의미한다. 서로 다른 타입에 속하는 객체들이 동일한 메시지를 수신할 경우 서로 다른 메서드를 이용해 메시지를 처리할 수 있는 메커니즘을 가리킨다. 다형성은 역할, 책임, 협력과 깊은 관련이 있다. 서로 다른 객체들이 다형성을 만족시킨다는 것은 객체들이 동일한 책임을 공유한다는 것을 의미한다. 다형성에서 중요한 것은 메시지 송신자의 관점이다. 메시지 수신자들이 동일한 오퍼레이션을 서로 다른 방식으로 처리하더라도 메시지 송신자의 관점에서 이 객체들은 동일한 책임을 수행하는 것이다. 즉, 다형성은 수신자의 종류를 캡슐화한다. 다형성은 송신자와 수신자 간의 객체 타입에 대한 결합도를 메시지에 대한 결합도로 낮춤으로써 달성된다. 다형성을 사용하면 메시지를 이해할 수 있는 어떤 객체와도 협력할 수 있는 유연하고 확장 가능한 구조를 만들 수 있다. 객체지향 패러다임이 강력한 이유는 다형성을 이용해 협력을 유연하게 만들 수 있기 때문이다. 객체지향의 기본 개념은 책임을 수행하는 자율적인 객체들의 협력을 통해 애플리케이션을 구축하는 것이다. 객체지향의 세계에서 객체들이 서로 협력하기 위해 사용할 수 있는 유일한 방법은 메시지를 전송하는 것이다. 객치지향 애플리케이션의 중심 사상은 연쇄적으로 메시지를 전송하고 수신하는 객체들 사이의 협력 관계를 기반으로 사용자에게 유용한 기능을 제공하는 것이다. 클래스 기반의 객체지향 언어를 사용하는 대부분의 사람들은 객체지향 애플리케이션을 클래스의 집합으로 생각한다. 프로그래머 입장에서 클래스는 실제로 볼 수 있고 수정할 수 있는 구체적인 존재다. 그러나 클래스는 단지 동적인 객체들의 특성과 행위를 정적인 텍스트로 표현하기 위해 사용할 수 있는 추상화 도구일 뿐이다. 중요한 것은 클래스가 아니라 객체다. 클래스를 정의하는 것이 먼저가 아니라 객체들의 속성과 행위를 식별하는 것이 먼저다. 클래스는 객체의 속성과 행위를 담는 틀일 뿐이다. 객체지향 패러다임으로의 전환은 시스템을 정적인 클래스들의 집합이 아니라 메시지를 주고받는 동적인 객체들의 집합으로 바라보는 것에서 시작된다. 클래스에 담길 객체들의 공통적인 행위와 속성을 포착하기 위해서는 먼저 협력하는 객체들의 관점에서 시스템을 바라봐야 한다. 진정한 객체지향 패러다임으로의 도약은 개별적인 객체가 아니라 메시지를 주고받는 객체들 사이의 커뮤니케이션에 초점을 맞출 때 일어난다. 훌륭한 객체지향 설계는 어떤 객체가 어떤 메시지를 전송할 수 있는가와 어떤 객체가 어떤 메시지를 이해할 수 있는가를 중심으로 객체 사이의 협력 관계를 구성하는 것이다. 이것은 개별 객체에 초점을 맞추는 관점과는 매우 다르다. 사실 협력이라는 문맥에서 벗어나 독립적인 객체에 관해 고민하는 것은 클래스에 초점을 맞추는 것과 별다른 차이가 없다. 객체지향 설계의 중심에는 메시지가 위치한다. 객체가 메시지를 선택하는 것이 아니라 메시지가 객체를 선택하게 해야 한다. 메시지가 객체를 선택하게 만들려면 메시지를 중심으로 협력을 설계해야 한다. 책임-주도 설계의 핵심은 어떤 행위가 필요한지를 먼저 결정한 후에 이 행위를 수행할 객체를 결정하는 것이다. 이 과정을 흔히 What/Who 사이클이라고 한다. 결론적으로 협력이라는 문맥 안에서 필요한 메시지를 먼저 결정한 후에 메시지를 수신하기에 적합한 객체를 선택한다. 그리고 수신된 메시지가 객체의 책임을 결정한다. 이것은 객체를 고립된 상태로 놓고 어떤 책임이 적절한지를 결정하는 것과는 근본적으로 다른 접근 방법이다. 협력이라는 문맥 안에서 객체의 책임을 결정하는 것은 메시지다. 책임이 먼저 오고 객체가 책임을 따른다. 결과적으로 시스템이 수행해야 하는 전체 행위는 협력하는 객체들의 책임으로 분배된다. 객체가 자신이 수신할 메시지를 결정하게 하지 말고 메시지가 협력에 필요한 객체를 발견하게 해야 한다.","link":"/2019/02/10/Programming/object_oriented_facts_and_misunderstandings/"},{"title":"HMAC을 이용한 무결성 보장","text":"지난번에 Hash에 대한 내용을 살펴보았다. 이번에는 Hash의 개념을 이용한 HMAC에 대해서 알아보자. HMAC(Hash-based Message Authentication Code)메시지 인증 코드(Message Authentication Code, MAC)는 메시지의 인증에 쓰이는 정보(코드)이다. 메시지의 무결성 및 신뢰성을 보장하는 용도로 MAC을 사용한다. 무결성이란, 서버 입장에서 클라이언트로부터 API 요청을 받았을 때, 이 요청이 신뢰할 수 있는 것인지 (정보가 중간에 변경없이 그대로 전달된 것인지)에 대한 성질을 말한다. HMAC은 인증을 위한 Secret Key와 임의의 길이를 가진 Message를 해시 함수(알고리즘)을 사용해서 생성한다. 해시 함수로는 MD5, SHA-256과 같은 일반적인 해시 함수를 그대로 사용할 수 있으며 각 알고리즘에 따라 다른 고정길이의 MAC(Hash value)가 생성된다. Secret Key: 서버와 클라이언트가 함께 알고 있는 외부로 유출되어서는 안되는 값. Message: 클라이언트가 전송하는 요청의 전체(Header + Body)가 될 수도 있고, URL만 될 수도 있다. 만약 Message를 변경하지 않고, 중간에 Message를 취득한 공격자가 변조 없이 동일한 요청을 계속 보낸다면, Message를 변조하지 않았기 때문에 서버는 이를 유효한 요청으로 인식할 것이다. 이것을 Replay Attack이라고 하는데 이를 방지하기 위해서 MAC을 생성할 때 timestamp를 추가해서 사용하는 방법이 있다.이렇게 하면 서버는 이 Message가 생성된 시간을 알 수 있고, 생성된 시간부터 일정 시간내의 호출만 정상적인 호출로 사용하면 된다. 전체 과정은 아래와 같다. 해시 생성: 클라이언트는 Key와 Message를 이용해 해시함수로부터 MAC을 생성한다. 데이터 전송: 생성된 MAC과 Message를 서버에게 전송한다. MAC은 HTTP Request Header 혹은 URL에 포함된다. 해시 생성: 서버는 클라이언트로부터 전달받은 Message와 갖고 있던 Key를 이용해 해시함수로부터 MAC을 생성한다. 해시 비교: 서버에서 생성된 MAC과 클라이언트로부터 전달받은 MAC의 값이 같은지 비교한다. 사용되는 곳을 보자면, AWS에서는 Authorization(HTTP Request Header)에 HMAC-SHA256으로 만들어진 값을 포함해 인증한다.","link":"/2019/12/23/Programming/hmac/"},{"title":"Intellij IDEA 단축키","text":"산뜻한 월요일 출근길 아침에 한통의 메시지를 받았다. 얼마전에 요런 이벤트에 응모했는데 오오…? 당첨된 것이다. 신가하게 개발 서적 혹은 강의 관련된 이벤트에 자주 당첨되는것 같다. 자세히 보니 5명 뽑는 이벤트에 15명이 지원한건가…그래도 당첨됐다는 사실에 기뻤다!평소에 자주보는 페이지이기도 하고 위의 IntelliJ 강의는 처음 나왔을 때, 들어보고 싶었다는 생각이 있었지만 공부할게 너무 많아 미뤄놨었는데 마침 당첨된 기념으로 월요일 퇴근 후 바로 끝장을 보았다. 어디에 도움이 될까?대부분의 개발자는 자신만의 개발 환경을 구축해서 사용한다. 예를 들면, 자신만의 dot file 들을 만들어 사용한다던가 IDEA의 세팅들을 커스터마이징해서 사용하는 것들이 있다.나도 처음에는 IDEA의 “자동 정렬”과 같은 가장 간단한 단축키부터 사용하기 시작해 현재는 IntelliJ에 IdeaVim 플러그인 설치해서 사용할 정도로 나만의 개발환경을 구축하는데 적지 않은 시간을 쏟았다. 처음에는 물론 사용하기 쉽지 않다. 그러나 적응하기 시작하는 순간 엄청난 생산성의 향상을 가져온다. 손이 마우스로 가지 않고 vim을 사용하면 심지어 방향키 까지도 손이 가지 않는다. 이런 개발 환경을 구축하는데 있어 한가지 문제가 있다. 어떤 기능들이 있는지 알아야 찾아서 사용할텐데 어떤 기능들이 있는지 조차 파악하기가 마냥 쉬운게 아니라는 것이다. 대부분 내가 모르는 기능을 누군가 사용할때는 “이런 기능이 있었어?” 라는 반응이 많은데 이게 문제다! 한 번 사용하면 계속 사용하게 되는데 처음 사용하기가 어려운 이유이기도 하다. 다행히도 위의 강의는 이런 문제를 해소해준다! IntelliJ를 처음 사용하는 사람도! 이미 사용하고 있던 사람도! 모두 도움이 될 것이다. 어떤 기능이 있는지, 해당 기능을 어떤 단축키를 통해 사용할 수 있는지 강의를 보고 배워보자! 강의는 인프런을 통해서 수강할 수 있다. -&gt; IntelliJ를 시작하는 분들을 위한 가이드 강의를 수강하며 새롭게 알게된 기능중 라인 합치기의 경우 Vim의 Shift + J 단축키를 이용해 사용하고 있었는데, 단순히 두 라인을 합쳐주는 기능하는 걸 넘어서, IntelliJ의 Shift + Cmd + J는 문자열을 합칠 경우 더 유용하게 사용 가능했다. 그래서 Shift + Cmd + J를 Shift + J로 변경해버렸다! 단축키수강하며 실습해 볼 수 있는 단축키 리스트 코드 템플릿메인 메소드 : psvmSystem.out.println() : sout 실행환경 실행현재 포커스 : Ctrl + Shift + R이전 실행 : Ctrl + R 코드 Edit메인 메소드 실행 :라인 복사 : Cmd + D라인 삭제 : Cmd + 백스페이스라인 합치기 : Ctrl + Shift + J라인 이동 : Shfit + Option + 위 (아래)구문 이동 : Shift + Cmd + 위 (아래)Element 단위 이동 : Option + Shift + Cmd + 좌 (우)인자값 즉시 보기 : Cmd + P코드 구현부 즉시 보기 : Option + SpaceDoc 즉시 보기 : F1 포커스단어별 이동 : Option + &lt;, &gt;단어별 선택 : Shift + Option + &lt;, &gt;라인 첫/끝 이동 : Fn + &lt;, &gt;라인 전체 선택 : Shift + Cmd + &lt;, &gt; / Shift + Fn + &lt;, &gt;Page Up/Down : Fn + 위/아래포커스 범위 한 단계씩 늘리기 : Option + 위 (아래)포커스 뒤로/앞으로 가기 : Cmd + [, ]멀티 포커스 : Option + Option + 아래오류 라인 자동 포커스 : F2 검색현재 파일에서 검색 : Cmd + F현재 파일에서 교체 : Cmd + R전체에서 검색 : Shift + Cmd + F전체에서 교체 : Shift + Cmd + R정규표현식으로 검색, 교체 : Regex 체크파일 검색 : Shift + Cmd + O메소드 검색 : Option + Cmd + OAction 검색 : Shift + Cmd + A최근 열었던 파일 목록 보기 : Cmd + E최근 수정했던 파일 목록 보기 : Shift + Cmd + E 자동완성스마트 자동 완성 : Shift + Ctrl + Space스태틱 메소드 자동 완성 : Ctrl + Space + SpaceGetter/Setter/생성자 자동 완성 : Cmd + NOverride 메소드 자동완성 : Ctrl + ILive Template 목록 보기 : Cmd + J 리팩토링변수 추출하기 : Cmd + Option + V파라미터 추출하기 : Cmd + Option + P메소드 추출하기 : Cmd + Option + M이너클래스 추출하기 : F6이름 일괄 변경하기 : Shift + F6타입 일괄 변경하기 : Shift + Cmd + F6Import 정리하기 : Ctrl + Option + O코드 자동 정렬하기 : Cmd + Option + L 디버깅Debug 모드로 실행하기 (현재 위치의 메소드) : Shift + Ctrl + DDebug 모드로 실행하기 (이전에 실행한 메소드) : Ctrl + DResume (다음 브레이크 포인트로 이동하기) : Cmd + Option + RStep Over (현재 브레이크에서 다음 한줄로 이동하기) : F8Step Into (현재 브레이크의 다음 메소드로 이동) : F7Step Out (현재 메소드의 밖으로 이동) : Shift + F8Evaluate Expression (브레이크된 상태에서 코드 사용하기) : Option + F8Watch (브레이크 이후의 코드 변경 확인하기) : 단축키 X GitGit View On : Cmd + 9Git Option Popup : Ctrl + VGit History : Ctrl + V =&gt; 4Branch : Ctrl + V =&gt; 7Commit : Cmd + KPush : Shift + Cmd + KPull : Shift + Cmd + A =&gt; git pullGithub 연동하기 : Shift + Cmd + A =&gt; share GitHub","link":"/2018/07/31/Tip/intellij-shortcut/"},{"title":"Redux 사용하기","text":"Index Flux와 Redux Redux의 시작은 Flux 리듀서(Reducer) 스토어(Store) Redux 구성요소 액션(Action) 액션 생성자(Action Creator) 리듀서(Reducer) 스토어(Store) 뷰 레이어 바인딩(The view layer binding) 루트 컴포넌트 Redux 사용 준비 Redux 데이터 흐름 React Native에서 Redux 사용하기 프로젝트 생성 루트 컴포넌트 생성 &amp; 설정 Count 컴포넌트 생성 Count 액션 생성 Count 리듀서 생성 루트 컴포넌트에 스토어 연결 Count 컴포넌트 바인딩 포스팅 마치며 공부하고 반복해서 복습하고 마지막에는 스스로 정리해보는 시간을 갖는것이 스스로에게 많은 도움이 되는것 같습니다. 그래서 이번에는 ReactNative에서 Redux를 사용하기라는 주제로 포스팅을 하려합니다. Flux에서 Redux 그리고 ReactNative까지 정말 자세하고 친절하게 설명해주신 분들이 많습니다. 제가 공부하며 참고했던 좋은 글들과 강의는 React Native 글 모음에 따로 정리를 하였습니다. 이 글에서는 제가 그동안 Redux 공부하며 이해가 잘 되지 않았던 부분들에 중점을 맞춰서 정리해보고 React Native에 Redux를 적용시키는 것으로 마무리하려 합니다. 아직은 Redux에 대해 잘 안다고 말할 수 없지만, 이번 기회로 정리하며 다시 다잡으려 합니다. 혹시나 제가 잘못이하거나 틀린 부분이 있다면 댓글로 알려주시면 감사하겠습니다. Flux와 Redux Redux의 시작은 FluxRedux는 페이스북에서 MVC 패턴의 단점을 보완하고자 만든 아키텍처인 Flux의 구현체중 하나입니다. Flux의 구현체는 Redux 외에도 Reflux, rx-flux 등… 여러 구현체가 있지만 그중 Redux가 가장 널리 사용되고 있습니다. 저는 Redux를 처음 접했을때 Flux와 많이 혼동했습니다. Redux와 Flux의 구성 요소와 역할에 대해 혼란스러웠고 정리가 잘 되지 않았는데 이는 Redux와 Flux의 다른점에 대해 집중하지 않았기 때문입니다. Redux는 Flux와 마찬가지로 애플리케이션의 상태를 예측 가능하게 합니다. 그러나 Redux는 Flux와 다른 특징이 있습니다. 바로 핫 리로딩(hot reloading)과 시간 여행 디버깅(time travel debugging)입니다. 이 두가지의 특징으로 인해 Redux는 Flux의 구성요소에는 없는 리듀서(reducer)가 생겨나고, 스토어(Store)의 역할이 조금 변하게 됩니다. 리듀서(Reducer)Flux에서 스토어는 (1) 상태 변환을 위한 로직, (2) 현재 애플리케이션의 상태를 포함하고 있습니다. 스토어가 이 두 가지를 모두 갖고 있기 때문에 핫 리로딩시 문제가 발생합니다. 상태 변환을 위한 로직을 수정하기 위해 스토어 객체를 리로딩하면 스토어에 저장된 기존의 상태와 뷰를 비롯한 나머지 시스템과의 이벤트 구독이 사라지게 되어 문제가되기 때문입니다. 이를 해결하기 위해 Redux에서는 리듀서(reducer)가 새로운 구성요소로 추가됩니다. 리듀서는 스토어가 갖고 있던 상태 변환을 위한 로직을 대신 갖게됩니다. 따라서 스토어는 액션이 발생했을 때 어떤 상태 변화를 만들어야 하는지 알기위해 리듀서에게 요청합니다. 이렇게 기존 스토어에서 상태 변환을 위한 로직이 분리되었기 때문에 이제 핫 리로딩이 가능하게 됩니다. 리듀서는 첫 번째 인수로 기존 상태의 값 두 번째 인수로는 액션을 가집니다. 리듀서를 작성할 때는 주의사항이 있는데, 첫 번째 인수로서 기존 상태를 갖고 있는 state는 수정하지 않고 상태를 수정할 때는 새롭게 생성하여야 합니다. 이 주의사항으로 지킴으로써 각각의 액션이 발생할 때마다 새로운 상태의 객체가 생성되어 결과적으로는 Redux의 특징인 시간 여행 디버깅이 가능하게 됩니다. 스토어(Store)Redux의 스토어는 Flux의 스토어와는 다소 차이가 있습니다. 먼저 Flux에서는 다수의 스토어를 가질 수 있었고, 각 스토어는 자신의 범위에 있는 애플리케이션의 상태를 변환할 수 있는 로직을 포함하고 있었습니다. 그러나 Redux는 하나의 스토어만을 가집니다. 또한 Redux의 스토어는 상태 트리(state tree) 전체를 유지하는 책임을 가지며, Flux의 디스패쳐(dispatcher)의 역할도 대신합니다.(Flux의 디스패쳐는 모든 스토어를 갖고 있고, 액션 생성자로부터 액션을 넘겨받으면 스토어에 전달합니다.) 따라서 Redux에서는 스토어에서 제공하는 dispatch 함수로 디스패쳐의 동작을 대신합니다. Redux 구성요소지금까지 Flux와 Redux의 차이점과 그로 인해 Redux가 가질 수 있게된 특징에 대해 알아보았습니다. 지금부터는 Redux의 구성요소를 살펴보겠습니다. 액션(Action)액션은 애플리케이션의 상태를 갖고 있는 스토어로 전달하는 데이터 묶음입니다. store.dispatch() 를 통해 스토어에 액션을 전달할 수 있습니다. 액션은 평범한 자바스크립트 객체이며, type 속성을 갖고 있습니다. 이 type 속성은 액션을 전달받은 스토어가 애플리케이션의 상태변환 로직을 갖고 있는 리듀서를 참조할때 사용하게 됩니다. 액션 생성자(Action Creator)액션 생성자는 액션을 만드는 함수입니다. Flux에서는 함수 내부에서 dispatch 함수를 통해 액션을 전달하지만 Redux의 액션 생성자는 단지 액션을 반환하기만 합니다. 실제 액션을 전달할때는 결과값을 dispatch 함수에 전달하거나 생성된 액션을 자동으로 보내주는 바인드된 액션 생성자를 만듭니다. 리듀서(Reducer)액션은 무언가 일어나 상태가 변할것이라는 사실을 말할뿐, 그 결과 실제 애플리케이션의 상태가 어떻게 바뀌는지는 리듀서가 담당합니다. 리듀서는 이전 상태와 액션을 받아서 다음 상태를 반환하는 역할을 하는 순수 함수입니다. 따라서 항상 다음 상태를 계산해서 반환하는 역할만 합니다. API 호출이라던가, Date.now()나 Math.random() 과 같은 순수하지 않은 함수를 호출하는 일은 해서는 안됩니다. Redux는 처음에 리듀서를 undefined 상태로 호출하여 초기 상태를 반환합니다. 리듀서는 서로 독립적으로 수행된다면 분리될 수 있고, 이 분리된 리듀서는 *루트 리듀서라는 하나의 객체로 조합될 수 있습니다. 결과적으로 처음에 undefined 상태로 호출되면 각각의 자식 리듀서들이 초기 상태를 반환하게 되고, 각각의 리듀서는 전체 상태에서 자신의 부분만을 관리합니다. 모든 리듀서의 state 매개변수는 서로 다르고, 자신이 관리하는 상태 부분에 해당합니다. 스토어(Store)스토어는 “무엇이 일어날지”를 표현하는 액션과 이 액션에 따라 애플리케이션의 상태를 어떻게 수정할지를 나타는 리듀서를 함께 가져오는 객체입니다. 스토어는 다음과 같은 일들을 합니다. 애플리케이션의 상태를 저장 getState()를 통해 상태에 접근 dispatch(action)을 통해 상태를 수정할 수 있게 함 subscribe(listener)를 통해 리스너를 등록 Redux의 스토어는 Flux와는 달리 하나의 스토어만을 가질 수 있기 때문에 데이터를 다루는 로직을 나누고 싶다면 여러개의 리듀서를 조합하여 대신할 수 있습니다. 뷰 레이어 바인딩(The view layer binding)뷰 레이어 바인딩은 생성된 스토어를 뷰에 연결하기 위해 필요합니다. 뷰 레이어 바인딩은 connect() 을 통해 컴포넌트(뷰)가 애플리케이션의 상태 업데이트를 받을 수 있도록 모든 연결을 만들어줍니다. 루트 컴포넌트(Root component)모든 React 애플리케이션은 루트 컴포넌트를 가집니다. 루트 컴포넌트는 계층 구조에서 가장 위에 위치하는 컴포넌트이며, 스토어를 생성하고 어떤 리듀서를 사용할지 알려주며 뷰 레이어 바인딩과 뷰를 불러옵니다. Redux 사용 준비애플리케이션을 생성하며 Redux의 구성요소들이 서로 연결됩니다. combineReducers()를 통해 다수의 리듀서를 하나로 묶은 후 루트 컴포넌트가 createStore()를 이용해 스토어를 생성할때 전달합니다. 루트 컴포넌트는 공급 컴포넌트와 스토어 사이를 연결함으로써 스토어와 컴포넌트 사이의 커뮤니케이션을 준비합니다. (이후 컴포넌트에서 connect()를 통해 상태 업데이트를 받을 수 있습니다.) Redux 데이터 흐름Redux의 아키텍쳐는 엄격한 일방향 데이터 흐름에 따라 전개되며 데이터의 흐름은 4단계에 따라 진행됩니다. 1. 액션 생성 후 스토어에 전달액션은 무언가 일어나 상태가 변할 것이라는 내용을 담고 있는 객체입니다. 액션 생성자를 통해 액션을 생성한 후 store.dispatch(action)을 통해 스토어에 전달합니다. 2. 스토어가 리듀서를 호출스토어는 리듀서에 현재의 상태 트리와 전달받은 액션을 두 가지 인수로 전달합니다. 3. 루트 리듀서가 각 리듀서의 출력을 합쳐 하나의 상태 트리 생성각각의 상태를 다루는 리듀서에 의해 생성된 결과를 하나로 합쳐 루트 리듀서가 하나의 상태 트리를 생성합니다. 4. Redux 스토어가 루트 리듀서에 의해 반환된 상태 트리를 저장새로운 상태 트리가 앱의 다음 상태입니다. store.subscribe(listener)를 통해 등록된 모든 리스너가 불러내지고 이들은 현재 상태를 얻기 위해 store.getState()를 호출합니다. connect()를 통해 컴포넌트에 스토어가 연결되어 있다면 컴포넌트는 이를 반영하고 자신의 setState()나 forceUpdate() 메소드를 실행해 자동적으로 render() 메소드를 호출합니다. React Native에서 Redux 사용하기이제 React Native에서 Redux를 사용해보겠습니다. React Native를 위한 개발환경 설정은 공식홈페이지를 참조하시기 바랍니다. 이 예제 프로젝트에서는 간단하게 Redux를 사용하는 법에 초점을 맞춰 진행해보겠습니다.간단히 카운팅하는 앱을 만들어보려 합니다. 완성 화면은 다음과 같습니다. 프로젝트 생성 먼저 React Native 프로젝트를 생성합니다. (현재 버전은 0.41.2 입니다) 1react-native init example 다음으로 redux를 사용하기 위해 필요한 모듈들을 설치합니다.1npm install redux react-redux --save 이제 Redux의 구성요소를 참고하여 다음과 같이 새로운 폴더 구조를 생성합니다. (앞으로 사용할 폴더와 파일만 명시하였습니다.)12345678910111213141516171819example ├── __tests__/ ├── android/ ├── ios/ ├── node_modules/ └── src/ ├── actions/ ├── index.js ├── countAction.js └── types.js ├── components/ └── Count.js ├── reducers/ ├── index.js └── countReducer.js └── app.js ├── index.android.js ├── index.ios.js └── package.json 루트 컴포넌트 생성 &amp; 설정먼저 app.js 파일을 작성합니다. App 컴포넌트는 루트 컴포넌트로 사용될 것이며, 액션과 리듀서 파일을 작성후 스토어를 추가할것입니다. 다음은 Android와 iOS의 진입파일인 index.android.js와 index.ios.js을 수정하여 App 컴포넌트를 루트 컴포넌트로 등록합니다. 지금까지의 코드를 작성한 후 화면은 다음과 같습니다. Count 컴포넌트 생성이제 Count.js 파일을 작성하여 Count 컴포넌트를 생성하겠습니다. Count 컴포넌트는 현재 카운트 되고 있는 숫자를 보여주는 텍스트와 카운트를 증가시키는 버튼으로 구성됩니다. Count 컴포넌트를 app.js에서 사용합니다. Count 컴포넌트를 추가한 후 화면입니다. Count 액션 생성액션은 애플리케이션의 상태를 갖고 있는 스토어로 전달하는 데이터 묶음이라고 했습니다. 이 카운팅 앱에서는 액션 객체의 type을 통해서 증가인지 감소인지, payload를 통해서는 증가 혹은 감소할 값을 전달할 것입니다. 먼저 actions/types.js를 작성합니다. types.js 에는 액션의 타입으로 사용될 값을 상수로 정의합니다. 타입은 후에 리듀서에서도 사용되기 때문에 미리 상수로 정의하는것이 실수를 줄일수도 있고, 후에 액션을 관리하는데에도 유용합니다. 이제 countAction.js를 작성합니다. type과 payload로 이루어진 액션 객체 액션 생성자를 통해 생성되어 스토어로 전달됩니다. 마지막으로 index.js를 작성합니다. index.js 에서는 여러개의 액션을 하나의 객체로 묶어 컴포넌트 파일에서 쉽게 사용할 수 있도록 해주는 역할을 합니다. Count 리듀서 생성액션을 전달받은 스토어가 상태를 변경하기 위해 리듀서에게 어떠한 상태변환을 해야하는지 요청합니다. 리듀서에서는 이 요청을 처리할 수 있도록 코드를 작성해야 합니다.countReducer.js를 작성합니다. 리듀서는 함수입니다. 첫 번째 인자로 이전의 상태를 전달받고, 두 번째 인자로는 액션을 전달받습니다. 전달 받은 액션의 type을 통해 새로운 상태를 반환하는것이 리듀서의 역할입니다.애플리케이션 실행 후 Redux는 처음에 리듀서를 undefined 상태로 호출합니다. swtich문에서 default인 상태에서 초기 상태를 설정합니다. 액션과 마찬가지로 index.js를 작성합니다. 여러개의 리듀서를 묶어 컴포넌트 파일에서 쉽게 사용할 수 있도록 해주는 역할입니다.redux 모듈의 combineReducer는 트리 구조로 분리된 여러개의 상태를 하나의 단일 상태 트리로 조합합니다. 루트 컴포넌트에 스토어 연결생성한 액션과 리듀서를 애플리케이션에서 사용할 수 있도록 루트 컴포넌트에 설정해주어야 합니다. 처음 작성했던 app.js를 다음과 같이 수정합니다.redux 모듈에 있는 createStore를 통해 스토어를 생성할 수 있습니다. store 생성시 인자로 리듀서를 필요로 합니다.생성된 스토어를 React 에서 사용하기 위해 react-redux 모듈에서 Provider를 사용합니다. Count 컴포넌트 바인딩뷰 레이어 바인딩은 생성된 스토어를 뷰에 연결하기 위해 필요하다고 설명했습니다. 이제 생성한 액션과 리듀서를 Count 컴포넌트에서 사용할 수 있도록 connect를 통해 연결을 만들어줍니다.connect 메서드는 Store의 state를 컴포넌트의 props로 전달하고 상태의 변화가 있을 때 자동으로 컴포넌트의 render를 재호출합니다. connect 메서드는 다음의 인자를 가집니다. mapStateToProps : 스토어의 state를 해당 컴포넌트의 props로 전달(mapping)합니다. mapDispatchToProps : 스토어의 dispatch를 props에 전달합니다. dispatch를 통해 액션생성자에서 생성한 액션을 스토어로 전달할 수 있습니다. 간단한 카운팅앱이 완성되었습니다. 버튼을 통해 count의 값을 변경할 수 있습니다. 포스팅을 마치며MVC 패턴에 익숙해져있던 저에게 Redux는 머리로는 이해할 수 있었지만 가슴으로는? 이해기 쉽지 않았었습니다. 이번 기회에 다시 하번 정리를 하며 제가 처음에 혼란스러워했던 부분들을 최대한 설명해드리려 노력했습니다. 위의 예제가 좋은 예제라고는 말할 수 없지만 그래도 React Native에서 Redux가 어떻게 사용되는지 전체적인 구조를 보는데에는 나쁘지 않다고 생각합니다.액션과 리듀서를 생성하고 사용하는 부분에 있어서는 여러가지의 방법이 있지만 최대한 Redux를 쉽게 이해할 수 있도록 작성해보았습니다. 좀 더 효율적으로 작성하는 법은 다음에 기회가 된다면 포스팅해보겠습니다.","link":"/2017/02/12/ReactNative/redux-for-starter/"},{"title":"정적 이미지 사용하기","text":"Index React Native 정적 이미지 사용하기 Native 측면에서 바라보기 Android iOS 이미지 사용하기 코드로 한번 더 복습하기 눈으로 확인하는 결과 React Native는 웹뷰를 통해 인터페이스를 구축하는 하이브리드 방식(예를 들면 Ionic)과는 달리 자바스크립트로 작성한 코드가 Native UI 컴포넌트로 만들어집니다. React Native에서 이미지를 사용하는 코드는 iOS와 Android 모두 통합되어 있지만, 정적인 이미지 파일을 추가하는 부분은 Naming에 있어 차이가 있습니다. 이번에는 React Native에서 정적 이미지를 사용하는 방법과, 정적 이미지 추가 시 반복되는 작업을 좀 더 효율적으로 할 수 있도록 Node를 사용하여 스크립트를 작성하는 부분을 다뤄보도록 하겠습니다. 글 작성 기준 React Native의 최신버전은 0.4입니다. React Native 정적 이미지 사용하기React Native에서 정적 이미지를 추가하는 방법은 공식홈페이지에서도 잘 설명되어 있지만 한번 더 살펴보겠습니다. 다음과 같이 react-native 의 기본적인 Image 컴포넌트를 통해 정적인 이미지 파일을 사용할 수 있습니다. 아래의 코드는 작성된 컴포넌트의 파일과 같은 경로에 있는 gold.png라는 파일을 사용합니다.1&lt;Image source={require(&apos;./gold.png&apos;)} /&gt; 하나의 파일을 두개의 플랫폼(iOS와 Android)에서 같이 사용할 수 있지만 만약 플랫폼에 따라 다른 이미지를 사용하고 싶다면 gold.png라는 파일을 gold.android.png와 gold.ios.png로 각각 저장하여 사용할 수 있습니다. 이와 같은 경우는 주로 Android와 iOS에서 같은 목적으로 사용되는 이미지가 다를 경우 유용합니다. (React Native에서 iOS와 Android의 Entry file이 index.ios.js와 index.android.js 인것과 같은 개념입니다.) 또한 React Native의 packager는 플랫폼 뿐만 아니라 디바이스 스크린의 해상도에 따라서도 다른 이미지를 제공할 수 있습니다. 따라서 다음과 같이 이미지 파일의 이름을 해상도에 따라 달리하여 사용할 수 있습니다. 1234├─ Test.js└── img/ ├── gold@2x.png └── gold@3x.png 12{/* Test.js 코드의 render 부분 */}&lt;Image source={require(&apos;./img/gold.png&apos;)} /&gt; 파일 구조와 Test.js의 코드가 위와 같을 때 iPhone 6와 iPhone 6 Plus는 각각 gold@2x.png와 gold@3x.png 파일을 사용합니다. 만약 디바이스 스크린의 해상도에 해당하는 파일이 없다면 가장 밀접한 해상도를 가진 파일을 사용합니다. 정리하면 디바이스의 플랫폼과 해상도에 따라 파일을 사용하고 싶을 경우 다음과 같이 사용할 수 있습니다.123456├─ Test.js└── img/ ├── gold@2x.android.png ├── gold@2x.ios.png ├── gold@3x.android.png └── gold@3x.ios.png React Native에서 정적인 이미지를 사용할 경우 주의해야할 점은 공식홈페이지를 참고하시면 좋을것 같습니다. Native 측면에서 바라보기React Native는 기존 Android와 iOS에서 이미지를 추가하여 사용하는 방법을 그대로 사용할 수도 있습니다. 이미 위의 방법으로 해결이 가능하며 이 방법이 좀 더 복잡하기에 사용을 권장드리지 않지만 이런방법으로도 가능하다는걸 알고계시면 좋을것 같습니다. Native에서 Android와 iOS의 이미지 파일은 다음과 같은 경로에 저장하여 사용합니다. Android Test-app/android/app/src/main/res/ iOS Test-app/ios/Test-app/images.xcassets/ AndroidAndroid에서 해상도별로 이미지를 추가하는 방법을 알아보겠습니다. 1.처음 프로젝트 생성시에는 drawable관련 폴더가 없으므로 android/app/src/main/res/ 에 해당 폴더들을 생성합니다. drawable-mdpi drawable-hdpi drawable-xhdpi drawable-xxhdpi drawable-xxxhdpi 2.해상도 별로 각 drawable 폴더에 파일을 저장합니다. (각 폴더별 저장되는 이미지는 파일명이 모두 같아야합니다.) 파일명이 gold.png 라면 각 폴더에는 다음과 같이 존재하게 됩니다. drawable-mdpi/gold.png drawable-hdpi/gold.png drawable-xhdpi/gold.png drawable-xxhdpi/gold.png drawable-xxxhdpi/gold.png iOSiOS에서 이미지를 추가하는 방법은 Android에 비해 좀 더 번거롭습니다. 글로 설명하는것보다 사진을 참고하는 것이 이해하기 쉽기 때문에 사진을 첨부합니다. 1.먼저 xcode에서 프로젝트의 root폴더에서 ios폴더를 로드한 후 images.xcassets 폴더를 클릭 후 AppIcon 아래의 빈공간을 우클릭하면 New Image set라는 메뉴가 있습니다. 클릭 후 1x, 2x, 3x에 이미지를 넣으신 후 이미지의 이름을 설정합니다. 2.위와 같이 이미지를 넣고나면 해당 경로에 다음과 같은 형식으로 파일이 생성됩니다. Contents.json은 이미지 파일에 대한 정보를 갖고 있습니다. 이미지 사용하기Android와 iOS에 이미지 추가가 모두 끝났습니다. 추가한 이미지를 React Native 에서 사용해보겠습니다.12{/* Test.js 코드의 render 부분 */}&lt;Image source={require(&apos;image!gold&apos;)} /&gt; 위의 코드에 image!라는 부분의 추가와 이미지 파일의 확장자가 사라졌다는게 전과 다릅니다. 이미지의 위치를 알리는 경로 또한 명시할 필요가 사라졌습니다. 코드로 한번 더 복습하기이제 React Native에서 정적인 이미지를 추가하는 방법을 모두 알아보았습니다. 마지막으로 코드상에서 정적인 이미지를 사용하는 방법을 정리해보겠습니다. – Native 에서 이미지를 추가하는 방법을 사용하였을 경우12{/* Test.js 코드의 render 부분 */}&lt;Image source={require(&apos;image!gold&apos;)} /&gt; – 프로젝트 폴더내에 추가 후 상대경로를 사용하는 경우12{/* Test.js 코드의 render 부분 */}&lt;Image source={require(&apos;./image/gold.png&apos;)} /&gt; – 첫번째와 두번째 방법을 모두 사용하는 경우 (Native에서 사용되는 폴더에서 이미지를 찾은 후 존재하지 않을 경우 상대경로를 사용하여 이미지를 사용)12{/* Test.js 코드의 render 부분 */}&lt;Image source={ {uri: &apos;gold&apos;, isStatic: true} } /&gt; 눈으로 확인하는 결과iPhone6와 iPhone6 Plus 에서 Gold 이미지가 기기의 해상도에 맞게 다른 파일로 사용된것을 확인할 수 있습니다. 다음 포스팅에서는 정적인 이미지 파일을 쉽게 추가하여 사용할 수 있도록 자동화하는 스크립트 작성에 대해서 작성하겠습니다.","link":"/2017/01/22/ReactNative/image-res-management(1)/"},{"title":"create-react-native-app (crna) 사용하기","text":"Index 들어가며 create-react-native-app (crna)란? CRNA 프로젝트 생성 CRNA 프로젝트 실행 - 1 (With 모바일 Expo 앱) CRNA 프로젝트 실행 - 2 (With 데스크탑 Expo Tool (Expo XDE)) CRNA 프로젝트 ejecting Expo 라이브러리 사용해보기 마치며 들어가며회사에서 약 6개월간 React Native를 이용한 게임 앱(eyePoker - 화상채팅과 함께하는 포커게임) 개발을 마무리하였습니다. 후에 React Native를 사용해 새로운 앱을 개발할때 사용할 수 있도록 그간 React Native로 개발하면서 익힌 것들을 boilerplate로 만들려고 했습니다. 약 6개월전 처음 React Native를 접했을때 당시 v0.39 였으나 최근 확인해보니 stable 버전이 v0.46 까지 나와있었습니다. v0.46을 이용해 React Native 프로젝트를 생성하고자 하니 Create React Native App이 추가되어 있었습니다. (앞으로 Create React Native App을 CRNA라고 부르겠습니다.) CRNA는 기존의 React Native CLI를 이용하지 않고 프로젝트를 생성하는 방법입니다. 지금부터 CRNA에 대해 알아보고 기존의 React Native CLI를 사용해서 프로젝트를 생성할때와 어떤 다른점이 있는지 알아보도록 하겠습니다. create-react-native-app (crna)란?먼저 아래의 영상을 통해 CRNA를 통해 프로젝트를 생성하고 실행하는 과정을 볼 수 있습니다. 약 6분정도의 짧은 영상입니다. 간단하게 한번 보시면 뒤의 내용을 좀 더 쉽게 이해할 수 있습니다. React Native Document에서도 확인할 수 있듯이, CRNA는 React Native 프로젝트를 시작하기 훨씬 쉽게 해주는 도구입니다. React를 접해보신분은 한번쯤 들어보셨을 React Create App에서 영감을 받은 것이고, Expo라는 회사와 협업을 통해 만들어진 결과물 입니다. Android나 iOS를 개발해본 경험 없이 React Native를 통해 앱 개발을 시작함에 있어서 네이티브 빌드에 필요한 도구를 설치하고 환경을 구성하는 것은 쉽지 않은 작업 입니다. 그러나 CRNA를 사용하면 Xcode 또는 Android Studio가 필요없으며 Linux 또는 Windows를 사용하여 iOS 장치 용으로도 개발할 수 있습니다. (이제 Mac이 필수가 아닙니다…) CRNA는 네이티브 코드를 컴파일하지 않고 순수 JavaScript로 작성된 CRNA 프로젝트를 로드하고 Expo 앱을 사용하여 실행합니다. 그렇기 때문에 CRNA를 사용해 프로젝트를 생성할 경우 기존 CLI를 사용해서 생성한 결과물과는 다르게 프로젝트 폴더에 android와 ios 폴더가 없습니다. 그러나 아직 대부분의 React Native 라이브러리들을 사용하기 위해서는 android와 ios 폴더 아래 있는 네이티브 프로젝트 파일(Java, Objective-C, Swift)을 직접 수정하고 컴파일 해야하는 하는데 이러한 경우는 어떻게 할까요? 먼저, Expo는 이러한 경우를 대비해 카메라, 비디오, 연락처등 자주 사용되는 인기있는 라이브러리들을 번들로 제공하고 있습니다. 그렇기 때문에 대부분의 간단한 앱들은 따로 외부 라이브러리를 추가하지 않아도 만들 수 있습니다. 그러나 번들로 제공되지 않는 기능이 필요해 라이브러리를 추가해야하는 경우, 네이티브 코드 추가 및 빌드가 필요하기 때문에 CRNA를 사용해 생성한 프로젝트를 그대로 사용할 수가 없습니다. 이러한 경우를 대비해 Create React App에서 제공하는것과 마찬가지로 CRNA에서도 ejecting 기능을 제공하고 있습니다. npm run eject 명령어를 통해 CLI를 통해 프로젝트를 생성한 것과 유사한 프로젝트를 얻을 수 있습니다. android와 ios 프로젝트 폴더가 생성됩니다. 그렇기 때문에 네이티브 빌드를 하기 위해서는 Xcode 또는 Android Studio가 필요합니다. CRNA 프로젝트 생성 저는 nvm을 통해서 node v8.1.4, npm v4.6.1을 사용하고 있습니다. (npm은 v5.x대의 경우 에러가 발생하기 때문에 v4.x로 재설치를 하고 진행하셔야 합니다.) 이제 CRNA를 사용해서 프로젝트를 생성해보겠습니다.1234$ npm i -g create-react-native-app$ create-react-native-app crna-project$ cd crna-project$ npm install CRNA를 사용해 프로젝트를 생성한 결과 구조는 다음과 같습니다.12345678crna-project ├── App.js ├── App.test.js ├── app.json ├── node_modules/ ├── package.json ├── yarn.lock └── README.md 참고) CLI를 생성해 프로젝트를 생성한 결과는 다음과 같습니다.1234567891011cli-project ├── index.android.js ├── index.ios.js ├── android/ ├── ios/ ├── node_modules/ ├── __tests__/ ├── app.json ├── package-lock.json ├── package.json └── yarn.lock 기존 CLI를 사용했을때와 다르게 index.android.js와 index.ios.js는 App.js로 변경되었으며, 네이티브 빌드에 사용되는 android, ios 폴더는 사라졌습니다. 또한 app.json 파일은 그대로 존재하지만 파일 내용에는 차이가 있습니다. CRNA를 사용해 생성한 프로젝트의 app.json12345{ &quot;expo&quot;: { &quot;sdkVersion&quot;: &quot;18.0.0&quot; }} CLI를 사용해 생성한 프로젝트의 app.json1234{ &quot;name&quot;: &quot;cli-project&quot;, &quot;displayName&quot;: &quot;cli-project&quot;} CRNA를 사용해 생성한 프로젝트의 app.json은 expo의 sdkVersion을 표시하고 있습니다. CRNA 프로젝트 실행 - 1 (With 모바일 Expo 앱)이제 생성한 CRNA 프로젝트를 실행해 보겠습니다. 기존 CLI를 통해 프로젝트를 생성했을 때는 실행을 위해 Android SDK와 Xcode가 필요하였고 다음의 명령어로 네이티브 빌드를 하여 실행했습니다.12$ react-native run-android$ react-native run-ios 그러나 CRNA를 사용해 생성한 프로젝트는 다음의 명령어로 실행합니다. 명령어를 실행하면 다음과 같은 QR코드가 출력됩니다.1$ npm start QR코드가 출력되어 당황할 수 있지만 이 QR코드를 통해서 방금 생성한 프로젝트를 실행할 수 있습니다. 처음에 말씀드렸다시피 CRNA는 네이티브 코드를 컴파일하지 않고 순수 JavaScript로 작성된 CRNA 프로젝트를 로드하고 Expo 앱을 사용하여 실행한다고 했습니다. 그렇기 때문에 저희가 실행 결과를 확인하기 위해서는 Expo 앱을 추가로 설치해야합니다. Expo앱은 JavaScript를 작성하여 기본 iOS 및 Android 앱을 제작할 수있게 해주는 도구, 라이브러리 및 서비스 세트이며 Expo앱 다운로드를 통해서 다운로드 후 설치 합니다. 다운로드 후 Expo앱을 실행하고 QR코드를 입력하면 다음과 같이 앱이 실행됩니다. CLI를 통해 생성한 프로젝트를 실행하여 가상머신을 통해 결과를 확인했을 때와 같이 동일한 결과를 얻을 수 있습니다. CRNA 프로젝트 실행 - 2 (With 데스크탑 Expo Tool (Expo XDE))조금 전에는 Expo 앱과 CRNA를 실행한 후 QR코드를 통해 자신의 모바일에서 결과를 확인했습니다. 이번에는 모바일 앱이 아닌 Expo XDE를 설치한 후 가상머신을 통해 실행해 보도록 하겠습니다. Expo XDE를 실행한 후 조금전 생성한 CRNA 프로젝트를 로드합니다.(Expo XDE를 설치하면서 에러가 발생하시는 분은 Expo Installation을 참고해서 Expo XDE에 필요한 다른 도구들을 설치해야합니다.) 프로젝트가 로드되면 우측 상단의 Share 버튼을 통해 조금전 npm start에서 제공했던것과 동일하게 QR코드를 제공받아 모바일 Expo 앱에서 프로젝트를 실행할 수 있고, Device 버튼은 현재 데스크탑에 설치되어 있는 iOS, Android 가상머신을 통해 실행할 수 있습니다. 이외에도 Expo XDE의 기능은 여러가지가 있습니다. 이외의 기능들은 Expo Documentation &amp; Guides에서 확인할 수 있습니다. CRNA 프로젝트 ejecting지금까지 CRNA를 통해 프로젝트를 생성하고 실행해 보았습니다. 마지막으로 ejecting 기능에 대해서 알아보겠습니다. CRNA의 ejecting 기능은 번들로 제공되지 않는 기능이 필요해 라이브러리를 추가해야하는 경우 네이티브 코드 추가 및 빌드가 필요하기 때문에 CRNA를 사용해 생성한 프로젝트를 그대로 사용할 수가 없으므로 사용하게됩니다. 1$ npm run eject eject 기능을 실행하면 2가지 옵션중 하나를 선택하게 됩니다. 1) CLI로 생성한 프로젝트와 같은 모양을 같는 프로젝트로 변경할 것인지, 2) 인기있는 라이브러리이 포함된 ExpoKit을 그대로 사용하며 android, ios 와 같은 네이티브 폴더를 eject 할 것인지 선택하게 됩니다. ExpoKit 옵션을 선택하여 ExpoKit은 그대로 사용할 수 있도록 유지합니다. Expokit 옵션을 선택하게 되면 iOS bundle identifier등 Android의 package name을 설정하게 되는데, 이때 주의해야할 점은 package name을 올바르지 않게 설정하게 되면 후에 네이티브 컴파일에서 오류가 생기게 됩니다. 이를 다시 수정하는건 번거로운 일이니 처음 설정시 신중하게 설정해야합니다. (‘-‘나 ‘_’와 같은 문자 대신 ‘.’을 이용해 패키지 명을 작성합니다.) crna 프로젝트를 eject하고 난 후에는 다음과 같이 폴더 구조가 변경됩니다.123456789101112crna-project (eject with ExpoKit) ├── App.js ├── App.test.js ├── app.json ├── android/ ├── ios/ ├── node_modules/ ├── .expo ├── .expo-source/ ├── package.json ├── yarn.lock └── README.md 이제 네이티브 관련 코드가 생성되었기 때문에 react-native-cli 명령어들을 사용할 수 있습니다. 그러나 react-native run-ios 명령어를 통해 실행을 하게되면 에러가 발생합니다. 이는 eject후 expo관련 모듈을 네이티브(ios) 폴더 아래에서 다시 설치해줘야하기 때문입니다. ios 폴더 아래에서 다음의 명령어를 실행합니다. (CocoaPods이 없으신 분들은 CocoaPods 홈페이지를 참고하여 설치합니다.) 또한 node_module도 다시 설치해야 하기때문에 프로젝트 폴더 아래에서 npm install을 실행합니다. 12$ npm install // 프로젝트 폴더 아래에서$ pod install // 프로젝트폴더-ios 폴더 아래에서 이제 react-native run-ios 명령어를 실행하면 가상머신을 통해 실행할 수 있습니다. 그러나 기존 CLI를 통해 생성한 프로젝트와 다르게 CRNA로 프로젝트를 생성한 후 eject 하여도 최초 CRNA로 프로젝트를 생성한 것이라면 Expo 혹은 exp(Expo Cli Tool)의 도구가 필요합니다. (React Native 프로젝트 실행시 Packager라는게 필요한데 CRNA로 프로젝트를 셍성했다면 Expo혹은 exp가 이 packager를 대신 실행하게 됩니다.) 그렇기 때문에 Expo를 실행하여 프로젝트를 로드하거나 새로운 터미널을 실행하여 exp start를 실행한 후 react-native run-ios를 실행하면 가상머신에서 프로젝트가 실행됩니다. Expo 라이브러리 사용해보기Expo SDK는 다양한 라이브러리를 제공하고 있습니다. 기본적으로 자주 쓰이고 필요한 라이브러리들은 다 있고, 관리가 잘 되고 있기 때문에 믿고 쓸 수 있습니다. 아직 그 수가 많지는 않지만 Feature-Request에서 사용자와의 소통을 통해 지속적으로 라이브러리를 추가해가고 있습니다. 지금부터는 Expo SDK에 Lottie 라이브러리를 사용해 보겠습니다. Lottie는 Airbnb에서 만들어 제공하는 라이브러리로 iOS, Android, React Native에서 After Effects로 만든 애니메이션을 실시간으로 앱에서 정적 이미지를 사용하는 것처럼 쉽게 애니메이션을 사용할 수 있도록 도와줍니다. Expo Lottie Document를 참고해서 Lottie 라이브러리를 사용하면 다음과 같은 간단히 테스트가 가능합니다. 기존의 CLI를 통해 프로젝트를 생성하고 Lottie를 사용해보신분들은 정말 과정이 간편해졌다는걸 느낄 수 있습니다. Expo SDK를 사용하지 않고 React Native 프로젝트에서 Lottie를 사용하기 위해서는 네이티브 코드에 Lottie관련 코드들을 추가하고 컴파일 과정에서 생기는 문제를 해결하기 위해서 많은 시간이 필요했습니다. (React Native Lottie - Github을 참고해보세요) 그러나 Expo SDK를 사용하면 정말 간단한게 사용할 수 있게 되었습니다. 마치며새롭게 추가된 CRNA는 React Native에 있어서 큰 변화라고 생각합니다. 아직은 Expo SDK에서 제공하는 라이브러리가 많지 않기 때문에 ejecting이 불가피하지만 Expo의 지속적인 관리로 앞으로 더 많은 라이브러리들과 기능들이 추가되고 점점 사용하기 쉽고 편하게 바뀔것이라 생각됩니다. 앞으로 새롭게 시작하는 React Native 프로젝트는 CLI보다는 CRNA를 통해서 프로젝트를 시작한 후 ejecting 기능을 사용해 Expo SDK를 그대로 가져가며 프로젝트는 진행하는것이 좋을것 같습니다. 추가적으로 Expo에 대해서 더 궁금한게 있으신분은 Expo-Frequently Asked Questions를 참고하시면 될것 같습니다. 참고 Introducing Create React Native App","link":"/2017/07/20/ReactNative/create-react-native-app/"},{"title":"시작하며 읽기 좋은 글 모음","text":"React Native를 공부하고 사용하면서 도움이 되었던 글들을 모아놓았습니다. 각 카테고리별로 분류하였으며 처음 공부하시는 분들은 카테고리에서 위에서 아래로 순서대로 읽으시면 많은 도움이 될거라 생각합니다. 앞으로도 지속적으로 업데이트 할 예정입니다. 최근 업데이트 - 2017 / 05 / 30 React Velopert님의 React Tutorial - velopert’s dev blogReact를 처음 공부할때 큰 도움이 됩니다. Flux Flux로의 카툰 안내서 - bestalign’s dev blogRedux는 Flux 아키텍처의 구현체중 하나 입니다. Redux를 공부하기전 Flux에 대해 알아볼 수 있습니다. Redux Redux 공식홈페이지(영문) - redux.js.org Redux 공식홈페이지(한글 번역) - dobbit Redux로의 카툰 안내서 - bestalign’s dev blogReact Native를 시작하며 Redux를 처음 공부할때 도움이 많이 되었습니다. Redux의 시스템을 잘게 나누어 여러 캐릭터로 비유하여 설명하신 부분이 인상깊었습니다. Flux와 Redux(MVC의 한계를 극복한 단순한 데이터 모델) - 코드쓰는사람(taegon.kim)MVC 패턴의 문제점 부터 시작하여 Flux가 어떻게 나오게 되었는지 마지막으로 Redux 까지 정리해주셨습니다. React 적용 가이드 - React와 Redux - NAVER D2 리덕스(Redux) 애플리케이션 설계에 대한 생각 - 김코딩님이 코딩 잘하고 싶어서 만든 블로그Redux를 사용하여 애플리케이션을 개발하시면서 고민하셨던 생각을 정리한 글. Redux를 사용한다면 읽어보기에 정말 좋은 글입니다.","link":"/2017/02/10/ReactNative/useful-post-collection/"},{"title":"Spring Boot에서의 Bean Validation (1)","text":"Bean Validation은 Java 생태계에서 유효성(Validation) 검증 로직을 구현하기위한 사실상의 표준이다. Bean Validation은 Spring과 Spring Boot에도 잘 통합되어 있다. 해당 포스팅에서 사용된 예제 코드는 spring-boot validation example에서 확인 가능합니다. Validation 설정Spring Boot에서의 Bean Validation은 spring-boot-starter-validation를 추가함으로써 사용할 수 있다.1implementation('org.springframework.boot:spring-boot-starter-validation') Spring Dependency Management Gradle 플러그인(“io.spring.dependency-management”)을 사용한다면 현재 사용중인 Spring Boot 버전에서 자동으로 의존성(버전)을 가져오기 때문에 별도로 버전을 명시할 필요가 없다. 만약 spring-boot-starter-web를 포함하고 있다면 Validation Starter도 포함되어 있기 때문에 따로 추가할 필요는 없다.1implementation('org.springframework.boot:spring-boot-starter-web') Validation Starter는 Bean Validation Specification 구현체 중 가장 널리 사용되고 있는 hibernate validator를 포함하고 있다. Bean Validation 기본기본적으로 Bean Validation은 클래스 필드에 특정 어노테이션(annotation)을 달아 제약 조건을 정의하는 방식으로 동작한다. 그 후 해당 클래스 객체를 Validator를 이용해 제약 조건의 충족 여부를 확인한다. Spring MVC Controller의 ValidationSpring RestController를 통해 Client로부터 전달받은 요청(request, input)에 대해 유효성을 검사하고자 한다. Client로부터 들어오는 다음의 3가지 요청 형식에 대해서 유효성 검사를 할 수 있다. request body path에 포함된 variables (ex. /foos/{id}의 id) query parameters Request BodyPOST 혹은 PUT 요청에서 request body에 JSON 형식의 데이터를 전달하는 것은 일반적이며, Spring은 JSON 형식의 데이터를 Java 객체에 자동으로 매핑한다. 이 과정에서 매핑되는 Java 객체가 요구 사항을 충족하는지 확인하려 한다.12345678910111213@Datapublic class InputRequest { @Min(1) @Max(10) private int numberBetweenOneAndTen; @NotEmpty private String notEmptyString; @Pattern(regexp = \"^[0-9]{6}$\") private String pinCode;} numberBetweenOneAndTen는 1에서 10 사이의 값을 가져야 하며, notEmptyString은 빈 문자열(“”)이 아니어야 하고, pinCode는 6자리의 숫자를 가져야 한다. request body에서 InputRequest 객체를 가져와 유효성 검사를 하는 RestController는 다음과 같다.12345678@RestControllerpublic class ValidateRequestBodyController { @PostMapping(\"/validateBody\") ResponseEntity&lt;String&gt; validateBody(@Valid @RequestBody InputRequest request) { return ResponseEntity.ok(\"valid\"); }} @RequestBody 어노테이션을 사용하고 있는 Input 매개변수에 @Valid 어노테이션만 추가하면 된다. 이로인해 Spring은 다른 작업을 수행하기 전에 먼저 객체를 Validator에 전달해서 유효성을 검사하게 된다. 만약 InputRequest 클래스에 유효성을 검사해야하는 다른 객체가 필드로 포함된 경우, 이 필드에도 @Valid 어노테이션을 추가해야한다. 이러한 경우를 Complex Type이라고 부른다. 유효성 검사에 실패할 경우 MethodArgumentNotValidException 예외가 발생한다. 기본적으로 Spring은 이 예외에 대해서 HTTP status code 400(Bad Request)으로 변환한다. 아래의 테스트 코드를 통해 동작을 확인할 수 있다. 12345678910111213141516171819202122232425@ExtendWith(SpringExtension.class)@WebMvcTest(controllers = ValidateRequestBodyController.class)class ValidateRequestBodyControllerTest { @Autowired private MockMvc mvc; @Autowired private ObjectMapper objectMapper; @Test void whenInputRequestIsInvalid_thenReturnStatus400() throws Exception { final InputRequest request = new InputRequest(); request.setNumberBetweenOneAndTen(50); request.setNotEmptyString(\"\"); request.setPinCode(\"1234\"); final String body = objectMapper.writeValueAsString(request); mvc.perform(post(\"/validateBody\") .contentType(\"application/json\") .content(body)) .andExpect(status().isBadRequest()); }} Path Variables &amp; Request Parameterspath에 포함된 variables과 query parameters에 대한 유효성 검사는 조금 다르게 동작한다. Path Variable과 Request Parameter의 경우는 int와 같은 primitive type이거나 Integer 혹은 String과 같은 객체이기 때문에 복잡한 유효성 검사를 하지 않는다. 클래스 필드에 직접 어노테이션을 추가하지 않고 다음과 같이 Controller 메소드 매개 변수에 직접 제약 조건을 추가한다.1234567891011121314@Validated@RestControllerpublic class ValidateParametersController { @GetMapping(\"/validatePathVariable/{id}\") ResponseEntity&lt;String&gt; validatePathVariable(@PathVariable(\"id\") @Min(5) int id) { return ResponseEntity.ok(\"valid\"); } @GetMapping(\"/validateRequestParameter\") ResponseEntity&lt;String&gt; validateRequestParameter(@RequestParam(\"param\") @Min(5) int param) { return ResponseEntity.ok(\"valid\"); }} @Validated 어노테이션을 클래스 레벨의 Controller에 추가해 Spring이 메서드 매개 변수에 대한 제한 조건 annotation을 평가하게 해야한다. request body 유효성 검사와 달리 실패할 경우 MethodArgumentNotValidException 예외가 아닌 ConstraintViolationException 예외가 발생한다. 주의할 것으로는 Spring은 ConstraintViolationException 예외에 대해서는 기본적으로 exception을 handling 하지 않기 때문에 HTTP status code 500(Internal Server Error)로 처리한다. 만약 HTTP status code 400(Bad Request)으로 처리하고자 한다면, custom exception handler를 사용하면 된다.12345678910111213@Validated@RestControllerpublic class ValidateParametersController { // request mapping method omitted @ExceptionHandler(ConstraintViolationException.class) @ResponseStatus(HttpStatus.BAD_REQUEST) @ResponseBody String handleConstraintViolationException(ConstraintViolationException e) { return \"not valid due to validation error: \" + e.getMessage(); }} 테스트 코드를 통해 동작을 확인해보자.1234567891011121314151617181920@ExtendWith(SpringExtension.class)@WebMvcTest(controllers = ValidateParametersController.class)class ValidateParametersControllerTest { @Autowired private MockMvc mvc; @Test void whenPathVariableIsInValid_thenReturnStatus400() throws Exception { mvc.perform(get(\"/validatePathVariable/1\")) .andExpect(status().isBadRequest()); } @Test void whenRequestParameterIsInvalid_thenReturnStatus400() throws Exception { mvc.perform(get(\"/validateRequestParameter\") .param(\"param\", \"1\")) .andExpect(status().isBadRequest()); }} Spring Service의 ValidationController 레벨에서 입력을 검증하는것 뿐만 아니라 @Validated와 @Valid 어노테이션을 이용해 다른 Spring component에서도 입력에 대해 유효성을 검증할 수 있다.1234567@Service@Validatedpublic class ValidateService { void validateInputRequest(@Valid InputRequest input) { }} @Validated 어노테이션은 클래스 수준에서만 평가되기 때문에 메서드에는 추가하지 말아야 한다. 테스트 코드는 다음과 같다.12345678910111213141516171819@ExtendWith(SpringExtension.class)@SpringBootTestclass ValidateServiceTest { @Autowired private ValidateService service; @Test void whenInputRequestIsInvalid_thenThrowException() { final InputRequest request = new InputRequest(); request.setNumberBetweenOneAndTen(50); request.setNotEmptyString(\"\"); request.setPinCode(\"1234\"); assertThrows(ConstraintViolationException.class, () -&gt; { service.validateInputRequest(request); }); }} Spring Repository의 Validation유효성 검사를 위한 가장 마지막 계층은 persistence layer이다. 기본적으로 Spring Data는 Hibernate를 사용하여 Bean Validation을 지원한다. JPA EntitiesInputEntity 클래스의 객체를 DB에 저장하려고 한다. 먼저 필요한 JPA 어노테이션들을 추가한다.123456789101112131415161718@Data@Entitypublic class InputEntity { @Id @GeneratedValue private Long id; @Min(1) @Max(10) private int numberBetweenOneAndTen; @NotEmpty private String notEmptyString; @Pattern(regexp = \"^[0-9]{6}$\") private String pinCode;} 위의 Entity를 관리하는 CRUE Repository도 생성한다. 1public interface ValidateRepository extends CrudRepository&lt;InputEntity, Long&gt; {} 기본적으로 제약 조건을 위반한 InputEntity 객체를 저장할 때 ConstraintViolationException이 발생한다. 1234567891011121314151617181920212223@ExtendWith(SpringExtension.class)@DataJpaTestclass ValidateRepositoryTest { @Autowired private ValidateRepository repository; @Autowired private EntityManager entityManager; @Test void whenInputEntityIsInvalid_thenThrowsException() { final InputEntity inputEntity = new InputEntity(); inputEntity.setNumberBetweenOneAndTen(50); inputEntity.setNotEmptyString(\"\"); inputEntity.setPinCode(\"1234\"); assertThrows(ConstraintViolationException.class, () -&gt; { repository.save(inputEntity); entityManager.flush(); }); }} Bean Validation은 EntityManager가 flush된 후에 트리거 된다. Hibernate는 특정 상황에서 EntityManager를 자동으로 flush하지만 integration test의 경우에는 직접 수행해야한다. 만약 Spring Data Repository에서 Bean Validation을 비활성화하려면 Spring Boot property인 spring.jpa.properties.javax.persistence.validation.mode 값을 none으로 설정하면 된다.","link":"/2019/11/18/Spring/bean-validation-1/"},{"title":"SpringBoot Application의 monitoring 시스템 구축하기","text":"Spring Boot를 사용하고 있는 애플리케이션에서 이전에 살펴본 Micrometer를 이용해서 metric을 생성하고 Prometheus를 이용해 수집, 그리고 Grafana로 시각화하는 시스템을 만들어보자. Prometheus는 metric을 수집하고 모니터링 및 알람에 사용되는 오픈소스 애플리케이션이다. time series database를 사용해 metric을 저장하고 flexible한 query를 사용하 metric을 조회할 수 있다. Grafana는 데이터 시각화, 모니터링 및 분석을 위한 오픈소스 플랫폼이다. 사용자는 Grafana에서 패널(panel)을 사용해 설정된 기간 동안 특정 metric을 나타내는 dashboard를 만들 수 있다.Grafana는 그래프, 테이블 같은 것들을 지원할 뿐만 아니라 시각화를 위한 별도의 플러그인을 추가해서 사용할 수도 있다. Spring Boot DependencySpring Boot 2.0 이상부터는 애플리케이션의 metric 측정을 위해서 Micrometer를 제공한다. Micrometer는 Spring Boot 2의 Actuator에 포함되어 있기 때문에 spring-boot-starter-actuator를 dependency에 추가해주면 쉽게 사용할 수 있다. 추가적으로 micrometer-registry-prometheus dependency가 필요하다. 이 dependency는 Micrometer가 만들어내는 metric을 Prometheus 서버에서 사용할 수 있는 metric format으로 변경한다. 1234dependencies { implementation 'org.springframework.boot:spring-boot-starter-actuator' implementation 'io.micrometer:micrometer-registry-prometheus'} Actuator Endpoint 설정Actuator는 Spring MVC 혹은 Spring WebFlux를 사용하는 경우, Micrometer를 통해 생성된 애플리케이션의 metric을 Prometheus 서버에서 가져갈(Pull)수 있도록 추가적인 endpoint를 제공해준다. Spring Boot 2.0 이상부터 사용하는 Actuator는 1.x 버전에서 사용하던 것과는 달리 대부분의 endpoint가 disabled로 설정되어 있다. 기본적으로 /health와 /info 2가지 endpoint만 default로 사용 가능하다. 따라서 /Prometheus endpoint를 사용할 수 있도록 다음과 같이 application.yml에서 설정이 필요하다.12345management: endpoints: web: exposure: include: health, info, prometheus 애플리케이션을 실행하고 http://localhost:8080/actuator 를 통해 Actuator가 제공하는 endpoint들을 확인할 수 있다. http://localhost:8080/actuator/prometheus 에서는 Micrometer를 통해 수집된 metric들을 확인할 수 있다. Spring Boot 2는 기본적으로 다음과 같은 metric들을 제공하고 있다. JVM, report utilization of: Various memory and buffer pools Statistics related to garbage collection Thread utilization Number of classes loaded/unloaded CPU usage Spring MVC and WebFlux request latencies RestTemplate latencies Cache utilization Datasource utilization, including HikariCP pool metrics RabbitMQ connection factories File descriptor usage Logback: record the number of events logged to Logback at each level Uptime: report a gauge for uptime and a fixed gauge representing the application’s absolute start time Tomcat usage Prometheus 설치 및 설정애플리케이션에서의 설정은 끝났으니 애플리케이션에서 생성하는 metric을 수집하기 위한 Prometheus Server를 준비해보자. 테스트를 할 때는 역시나 docker(prometheus image)를 이용하면 간편하다. 만약 실제 로컬 환경 혹은 별도의 서버 환경에서 설치해서 사용하고 싶다면 https://prometheus.io/download/#prometheus 에서 다운받아 설치하자. Prometheus Server는 기동시 /etc/prometheus/prometheus.yml 설정 파일을 사용한다. docker volume mount를 이용해 Prometheus Server에서 사용할 설정 prometheus.yml 파일을 만들어보자.12345678global: scrape_interval: 10s # 10초 마다 Metric을 Pulling evaluation_interval: 10sscrape_configs: - job_name: 'spring-boot-app' metrics_path: '/actuator/prometheus' # Application prometheus endpoint static_configs: - targets: ['host.docker.internal:8080'] # Application host:port docker에서 host.docker.internal은 특별한 DNS name으로 사용되며 docker를 실행하는 host를 가리킨다. 개발용으로만 사용해야 하며, Docker Desktop(Mac) 외부의 환경에서는 동작하지 않는다. 파일 생성을 완료했다면 prom/prometheus 이미지를 이용해 docker로 prometheus를 실행한다. 1234$ pwd/Users/user/work/prometheus$ docker run -p 9090:9090 -v /Users/user/work/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml --name prometheus -d prom/prometheus --config.file=/etc/prometheus/prometheus.yml 문제 없이 실행되었다면 http://localhost:9090 에 접속해보자. 다음과 같이 Prometheus main 화면을 볼 수 있다. docker로 Prometheus를 실행하면서 설정 파일이 잘 적용되었는지도 확인해보자. Status -&gt; Targets 메뉴에서는 Application의 상태를 확인할 수 있다. Application의 상태(Status)가 DOWN인 경우에는 Application이 현재 기동중인지, prometheus.yml에서 targets의 값이 제대로 되어있는지 확인이 필요하다. 여기까지 문제가 없다면 아래와 같이 수집된 metric 중 하나를 선택해 값이 잘 나오는지 확인해보자. Prometheus에서 수집한 metric을 Grafana로 시각화하기Prometheus의 웹 페이지에서 쿼리를 실행해 원하는 metric을 그래프로 시각화할 수 있다. 하지만 매번 모니터링을 위해 수동으로 쿼리를 실행하는 것은 비효율적이고 기본적으로 제공하는 대시보드 또한 간단하게 그래프를 볼 수 있는 정도이다.Prometheus가 제공하는 것만으로는 시각화하는데 한계가 있기 때문에 보통 별도의 시각화 도구를 이용해서 metric들을 모니터링한다. 이번에는 별도의 시각화 도구로 Grafana를 사용해보자. 역시나 docker(grafana/grafana)를 사용한다. 1$ docker run -d --name=grafana -p 3000:3000 grafana/grafana 실행 후 http://localhost:3000 에 접속해보자. 다음과 같이 Grafana login 화면을 볼 수 있다.기본 설정된 ID/PW인 admin/admin 으로 로그인할 수 있다. Home Dashboard에서 Add data source를 클릭해 Data Source 추가하자. Grafana에서 시각화할 데이터로서 Prometheus에 수집되고 있는 metric을 사용할 것이기 때문에 Prometheus를 선택한다. Name과 URL(Prometheus Server)을 설정하고 Save &amp; Test를 클릭한다. Prometheus가 Data Source로 추가되었다. 다음으로는 Data Source를 이용해 Dashboard를 생성해보자. 그래프를 이용해볼 것이기 때문에 Choose Visualization을 클릭한다. Metrics로 이전에 Prometheus에서도 확인해보았던 jvm_memoruy_used_bytes를 선택한다. 작업한 Dashboard를 저장한다. 추가된 Dashboard를 확인할 수 있다. Spring Boot Application에서 생성하는 metric을 Prometheus를 통해 수집하고, Grafana로 시각화하는 것까지 마무리했다.실제로는 애플리케이션에서 기본적으로 제공하는 Metric 뿐만 아니라 Micrometer를 이용해 직접 필요한 Metric을 추가할 수도 있다.또한 Grafana에는 소개하지 않은 더 많은 유용한 기능들이 있다. 필요한 기능은 문서를 통해 찾아가며 사용해보자.","link":"/2019/12/04/Spring/prometheus/"},{"title":"Spring Boot에서의 Bean Validation (2)","text":"해당 포스팅에서 사용된 예제 코드는 spring-boot validation example에서 확인 가능합니다. Custom Validator사용 가능한 constraint 어노테이션이 제공하는 제약 조건 외에 필요한 경우, 직접 만들어서 사용할 수 있다. 이전 포스팅에서 InPutRequest와 InputEntity 클래스에서 정규식(Regular Expression)을 사용하여 String이 유효한 PinCode 형식(6자리)인지 확인했었다. 이 부분을 별도의 Validator를 구현해 대체해보려고 한다. 먼저, custom constraint 어노테이션 PinCode를 생성한다. 123456789101112@Target({ FIELD })@Retention(RUNTIME)@Constraint(validatedBy = PinCodeValidator.class)@Documentedpublic @interface PinCode { String message() default \"{PinCode.invalid}\"; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {};} custom constraint 어노테이션에는 다음과 같은 것들이 필요하다. parameter message: ValidationMessages.properties에서 특정 property key를 가리키는 메시지 (제약 조건 위반시 메시지로 사용된다.) parameter groups: 유효성 검사가 어떤 상황에서 실행되는지 정의할 수 있는 매개 변수 그룹. parameter payload: 유효성 검사에 전달할 payload를 정의할 수 있는 매개 변수. @Constraint: ConstraintValidator interface 구현을 나타내는 어노테이션 PinCode validator는 다음과 같이 구현한다. 1234567891011121314public class PinCodeValidator implements ConstraintValidator&lt;PinCode, String&gt; { @Override public boolean isValid(String value, ConstraintValidatorContext context) { final Pattern pattern = Pattern.compile(\"^[0-9]{6}$\"); final Matcher matcher = pattern.matcher(value); try { return matcher.matches(); } catch (Exception e) { return false; } }} 이제 다른 constraint 어노테이션과 마찬가지로 @PinCode 어노테이션을 사용할 수 있다. 1234567public class InputEntityWithCustomValidator { @PinCode private String pinCode; // ...} 직접 Validator를 생성해 Validation 하기Spring이 지원하는 Bean Validator에 의존하지 않고 직접 Bean Validation을 하고자하는 경우가 있을 수 있다. 이 경우, 직접 Validator를 생성하고 validation을 할 수 있다. Spring의 지원이 전혀 필요하지 않다는 것이다. 12345678910111213@Service@RequiredArgsConstructorpublic class DirectlyValidateService { public void validateInput(InputEntity inputEntity) { final ValidatorFactory factory = Validation.buildDefaultValidatorFactory(); final Validator validator = factory.getValidator(); final Set&lt;ConstraintViolation&lt;InputEntity&gt;&gt; violations = validator.validate(inputEntity); if (!violations.isEmpty()) { throw new ConstraintViolationException(violations); } }} 그러나, Spring Boot는 이미 사전에 설정되어 만들어진 Validator 인스턴스를 제공한다. 그렇기 때문에 위와 같이 별도의 Validator 인스턴스를 직접 생성하지 않고 서비스에서 주입받아 사용하면 된다. 12345678910111213@Service@RequiredArgsConstructorpublic class DirectlyValidateService { private final Validator validator; public void validateInputWithInjectedValidator(InputEntity inputEntity) { final Set&lt;ConstraintViolation&lt;InputEntity&gt;&gt; violations = validator.validate(inputEntity); if (!violations.isEmpty()) { throw new ConstraintViolationException(violations); } }} 위의 Service는 Spring에 의해 Bean으로 생성될 때, Validator를 주입받게 된다. 위의 두 방법이 제대로 동작하는지 확인하기 위해 테스트 코드를 작성해보자. 12345678910111213141516171819202122232425262728293031@ExtendWith(SpringExtension.class)@SpringBootTestclass DirectlyValidateServiceTest { @Autowired private DirectlyValidateService service; @Test void whenInputEntityIsInvalid_thenThrowsException() { final InputEntity inputEntity = new InputEntity(); inputEntity.setNumberBetweenOneAndTen(50); inputEntity.setNotEmptyString(\"\"); inputEntity.setPinCode(\"1234\"); assertThrows(ConstraintViolationException.class, () -&gt; { service.validateInput(inputEntity); }); } @Test void givenInjectedValidator_whenInputEntityIsInvalid_thenThrowsException() { final InputEntity inputEntity = new InputEntity(); inputEntity.setNumberBetweenOneAndTen(50); inputEntity.setNotEmptyString(\"\"); inputEntity.setPinCode(\"1234\"); assertThrows(ConstraintViolationException.class, () -&gt; { service.validateInputWithInjectedValidator(inputEntity); }); }} Validation Groups종종 특정 객체(클래스)는 서로 다른 상황에서 공유되어 사용될 수 있다. 예를 들면, CRUD와 같은 작업에서 “Create”와 “Update”를 수행할 때 같은 객체(클래스)를 사용하는 것이다. 그러나 다음의 경우처럼 서로 다른 상황에서 실행되어야 하는 validation이 있을 수 있다. “Create” 상황에서만 Validation “Update” 상황에서만 Validation 두 가지 상황 모두에서 Validation 위와 같이 Validation 규칙을 구현할 수 있는 Bean Validation 기능을 Validation Groups이라고 부른다. 이전에 custom constraint 어노테이션을 직접 만들면서 groups 필드가 반드시 있어야 하는것을 보았다. 이를 이용해서 Validation이 실행되어야 하는 특정 validation group을 명시할 수 있다. CRUD 예제를 위해 OnCreate와 OnUpdate라는 2개의 marker interface를 정의한다.123interface OnCreate {}interface OnUpdate {} 그 다음 marker interface를 다음과 같은 constraint 어노테이션과 함께 사용할 수 있다.12345678class InputEntityWithCustomValidator { @Null(groups = OnCreate.class) @NotNull(groups = OnUpdate.class) private Long id; // ...} 위의 코드는 “Create” 상황에서는 id가 null일 수 있고, “Update” 상황에서는 not null이어야 함을 의미한다. Spring은 @Validated 어노테이션을 이용해 validation group을 사용할 수 있도록 지원한다. 1234567891011121314@Service@Validatedpublic class ValidateServiceWithGroups { @Validated(OnCreate.class) void validateForCreate(@Valid InputEntityWithCustomValidator input) { // do something } @Validated(OnUpdate.class) void validateForUpdate(@Valid InputEntityWithCustomValidator input) { // do something }} @Validated 어노테이션은 클래스에도 적용되어야 하며, validation group에 의한 Validation을 하기 위해서는 메서드에도 적용되어야 한다. 제대로 동작하는지 확인하기 위해 테스트 코드를 작성해보자. 123456789101112131415161718192021222324252627282930313233@ExtendWith(SpringExtension.class)@SpringBootTestclass ValidateServiceWithGroupsTest { @Autowired private ValidateServiceWithGroups service; @Test void whenInputIsInvalidForCreate_thenThrowsException() { InputEntityWithCustomValidator input = new InputEntityWithCustomValidator(); input.setId(17L); input.setNumberBetweenOneAndTen(5); input.setNotEmptyString(\"not empty\"); input.setPinCode(\"123456\"); assertThrows(ConstraintViolationException.class, () -&gt; { service.validateForCreate(input); }); } @Test void whenInputIsInvalidForUpdate_thenThrowsException() { InputEntityWithCustomValidator input = new InputEntityWithCustomValidator(); input.setId(null); input.setNumberBetweenOneAndTen(5); input.setNotEmptyString(\"not empty\"); input.setPinCode(\"123456\"); assertThrows(ConstraintViolationException.class, () -&gt; { service.validateForUpdate(input); }); }}","link":"/2019/11/21/Spring/bean-validation-2/"},{"title":"Spring Bean LifeCycle","text":"최근 사내에서 Kafka 관련된 설정을 리팩토링하는 작업을 했습니다. SpringBoot를 도입하며 Kafka 설정 관련된 부분들을 SpringBoot의 @ConfigurationProperties를 이용하도록 변경하고, XML 기반의 빈 생성 부분을 Java Config 기반으로 변경했습니다.현재 프로젝트에서는 여러가지 이유로 기존의 Kafka Producer를 확장(extends)해서 사용하고 있는데, 이번에 리팩토링 관련한 PR에서 확장해서 사용하고 있는 Kafka Producer에서 close 메서드를 구현하고 있는지 확인해달라는 리뷰를 받았습니다. 컨테이너에 등록된 Bean이 DisposableBean interface를 구현하고 있거나 @PreDestroy 어노테이션 또는 destroyMethod 속성을 사용하고 있다면 Bean의 Lifecycle 마지막에 자원을 해제하거나 필요한 작업을 수행할 수 있습니다. 그러나 위의 방법 말고도 Spring container에서 Bean을 제거 할 때, close() 와 shutdown() 메서드를 호출합니다. Kafka Producer는 Closeable interface를 구현(implement)하고 있기 때문에 close 메서드를 포함하고 있습니다. Kafka Producer가 Bean으로 등록되어 있고 후에 소멸될 때 close 메서드가 호출되어 해당 자원이 모두 해제될 것입니다. 따라서 제가 받았던 리뷰는 기존 Kafka Producer를 확장한 것을 Bean으로 등록해 사용하고 있는데, 해당 확장 클래스가 close 메서드를 제대로 구현해 Bean이 소멸 될 때 호출될 close 메서드에서 자원이 제대로 해제하고 있는지 확인해 달라는 것이었습니다. AutoCloseable 은 try-with-resource 구문과 함께 사용됩니다. 이번 리뷰를 통해 Bean의 LifeCycle과 close, shutdown 메서드에 대해 다시 살펴보는 계기가 되었습니다. Initialize 메서드Initialize 메서드는 Bean Object가 생성되고 DI를 마친 후 실행되는 메서드입니다. 일반적으로 Object의 초기화 작업이 필요한 경우 생성자에서 처리하지만 DI를 통해 Bean이 주입된 후에 초기화할 작업이 있다면 초기화 메서드를 이용해서 초기화를 진행할 수 있습니다. @PostConstruct초기화 하고 싶은 메서드에 @PostConstruct 어노테이션을 붙여주면 Spring이 해당 메서드를 초기화시에 호출합니다. PostConstruct는 JSR-250 스펙에 포함되어 있기 때문에 JSR-250을 구현한 다른 프레임워크 혹은 라이브러리에서도 동작합니다. 다른 초기화 메서드에 비해 Spring에 의존적이지 않다는 장점이 있습니다. JSR-250JSR 250 is a Java Specification Request with the objective to develop annotations (that is, information about a software program that is not part of the program itself) for common semantic concepts in the Java SE and Java EE platforms that apply across a variety of individual technologies. 123456789@Slf4j@Componentpublic class SimpleBean { @PostConstruct public void postConstruct() { log.info(\"postConstruct\"); }} InitializingBeanInitializingBean 인터페이스를 구현하면 Spring이 afterPropertiesSet 메서드를 초기화시에 호출합니다.123456789@Slf4j@Componentpublic class SimpleBean implements InitializingBean { @Override public void afterPropertiesSet() throws Exception { log.info(\"afterPropertiesSet\"); }} @Bean(initMethod)@Bean 어노테이션을 이용해 Bean을 생성할 때, @Bean 어노테이션의 initMethod 속성을 이용해 초기화 메서드를 지정할 수 있습니다.12345678910111213141516@Configurationpublic class TestConfiguration { @Bean(initMethod = \"init\") public SimpleBean simpleBean() { return new SimpleBean(); } @Slf4j public static class SimpleBean { public void init() throws Exception { log.info(\"init\"); } }} Destroy 메서드Destroy 메서드는 스프링 컨테이너가 종료 될 때, 호출되어 Bean이 사용한 리소스들을 반환하거나 종료 시점에 처리해야할 작업이 있을 경우 사용합니다. PreDestroy@PreDestroy 도 PostConstruct처럼 JSR-250 스펙에 포함되어 있기 때문에 JSR-250을 구현한 다른 프레임워크 혹은 라이브러리에서도 동작합니다. 컨테이너가 종료 될 때 실행하고 싶은 메서드에 어노테이션을 붙여주면 Spring이 컨테이너 종료 시 해당 메서드를 호출합니다.123456789@Slf4j@Componentpublic class SimpleBean { @PreDestroy public void preDestroy() { log.info(\"preDestroy\"); }} DisposableBeanDisposableBean 인터페이스를 구현하면 Spring이 destroy 메서드를 호출합니다.123456789lf4j@Componentpublic class SimpleBean implements DisposableBean { @Override public void destroy() throws Exception { log.info(\"destroy\"); }} @Bean(destroyMethod)@Bean 어노테이션을 이용해 Bean을 생성할 때, @Bean 어노테이션의 destroyMethod 속성을 이용해 컨테이너 종료시 실행하고자 하는 메서드를 지정할 수 있습니다.12345678910111213141516@Configurationpublic class TestConfiguration { @Bean(destroyMethod = \"destroy\") public SimpleBean simpleBean() { return new SimpleBean(); } @Slf4j public static class SimpleBean { public void destroy() throws Exception { log.info(\"destroy\"); } }} close &amp; shutdownclose와 shutdown 메서드는 DisposableBeanAdapter에 의해 실행됩니다.","link":"/2019/05/21/Spring/spring-bean-life-cycle/"},{"title":"Spring - AOP","text":"AOP의 등장 배경몇 년에 걸쳐 객체지향 프로그래밍(Object Oriented Programming, OOP)은 절차적 프로그래밍 방법론을 거의 완벽히 대체하며 프로그래밍 방법론의 새로운 패러다임으로 떠오르게 되었습니다. 객체지향적 방식의 가장 큰 이점 중 하나는 소프트웨어 시스템이 여러 개의 독립된 클래스들의 집합으로 구성된다는 것입니다. 이들 각각의 클래스들은 잘 정의된 고유 작업을 수행하게 되고, 그 역할 또한 명백히 정의되어 있습니다. 객체지향 어플리케이션에서는 어플리케이션이 목표한 동작을 수행하기 위해 이런 클래스들이 서로 유기적으로 협력합니다. 하지만 시스템의 어떤 기능들은 특정 한 클래스가 도맡아 처리할 수 없습니다. 이들은 시스템 전체에 걸쳐 존재하며 해당 코드들을 여러 클래스들에서 사용합니다. 이런 현상을 횡단적(cross-cutting)이라 표현합니다. 분산 어플리케이션에서의 동기화(locking) 문제, 예외 처리, 로깅 등이 그 예입니다. 물론 필요한 모든 클래스들에 관련 코드를 집어 넣으면 해결될 문제입니다. 하지만 이런 행위는 각각의 클래스는 잘 정의된(well-defined) 역할만을 수행한다는 기본 원칙에 위배됩니다. 이런 상황이 바로 Aspect Oriented Programming (AOP)가 생겨난 원인이 되었습니다. AOP에서는 aspect라는 새로운 프로그램 구조를 정의해 사용합니다. 쉽게 class, interface 등과 같이 특정한 용도의 구조라 생각하면 됩니다. Aspect 내에는 프로그램의 여러 모듈들에 흩어져 있는 기능(하나의 기능이 여러 모듈에 흩어져 있음을 뜻함)을 모아 정의하게 됩니다. 전체적으로, 어플리케이션의 각각의 클래스는 자신에게 주어진 기능만을 수행하고, 추가된 각 aspect들이 횡단적인 행위(기능)들을 모아 처리하며 전체 프로그램을 이루는 형태가 만들어집니다. AOP가 필요한 사례이해를 돕기 위해 어플리케이션의 여러 스레드들이 하나의 데이터를 공유하는 상황을 가정해봅시다. 공유 데이터는 Data라는 객체(Data 클래스의 인스턴스)로 캡슐화되어 있습니다. 서로 다른 여러 클래스의 인스턴스들이 하나의 Data 객체를 사용하고 있으나, 이 공유 데이터에 접근할 수 있는 객체는 한 번에 하나씩이어야만 합니다. 그렇다면 어떤 형태이건 동기화 메커니즘이 도입되어야 할 것입니다. 즉, 어떤 한 객체가 데이터를 사용중이라면 Data 객체는 잠겨(lock)져야 하며, 사용이 끝났을 때 해제(unlock)되어야 합니다. 전통적인 해결책은 공유 데이터를 사용하는 모든 클래스들이 하나의 공통 부모 클래스(“worker” 라 부르겠습니다)로부터 파생되는 형태로 만드는 것입니다. worker 클래스에는 lock()과 unlock() 메소드를 정의하여 작업의 시작과 끝에 이 메소드를 호출토록 하면 됩니다. 하지만 이런 형태는 다음과 문제들을 파생시킵니다. 공유 데이터를 사용하는 메소드는 상당히 주의해서 작성되어야 합니다. 동기화 코드를 잘못 삽입하면 데드락(dead-lock)이 발생하거나 데이터 영속성이 깨질 수 있습니다. 또한 메소드 내부는 본래의 기능과 관련 없는 동기화 관련 코드들로 더럽혀질 것입니다.Java와 같은 단일 상속 모델에서는 worker를 만든다는 것이 불가능할 수 있습니다. 어떤 클래스들은 이미 다른 클래스들로부터 확장되었을 수도 있기 때문입니다. 이는 특히 클래스 계층 구조 설계가 마무리된 후, 뒤늦게 동기화의 필요성을 깨달았을 때 흔히 발생합니다. 동기화를 신경 쓰지 않은 범용 클래스 라이브러리를 통해 공유 데이터에 접근하려 하는 경우가 한 예가 될 수 있습니다.앞서 가정한 어플리케이션에서 동기화 개념은 다음과 같은 속성들을 갖습니다. 동기화는 worker 클래스에 할당된 최우선 작업이 아니다. 동기화 메커니즘은 worker 클래스의 최우선 작업과 독립적이다. 한 객체에 대한 동기화 관련 코드가 시스템 전체에 횡단적으로 존재한다. 다수의 클래스와 더 많은 수의 메소드들이 이 동기화 메커니즘에 영향 받는다. AOP에서는 이런 형태의 문제를 해결하기 위해 새로운 형태의 접근 방법을 제기하고 있습니다. AOP는 새로 도입된 프로그램 구조를 통해 시스템에 횡단되어 있는 기능들을 정의해 처리하도록 했습니다. 이 새로운 구조를 aspect라 부릅니다. 위의 예시에 Lock이라는 aspect를 도입해보겠습니다. Lock aspect에는 다음과 같은 역할이 할당될 것입니다. Data 객체를 사용하는 클래스들을 위해 lock 및 unlock 메커니즘을 제공한다(lock(), unlock()). Data 객체를 수정하는 모든 메소드들이 수행 전에 lock()을 호출하고, 수행 후에는 unlock()을 호출함을 보장한다. 이상의 기능을 Data 객체를 사용하는 클래스의 자바 소스를 변경하지 않고 투명하게 수행한다. Aspect는 또 어떤 일들을 수행할 수 있을까?특정 메소드(ex. 객체 생성 과정 추적) 호출을 로깅할 경우 aspect가 도움이 될 수 있습니다. 기존 방법대로라면 log() 메소드를 만들어 놓은 후, 자바 소스에서 로깅을 원하는 메소드를 찾아 log()를 호출하는 형태를 취해야할 것입니다. 그러나 여기서 AOP를 사용하면 원본 자바 코드를 수정할 필요 없이 원하는 위치에서 원하는 로깅을 수행할 수 있습니다. 이런 작업 모두는 aspect라는 외부 모듈에 의해 수행됩니다.또 다른 예로 예외 처리가 있습니다. Aspect를 이용해 여러 클래스들의 산재된 메소드들에 영향을 주는 catch() 조항(clause)을 정의해 어플리케이션 전체에 걸쳐 지속적이고 일관적으로 예외를 처리할 수 있습니다. AOP 용어 JoinPoint : 메소드 호출이나 특정 예외를 던지는 것과 프로그램이 실행되는 지점을 이야기한다. Advice : Logging과 같은 횡단관심사의 경우 거의 모든 클래스에 분산되어 있는 것을 볼 수 있다. 이와 같은 횡단관심사를 여러 영역에 분산해 구현하는 것이 아니라 한 곳에 모아서 구현하는 것을 Advice라고 한다. 즉, JoinPoint에서 실행되는 코드를 말한다. Point-cut : 횡단관심사에 해당하는 기능을 구현한 부분이 Advice라고 했다. 그렇다면 이렇게 구현되어 있는 Advice를 어떤 패턴을 가지는 클래스와 메소드에 적용할지를 결정하는 것이 Point-cut이다. 즉 해당 Advice가 적용되어야 하는 곳을 가리키는 것이 Point-cut이다. Point-cut은 JoinPoin와 Advice의 중간에 있으면서 처리가 JoinPoint에 이르렀을 때 Advice를 호출할지를 결정한다. Aspect : Aspect는 Advice와 Point-cut을 합쳐서 하나의 Aspect라고 칭한다. Advice와 Point-cut을 이용하여 Logging이라는 관심사를 분리하여 독립적으로 구현할 수 있었다. 이처럼 Advice와 Point-cut을 이용하여 원하는 관심사를 구현하는 것을 하나의 Aspect라고 한다. 지금까지 살펴본 Logging은 Logging Aspect가 될 것이다. Introduction : 실행되고 있는 클래스에 새로운 인터페이스를 추가하여 원래의 Object가 가지고 있는 속성, 행위 이외의 다른 일이 가능하도록 하게 된다. Spring AOP의 Advice는 여러개의 Advice를 가집니다. Spring에서 지원하고 있는 Advice는 다음과 같습니다. Before advice : JoinPoint 앞에서 수행되는 Advice. 하지만 JoinPoint를 위한 수행 흐름 처리(execution flow proceeding)를 막기위한 능력(만약 예외를 던지지 않는다면)을 가지지는 않는다. After returning advice : JoinPoint가 완전히 정상 종료한 다음 실행되는 Advice. (메소드가 예외를 던지는것 없이 반환된다면 완성된 후에 수행되는 advice.) Around advice : JoinPoint 앞뒤에서 실행되는 Advice. Around advice는 메소드 호출 전후에 사용자 지정 행위를 수행한다. Throws advice : JoinPoint에서 예외가 발생했을 때 실행되는 Advice. Spring은 강력한 타입의 Throws advice를 제공한다. 그래서 Throwable 나 Exception으로 부터 형변환 할 필요가 없는 관심가는 예외(그리고 하위클래스)를 처리하는 코드를 쓸 수 있다.","link":"/2018/02/17/Spring/spring-aop/"},{"title":"Micrometer","text":"Micrometer란?micrometer.io에서는 Micrometer에 대해서 다음과 같이 소개하고 있다. Micrometer provides a simple facade over the instrumentation clients for the most popular monitoring systems, allowing you to instrument your JVM-based application code without vendor lock-in. Think SLF4J, but for metrics Micrometer는 JVM 기반의 애플리케이션에서 다양한 모니터링 도구가 제공하는 클라이언트 라이브러리에 대한 facade를 제공한다. 로깅 관련된 시스템에서는 SLF4J가 있다면 모니터링(metric) 시스템에서는 Micrometer가 있는 것이다. 즉, 모니터링 시스템을 만드는 vendor들은 Micrometer 인터페이스를 따르기 때문에 Micrometer를 사용하면 애플리케이션 내의 코드 상에서는 모니터링 시스템 클라이언트로 어떤 것을 사용할지에 대한 고민에서 벗어나 Micrometer를 이용해 애플리케이션 metric을 수집하기만 하면 된다.(모니터링 시스템을 선택하는 것은 런타임 시점에 정해진다고 생각하면 된다.) 예를 들어, 모니터링 시스템으로 Prometheus를 사용한다고 하면 아래와 같이 표현할 수 있다. Micrometer는 다음과 같은 모니터링 시스템을 지원한다. AppOptics, Azure Monitor, Netflix Atlas, CloudWatch, Datadog, Dynatrace, Elastic, Ganglia, Graphite, Humio, Influx/Telegraf, JMX, KairosDB, New Relic, Prometheus, SignalFx, Google Stackdriver, StatsD, Wavefront Micrometer에 의해서 기록된 애플리케이션의 metric 정보는 시스템의 이상 유뮤룰 판단하기 위한 모니터링(알람) 용도로 사용된다. Supported monitoring systemsMicrometer는 코어 모듈과 측정 SPI(Service Provider Interface)를 포함하고 있다. (각각 Registry라고 부르는 다양한 모니터링 시스템에 대한 구현을 포함하고 있다.)모니터링 시스템에는 중요한 3가지 특징이 있다. DimensionalityDimensionality는 수집하는 metric 이름에 tag(key-value)를 붙일 수 있도록 지원하는 것을 말한다. 반면 일부 모니터링 시스템의 경우에는 tag 형태가 아닌, flat한 metric name만 사용이 가능하다. 이를 hierarchical system이라고 한다.Micrometer는 hierarchical system에 metric을 보낼 때는 tag를 metric name에 추가한다. Dimensional: AppOptics, Atlas, Azure Monitor, Cloudwatch, Datadog, Datadog StatsD, Dynatrace, Elastic, Humio, Influx, KairosDB, New Relic, Prometheus, SignalFx, Sysdig StatsD, Telegraf StatsD, Wavefront Hierarchical: Graphite, Ganglia, JMX, Etsy StatsD Rate aggregation모니터링 시스템 사용자들은 일정 시간 간격 동안의 특정 지표에 대한 평균값을 필요로 하는 경우가 많다. 어떤 모니터링 시스템은 애플리케이션에서 평균값을 직접 구해서 보내주기를 기대한다. 반면에 어떤 모니터링 시스템은 애플리케이션이 누적된 값을 보내주기를 기대하며, 모니터링 시스템이 직접 평균값을 구하는 경우도 있다. Client-side: AppOptics, Atlas, Azure Monitor, Datadog, Elastic, Graphite, Ganglia, Humio, Influx, JMX, Kairos, New Relic, all StatsD flavors, SignalFx Server-side: Prometheus, Wavefront Publishing일부 모니터링 시스템은 metric 정보를 애플리케이션으로부터 polling한다. 반면 일부 모니터링 시스템은 애플리케이션이 일정한 간격으로 metric 정보를 push하는 방식으로 사용된다. Client pushes: AppOptics, Atlas, Azure Monitor, Datadog, Elastic, Graphite, Ganglia, Humio, Influx, JMX, Kairos, New Relic, SignalFx, Wavefront Server polls: Prometheus, all StatsD flavors Micrometer 어떤 Registry를 사용하는지에 따라, 위와 같은 요구사항을 충족하도록 metric 정보를 커스터마이징한다. RegistryMeter는 애플리케이션의 metric을 수집하기 위한 인터페이스이다. Meter는 MeterRegistry에 의해 생성되어 등록된다. 지원되는 각 모니터링 시스템은 MeterRegistry 구현체를 갖고 있다. SimpleMeterRegistry는 각 meter의 최신 값을 메모리에 저장한다. 그리고 metric 정보를 다른 시스템으로 내보내지 않는다. 따라서 만약 어떤 모니터링 시스템을 사용할지 결정하지 못했다면 SimpleMegerRegistry를 사용하면 된다.1MeterRegistry registry = new SimpleMeterRegistry(); Composite registriesMicrometer는 여러 Registry를 추가할 수 있는 CompositeMeterRegistry를 제공한다. 따라서 CompositeMeterRegistry를 사용하면 둘 이상의 모니터링 시스템에서 동시에 metric을 사용할 수 있다.123456CompositeMeterRegistry compositeRegistry = new CompositeMeterRegistry();SimpleMeterRegistry oneSimpleMeter = new SimpleMeterRegistry();AtlasMeterRegistry atlasMeterRegistry = new AtlasMeterRegistry(atlasConfig, Clock.SYSTEM); compositeRegistry.add(oneSimpleMeter);compositeRegistry.add(atlasMeterRegistry); Global registryMicrometer는 static 변수로 Global MeterRegistry를 제공한다. Metrics.globalRegistry를 통해 static 변수에 접근할 수 있으며 Metrics 클래스에는 글로벌 MeterRegistry를 기반으로 Meter를 생성하는 정적 빌더 메소드가 있다.Global MeterRegistry는 CompositeMeterRegistry 객체이다. MetersMicrometer는 Meter의 구현체로 다음의 것들을 지원한다. Meter의 type 별로 수집되는 metric 수가 다르다. Timer, Counter, Gauge, DistributionSummary, LongTaskTimer, FunctionCounter, FunctionTimer, TimeGauge Meter는 이름(name)과 태그(tag)로 고유하게 식별된다. NamingMicrometer는 소문자 단어를 ‘.’으로 구분하는 naming 규칙을 사용한다. 각각의 모니터링 시스템은 naming 규칙과 관련해 권장 사항을 갖고 있으며 일부 모니터링 시스템은 서로의 naming 규칙이 달라 호환되지 않을 수도 있다. 따라서 모니터링 시스템의 각 Micrometer 구현체는 소문자 단어와 ‘.’으로 구분된 이름을 각자의 모니터링 시스템 naming 규칙으로 변환하는 기능을 제공한다. 예를 들면 아래의 timer meter는 각각의 모니터링에서 다음과 같이 변경된다.1registry.timer(\"http.server.requests\"); Prometheus: http_server_requests_duration_seconds Atlas: httpServerRequests Graphite: http.server.requests InfluxDB: http_server_requests 그러므로 Micrometer의 소문자 단어를 ‘.’으로 구분하는 naming 규칙을 사용하면 모니터링 시스템 종류에 상관없이 metric name에 대해 이식성을 보장할 수 있다. CounterCounter는 애플리케이션에서 특정 속성에 대한 카운트를 기록한다. Build method 혹은 MetricRegistry의 helper method를 통해 custom counter를 생성할 수 있다.12345678910111213Counter counter = Counter .builder(\"instance\") .description(\"indicates instance count of the object\") .tags(\"dev\", \"performance\") .register(registry); counter.increment(2.0); assertTrue(counter.count() == 2); counter.increment(-1); // 카운트는 증가만 가능하다. assertTrue(counter.count() == 2); Timers시스템의 latency(지연 시간) 혹은 이벤트 빈도를 측정하기 위해서 Timers를 사용할 수 있다. Timer는 이벤트가 발생한 수와 총 시간을 기록한다.123456789101112SimpleMeterRegistry registry = new SimpleMeterRegistry();Timer timer = registry.timer(\"app.event\");timer.record(() -&gt; { try { TimeUnit.MILLISECONDS.sleep(1500); } catch (InterruptedException ignored) { }}); timer.record(3000, MILLISECONDS); assertTrue(2 == timer.count());assertTrue(4510 &gt; timer.totalTime(MILLISECONDS) &amp;&amp; 4500 &lt;= timer.totalTime(MILLISECONDS)); GaugeGauge는 Meter의 현재 값을 보여준다. 다른 Meter와 다르게 Guage는 데이터의 변경이 관찰 된 경우에만 데이터를 기록한다. 캐시 등의 통계를 모니터링 할 때 유용하다.123456789101112SimpleMeterRegistry registry = new SimpleMeterRegistry();List&lt;String&gt; list = new ArrayList&lt;&gt;(4); Gauge gauge = Gauge .builder(\"cache.size\", list, List::size) .register(registry); assertTrue(gauge.value() == 0.0); list.add(\"1\"); assertTrue(gauge.value() == 1.0); BindersMicrometer에는 JVM, 캐시, ExecutorService 및 로깅 서비스를 모니터링하기 위한 여러 내장 Binder가 있다. JVM 및 시스템 모니터링: ClassLoaderMetrics JVM memory pool: JvmMemoryMetrics GC metrics: JvmGcMetrics Thread 및 CPU 사용률: JvmThreadMetrics, ProcessorMetrics","link":"/2019/12/03/Spring/micrometer/"},{"title":"Spring - MVC","text":"DispatcherServlet 이란?Spring MVC는 DispatcherServlet의 등장으로 web.xml의 역할이 축소되었습니다. 이전에는 서블릿을 URL로 활용하기 위해서는 반드시 web.xml에 등록해야 했지만, 이제는 DispatcherServlet이 해당 어플리케이션으로 들어오는 요청을 모두 핸들링 해주기 때문입니다. web.xml의 역할이 축소되었지만, &lt;servlet&gt;으로 DispatcherServlet을 등록해줘야 하며, 이 객체의 URL 적용범위 또한 web.xml에 설정해야 합니다. 또한 encoding과 관련된 &lt;filter&gt;나 &lt;listener&gt;를 등록하기 위해서 web.xml은 필요합니다. 그러나 web.xml에서 중요하게 사용되었던 &lt;servlet&gt; 매핑은 이제 DispatcherServlet이 대신 맡아서 처리하게 되었습니다. web.xml에 DispatcherServlet의 을 ‘/‘로 설정함으로써 동시에 이제 모든 요청은 DispatcherServlet으로 전달됩니다. 물론 DispatcherServlet을 web.xml에 등록해도 계속 서블릿을 web.xml에 매핑해서 사용할 수 있지만, 이런 옛 방식을 버리고 DispatcherServlet을 이용해 웹 개발을 한다면 앞으로 서블릿 파일을 만들 필요도 없어지고 동시에 놀라운 @MVC의 혜택을 얻을 수 있습니다. DispatcherServlet을 이용한다는 것은 스프링에서 제공하는 @MVC를 이용하겠단 뜻입니다. @MVC는 그동안 추상적으로 알아오고 발전했던 MVC(Model, View, Controller) 설계 영역을 노골적으로 분할하여 사용자가 무조건 MVC로 어플리케이션을 설계하게끔 유도하는 방식입니다. 즉, @MVC를 이용해 어플리케이션을 개발한다면 MVC 설계의 원칙대로 웹 어플리케이션을 제작할 수 있게 된다는 뜻입니다. 그럼 간단하게 DispatcherServlet이 담당하는 역할이 무엇인지 알아봅시다. 먼저 DispatcherServlet에 대해 간단히 정의해보자면, 각각 분리하여 만든 Model, View, Controller를 조합하여 브라우저로 출력해주는 역할을 수행합니다. Spring MVC 구조 등장 요소 DispatcherServlet : 프런트 컨트롤러 담당, 모든 HTTP 요청을 받아들여 그 밖의 오브젝트 사이의 흐름을 제어, 기본적으로 스프링 MVC의 DispatcherServlet 클래스를 그대로 적용 HandlerMapping : 클라이언트의 요청을 바탕으로 어느 컨트롤러를 실행할지 결정 Model : 컨트롤러에서 뷰로 넘겨줄 오브젝트를 저장하기 위한 오브젝트, HttpServletRequest와 HttpSession처럼 String 형 키와 오브젝트를 연결해서 오브젝트를 유지 ViewResolver : View 이름을 바탕으로 View 오브젝트를 결정 View : 뷰에 화명 표시 처리를 의뢰 비즈니스 로직 : 비즈니스 로직을 실행. 애플리케이션 개발자가 비즈니스 처리 사양에 맞게 작성 컨트롤러(Controller) : 클라이언트 요청에 맞는 프레젠테이션 층의 애플리케이션 처리를 실행해야 함. 애플리케이션 개발자가 애플리케이션 처리 사양에 맞게 작성 뷰 / JSP 등 : 클라이언트에 대해 화면 표시 처리. 자바에서는 JSP 등으로 작성하는 일이 많으며, 애플리케이션 개발자가 화면의 사양에 맞게 작성 동작 순서 DispatcherServlet은 브라우저로부터 요청을 받아들입니다. DispatcherServlet은 요청된 URL을 HandlerMapping 오브젝트에 넘기고 호출 대상의 컨트롤러 오브젝트를 얻어 URL에 해당하는 메서드를 실행합니다. 컨트롤러 오브젝트는 비즈니스 로직으로 처리를 실행하고, 그 결과를 바탕으로 뷰에 전달할 오브젝트를 Model 오브젝트에 저장합니다. 끝으로 컨트롤러 오브젝트는 처리 결과에 맞는 View 이름을 반환합니다. DispatcherServlet은 컨트롤러에서 반환된 View 이름을 ViewResolver에 전달해서 View 오브젝트를 얻습니다. DispatcherServlet은 View 오브젝트에 화면 표시를 의뢰합니다. View 오브젝트는 해당하는 뷰를 호출해서 화면 표시를 의뢰합니다. 뷰는 Model 오브젝트에서 화면 표시에 필요한 오브젝트를 가져와 화면 표시 처리를 실행합니다. 참고 스프링4 입문 - 한빛미디어","link":"/2018/03/12/Spring/spring-mvc/"},{"title":"토비의 스프링 1장 (오브젝트와 의존관계)","text":"스프링스프링은 자바 엔터프라이즈 애플리케이션 개발에 사용되는 프레임워크다. 애플리케이션 프레임워크는 애플리케이션 개발을 빠르고 효율적으로 할 수 있도록 애플리케이션의 바탕이 되는 틀과 공통 프로 그래밍 모델, 기술 API 등을 제공해준다. 스프링은 스프링 컨테이너 또는 애플리케이션 컨텍스트라고 불리는 스프링 런타임 엔진을 제공한다. 스프링 컨테이너는 설정정보를 참고로 해서 애플리케이션을 구성하는 오브젝트를 생성하고 관리한다. 스프링은 세 가지 핵심 프로그래밍 모델을 지원한다. IOC/DI : 오브젝트의 생명주기와 의존관계에 대한 프로그래밍 모델 서비스 추상화 : 환경이나 서버, 특정 기술에 종속되지 않고 이식성이 뛰어나며 유연한 애플리케이션을 만들 수 있다. AOP : 애플리케이션 코드에 산재해서 나타나는 부가적인 기능을 독립적으로 모듈화하는 프로그래밍 모델 자바빈 다음과 같은 두 가지 관례를 따라 만들어진 오브젝트를 말한다. 간단히 빈이라고 부르기도 한다. 디폴트 생성자 : 자바빈은 파라미터가 없는 디폴트 생성자를 갖고 있어야 한다. 툴이나 프레임워크에서 리플렉션을 이용해 오브젝트를 생성하기 때문에 필요하다. 프로퍼티 : 자자빈이 노출하는 이름을 가진 속성을 프로퍼티라고 한다. 프로퍼티는 setter와 getter를 이용해 수정 또는 조회할 수 있다. 디자인 패턴 : 소프트웨어 설계 시 특정 상황에서 자주 만나는 문제를 해결하기 위해 사용할 수 있는 재사용 가능한 솔루션. 주로 객체지향 설계에 관한 것이고, 대부분 객체지향적 설계 원칙을 이용해 문제를 해결한다. 템플릿 메소드 패턴상속을 통해 슈퍼클래스의 기능을 확장할 때 사용하는 가장 대표적인 방법이다. 변하지 않는 기능은 슈퍼클래스에 만들어두고 자주 변경되며 확장할 기능은 서브클래스에 만들도록 한다. 슈퍼클래스에서는 미리 추상메소드 또는 오버라이드 가능한 메소드를 정의해두고 이를 활용해 코드의 기본 알고리즘을 담고 있는 템플릿 메소드를 만든다. 팩토리 메소드 패턴슈퍼클래스 코드에서는 서브클래스에서 구현할 메소드를 호출해서 필요한 타입의 오브젝트를 가져와 사용한다. 이 메소드는 주로 인터페이스 타입으로 오브젝트를 리턴하므로 서브클래스에서 정확히 어떤 클래스의 오브젝트를 만들어 리턴할지는 슈퍼클래스에서는 알지 못한다. 팩토리 메소드와 메소드 패턴의 팩토리 메소드는 의미가 다르므로 혼동하지 않도록 주의해야 한다. 클래스 사이의 관계와 오브젝트 사이의 관계를 구분할 수 있어야 한다. 클래스 사이의 관계 : 코드에 다른 클래스의 이름이 나타나기 때문에 만들어지는 것이다. 오브젝트 사이의 관계 : 코드에서는 특정 클래스를 전혀 알지 못하더라도 해당 클래스가 구현한 인터페이스를 사용했다면, 그 클래스의 오브젝트를 인터페이스 타입으로 받아서 사용할 수 있다. 개방 폐쇄 원칙 (OCP, Open-Closed Principle) 클래스나 모듈은 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다. 인터페이스를 사용해 확장 기능을 정의한 대부분의 API는 바로 이 개방 폐쇄 원칙을 따른다. 개방 폐쇄 원칙은 높은 응집도와 낮은 결합도라는 소프트웨어 개발의 고전적인 원리로도 설명이 가능하다. 전략 패턴 개방 폐쇄 원칙의 실현에도 가장 잘 들어맞는 패턴이다. 전략 패턴은 자신의 기능 맥락(context)에서, 필요에 따라 변경이 필요한 알고리즘(독립적인 책임으로 분리가 가능한 기능)을 인터페이스를 통해 통째로 외부로 분리시키고, 이를 구현한 구체적인 알고리즘 클래스를 필요에 따라 바꿔서 사용할 수 있게 하는 디자인패턴이다. 전략 패턴의 적용방법을 보면 클라이언트의 역할이 잘 설명되어 있다. 컨텍스트를 사용하는 클라이언트는 컨텍스트가 사용할 전략을 컨텍스트의 생성자 등을 통해 제공해주는게 일반적이다. 제어의 역전 (IOC, Inversion Of Control)제어의 역전이라는 건, 간단히 프로그램의 제어 흐름 구조가 뒤바뀌는 것이다. 제어의 역전에서는 오브젝트가 자신이 사용할 오브젝트를 스스로 선택하지 않는다. 당연히 생성하지도 않는다. 또 자신도 어떻게 만들어지고 어디서 사용되는지를 알 수 없다. 모든 제어 권한을 자신이 아닌 다른 대상에게 위임하기 때문이다. 서블릿이나 JSP, EJB처럼 컨테이너 안에서 동작하는 구조는 간단한 방식이긴 하지만 제어의 역전 개념이 적용되어 있다고 볼 수 있다. 프레임워크도 제어의 역전 개념 적용된 대표적인 기술이다. 라이브러리와 프레임워크의 차이점에 대해 설명하면, 라이브러리를 사용하는 애플리케이션 코드는 애플리케이션 흐름을 직접 제어한다. 단지 동작하는 중에 필요한 기능이 있을 때 능동적으로 라이브러리를 사용할 뿐이다. 반면에 프레임워크는 거꾸로 애플리케이션 코드가 프레임워크에 의해 사용된다. 보통 프레임워크 위에 개발한 클래스를 등록해주고, 프레임워크가 흐름을 주도하는 중에 개발자가 만든 애플리케이션 코드를 사용하도록 만드는 방식이다. 제어의 역전에서는 프레임워크 또는 컨테이너와 같이 애플리케이션 컴포넌트의 생성과 관계설정, 사용, 생명주기 관리 등을 관장하는 존재가 필요하다. 스프링은 IoC를 모든 기능의 기초가 되는 기반기술로 삼고 있으며, IoC를 극한까지 적용하고 있는 프레임워크다. 스프링의 IoC오브젝트 팩토리를 이용한 스프링 IoC스프링에서는 스프링이 제어권을 가지고 직접 만들고 관계를 부여하는 오브젝트를 빈(bean)이라고 부른다. 자바빈 또는 엔터프라이즈 자바빈(EJB)에서 말하는 빈과 비슷한 오브젝트 단위의 애플리케이션 컴포넌트를 말한다. 동시에 스프링 빈은 스프링 컨테이너가 생성과 관계설정, 사용 등을 제어해주는 제어의 역전이 적용된 오브젝트를 가리키는 말이다. 스프링에서는 빈의 생성과 관계설정 같은 제어를 담당하는 IoC 오브젝트를 빈 팩토리(bean factory)라고 부른다. 보통 빈 팩토리보다는 이를 좀 더 확장한 애플리케이션 컨텍스트(applcation context)를 주로 사용한다. 애플리케이션 컨텍스트는 그 자체로는 애플리케이션 로직을 담당하지는 않지만 IoC 방식을 이용함으로써, 별도의 정보를 참고해서 빈의 생성과 관계설정 등의 제어 작업을 총괄한다. @Configuration : 애플리케이션 컨텍스트 또는 빈 팩토리가 사용할 설정정보라는 표시 @Bean : 오브젝트 생성을 담당하는 IoC용 메소드라는 표시 애플리케이션 컨텍스트는 ApplicationContext 타입의 오브젝트다. ApplicationContext를 구현한 클래스는 여러 가지가 있는데 DaoFactory처럼 @Configuration이 붙은 자바 코드를 설정정보로 사용하려면 AnnotationConfigApplicationContext를 이용하면 된다. getBean() 메소드는 ApplicationContext가 관리하는 오브젝트를 요청하는 메소드다. getBean()은 기본적으로 Object 타입으로 리턴하게 되어 있어서 매번 리턴되는 오브젝트에 다시 캐스팅을 해줘야 하는 부담이 있다. 그러나 자바 5 이상의 제네릭 메소드 방식을 사용해 getBean()의 두 번째 파라미터에 리턴 타입을 주면, 지저분한 캐스팅 코드를 사용하지 않아도 된다. 오브젝트 팩토리에서 사용했던 IoC 원리를 그대로 적용하는데 애플리케이션 컨텍스트를 사용하는 이유는 범용적이고 유연한 방법으로 IoC 기능을 확장하기 위해서다. 애플리케이션 컨텍스트를 사용했을 때 얻을 수 있는 장점은 다음과 같다. 클라이언트는 구체적인 팩토리 메서드를 알 필요가 없다. 애플리케이션 컨텍스트는 종합 IoC 서비스를 제공해준다. 애플리케이션 컨텍스트는 빈을 검색하는 다양한 방법을 제공한다. 스프링 IoC의 용어 정리 빈빈 또는 빈 오브젝트는 스프링이 IoC 방식으로 관리하는 오브젝트라는 뜻이다. 주의할 점은 스프링을 사용하는 애플리케이션에서 만들어지는 모든 오브젝트가 다 빈은 아니라는 사실이다. 그 중에서 스프링이 직접 그 생성과 제어를 담당하는 오브젝트만을 빈이라고 부른다. 빈 팩토리스프링의 IoC를 담당하는 핵심 컨테이너를 말한다. 빈을 등록하고, 생성하고, 조회하고 돌려주고, 그 외에 부가적인 빈을 관리하는 기능을 담당한다. 애플리케이션 컨텍스트빈 팩토리를 확장한 IoC.컨테이너다. 스프링이 제공하는 각종 부가 서비스를 추가로 제공한다. 애플리케이션 컨텍스트 오브젝트는 하나의 애플리케이션에서 보통 여러 개가 만들어져 사용된다. 설정정보/설정 메타정보스프링의 설정정보란 애플리케이션 컨텍스트 또는 빈 팩토리가 IoC를 적용하기 위해 사용하는 메타정보를 말한다. IoC 컨테이너에 의해 관리되는 애플리케이션 오브젝트를 생성하고 구성할 때 사용된다. 컨테이너 또는 IoC 컨테이너IoC 방식으로 빈을 관리한다는 의미에서 애플리케이션 컨텍스트나 빈 팩토리를 컨테이너 또는 IoC 컨테이너라고도 한다. 그냥 컨테이너 또는 스프링 컨테이너라고 할 때는 애플리케이션 컨텍스트를 가리키는 것이라고 보면 된다. 싱글톤 레지스트리로서의 애플리케이션 컨텍스트 오브젝트의 동일성과 동등성 자바에서는 두 개의 오브젝트가 같은가라는 말을 주의해서 써야 한다. 자바에서는 두개의 오브젝트가 완전히 같은 동일한 오브젝트라고 말하는 것(동일성)과, 동일한 정보를 담고 있는 오브젝트라고 말하는 것(동등성)은 분명한 차이가 있다. 물론 동일한 오브젝트는 동등하기도 하다. 동일성은 == 연산자로, 동등성은 equals() 메소드를 이용해 비교한다. 스프링의 애플리케이션 컨텍스트는 기존에 직접 만든 오브젝트 팩토리와는 중요한 차이점이 있다. 스프링은 내부에서 생성하는 빈 오브젝트를 모두 싱글톤으로 만든다는 것이다. 애플리케이션 컨텍스트는 싱글톤을 저장하고 관리하는 싱글톤 레지스트리이기도 하다. 스프링은 기본적으로 별다른 설정을 하지 않으면 내부에서 생성하는 빈 오브젝트를 모두 싱글톤으로 만든다. (디자인 패턴에서 나오는 싱글톤 패턴과 비슷한 개념이지만 그 구현 방법은 확연히 다르다.) 싱글톤 패턴의 한계일반적인 싱글톤 패턴 구현 방식에는 다음과 같은 문제(한계)가 있다. private 생성자를 갖고 있기 때문에 상속할 수 없다. 싱글톤은 테스트하기가 힘들다. 서버환경에서는 싱글톤이 하나만 만들어지는 것을 보장하지 못한다. 싱글톤의 사용은 전역 상태를 만들 수 있기 때문에 바람직하지 못하다. 싱글톤 레지스트리스프링은 서버환경에서 싱글톤이 만들어져서 서비스 오브젝트 방식으로 사용되는 것은 적극 지지한다. 그러나 자바의 기본적인 싱글톤 패턴의 구현 방식은 여러 가지 단점이 있기 때문에, 스프링은 직접 싱글톤 형태의 오브젝트를 만들고 관리하는 기능을 제공한다. 그것이 바로 싱글톤 레지스트리다 싱글톤 레지스트리의 장점은 스태틱 메소드와 private 생성자를 사용해야 하는 비정상적인 클래스가 아니라 평범한 자바 클래스를 싱글톤으로 활용하게 해준다는 것이다. 스프링의 싱글톤 레지스트리 덕분에 싱글톤 방식으로 사용될 애플리케이션 클래스라도 public 생성자를 가질 수 있다. 싱글톤과 오브젝트의 한계싱글톤은 멀티스레드 환경이라면 여러 스레드가 동시에 접근해서 사용할 수 있다. 따라서 상태 관리에 주의를 기울여야 한다. 기본적으로 싱글톤이 멀티스레드 환경에서 서비스 형태의 오브젝트로 사용되는 경우에는 상태정보를 내부에 갖고 있지 않은 무상태(stateless) 방식으로 만들어져야 한다. 무상태 방식으로 만들기 위해서는 메소드 안에서 생성되는 로컬 변수를 사용하면 된다. 로컬 변수는 매번 새로운 값을 저장할 독립적인 공간이 만들어지기 때문에 싱글톤이라고 해도 여러 스레드 변수의 값을 덮어쓸 일은 없다. 따라서 스프링의 싱글톤 빈으로 사용되는 클래스를 만들 때는 개별적으로 바뀌는 정보는 로컬 변수로 정의하거나, 파라미터로 주고받으면서 사용하게 해야 한다. 그러나, 자신이 사용하는 다른 싱글톤 빈을 저장하려는 용도라면 인스턴스 변수를 사용해도 좋다. 스프링이 한 번 초기화해주고 나면 이후에는 수정되지 않기 때문에 멀티스레드 환경에서 사용해도 아무런 문제가 없다. 스프링 빈의 스코프스프링이 관리하는 오브젝트, 즉 빈이 생성되고, 존재하고, 적용되는 범위를 빈의 스코프(scope)라고 한다. 스프링 빈의 기본 스코프는 싱글톤이다. 경우에 따라서는 싱글톤 외의 스코프를 가질 수 있다. 그 예로 웹을 통해 새로운 HTTP 요청이 생길 때마다 생성되는 요청(request) 스코프가 있고, 웹의 세션과 스코프가 유사한 세션(session) 스코프도 있다. 의존관계 주입 (DI)IoC가 매우 느슨하게 정의돼서 폭넓게 사용되는 용어이기 때문에 스프링을 IoC 컨테이너라고만 해서는 스프링이 제공하는 기능의 특징을 명확하게 설명하지 못한다. 그래서 스프링이 제공하는 IoC 방식을 핵심을 짚어주는 의존관계 주입(Dependency Injection)이라는, 좀 더 의도가 명확한 이름을 사용하기 시작했다. 스프링이 다른 프레임워크와 차별화돼서 제공해주는 기능은 의존관계 주입이라는 새로운 용어를 사용할 때 분명하게 드러난다. DI는 오브젝트 레퍼런스를 외부로부터 제공(주입)받고 이를 통해 다른 오브젝트와 다이내믹하게 의존관계가 만들어지는 것이 핵심이다. 런타임 의존관계 설정모델이나 코드에서 클래스와 인터페이스를 통해 드러나는 의존관계 말고, 런타임 시에 오브젝트 사이에서 만들어지는 의존관계도 있다. 설계 시점의 의존관계가 실체화된 것이다. 런타임 시에 의존관계를 맺는 대상, 즉 실제 사용대상인 오브젝트를 의존 오브젝트라고 한다. 의존관계 주입은 구체적인 의존 오브젝트와 그것을 사용할 주체, 보통 클라이언트라고 부르는 오브젝트를 런타임 시에 연결해주는 작업을 말한다. 의존관계 주입이란 다음의 세 가지 조건을 충족하는 작업을 말한다. 클래스 모델이나 코드에는 런타임 시점의 의존관계가 드러나지 않는다. 그러기 위해서는 인터페이스에만 의존하고 있어야 한다. 런타임 시점의 의존관계는 컨테이너나 팩토리 같은 제3의 존재가 결정한다. 이존관계는 사용할 오브젝트에 대한 레퍼런스를 외부에서 제공(주입)해줌으로써 만들어진다. 의존관계 주입의 핵심은 설계 시점에는 알지 못했던 두 오브젝트의 관계를 맺도록 도와주는 제3의 존재가 있다는 것이다. 스프링의 애플리케이션 컨텍스트, 빈 팩토리, IoC 컨테이너 등이 모두 외부에서 오브젝트 사이의 런타임 관계를 맺어주는 책임을 지닌 제 3의 존재이다. DI는 자신이 사용할 오브젝트에 대한 선택과 생성 제어권을 외부로 넘기고 자신은 수동적으로 주입받은 오브젝트를 사용한다는 점에서 IoC의 개념에 잘 들어맞는다. 의존관계 검색과 주입스프링이 제공하는 IoC 방법에는 의존관계 주입만 있는 것이 아니다. 의존관계를 맺는 방법이 외부로부터의 주입이 아니라 스스로 검색을 이용하기 때문에 의존관계 검색이라고 불리는 것도 있다. 의존관계 검색은 자신이 필요로 하는 의존 오브젝트를 능동적으로 찾는다. 의존관계 검색은 런타임 시 의존관계를 맺을 오브젝트를 결정하는 것과 오브젝트의 생성작업은 외부 컨테이너에게 IoC로 맡기지만, 이를 가져올 때는 메소드나 생성자를 통한 주입 대신 스스로 컨테이너에게 요청하는 방법을 사용한다. 스프링의 IoC와 DI 컨테이너를 적용했다고 하더라도 애플리케이션의 기동 시점에서 적어도 한 번은 의존관계 검색 방식을 사용해 오브젝트를 가져와야 한다. static 메소드인 main()에서는 DI를 이용해 오브젝트를 주입받을 방법이 없기 때문이다. 의존관계 검색(DL)과 의존관계 주입을 적용할 때 발견할 수 있는 중요한 차이점이 하나 있다. 의존관계 검색 방식에서는 검색하는 오브젝트는 자신이 스프링의 빈일 필요가 없다. 반면에 의존관계 주입에서는 오브젝트 사이에 DI가 적용되려면 반드시 두 오브젝트 모두 컨테이너가 만드는 빈 오브젝트여야 한다. 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/03/25/Spring/toby-1/"},{"title":"@Bean Lite Mode & inter-bean references","text":"@Bean Methods in @Configuration Classes일반적으로 @Bean 어노테이션은 @Configuration 어노테이션이 사용된 클래스 내의 메서드에 선언이 됩니다. 이 경우 @Bean 어노테이션을 사용하는 메서드는 같은 클래스의 다른 @Bean 메소드를 직접 호출하여 참조할 수 있습니다. 이렇게하면 bean 간의 참조(reference)가 강하게 만들어집니다. 아래 코드의 실행 후 로그를 통해 a() 메서드의 결과로 생성되는 A 클래스의 빈은 b() 와 c() 메서드에서 a() 메서드를 직접 호출해 참조가 되는 것을 확인할 수 있습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@SpringBootApplicationpublic class TestApplication { @Autowired private ApplicationContext context; public static void main(String[] args) { ApplicationContext context = SpringApplication.run(TestApplication.class, args); } @Configuration public static class TestConfiguration { @Bean public A a() { return new A(); } @Bean public B b() { A a = a(); System.out.println(a); return new B(); } @Bean public C c() { A a = a(); System.out.println(a); return new C(); } } public static class A { } public static class B { } public static class C { }}// 샐행 결과2019-04-30 19:41:04.837 INFO 24509 --- [ main] com.example.test.TestApplication : Starting TestApplication on AL01297960.local with PID 24509 (/Users/user/work/test/build/classes/java/main started by user in /Users/user/work/test)2019-04-30 19:41:04.841 INFO 24509 --- [ main] com.example.test.TestApplication : No active profile set, falling back to default profiles: default2019-04-30 19:41:06.229 INFO 24509 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2019-04-30 19:41:06.262 INFO 24509 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2019-04-30 19:41:06.262 INFO 24509 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.17]2019-04-30 19:41:06.353 INFO 24509 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-04-30 19:41:06.353 INFO 24509 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1441 mscom.example.test.TestApplication$A@42163c37com.example.test.TestApplication$A@42163c372019-04-30 19:41:06.620 INFO 24509 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'2019-04-30 19:41:06.846 INFO 24509 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2019-04-30 19:41:06.850 INFO 24509 --- [ main] com.example.test.TestApplication : Started TestApplication in 2.489 seconds (JVM running for 3.45) 이러한 관계를 빈 간의 참조(inter-bean references)라 부릅니다. 이러한 빈 간의 참조는 @Configuration 클래스의 @Bean이 cglib wrapper에 의해 래핑되기 때문에 동작하게 됩니다.(@Bean 메서드에 대한 호출을 가로채고 Bean 인스턴스를 컨텍스트에서 반환하게 됩니다.) @Bean Lite Mode처음 알게된 분도 계실 수 있을텐데요, @Bean 메소드는 @Configuration으로 주석을 달지 않은 클래스 내에서도 선언 될 수도 있습니다. 이런 경우, @Bean 메서드는 lite mode로 처리됩니다. lite mode의 Bean 메서드는 스프링 컨테이너에 의해 일반 팩토리 메서드로 처리됩니다. 그렇기 때문에, lite mode에서는 빈 간의 참조가 지원되지 않습니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@SpringBootApplicationpublic class TestApplication { @Autowired private ApplicationContext context; public static void main(String[] args) { ApplicationContext context = SpringApplication.run(TestApplication.class, args); } @Configuration public static class TestConfiguration { public A a() { return new A(); } @Bean public B b() { A a = a(); System.out.println(a); return new B(); } @Bean public C c() { A a = a(); System.out.println(a); return new C(); } } public static class A { } public static class B { } public static class C { }}// 실행 결과```java2019-04-30 20:02:17.530 INFO 65524 --- [ main] com.example.test.TestApplication : Starting TestApplication on AL01297960.local with PID 65524 (/Users/user/work/test/build/classes/java/main started by user in /Users/user/work/test)2019-04-30 20:02:17.534 INFO 65524 --- [ main] com.example.test.TestApplication : No active profile set, falling back to default profiles: default2019-04-30 20:02:18.857 INFO 65524 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2019-04-30 20:02:18.891 INFO 65524 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2019-04-30 20:02:18.891 INFO 65524 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.17]2019-04-30 20:02:18.973 INFO 65524 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-04-30 20:02:18.973 INFO 65524 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1368 mscom.example.test.TestApplication$A@919d542ccom.example.test.TestApplication$A@414fc49c2019-04-30 20:02:19.240 INFO 65524 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'2019-04-30 20:02:19.471 INFO 65524 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2019-04-30 20:02:19.474 INFO 65524 --- [ main] com.example.test.TestApplication : Started TestApplication in 2.406 seconds (JVM running for 3.2)","link":"/2019/04/30/Spring/spring-bean-lite-mode/"},{"title":"Spring - IoC & DI","text":"IoC란?IoC 컨테이너 개념을 이해하기 위하여 이와 같은 컨테이너가 왜 등장하게 되었는지를 먼저 이해하는 것이 중요합니다. 애플리케이션 코드를 작성할 때, 특정 기능이 필요하면 라이브러리 사용하곤 합니다. 이때는 프로그램의 흐름을 제어하는 주체가 애플리케이션 코드입니다. 하지만 프레임워크(Framework) 기반의 개발에서는 프레임워크 자신이 흐름을 제어하는 주체가 되어, 필요 할 때마다 애플리케이션 코드를 호출하여 사용합니다. 프레임워크에서 이 제어권을 가지는 것이 바로 컨테이너(Container)입니다. 객체에 대한 제어권이 개발자로부터 컨테이너에게 넘어가면서 객체의 생성부터 생명주기 관리까지의 모든 것을 컨테이너가 맡아서 하게됩니다. 이를 일반적인 제어권의 흐름이 바뀌었다고 하여 IoC(Inversion of Control : 제어의 역전)라고 합니다. 먼저 지금까지 일반적으로 개발하던 방식에 대해서 생각해보아야 합니다. 모든 인스턴스에 대한 생성 권한은 지금까지 모든 개발자들에게 있었습니다. 즉, 작성하는 코드상에서 개발자가 직접 생성했다는 것입니다. EJB나 IoC 컨테이너를 사용하지 않았던 개발자들은 지금까지 이와 같은 방식을 사용했습니다. EJB는 각 개발자들이 모든 인스턴스의 생성 권한에 제약을 가하는 첫번째 프레임워크입니다. EJB는 서비스를 위해 생성되는 컴포넌트에 대한 생성 권한을 EJB 컨테이너에게 위임했습니다. 생성된 인스턴스는 EJB 컨테이너가 생명주기를 관리했습니다. EJB가 EJB 컨테이너에 의하여 관리됨으로 인해 큰 장점을 얻을 수 있었습니다. 그러나 장점 이외에 EJB가 가지고 있는 한계에 부딪히게 되었으며, 이 같은 요구사항을 해결하기 위해 EJB의 한계를 극복하기 위한 시도가 발생했습니다. 그래서 등장한 것이 경량(LightWeight) IoC 컨테이너 입니다. 경량 IoC 컨테이너는 EJB 컨테이너가 가지고 있던 단점을 보완하기 위하여 탄생한 컨테이너 개념입니다. Spring 프레임워크에서 지원하는 IoC 컨테이너는 우리들이 흔히 개발하고 사용해왔던 일반 POJO(Plain Old Java Object) 클래스들이 지금까지 EJB를 통하여 실행했던 많은 기능들을 서비스 가능하도록 지원합니다.또한, EJB 컨테이너가 지원하고 있던 Transaction, Object Pooling, 인스턴스 생명주기 관리등의 기능들을 Spring 컨테이너가 지원하며 부가적으로 테스트의 용이성(애플리케이션 품질의 향상), 개발 생산성을 향상 시킬 수 있습니다. 사용하는 목적IoC를 사용하는 목적에 대해서는 지금까지의 클래스호출 방식의 변화를 살펴보면 더 쉽게 이해할 수 있습니다. 클래스 호출 방식클래스내에 선언과 구현이 같이 있기 때문에 다양한 형태로 변화가 불가능합니다. 인터페이스 호출 방식클래스를 인터페이스와 인터페이스를 상속받아 구현하는 클래스로 분리했습니다. 구현클래스 교체가 용이하여 다양한 변화가 가능합니다. 그러나 구현클래스 교체시 호출클래스의 코드에서 수정이 필요합니다. (부분적으로 종속적) 팩토리 호출 방식팩토리 방식은 팩토리가 구현클래스를 생성하기 때문에 호출클래스는 팩토리를 호출 하는 코드로 충분합니다. 구현클래스 변경시 팩토리만 수정하면 되기 때문에 호출클래스에는 영향을 미치지 않습니다. 그러나 호출클래스에서 팩토리를 호출하는 코드가 들어가야 하는 것 또한 팩토리에 의존함을 의미합니다. IoC팩토리 패턴의 장점을 더해 어떠한 것에도 의존하지 않는 형태가 되었습니다. 실행시점에 클래스간의 관계가 형성이 됩니다. 즉, 의존성이 삽입된다는 의미로 IoC를 DI라는 표현으로 사용합니다. IoC 용어 정리 bean : 스프링에서 제어권을 가지고 직접 만들어 관계를 부여하는 오브젝트Java Bean, EJB의 Bean과 비슷한 오브젝트 단위의 애플리케이션 컴포넌트이다. 하지만 스프링을 사용하는 애플리케이션에서 만들어지는 모든 오브젝트가 빈은 아니다. 스프링의 빈은 스프링 컨테이너가 생성하고 관계설정, 사용을 제어해주는 오브젝트를 말한다. bean factory : 스프링의 IoC를 담당하는 핵심 컨테이너Bean을 등록/생성/조회/반환/관리 한다. 보통 bean factory를 바로 사용하지 않고 이를 확장한 application context를 이용한다. BeanFactory는 bean factory가 구현하는 interface이다. (getBean()등의 메서드가 정의되어 있다.) application context : bean factory를 확장한 IoC 컨테이너Bean의 등록/생성/조회/반환/관리 기능은 bean factory와 같지만, 추가적으로 spring의 각종 부가 서비스를 제공한다. ApplicationContext는 application context가 구현해야 하는 interface이며, BeanFactory를 상속한다. configuration metadata : application context 혹은 bean factory가 IoC를 적용하기 위해 사용하는 메타정보스프링의 설정정보는 컨테이너에 어떤 기능을 세팅하거나 조정하는 경우에도 사용하지만 주로 bean을 생성/구성하는 용도로 사용한다. container (ioC container) : IoC 방식으로 bean을 관리한다는 의미에서 bean factory나 application context를 가리킨다.application context는 그 자체로 ApplicationContext 인터페이스를 구현한 오브젝트를 말하기도 하는데, 하나의 애플리케이션에 보통 여러개의 ApplicationContext 객체가 만들어진다. 이를 통칭해서 spring container라고 부를 수 있다. 스프링을 사용하지 않을 때 일어날 수 있는 문제스프링의 특징을 알아보기 앞서 스프링을 사용하지 않을 때 어떤 문제가 일어날 수 있는지 알아보겠습니다. 오브젝트의 생명 주기 문제 부품화 문제 기술 은닉과 부적절한 기술 은닉 문제 이러한 문제를 해결하지 않는 한 웹 애플리케이션은 리소스를 잘 이용하지 못하고, 테스트하기 어려우며, 확장이나 변경 또한 어려울 것입니다. 스프링은 이러한 문제를 해결하기 위해 만들어진 컨테이너라고도 할 수 있습니다.스프링은 위의 문제를 다음과 같이 해결합니다. 오브젝트의 생명 주기 문제는 DI 컨테이너로 해결 부품화 문제는 DI 컨테이너로 해결 기술 은닉과 부적절한 기술 은닉 문제는 AOP로 해결 DIIoC는 직관적이지 못하기 때문에 DI(Dependency Injection)라고도 부릅니다. DI는 오브젝트를 생성하고 오브젝트끼리의 관계를 생성해 소프트웨어의 부품화 및 설계를 가능하게 합니다. DI를 이용하면 인터페이스 기반의 컴포넌트를 쉽게 구현할 수 있습니다.DI를 우리말로 옮기면 의존 관계의 주입입니다. 쉽게 말하면 오브젝트 사이의 의존 관계를 만드는 것입니다. 어떤 오브젝트의 프로퍼티(인스턴스 변수)에 오브젝트가 이용할 오브젝트를 설정한다는 의미입니다. 이를 학술적으로 말하면, 어떤 오브젝트가 의존(이용)할 오브젝트를 주입 혹은 인젝션(프로퍼티에 설정)한다는 것입니다.DI를 구현하는 컨테이너는 단순한 인젝션 외에도 클래스의 인스턴스화 등의 생명 주기 관리 기능이 있는 경우가 많습니다. 클래스에서 new 연산자가 사라졌다는 사실이 중요합니다. 클래스에서 new 연산자가 사라짐으로써 개발자가 팩토리 메서드 같은 디자인 패턴을 구사하지 않아도 DI 컨테이너가 건내주는 인스턴스를 인터페이스로 받아서 인터페이스 기반의 컴포넌트화를 구현할 수 있게 됐습니다. DI 컨테이너의 구상 클래스 인스턴스화는(디폴트로는) 1회만 실행합니다. 생성된 인스턴스는 필요한 곳에서 사용합니다. 이렇게 하는 것으로 서비스와 DAO처럼 Singleton으로 만들고 싶은 컴포넌트를 특별히 Singleton으로 만들지 않아도 간단히 실현되게 해줍니다. 스프링에는 크게 (1)XML로 작성된 Bean 정의 파일을 이용한 DI, (2)어노테이션을 이용한 DI, (3)JavaConfig에 의한 DI가 있습니다. 이번 포스팅에서는 어노테이션을 이용한 DI에 대해 알아보겠습니다. @Autowired와 @Component인스턴스 변수 앞에 @Autowired를 붙이면 DI 컨테이너가 그 인스턴스 변수의 형에 대입할 수 있는 클래스를 @Component가 붙은 클래스 중에서 찾아내 그 인스턴스를 인젝션해줍니다(정확히는 Bean 정의에서 클래스를 스캔할 범위를 정해야 합니다).인스턴스 변수로의 인젝션은 접근 제어자가 private라도 인젝션 할 수 있으므로 Setter 메서드를 만들 필요는 없습니다. (과거에 캡슐화의 정보 은닉에 반하는 것이 아니냐는 논의가 있었지만, 현재는 편리함에 밀려 그런 논의를 보기 힘들어졌습니다.) 만약 @Component가 붙은 클래스가 여러 개 있어도 형이 다르면 @Autowired가 붙은 인스턴스 변수에 인젝션되지 않습니다. 이렇게 형을 보고 인젝션하는 방법을 byType이라고 합니다. @Autowired@Autowired는 인스턴스 변수 앞에 붙이는 것 외에도, 다음과 같이 적당한 메서드 선언 앞에도 붙일 수 있습니다.123456789@Autowiredpublic void setFoo(Foo foo) { this.foo = foo;}@Autowiredpublic void setFoo(Foo foo, Bar bar) { this.foo = foo; this.bar = bar;} 또한 생성자에도 이용할 수 있습니다.1234public class Foo { @Autowired public Food(Bar b) {...}} 그런데 위의 사진과 같이 인터페이스에 구현 클래스가 2개여서 @Autowired로 인젝션할 수 있는 클래스의 형이 2개 존재한다면 에러가 발생합니다. 인젝션할 수 있는 클래스의 형은 반드시 하나로 해야합니다. 하지만 이래서는 인터페이스의 구현 클래스를 테스트용 클래스 등 다른 클래스로 바꿀 경우에 불편합니다. 그래서 이를 회피하는 세 가지 방법에 대해 알아보겠습니다. 우선할 디폴트 Bean을 설정하는 @Primary를 @Bean이나 @Component에 부여하는 방법(Bean 정의 파일에서는 ) 12345@Component@Primarypublic class ProductDaoImpl implements ProductDao {...(생략)...} @Autowired와 병행해서 @Qualifier를 하는 방법단, 이 경우는 @Component에도 이름을 같이 지정해야 한다. 이렇게 인젝션할 클래스를 형이 아닌 이름으로 찾아주는 방법을 byName이라고 한다. (물론 @Component에 같은 이름이 붙은 클래스가 중복되면 오류가 발생한다.) 12345678910@Autowired@Qualifier(\"productDao\")private ProductDao productDao;-----------------------------------------@Component(\"productDao\")public class ProductDaoImpl implements ProductDao {...(생략)...} Bean 정의 파일인 context:component-scan을 이용하는 방법(context:component-scan을 어느 정도 크기의 컴포넌트마다 기술해두고, 만약 어떤 컴포넌트를 테스트용으로 바꾸고자 할 때는 그 컴포넌트 부분의 정의만 테스트용 부품을 스캔하게 수정하는 방법이다.) 확장된 @Component@Component에는 확장된 어노테이션이 있습니다. 웹 애플리케이션 개발에는 @Component를 이용할 것이 아니라 클래스가 어느 레이어에 배치될지 고려해서 배치될 레이어에 있는 @Component 확장 어노테이션을 사용하는 것이 좋습니다. 예를 들어 ProductServiceImpl은 @Component가 아니라 @Service로 바꾸는 편이 좋고, ProductDaoImpl 클래스도 @Component가 아니라 @Repository로 바꾸는 편이 좋습니다. @Controller : 프레젠테이션 층 스프링 MVC용 어노테이션 @Service : 비즈니스 로직 층 Service용 어노테이션, @Component와 동일 @Repository : 데이터 엑세스 층의 DAO용 어노테이션 @Configuration : Bean 정의를 자바 프로그램에서 실행하는 JavaConfig용 어노테이션 @Component와 함께 사용하는 어노테이션의 하나로 @Scope가 있습니다. @Scope 뒤에 Value 속성을 지정하면 인스턴스화와 소멸을 제어할 수 있습니다. @Scope를 생략하면 해당 클래스는 싱글턴이 됩니다.12345@Component@Scope(\"singletone\")public class ProductDaoImple implements ProductDao {...(생략)...} singleton : 인스턴스를 싱글턴으로 함 prototype : 이용할 때마다 인스턴스화함 request : Servlet API의 request 스코프인 동안만 인스턴스가 생존함 session : Servlet API의 session 스코프인 동안만 인스턴스가 생존함 application : Servlet API의 application 스코프인 동안만 인스턴스가 생존함 value 속성의 값은 직접 문자열로 넣어도 되지만, 상수가 존재하기 때문에 상수를 사용하는 것이 좋습니다. singleton : BeanDefinition.SCOPE_SINGLETON prototype : BeanDefinition.SCOPE_PROTOTYPE request : WebApplicationContext.SCOPE_REQUEST session : WebApplicationContext.SCOPE_SESSION application : WebApplicationContext.SCOPE_APPLICATION 생명 주기 관리스프링 DI 컨테이너에는 인스턴스의 생성과 소멸 타이밍에 호출되는 메서드를 설정할 수 있는 @PosetConstruct와 @PreDestroy라는 2개의 어노테이션이 있습니다. @PostConstruct : 초기 처리를 하는 메서드 선언. 메서드 이름은 임의로 지정할 수 있다. 단, 메서드 인수 없이 반환형은 void 형으로 해야한다. @PreDestroy : 종료 처리를 하는 메서드 선언. 메서드 이름은 임의로 지정할 수 있다. 단, 메서드 인수 없이 반환형은 void 형으로 해야한다. @PostConstruct는 DI 컨테이너에 의해 인스턴스 변수에 무언가 인젝션된 다음에 호출됩니다. 따라서 인젝션 된 값으로 초기 처리를 할 때 사용합니다. (생성자에서도 초기 처리를 할 수 있습니다.)@PreDestroy는 소멸자가 없는 자바에서 종료 처리를 하기 위해 사용합니다. 참고 Spring Core API 및 IoC(DI) Spring IoC 개념 및 활용방안 IoC 컨테이너와 의존성 삽입 패턴 자바EE의 역사 및 스프링과의 관계 Spring - IoC &amp; DI 스프링4 입문 - 한빛미디어","link":"/2018/02/11/Spring/spring-ioc-di/"},{"title":"Spring - RequestBody & ResponseBody","text":"웹 서비스와 RESTful한 방식이 시스템을 구성하는 주요 요소로 자리 잡으면서 웹 시스템간에 XML이나 JSON 등의 형식으로 데이터를 주고 받는 경우가 증가했습니다. 이에 따라 스프링 MVC도 클라이언트에서 전송한 XML 데이터나 JSON 또는 기타 데이터를 컨트롤러에서 DOM 객체나 자바 객체로 변환해서 받을 수있는 기능(수신)을 제공하고 있으며, 비슷하게 자바 객체를 XML이나 JSON 또는 기타 형식으로 변환해서 전송할 수 있는 기능(송신)을 제공하고 있습니다. @RequestBody 어노테이션과 @ResponseBody 어노테이션은 각각 HTTP 요청의 body 부분을 자바 객체로 변환하고 자바 객체를 HTTP 응답 body로 변환하는데 사용됩니다. @RequestBodySpring MVC 컨트롤러에서 HTTP 요청의 body 부분을 자바 객체로 mapping할 때 @RequestBody 어노테이션을 사용합니다. @RequestBody 어노테이션의 기능은 다음과 같습니다. @ReuqestBody를 사용하지 않는 경우 : query parameter, form data를 객체에 mapping한다. @ReuqestBody를 사용하는 경우 : body에 있는 data를 HttpMessageConverter를 이용해 선언한 객체에 mapping한다. @ResponseBody@ResponseBody는 @RequestBody와 비슷한 방식으로 동작합니다. @ResponseBody가 메소드 레벨에서 부여되면 메소드가 리턴하는 오브젝트는 ContentNegotiatingViewResolver를 이용해 뷰를 통해 결과를 만들어내는 것이 아닌, message converter를 통해 바로 HTTP 응답의 메시지 본문으로 변환됩니다. ContentNegotiatingViewResolver는 등록되어 있는 ViewResolver중에서 controller 메소드의 리턴값을 통해 등록된 ViewResolver 중에서 적합한 형태로 처리해서 반환하는 반면, @ResponseBody는 @RequestBody가 선택한 형식으로 결과값을 변환하여 반환한다고 보면 됩니다. @RestController는 @Controller와 @ResponseBody를 동시에 사용하는 것과 같습니다. @Controller를 사용하는 경우에만 @ResponseBody를 추가하면 됩니다. HttpMessageConverter를 이용한 변환 처리AnnotationMethodHandlerAdapter에는 HttpMessageConverter 타입의 메시지 변환기인 message converter가 여러 개 등록되어 있습니다. @RequestBody가 붙은 파라미터가 있으면 HTTP 요청의 미디어 타입과 파라미터의 타입을 먼저 확인하고, message converter 중에서 해당 미디어 타입과 파라미터 타입을 처리할 수 있다면, HTTP 요청의 body 부분을 통째로 변환해서 지정된 메소드 파라미터로 전달해줍니다. HttpMessageConverter의 종류AnnotationMethodHandlerAdapter 클래스는 @RequestBody 어노테이션이 적용된 파라미터나 @ResponseBody 어노테이션이 적용된 메서드에 대해 HttpMessageConverter를 사용해서 변환을 처리합니다. 주요 HttpMessageConverter 구현 클래스는 다음과 같습니다. ByteArrayHttpMessageConverter : HTTP 메시지와 byte 배열 사이의 변환을 처리한다. 컨텐츠 타입은 application/octet-stream이다. StringHttpMessageConverter : HTTP 메시지와 String 사이의 변환을 처리한다. 컨텐츠 타입은 text/plain;charset=ISO-8859-1이다. SourceHttpMessageConverter : HTTP 메시지와 javax.xml.transform.Source 사이 변환을 처리한다. 컨텐츠 타입은 application/xml 또는 text/xml이다. FormHttpMessageConverter : HTML 폼 데이터를 MultiValueMap으로 전달받을 때 사용된다. 지원하는 컨텐츠 타입은 application-x-www-form-urlencorded이다. MappingJacksonHttpMessageConverter : Jackson 라이브러리를 이용해서 JSON HTTP 메시지와 객체 사이의 변환을 처리한다. 컨텐츠 타입은 applicaion/json이다. MarshallingHttpMessageConverter : 스프링의 Marshaller와 unMarshaller를 이용해서 XML HTTP 메시지와 객체 사이의 변환을 처리한다. 컨텐츠 타입은 application/xml 또는 text/xml이다. Content-Type과 Accept header 기반의 변환 처리AnnotationMethodHandlerAdapter가 HttpMessageConverter를 이용해서 request의 body 데이터를 @RequestBody 어노테이션이 적용된 자바 객체로 변환할 때에는, HTTP 요청 header의 Content-Type에 명시된 미디어 타입(MIME)을 지원하는 HttpMessageConverter 구현체를 선택합니다.예를 들어, 요청 미디어 타입이 application/json이고 @RequestBody 어노테이션이 적용된 경우 MappingJacksonHttpMessageConverter가 선택됩니다. 비슷하게 @ResponseBody 어노테이션을 이용해서 리턴한 객체를 HTTP 응답 객체로 변환할 때에는 HTTP 요청 header의 Accept에 명시된 미디어 타입(MIME)을 지원하는 HttpMessageConveter 구현체를 선택합니다.예를 들어, Accept에 명시된 값이 application/json이고 @ResponseBody 어노테이션이 적용된 메서드의 리턴 타입이 자바 객체인 경우 MappingJacksonHttpMessageConverter가 선택됩니다. 참고Http Message Converters with the Spring Framework","link":"/2018/03/02/Spring/spring-requestbody-responsebody/"},{"title":"토비의 스프링 2장 (테스트)","text":"테스트스프링이 개발자에게 제공하는 가장 중요한 가치는 객체지향과 테스트이다. 테스트란 내가 예상하고 의도했던 대로 코드가 정확히 동작하는지를 확인해서, 만든 코드를 확신할 수 있게 해주는 작업이다. 또한 테스트의 결과가 원하는 대로 나오지 않는 경우에는 코드나 설계에 결함이 있음을 알수 있다. 이를 통해 코드의 결함을 제거해가는 작업, 디버깅을 거치게 되고, 최종적으로 테스트가 성공하면 모든 결함이 제거됐다는 확신을 얻을 수 있다. 보통 웹 프로그램에서 사용하는 DAO를 테스트 하는 방법은 다음과 같다. DAO를 만든 뒤 바로 테스트하지 않고, 서비스 계층, MVC 프레젠테이션 계층까지 포함한 모든 입출력 기능을 대충이라도 코드로 다 만든다. 이렇게 만들어진 테스트 용 웹 애플리케이션을 서버에 배치한 뒤, 웹 화면을 띄워 폼을 열고, 값을 입력한 뒤 버튼을 눌러 등록해본다. 이렇게 웹 화면을 통해 값을 입력하고, 기능을 수행하고, 결과를 확인하는 방법은 가장 흔하게 쓰이는 방법이지만 단점이 너무 많다. 테스트를 하는 중에 에러가 나거나 테스트가 실패했다면, 과연 어디에서 문제가 발생했는지를 찾아내야 하는 수고도 필요하다. 하나의 테스트를 수행하는 데 참여하는 클래스와 코드가 너무 많기 때문이다. 테스트를 하고자 하는 대상이 명확하다면 그 대상에만 집중해서 테스트하는 것이 바람직하다. 테스트는 가능하면 작은 단위로 쪼개서 집중해서 할 수 있어야 한다. 관심사의 분리라는 원리가 여기에도 적용된다. 테스트의 관심이 다르다면 테스트할 대상을 분리하고 집중해서 접근해야한다. 작은 단위의 코드에 대해 테스트를 수행한 것을 단위 테스트(Unit test)라고 한다. 여기서 말하는 단위란 그 크기와 범위가 어느 정도인지 딱 정해진 건 아니다. 충분히 하나의 관심에 집중해서 효율적으로 텧스트할 만한 범위의 단위라고 보면 된다. 일반적으로 단위는 작을수록 좋다. 단위를 넘어서는 다른 코드들은 신경 쓰지 않고, 참여하지도 않고 테스트가 동작할 수 있으면 좋다. 그런 차원에서 통제할 수 없는 외부의 리소스에 의존하는 테스트는 단위 테스트가 아니라고 보기도 한다. 단위 테스트를 하는 이유는 개발자가 설계하고 만든 코드가 원래 의도한 대로 동작하는지를 개발자 스스로 빨리 확인받기 위해서다. 이때 확인의 대상과 조건이 간단하고 명확할수록 좋다. 테스트는 자동으로 수행되도록 코드로 만들어지는 것이 중요하다. 그렇게 되면 자주 반복할 수 있다는 장점을 얻을 수 있다. 테스트 자체가 사람의 수작업을 거치는 방법을 사용하기 보다는 코드로 만들어져서 자동으로 수행될 수 있어야 한다는 건 매우 중요하다. 그런데 애플리케이션을 구성하는 클래스 안에 테스트 코드를 포함시키는 것보다는 별도로 테스트용 클래스를 만들어서 테스트 코드를 넣는 편이 낫다. 테스트를 이용하면 새로운 기능도 기대한 대로 동작하는지 확인할 수 있을 뿐 아니라, 기존에 만들어뒀던 기능들이 새로운 기능을 추가하느라 수정한 코드에 영향을 받지 않고 여전히 잘 동작하는지를 확인할 수도 있다. 테스트 검증의 자동화모든 테스트는 성공과 실패의 두 가지 결과를 가질 수 있다. 또 테스트의 실패는 테스트가 진행되는 동안에 에러가 발생해서 실패하는 경우와, 테스트 작업 중에 에러가 발생하진 않았지만 그 결과가 기대한 것과 다르게 나오는 경우로 구분해볼 수 있다. 여기서 전자를 테스트 에러, 후자를 테스트 실패로 구분할 수 있다. 테스트 중에 에러가 발생하는 것은 쉽게 확인이 가능하다. 콘솔에 에러 메시지와 긴호출 스택 정보가 출력되기 때문이다. 하지만 테스트가 실패하는 것은 별도의 확인 작업과 그 결과가 있어야만 알 수 있다. 자바에는 단순하면서도 실용적인 테스트를 위한 도구가 여러 가지 존재한다. JUnit은 이름 그대로 자바로 단위 테스트를 만들 때 유용하게 쓸 수 있다. JUnit은 프레임워크다. 프레임워크는 개발자가 만든 클래스에 대한 제어 권한을 넘겨받아서 주도적으로 애플리케이션의 흐름을 제어한다. 개발자가 만든 클래스의 오브젝트를 생성하고 실행하는 일은 프레임워크에 의해 진행된다. 따라서 프레임워크에서 동작하는 코드는 main() 메소드도 필요 없고 오브젝트를 만들어서 실행시키는 코드를 만들 필요도 없다. main() 메소드 테스트는 그런면에서 프레임워크에 적용하기엔 적합하지 않다. 테스트가 main() 메소드로 만들어졌다는 건 제어권을 직접 갖는다는 의미이기 때문이다. 그래서 가장 먼저 할 일은 main() 메소드에 있던 테스트 코드를 일반 메소드로 옮기는 것이다. 새로 만들 테스트 메소드는 JUnit 프레임워크가 요구하는 조건 두가지를 따라야 한다. 첫째는 메소드가 public으로 선언돼야 하는 것이고, 다른 하나는 메소드에 @Test라는 애노테이션을 붙여주는 것이다. JUnit은 하나의 클래스 안에 여러 개의 테스트 메소드가 들어가는 것을 허용한다. @Test가 붙어있고 public 접근자가 있으며 리턴 값이 void 형이고 파라미터가 없다는 조건을 지키기만 하면된다. 12345678public class Test { @Test public void add() { ApplicationContext context = new GenericXmlApplicationContext(\"applicationContext.xml\"); ... }} 검증 코드 변환1if (!user.getName().equals(user2.getName())) { ... } 이 if 문장의 기능을 JUnit이 제공해주는 assertThat이라는 스태틱 메소드를 이용해 다음과 같이 변경할 수 있다. 1assertThat(user2.getName(), is(user.getName())); assertThat() 메소드는 첫 번째 파라미터의 값을 뒤에 나오는 매처(matcher)라고 불리는 조건으로 비교해서 일치하면 다음으로 넘어가고, 아니면 테스트가 실패하도록 만들어 준다. is()는 매처의 일종으로 equals()로 비교해주는 기능을 가졌다. JUni은 예외가 발생하거나 assertThat()에서 실패하지 않고 테스트 메소드의 실행이 완료되면 테스트가 성공했다고 인식한다. JUnit 테스트 실행스프링 컨테이너와 마찬가지로 JUnit 프레임워크도 자바 코드로 만들어진 프로그램이므로 어디선가 한 번은 JUnit 프레임워크를 시작시켜 줘야 한다. 어디에든 main() 메소드를 하나 추가하고, 그 안에 JUnitCore 클래스의 main 메소드를 호출해주는 간단한 코드를 넣어주면 된다. 메소드 파라미터에는 @Test 테스트 메소드를 가진 클래스의 이름을 넣어준다. 12345import org.junit.runner.jUnitCore;...public static void main(String[] args) { JUnitCore.main(\"Springbook.user.dao.UserDaoTest\");} JUnit은 assertThat()을 이용해 검증을 했을 때 기대한 결과가 아니면 이 AssertionError를 던진다. 또한 테스트 수행 중에 일반 예외가 발생한 경우에도 마찬가지로 테스트 수행은 중단되고 테스트는 실패한다. JUnitJUnit은 사실상 자바의 표준 테스팅 프레임워크라고 불릴만큼 폭넓게 사용되고 있다. 스프링의 핵심 기능 중 하나인 스프링 테스트 모듈도 JUnit을 이용한다. 또, 테스트 작성시 자주 필요한 편리한 여러 가지 부가기능도 제공한다. 대부분의 자바 IDE는 JUnit 테스트를 손쉽게 실행할 수 있는 JUnit 테스트 지원 기능을 내장하고 있어서 더욱 편리하게 JUnit 테스트를 만들고 활용할 수 있게 해준다. JUnit 테스트 실행 방법JUnitCore를 이용해 테스트를 실행하고 콘솔에 출력된 메시지를 보고 결과를 확인하는 방법은 가장 간단하긴 하지만 테스트의 수가 많아지면 관리하기가 힘들어진다는 단점이 있다. 가장좋은 JUnit 테스트 실행 방법은 자바 IDE에 내장된 JUnit 테스트 지원 도구를 사용하는 것이다. IDE를 사용하면 JUnitCore를 이용할 때처럼 main() 메소드를 만들지 않아도 된다. JUnit은 한 번에 여러 테스트 클래스를 동시에 실행할 수도 있다. 패키지 아래에 있는 모든 JUnit 테스트를 한 번에 실행할 수도 있고, 소스 폴더나 프로젝트 전체를 선택해서 모든 테스트를 한 번에 실행할 수도 있다. 이런 면에서 JUnitCore를 사용해 테스트를 실행하는 것보다 훨씬 편리하다. 주의해야 할 점은 여러개의 테스트가 어떤 순서로 실행될지는 알 수 없다. JUnit은 특정한 테스트 메소드의 실행 순서를 보장해주지 않는다. 테스트의 결과가 테스트 실행 순서에 영향을 받는다면 테스트를 잘못 만든 것이다. 모든 테스트는 실행 순서에 상관없이 독립적으로 항상 동일한 결과를 낼 수 있도록 해야 한다. 빌드툴프로젝트의 빌드를 위해 ANT나 메이븐(Maven)같은 빌드 툴과 스크립트를 사용하고 있다면, 빌드 툴에서 제공하는 JUnit 플러그인이나 태스크를 이용해 JUnit 테스트를 실행할 수 있다. 여러 개발자가 만든 코드를 모두 통합해서 테스트를 수행해야 할 때도 있다. 이런 경우에는 서버에서 모든 코드를 가져와 통합하고 빌드한 뒤에 테스트를 수행하는 것이 좋다. 이때는 빌드 스크립트를 이용해 JUnit 테스트를 실행하고 그 결과를 메일 등으로 통보받는 방법을 사용하면 된다. 포괄적인 테스트예외조건에 대한 테스트일반적으로는 테스트 중에 예외가 던져지면 테스트 메소드의 실행은 중단되고 테스트는 실패한다. assertThat()을 통한 검증 실패는 아니고 테스트 에러라고 볼 수 있다. 그런데 이번에는 반대로 테스트 진행 중에 특정 예외가 던져지면 테스트가 성공한 것이고, 예외가 던져지지 않고 정상적으로 작업을 마치면 테스트가 실패했다고 판단해야 한다. 문제는 예외 발생 여부는 메소드를 실행해서 리턴 값을 비교하는 방법으로 확인할 수 없다는 점이다. 그런데 바로 이런 경우를 위해 JUnit은 예외조건 테스트를 위한 특별한 방법을 제공해준다. @Test 애노테이션의 expected 엘리먼트다. expected는 메소드 실행 중에 발생하리라 기대하는 예외 클래스를 넣어주면 된다. @Test에 expected를 추가해놓으면 보통의 테스트와는 반대로, 정상적으로 테스트 메소드를 마치면 테스트가 실패하고, expected에서 지정한 예외가 던져지면 테스트가 성공한다. 예외가 반드시 발생해야 하는 경우를 테스트하고 싶을 때 유용하게 쓸 수 있다. 테스트가 이끄는 개발테스트 주도 개발만들고자 하는 기능의 내용을 담고 있으면서 만들어진 코드를 검증도 해줄 수 있도록 테스트 코드를 먼저 만들고, 테스트를 성공하게 해주는 코드를 작성하는 방식의 개발 방법이 있다. 이를 테스트 주도 개발(TDD)이라고 한다. 또는 테스트를 코드보다 먼저 작성한다고 해서 테스트 우선 개발(Test First Development)이라고도 한다. “실패한 테스트를 성공시키기 위한 목적이 아닌 코드는 만들지 않는다”는 것이 TDD의 기본 원칙이다. TDD는 아예 테스트를 먼저 만들고 그 테스트가 성공하도록 하는 코드만 만드는 식으로 진행하기 때문에 테스트를 빼먹지 않고 꼼꼼하게 만들어낼 수 있다. 또한 TDD를 하면 자연스럽게 단위 테스트를 만들 수 있다. TDD의 장점 중 하나는 코드를 만들어 테스트를 실행하는 그 사이의 간격이 매우 짧다는 점이다. 개발한 코드의 오류는 빨리 발견할수록 좋다. 빨리 발견된 오류는 쉽게 대응이 가능하기 때문이다. 테스트 없이 오랜 시간 동안 코드를 만들고 나서 테스트를 하면, 오류가 발생했을 때 원인을 찾기가 쉽지 않다. 테스트 코드 개선JUnit 프레임워크는 테스트 메소드를 실행할 때 부가적으로 해주는 작업이 몇 가지 있다. 그 중에서 테스트를 실행할 때마다 반복되는 준비 작업을 별도의 메소드에 넣게 해주고, 이를 매번 테스트 메소드를 실행하기 전에 먼저 실행시켜주는 기능이다. 이를 알기위해서는 JUnit 프레임워크가 테스트 메소드를 실행하는 과정을 알아야 한다. JUnit이 하나의 테스트 클래스를 가져와 테스트를 수행하는 방식은 다음과 같다. 테스트 클래스에서 @Test가 붙은 public이고 void형이며 파라미터가 없는 테스트 메소드를 모두 찾는다. 테스트 클래스의 오브젝트를 하나 만든다. @Before가 붙은 메소드가 있으면 실행한다. @Test가 붙은 메소드를 하나 호출하고 테스트 결과를 저장해둔다. @After가 붙은 메소드가 있으면 실행한다. 나머지 테스트 메소드에 대해 2~5번을 반복한다. 모든 테스트의 결과를 종합해서 돌려준다. JUnit은 @Test가 붙은 메소드를 실행하기 전과 후에 각각 @Before와 @After가 붙은 메소드를 자동으로 실행한다. 보통 하나의 테스트 클래스 안에 있는 테스트 메소드들은 공통적인 준비작업과 정리 작업이 필요한 경우가 많다. 이런 작업들을 @Before, @After가 붙은 메소드에 넣어두면 JUnit이 자동으로 메소드를 실행해주니 매우 편리하다. 대신 @Before나 @After 메소드를 테스트 메소드에서 직접 호출하지 않기 때문에 서로 주고받을 정보나 오브젝트가 있다면 인스턴스 변수를 이용해야 한다. 또 한가지 기억해야 할 사항은 각 테스트 메소드를 실행할 때마다 테스트 클래스의 오브젝트를 새로 만든다는 것이다. 한번 만들어진 테스트 클래스의 오브젝트는 하나의 테스트 메소드를 사용하고 나면 버려진다. 그렇기 때문에 각 테스트가 서로 영향을 주지 않고 독립적으로 실행됨을 확실히 보장할 수 있다. 덕분에 인스턴스 변수도 부담 없이 사용할 수 있다. 어차피 다음 테스트 메소드가 실행될 때는 새로운 오브젝트가 만들어져서 다 초기화될 것이다. 픽스처 테스트를 수행하는 데 필요한 정보나 오브젝트를 픽스처(fixture)라고 한다. 일반적으로 픽스처는 여러 테스트에서 반복적으로 사용되기 때문에 @Before 메소드를 이용해 생성해두면 편리하다. 스프링 테스트 적용빈이 많아지고 복잡해지면 애플리케이션 컨텍스트 생성이 적지 않은 시간이 걸린다. 애플리케이션 컨텍스트가 만들어질 때는 모든 싱글톤 빈 오브젝트를 초기화한다. 또 한가지 문제는 애플리케이션 컨텍스트가 초기화될 때 어떤 빈은 독자적으로 많은 리스소를 할당하거나 독립적인 스레드를 띄우기도 한다는 것이다. 이런 경우에는 테스트를 마칠 때마다 애플리케이션 컨텍스트 내의 빈이 할당한 리소스 등을 깔끔하게 정리해주지 않으면 다음 테스트에서 새로운 애플리케이션 컨텍스트가 만들어지면서 문제를 일으킬 수도 있다. 다행히도 애플리케이션 컨텍스트는 초기화되고 나면 내부의 상태가 바뀌는 일은 거의 없다. 빈은 싱글톤으로 만들었기 때문에 상태를 갖지 않는다. 따라서 애플리케이션 컨텍스트는 한 번만 만들고 여러 테스트가 공유해서 사용해도 된다. 스프링이 직접 제공하는 애플리케이션 컨텍스트 지원 기능을 사용하면 애플리케이션을 한 번만 만들어 공유해 사용할 수 있다. 테스트를 위한 애플리케이션 컨텍스트 관리스프링은 JUnit을 이용하는 테스트 컨택스트 프레임워크를 제공한다. 테스트 컨텍스트의 지원을 받으면 간단한 애노테이션 설정만으로 테스트에서 필요로 하는 애플리케이션 컨텍스트를 만들어서 모든 테스트가 공유하게 할 수 있다. 먼저 ApplicationContext 타입의 인스턴스 변수를 선언하고 스프링이 제공하는 @Autowired 애노테이션을 붙인다. 마지막으로 클래스 레벨에 @RunWith와 @ContextConfiguration 애노테이션을 추가해준다. 12345678@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(location=\"/applicationContext.xml\")public class Test { @Autowired private ApplicationContext context; ...} @RunWith는 JUnit 프레임워크의 테스트 실행 방법을 확장할 때 사용하는 어노테이션이다. SpringJUnit4ClassRunner라는 JUnit용 테스트 컨텍스트 프레임워크 확장 클래스를 지정해주면 JUnit이 테스트를 진행하는 중에 테스트가 사용할 애플리케이션 컨텍스트를 만들고 관리하는 작업을 진행해준다. @ContextConfiguration은 자동으로 만들어줄 애플리케이션 컨텍스트의 설정파일 위치를 지정한 것이다. context 변수에는 어떻게 애플리케이션 컨텍스트가 들어가 있을까? 스프링의 JUnit 확장기능은 테스트가 실행되기 전에 딱 한 번만 애플리케이션 컨텍스트를 만들어두고, 테스트 오브젝트가 만들어질 때마다 특별한 방법을 이용해 애플리케이션 컨텍스트 자신을 테스트 오브젝트의 특정 필드에 주입해주는 것이다. 일종의 DI라고 볼 수 있는데, 애플리케이션 오브젝트 사이의 관계를 관리하기 위한 DI와는 조금 성격이 다르다. 이렇게 해서 하나의 테스트 클래스 내의 테스트 메소드는 같은 애플리케이션 컨텍스트를 공유해서 사용할 수 있다. 테스트 클래스의 컨텍스트 공유스프링 테스트 컨텍스트 프레임워크의 기능은 하나의 테스트 클래스 안에서 애플리케이션 컨텍스트를 공유해주는 것이 전부가 아니다. 여러 개의 테스트 클래스가 있는데 모두 같은 설정파일을 가진 애플리케이션 컨텍스트를 사용한다면, 스프링은 테스트 클래스 사이에서도 애플리케이션 컨텍스트를 공유하게 해준다. 테스트 클래스마다 다른 설정파일을 사용하도록 만들어도 되고, 몇 개의 테스트에서만 다른 설정파일을 사용할 수도 있다. 스프링은 설정파일의 종류만큼 애플리케이션 컨텍스트를 만들고, 같은 설정파일을 지정한 테스트에서는 이를 공유하게 해준다. @Autowired@Autowired는 스프링의 DI에 사용되는 특별한 애노테이션이다. @Autowired가 붙은 인스턴스 변수가 있으면, 테스트 컨텍스트 프레임워크는 변수 타입과 일치하는 컨텍스트 내의 빈을 찾는다. 타입이 일치하는 빈이 있으면 인스턴스 변수에 주입해준다. 일반적으로는 주입을 위해서는 생성자나 수정자 메소드 같은 메소드가 필요하지만, 이 경우에는 메소드가 없어도 주입이 가능하다. 또 별도의 DI 설정 없이 필드의 타입정보를 이용해 빈을 자동으로 가져올 수 있는데, 이런 방법을 타입에 의한 자동와이어링이라고 한다. 스프링 애플리케이션 컨텍스트는 초기화할 때 자기 자신도 빈으로 등록한다. 따라서 애플리케이션 컨텍스트에는 ApplicationContext 타입의 빈이 존재하는 것이고 DI도 가능하다. @Autowired를 이용해 애플리케이션 컨텍스트가 갖고 있는 빈을 DI 받을 수 있다면 굳이 컨텍스트를 가져와 getBean()을 사용하는 것이 아니라, 아예 빈을 직접 DI 받을 수도 있다. (@Autowired를 지정하기만 하면 어떤 빈이든 다 가져올 수 있다.) @Autowired는 변수에 할당 가능한 타입을 가진 빈을 자동으로 찾는다. 단, @Autowired는 같은 타입의 빈이 두 개 이상 있는 경우에는 타입만으로는 어떤 빈을 가져올지 결정할 수 없다. 타입으로 가져올 빈 하나를 선택할 수 없는 경우에는 변수의 이름과 같은 이름의 빈이 있는지 확인한다. 변수 이름으로도 빈을 찾을 수 없는 경우에는 예외가 발생한다. 테스트는 필요하다면 얼마든지 애플리케이션 클래스와 밀접한 관계를 맺고 있어도 상관없다. 개발자가 만드는 테스트는 코드 내부구조와 설정 등을 알고 있고 의도적으로 그 내용을 검증해야 할 필요가 있기 때문이다. 하지만 꼭 필요하지 않다면 테스트에서도 가능한 한 인터페이스를 사용해서 애플리케이션 코드와 느슨하게 연결해두는 편이 좋다. DI와 테스트인터페이스를 통해 DI를 적용해야 하는 이유는 다음과 같다. 소프트웨어 개발에서 절대로 바뀌지 않는 것은 없기 때문이다. 클래스의 구현 방식은 바뀌지 않는다고 하더라도 인터페이스를 두고 DI를 적용하게 해두면 다른 차원의 서비스 기능을 도입할 수 있기 때문이다. 테스트 때문이다. SingleConnectionDataSource 스프링이 제공하는 가장 빠른 DataSource이다. DB 커넥션을 하나만 만들어두고 계속 사용하기 때문에 매우 빠르다. 다중 사용자 환경에서는 사용할 수 없겠지만 순차적으로 진행되는 테스트에서라면 문제없다. 스프링 테스트 컨텍스트 프레임워크를 적용했다면 애플리케이션 컨텍스트는 테스트 중에 딱 한 개만 만들어지고 모든 테스트에서 공유해서 사용한다. 따라서 애플리케이션 컨텍스트의 구성이나 상태를 테스트 내에서 변경하지 않는 것이 원칙이다. 만약 한 번 변경하면 나머지 모든 테스트를 수행하는 동안 변경된 애플리케이션 컨텍스트가 계속 사용될 것이다. 이는 별로 바람직하지 못하다. 그럴때는 @DirtiesContext라는 애노테이션을 추가한다. 이 애노테이션은 스프링의 테스트 컨텍스트 프레임워크에게 해당 클래스의 테스트에서 애플리케이션 컨텍스트의 상태를 변경한다는 것을 알려준다. 테스트 컨텍스트는 이 애노테이션이 붙은 테스트 클래스에는 애플리케이션 컨텍스트 공유를 허용하지 않는다. 테스트 메소드를 수행하고 나면 매번 새로운 애플리케이션 컨텍스트를 만들어서 다음 테스트가 사용하게 해준다. 테스트 중에 변경한 컨텍스트가 뒤의 테스트에 영향을 주지 않게하기 위해서다. @DirtiesContext는 클래스에만 적용할 수 있는 건 아니다. 하나의 메소드에서만 컨텍스트 상태를 변경한다면 메소드 레벨에 @DirtiesContext를 붙여주는 편이 낫다. 해당 메소드의 실행이 끝나고 나면 이후에 진행되는 테스트를 위해 변경된 애플리케이션 컨텍스트는 폐기되고 새로운 애플리케이션 컨텍스트가 만들어진다. 테스트를 위한 별도의 DI 설정테스트 코드에서 빈 오브젝트에 수동으로 DI 하는 방법은 장점보다 단점이 많다. 코드가 많아져 번거롭기도 하고 애플리케이션 컨텍스트도 매번 새로 만들어야 하는 부담이 있다. 그래서 테스트 전용 설정파일을 따로 만들어 사용하는 방법을 이용한다. 테스트에서는 항상 테스트 전용 설정파일만 사용하게 해주면 된다. @ContextConfiguration 애노테이션에 있는 locations 엘리먼트의 값을 새로 만든 테스트용 설정파일로 변경해준다. 123@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=\"/test-applicationContext.xml\")public class Test { 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/03/26/Spring/toby-2/"},{"title":"IntelliJ에서 SpringBoot 프로젝트 생성하기","text":"서론Spring은 J2EE나 JEE로 알려진 자바 엔터프라이즈 에디션을 경량화하기 위해 시작되었다. 스프링은 무거운 엔터프라이즈 자바 빈(EJB)로 컴포넌트를 개발하지 않았다. 그 대신 의존성 주입(DI)과 관점 지향 프로그래밍(AOP)을 활용해서 EJB의 기능을 평범한 자바 객체(POJO)로 구현할 수 있게 하여 간단하게 엔터프라이즈 자바 개발에 접근할 수 있도록 했다.컴포넌트 코드 작성은 가벼워졌지만, Spring Framework 기반의 웹 프로젝트를 진행하게되면 최초 개발 구성(설정)하는 부분에 많은 시간이 소모되었다. 결국 애플리케이션 로직 작성이 아닌 프로젝트 구성 작업에 쓰는 시간이 많이 Gk소모되는 것이다.SpringBoot는 Spring의 복잡한 설정을 최소화하여 빠르게 프로젝트 개발을 시작할 수 있게 해준다. 이 포스팅에서는 IntelliJ에서 SpringBoot로 웹 프로젝트를 시작하는 방법을 소개하며 SpringBoot의 특징을 소개한다. IntelliJ에서 SpringBoot 프로젝트 생성Spring Initializr는 SpringBoot 프로젝트 구조를 만드는 웹 애플리케이션이다. 기본적인 프로젝트 구조와 코드를 빌드하는 데 필요한 maven이나 gradle 빌드 명세를 만들어준다. 그러므로 Spring Initializr가 만든 프젝트에 애플리케이션 코드만 작성하면 된다.Spring Initializr는 웹 기반 인터페이스, Spring Tool Suite(STS), IntelliJ IDE, SpringBoot CLI로 사용할 수 있다. 그 중 IntelliJ를 사용해 프로젝트를 생성해보자. IntelliJ를 시작하여 Create New Project를 선택하고 새로운 프로젝트 다이얼로그를 연다. New Project 다이얼로그에서 Spring Initializr 프로젝트를 선택하고 자바 SDK를 설정한 후 Next 버튼을 누른다. 두 번째 화면에서는 프로젝트 이름, 빌드할 때 maven과 gradle 중 어느 것을 사용할지, 자바 버전 등 프로젝트의 기본적인 사항을 물어본다. 프로젝트 정보를 입력하고 Next 버튼을 누른다. 세 번째 화면에서는 프로젝트에서 필요한 종류의 의존성을 추가한다. Web, Thymeleaf, JPA, H2를 선택한 후 Next 버튼을 누른다. 다음으로 프로젝트가 저장되는 경로를 지정한다. Gradle 설정을 지정한다. 코드 작성도메인 정의 (Diary.java)src/main/java/com.example.demo/Diary.java 파일을 작성한다.일기를 나타내는 엔티티 정의한다. 간단하게 id, title, ocntent 필드를 갖고 있는 POJO 객체로 만든다. @Entity 어노테이션을 붙여 클래스를 JPA 엔티티로 지정했고, id 필드에는 @Id와 @GeneratedValue 어노테이션을 붙여 엔티티의 유일성을 식별하고 자동으로 값을 제공하는 필드로 지정했다.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.example.demo;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;@Entitypublic class Diary { @Id @GeneratedValue(strategy = GenerationType.AUTO) private long id; private String user; private String title; private String content; public long getId() { return id; } public void setId(long id) { this.id = id; } public String getUser() { return user; } public void setUser(String user) { this.user = user; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getContent() { return content; } public void setContent(String content) { this.content = content; }} 레파지토리 인터페이스 선언 (DiaryListRepository.java)src/main/java/com.example.demo/DiaryListRepository.java 파일을 작성한다.데이터베이스에 Diary 객체를 저장할 수 있는 레파지토리를 선언한다. 스프링 JPA를 사용하므로 스프링 데이터 JAP의 인터페이스를 상속하여 인터페이스를 만든다. JpaRepository 인터페이스는 타입 매개변수 두 개를 받는다. 첫 번째는 레파지토리가 사용할 도메인 타입, 두번 째는 클래스의 ID 프로퍼티 타입이다. 지정한 유저의 이름으로 도서 목록을 검색하는 findByUser() 메서드를 추가했다.DiaryListRepository는 JpaRepository 인터페이스를 상속받아 18개의 메서드를 구현해야 한다. 그러나 스프링 데이터는 레파지토리를 인터페이스로 정의만 해도 잘 작동할 수 있게 런타임 시에 자동으로 구현해준다.12345678910package com.example.demo;import java.util.List;import org.springframework.data.jpa.repository.JpaRepository;public interface DiaryListRepository extends JpaRepository&lt;Diary, Long&gt; { List&lt;Diary&gt; findByUser(String user);} 일기 목록 애플리케이션의 스프링 MVC 컨트롤러 (DiaryListController.java)src/main/java/com.example.demo/DiaryListController.java 파일을 작성한다.클래스에 @Controller 어노테이션을 추가하면, 자동 컴포넌트 검색으로 DiaryListController를 발견해 자동으로 스프링 애플리케이션 컨텍스트에 빈으로 등록한다. 요청을 처리하는 모든 메서드를 기본 URL 경로인 /로 매핑하기 위해 @RequestMapping 어노테이션을 붙였다.usersDiarys() 메서드는 “diaryList”를 논리적 뷰 이름으로 반환한다. 그러므로 이 뷰도 만들어야 한다.123456789101112131415161718192021222324252627282930313233343536373839package com.example.demo;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;@Controller@RequestMapping(\"/\")public class DiaryListController { private static final String user=\"jongmin\"; private DiaryListRepository diaryListRepository; @Autowired public DiaryListController(DiaryListRepository diaryListRepository) { this.diaryListRepository = diaryListRepository; } @RequestMapping(method= RequestMethod.GET) public String usersDiarys(Model model) { List&lt;Diary&gt; diaryList = diaryListRepository.findByUser(user); if (diaryList != null) { model.addAttribute(\"diarys\", diaryList); } return \"diaryList\"; } @RequestMapping(method = RequestMethod.POST) public String addToReadingList(Diary diary) { diary.setUser(user); diaryListRepository.save(diary); return \"redirect:/\"; }} 일기 목록을 보여주는 Thymeleaf 탬플릿 (diaryList.html)src/main/resources/template/diaryList.html 파일을 작성한다.유저의 일기 목록 부분과 일기를 일기 목록에 추가할 때 사용하는 입력 폼을 작성한다.12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.springframework.org/schema/data/jaxb\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\" /&gt; &lt;title&gt;일기 리스트&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;일기 목록&lt;/h2&gt;&lt;div th:unless=\"${#lists.isEmpty(diarys)}\"&gt; &lt;dl th:each=\"diary : ${diarys}\"&gt; &lt;dt&gt; &lt;span th:if=\"${diary.title}\" th:text=\"${diary.title}\"&gt;Title&lt;/span&gt; &lt;/dt&gt; &lt;dd&gt; &lt;span th:if=\"${diary.content}\" th:text=\"${diary.content}\"&gt;Content&lt;/span&gt; &lt;/dd&gt; &lt;/dl&gt;&lt;/div&gt;&lt;hr /&gt;&lt;h3&gt;일기 작성&lt;/h3&gt;&lt;form method=\"POST\" th:action=\"@{/}\"&gt; &lt;label for=\"title\"&gt;Title:&lt;/label&gt; &lt;input type=\"text\" name=\"title\" size=\"50\" /&gt;&lt;br /&gt; &lt;label for=\"content\"&gt;Content:&lt;/label&gt; &lt;input type=\"text\" name=\"content\" size=\"100\" /&gt;&lt;br /&gt; &lt;input type=\"submit\" value=\"추가\" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 실행 결과 SpringBoot 특징 살펴보기SpringBoot를 이용해 간단한 애플리케이션을 만들어 보았다. 이 애플리케이션을 바탕으로 SpringBoot의 특징을 알아보자. 스타터 의존성처음 프로젝트를 생성하며 Spring Initializr에서 필요한 Dependencies들(Web, Thymeleaf, JPA, H2)을 쉽게 추가했었다. 만약 이런 스타터 의존성이 없었다면, 애플리케이션을 개발하기도 전에 build.gradle 또는 pom.xml에서 필요한 Dependencies를 직접 추가해야했을 것이다. (또햔, 여러 의존성들 사이에 잘 호환이 되는지도 확인해야 한다.) 프로젝트의 build.gradle 코드를 잠시 살펴보자.1234567dependencies { compile('org.springframework.boot:spring-boot-starter-data-jpa') compile('org.springframework.boot:spring-boot-starter-thymeleaf') compile('org.springframework.boot:spring-boot-starter-web') runtime('com.h2database:h2') testCompile('org.springframework.boot:spring-boot-starter-test')} Spring Initializr에서 체크했던 의존성들이 gradle에 추가되어 있는것을 볼 수 있다. 또한 각 라이브러리의 버전이 명시되어 있지 않은데, 이는 SpringBoot 버전에 따라 스타터 의존성 버전이 결정되기 때문이다. 즉, 사용자는 스타터 의존성만 지정하면 어떤 라이브러리와 어떤 버전을 사용해야 하는지 걱정없이 구성에서 자유로워질 수 있는 것이다. 자동 구성SpringBoot Auto-configuration은 스프링 구성을 적용해야 할지 말지를 결정하는 요인들을 판단하는 런타임 과정이다. 애플리케이션이 시작될 때마다 스프링 부트는 보안, 통합, 데이터 저장, 웹 개발 영역 등을 커버하기 위해 자도성에서 대략 200가지 정도 결정을 내린다. 이 자동 구성 덕분에 필요한 상황이 아니면 명시적으로 구성을 작성하지 않아도 된다. 참고 스프링 부트 코딩 공작소 http://blog.saltfactory.net/creating-springboot-project-in-intellij/","link":"/2018/02/04/Spring/springboot-start/"},{"title":"토비의 스프링 5장 (서비스 추상화)","text":"서비스 추상화트랜잭션 서비스 추상화트랜잭션이란 더 이상 나눌 수 없는 단위 작업을 말한다. 작업을 쪼개서 작은 단위로 만들 수 없다는 것은 트랜잭션의 핵심 속성인 원자성을 의미한다. 트랜잭션 경계설정DB는 그 자체로 완벽한 트랜잭션을 지원한다. SQL을 이용해 다중 로우의 수정이나 삭제를 위한 요청을 했을 때 일부 로우만 삭제되고 안 된다거나, 일부 필드는 수정했는데 나머지 필드는 수정이 안 되고 실패로 끝나는 경우는 없다. 하나의 SQL 명령을 처리하는 경우는 DB가 트랜잭션을 보장해준다고 믿을 수 있다. 하지만 여러 개의 SQL이 사용되는 작업을 하나의 트랜잭션으로 취급해야 하는 경우도 있다. 이때 여러 가지 작업이 하나의 트랜잭션이 되려면, 두 번째 이후의 SQL이 성공적으로 DB에서 수행되기 전에 문제가 발생할 경우 앞에서 처리한 SQL 작업도 취소시켜야 한다. 이런 취소 작업을 트랜잭션 롤백(transaction roolback)이라고 한다. 반대로 여러 개의 SQL을 하나의 트랜잭션으로 처리하는 경우에 모든 SQL 수행 작업이 다 성공적으로 마무리됐다고 DB에 알려줘서 작업을 확정시켜야 한다. 이것을 트랜잭션 커밋(transaction commit)이라고 한다. JDBC 트랜잭션의 트랜잭션 경계설정모든 트랜잭션은 시작하는 지점과 끝나는 지점이 있다. 시작하는 방법은 한 가지이지만 끝나는 방법은 두 가지다. 모든 작업을 무효화하는 롤백과 모든 작업을 다 확장하는 커밋이다. JDBC의 트랜잭션은 하나의 Connection을 가져와 사용하다가 닫는 사이에 일어난다. 트랜잭션의 시작과 종료는 Coonection 오브젝트를 통해 이루어지기 때문이다. JDBC의 기본 설정은 DB 작업을 수행한 직후에 자동으로 커밋이 되도록 되어 있다. 트랜잭션이 한 번 시작되면 commit() 또는 rollback() 메소드가 호출될 때까지의 작업이 하나의 트랜잭션으로 묶인다. commit() 또는 rollback()이 호출되면 그에 따라 작업 결과가 DB에 반영되거나 취소되고 트랜잭션이 종료된다. setAutoCommit(false)로 트랜잭션의 시작을 선언하고 commit() 또는 rollback()으로 트랜잭션을 종료하는 작업을 트랜잭션의 경계설정(transaction demarcation)이라고 한다. 트랜잭션의 경계는 하나의 Connection이 만들어지고 닫히는 범위 안에 존재한다는 점도 기억하자. 이렇게 하나의 DB 커넥션 안에서 만들어지는 트랜잭션을 로컬 트랜잭션(local transaction)이라고도 한다. 비즈니스 로직 내의 트랜잭션 경계설정UserService와 UserDao를 그대로 둔 채로 트랜잭션을 적용하려면 결국 트랜잭션의 경계설정 작업을 UserService 쪽으로 가져와야 한다. UserDao가 가진 SQL이나 JDBC API를 이용한 데이터 엑세스 코드는 최대한 그대로 남겨둔 채로, UserService에는 트랜잭션 시작과 종료를 담당하는 최소한의 코드만 가져오게 만들면 어느 정도 책임이 다른 코드를 분리해 둔 채로 트랜잭션 문제를 해결할 수 있다. UserService 트랜잭션 경계설정의 문제점위의 방법을 사용하면 다음과 같은 문제점이 발생한다. 첫째는 DB 커넥션을 비롯한 리소스의 깔끔한 처리를 가능하게 했던 JdbcTemplate을 더 이상 활용할 수 없다는 점이다. Try/catch/finally 블록은 이제 UserService 내에 존재하고, UserService의 코드는 JDBC 작업 코드의 전형적인 문제점을 그대로 가질 수 밖에 없다. 두 번째 문제점은 DAO의 메소드와 비즈니스 로직을 담고 있는 UserService의 메소드에 Connection 파라미터가 추가돼야 한다는 점이다. 세 번째 문제는 Connection 파라미터가 UserDao 인터페이스 메소드에 추가되면 UserDao는 더 이상 데이터 액세스 기술에 독립적일 수가 없다는 점이다. 트랜잭션 동기화스프링은 위의 문제를 해결할 수 있는 멋진 방법을 제공해준다. Connection 파라미터 제거Connection 오브젝트를 한번 생성 후 계속 메소드의 파라미터로 전달하다가 DAO를 호출할 때 사용하는 건 피하고 싶다. 이를 위해 스프링이 제안하는 방법은 트랜잭션 동기화(transaction synchronization) 방식이다. 트랜잭션 동기화란 UserService에서 트랜잭션을 시작하기 위해 만든 Connection 오브젝트를 특별한 저장소에 보관해두고, 이후에 호출되는 DAO의 메소드에서는 저장된 Coonection을 가져다가 사용하게 하는 것이다. 트랜잭션 동기화 저장소는 작업 스레드마다 독립적으로 Connection 오브젝트를 저장하고 관리하기 때문에 다중 사용자를 처리하는 서버의 멀티스레드 환경에서도 충돌이 날 염려는 없다. 이렇게 트랜잭션 동기화 기법을 사용하면 파라미터를 통해 일일이 Connection 오브젝트를 전달할 필요가 없어진다. 트래잭션의 경계설정이 필요한 Service에서만 Connection을 다루게 하고, 여기에 생성된 Connection과 트랜잭션을 DAO의 JdbcTemplate이 사용할 수 있도록 별도의 저장소에 동기화하는 방법을 적용하기만 하면 된다. 더 이상 로직을 담은 메소드에 Connection 타입의 파라미터가 전달될 필요도 없고, UserDao의 인터페이스에도 일일이 JDBC 인터페이스인 Connection을 사용한다고 노출할 필요가 없다. 트랜잭션 동기화 적용스프링은 JdbcTemplate과 더불어 이런 트랜잭션 동기화 기능을 지원하는 간단한 유틸리티 메소드를 제공하고 있다. 123456789101112131415161718192021222324252627282930313233private DeataSource dataSource;// Connection을 생성할 때 사용할 DataSource를 DI 받도록 한다.public void setDataSource(DataSource dataSource) { this.dataSource = dataSource;}public void upgradeLevels() throws Exception { // 트랜잭션 동기화 관리자를 이용해 동기화 작업을 초기화 한다. TransactionSynchronizationManager.initSynchronization(); // DB 커넥션을 생성하고 트랜잭션을 시작한다. 이후의 DAO 작업은 모두 여기서 시작한 트랜잭션 안에서 진행한다. // DB 커넥션 생성과 동기화를 함께 해주는 유틸리티 메소드 Connection c = DataSourceUtils.getConnection(dataSource); c.setAuthCommit(false); try { List&lt;User&gt; users = UserDao.getAll(); for (User user : users) { if (canUpdatedLevel(user)) { upgradeLevel(user); } } c.commit(); } catch (Exception e) { c.rollback(); throw e; } finally { DataSourceUtils.releaseConnection(c, dataSource); // 동기화 작업 종료 및 정리 TransactionSynchronizationManager.unbindResource(this.dataSource); TransactionSynchronizationManager.clearSynchronization(); }} 스프링이 제공하는 트랜잭션 동기화 관리 클래스는 TransactionSynchronizationManager다. 이 클래스를 이용해 먼저 트랜잭션 동기화 작업을 초기화하도록 요청한다. 그리고 DataSourceUtils에서 제공하는 getConnection() 메소드를 통해 DB 커넥션을 생성한다. DataSource에서 Connection을 직접 가져오지 않고, 스프링이 제공하는 유틸리티 메소드를 쓰는 이유는 이 DataSourceUtils의 getConnection() 메소드는 Connection 오브젝트를 생성해줄 뿐만 아니라 트랜잭션 동기화에 사용하도록 저장소에 바인딩해주기 때문이다. 트랜잭션 동기화가 되어 있는 채로 JdbcTemplate을 사용하면 JdbcTemplate의 작업에서 동기화시킨 DB 커넥션을 사용하게 된다. JdbcTemplate과 트랜잭션 동기화JdbcTemplate은 영리하게 동작하도록 설계되어 있다. 만약 미리 생성돼서 트랜잭션 동기화 저장소에 등록된 DB 커넥션이나 트랜잭션이 없는 경우에는 JdbcTemplate이 직접 DB 커넥션을 만들고 트랜잭션을 시작해서 JDBC 작업을 진행한다. 반면에 upgradeLevels() 메소드에서처럼 트랜잭션 동기화를 시작해놓았다면 그때부터 실행되는 JdbcTemplate의 메소드에서는 직접 DB 커넥션을 만드는 대신 트랜잭션 동기화 저장소에 들어 있는 DB 커넥션을 가져와서 사용한다. 이를 통해 이미 시작된 트랜잭션에 참여하는 것이다. 트랜잭션 서비스 추상화기술과 환경에 종속되는 트랜잭션 경계설정 코드한 개 이상의 DB로의 작업을 하나의 트랜잭션으로 만드는 건 JDBC의 Connection을 이용한 트랜잭션 방식인 로컬 트랜재션으로는 불가능하다. 왜냐하면 로컬 트랜잭션은 하나의 DB Connection에 종속되기 때문이다. 따라서 각 DB와 독립적으로 만들어지는 Connection을 통해서가 아니라, 별도의 트랜잭션 고나리자를 통해 트랜잭션을 관리하는 글로벌 트랜잭션(global transaction)방식을 사용해야 한다. 글로벌 트랜잭션을 적용해야 트랜잭션 매니저를 통해 여러 개의 DB가 참여하는 작업을 하나의 트랜잭션으로 만들 수 있다. 자바는 JDBC 외에 이런 글로벌 트랜잭션을 지원하는 트랜잭션 메니저를 지원하기 위한 API은 JTA(Java Transaction API)를 제공하고 있다. 트랜잭션 매니저는 DB와 메시징 서버를 제어하고 관리하는 각각의 리소스 매니저와 XA 프로토콜을 통해 연결된다. 이를 통해 트랜잭션 매니저가 실제 DB와 메시징 서버의 트랜잭션을 종합적으로 제어할 수 있게 되는 것이다. 이렇게 JTA를 이용해 트랜잭션 매니저를 활용하면 여러 개의 DB나 메시징 서버에 대한 작업을 하나의 트랜잭션으로 통합하는 분산 트랜잭션 또는 글로벌 트랜잭션이 가능해진다. 트랜잭션 API의 의존관계 문제와 해결책UserDao가 DAO 패턴을 사용해 구현 데이터 액세스 기술을 유연하게 바꿔서 사용할 수 있게 했지만 UserService에서 트랜잭션의 경계 설정을 해야 할 필요가 생기면서 다시 특정 데이터 액세스 기술에 종속되는 구조가 되고 말았다. UserService의 코드가 특정 트랜잭션 방법에 의존적이지 않고 독립적일 수 있게 만들려면 어떻게 해야 할까? UserService의 메소드 안에서 트랜잭션 경계설정 코드를 제거할 수는 없다. 하지만 특정 기술에 의존적인 Connection, UserTransaction, Session/Transaction API 등에 종속되지 않게 할 수 있는 방법은 있다. 추상화란 하위 시스템의 공통점을 뽑아내서 분리시키는 것을 말한다. 그렇게 하면 하위 시스템이 어떤 것인지 알지 못해도, 또는 하위 시스템이 바뀌더라도 일관된 방법으로 접할 수가 있다. 스프링의 트랜잭션 서비스 추상화스프링은 트랜잭션 기술의 공통점을 담은 트랜잭션 추상화 기술을 제공하고 있다. 1234567891011121314151617public void upgradeLevels() { PlatformTransactionManager transactionManager = new DataSourceTransactionManager(dataSource); TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition()); try { List&lt;User&gt; users = userDao.getAll(); for (User user : users) { if (canUpgradeLevel(user)) { upgradeLevel(user); } } transactionManager.commit(status); } catch (RuntimeException e) { transactionManager.rollback(status); throw e; }} 스프링이 제공하는 트랜잭션 경계설정을 위한 추상 인터페이스는 PlatformTransactionManager다. JDBC의 로컬 트랜잭션을 이용한다면 PlatformTransactionManager를 구현한 DataSourceTransactionManager를 사용하면 된다. 사용할 DB의 DataSource를 생성자 파라미터로 넣으면서 DataSourceTransactionManager의 오브젝트를 만든다. JDBC를 이용하는 경우에는 먼저 Connection을 생성하고 나서 트랜잭션을 시작했다. 하지만 PlatformTransactionManager에서는 트랜잭션을 가져오는 요청인 getTransation() 메소드를 호출하기만 하면 된다. 필요에 따라 트랜잭션 매니저가 DB 커넥션을 가져오는 작업도 같이 수행해주기 때문이다. 여기서 트랜잭션을 가져온다는 것은 일단 트랜잭션을 시작한다는 의미라고 생각하자. 파라미터로 넘기는 DefaultTransactionDefinition 오브젝트는 트랜잭션에 대한 속성을 담고 있다. 이렇게 시작된 트랜잭션은 TransactionStatus 타입의 변수에 저장된다. TransactionStatus는 트랜잭션에 대한 조작이 필요할 때 PlatformTransactionManager 메소드의 파라미터로 전달해주면 된다. 트랜잭션이 시작됐으니 이제 JdbcTemplate을 사용하는 DAO를 이용하는 작업을 진행한다. 스프링의 트랜잭션 추상화 기술은 앞에서 적용해봤던 트랜잭션 동기화를 사용한다. PlatformTransactionManager로 시작한 트랜잭션 동기화 저장소에 저장된다. PlatformTransactionManager를 구현한 DataSourceTransactionManager 오브젝트는 JdbcTemplate에서 사용될 수 있는 방식으로 트랜잭션을 관리해준다. 따라서 PlatformTransactionManager를 통해 시작한 트랜잭션은 UserDao의 JdbcTemplate 안에서 사용된다. 트랜잭션 기술 설정의 분리JTATransactionManager는 주요 자바 서버에서 제공하는 JTA 정보를 JNDI를 통해 자동으로 인식하는 기능을 갖고 있다. 따라서 별다른 설정 없이 JTATransactionManager를 사용하기만 해도 서버의 트랜잭션 매니저/서비스와 연동해서 동작한다. 어떤 트랜잭션 매니저 구현 클래스를 사용할지 UserService 코드가 알고 있는 것은 DI 원칙에 위배된다. 자신이 사용할 구체적인 클래스를 스스로 결정하고 생성하지 말고 컨테이너를 통해 외부에서 제공받게 하는 스프링 DI의 방식으로 바꾸자. 서비스 추상화와 단일 책임 원칙수직, 수평 계층구조와 의존관계기술과 서비스에 대한 추상화 기법을 이용하면 특정 기술환경에 종속되지 않는 포터블한 코드를 만들 수 있다. 애플리케이션 로직의 종류에 따른 수평적인 구분이든, 로직과 기술이라는 수직적인 구분이든 모두 결합도가 낮으며, 서로 영향을 주지 않고 자유롭게 확장될 수 있는 구조를 만들 수 있는 데는 스프링의 DI가 중요한 역할을 하고 있다. DI의 가치는 이렇게 관심, 책임, 성격이 다른 코드를 깔끔하게 분리하는 데 있다. 단일 책임 원칙이런 적절한 분리가 가져오는 특징은 객체지향 설계의 원칙 중의 하나인 단일 책임 원칙(Single Responsibility Principle)으로 설명할 수 있다. 단일 책임 원칙은 하나의 모듈은 한 가지 책임을 가져야 한다는 의미다. 하나의 모듈이 바뀌는 이유는 한 가지여야 한다고 설명할 수도 있다. 단일 책임 원칙의 장점단일 책임 원칙을 잘 지키고 있다면, 어떤 변경이 필요할 때 수정대상이 명확해진다. 기술이 바뀌면 기술 계층과의 연동을 담당하는 기술 추상화 계층의 설정만 바꿔주면 된다. 데이터를 가져오는 테이블의 이름이 바뀌었다면 데이터 액세스 로직을 담고 있는 UserDao를 변경하면 된다. 비즈니스 로직도 마찬가지다. 적절하게 책임과 관심이 다른 코드를 분리하고, 서로 영향을 주지 않도록 다양한 추상화 기법을 도입하고, 애플리케이션 로직과 기술/환경을 분리하는 등의 작업은 갈수록 복잡해지는 엔터프라이즈 애플리케이션에는 반드시 필요하다. 이를 위한 핵심적인 도구가 바로 스프링이 제공하는 DI다. 이렇게 스프링의 의존관계 주입 기술인 DI는 모든 스프링 기술의 기반이 되는 핵심엔진이자 원리이며, 스프링이 지지하고 지원하는, 좋은 설계와 코드를 만드는 모든 과정에서 사용되는 가장 중요한 도구다. 스프링을 DI 프레임워크라고 부르는 이유는 외부 설정정보를 통한 런타임 오브젝트 DI라는 단순한 기능을 제공하기 때문이 아니다. 오히려 스프링이 DI에 담긴 원칙과 이를 응용하는 프로그래밍 모델을 자바 엔터프라이즈 기술의 많은 문제를 해결하는 데 적극적으로 활용하고 있기 때문이다. 메일 서비스 추상화테스트와 서비스 추상화일반적으로 서비스 추상화라고 하면 트랜잭션과 같은 기능은 유사하거나 사용 방법이 다른 로우레벨의 다양한 기술에 대해 추상 인터페이스와 일관성 있는 잡근 방법을 제공해주는 것을 말한다. 이를 적용하면 어떤 경우에도 UserService와 같은 애플리케이션 계층의 코드는 아래 계층에서는 어떤 일이 일어나는지 상관없이 메일 발송을 요청한다는 기본 기능에 충실하게 작성하면 된다. 서비스 추상화란 이렇게 원활한 테스트만을 위해서도 충분한 가치가 있다. 기술이나 환경이 바뀔 가능성이 있음에도, JavaMail처럼 확장이 불가능하게 설계해놓은 API를 사용해야 하는 경우라면 추상화 계층의 도입을 적극 고려해볼 필요가 있다. 테스트 대역의 종류와 특징테스트 환경을 만들어주기 위해, 테스트 대상이 되는 오브젝트의 기능에만 충실하게 수행하면서 빠르게, 자주 테스트를 실행할 수 있도록 사용하는 이런 오브젝트를 통틀어서 테스트 대역(test double)이라고 부른다. 대표적인 테스트 대역은 테스트 스텁(test stub)이다. 테스트 스텁은 테스트 대상 오브젝트의 의존객체로서 존재하면서 테스트 동안에 코드가 정상적으로 수행할 수 있도록 돕는 것을 말한다. 많은 경우 테스트 스텁이 결과를 돌려줘야 할 때도 있다. MailSender처럼 호출만 하면 그만인 것도 있지만, 리턴 값이 있는 메소드를 이용하는 경우에는 결과가 필요하다. 이럴 땐 스텁에 미리 테스트 중에 필요한 정보를 리턴해주도록 만들 수 있다. 테스트는 보통 어떤 시스템에 입력을 주었을 때 기대하는 출력이 나오는지를 검증한다. 목 오브젝트는 스텁처럼 테스트 오브젝트가 정상적으로 실행되도록 도와주면서, 테스트 오브젝트와 자신의 사이에서 일어나는 커뮤니케이션 내용을 저장해뒀다가 테스트 결과를 검증하는 데 활용할 수 있게 해준다. 테스트는 테스트의 대상이 되는 오브젝트에 직접 입력 값을 제공하고, 테스트 오브젝트가 돌려주는 출력 값, 즉 리턴 값을 가지고 결과를 확인한다. 테스트 대상이 받게 될 이볅 값을 제어하면서 그 결과가 어떻게 달라지는지 확인하기도 한다. 문제는 테스트 대상 오브젝트는 테스트로부터만 입력을 받는 것이 아니라는 점이다. 테스트가 수행되는 동안 실행되는 코드는 테스트 대상이 의존하고 있는 다른 의존 오브젝트와도 커뮤니케이션하기도 한다. 때론 테스트 대상 오브젝트가 의존 오브젝트에게 출력한 값에 관심이 있을 겨웅가 있다. 또는 의존 오브젝트를 얼마나 사용했는가 하는 커뮤니케이션 행위 자체에 관심이 있을 수가 있다. 문제는 이 정보는 테스트에서는 직접 알 수가 없다는 것이다. 이때는 테스트 대상과 의존 오브젝트 사이에 주고받는 정보를 보존해두는 기능을 가진 테스트용 의존 오브젝트인 목 오브젝트를 만들어서 사용해야 한다. 테스트 대상 오브젝트의 메소드 호출이 끝나고 나면 테스트는 목 오브젝트에게 테스트 대상과 목 오브젝트 사이에서 일어났던 일에 대해 확인을 요청해서, 그것을 테스트 검증 자료로 삼을 수 있다. 목 오브젝트를 이용한 테스트라는 게, 작성하기는 간단하면서도 기능은 상당히 막강하다는 사실을 알 수 있을 것이다. 보통의 테스트 방법으로는 검증하기가 매우 까다로운 테스트 대상 오브젝트의 내부에서 일어나는 일이나 다른 오브젝트 사이에서 부고받은 정보까지 검증하는 일이 손쉽기 때문이다. 정리 비즈니스 로직을 담은 코드는 데이터 엑세스 로직을 담은 코드와 깔끔하게 분리되는 것이 바람직하다. 비즈니스 로직 코드 또한 내부적으로 책임과 역할에 따라서 깔끔하게 메소드로 정리돼야 한다. 이를 위해서는 DAO의 기술 변화에 서비스 계층의 코드가 영향을 받지 않도록 인터페이스와 DI를 잘 활용해서 결합도를 낮춰줘야 한다. DAO를 사용하는 비즈니스 로직에는 단위 작업을 보장해주는 트랜잭션이 필요하다. 트랜잭션의 시작과 종료를 지정하는 일을 트랜잭션 경계설정이라고 한다. 트랜잭션 경계설정은 주로 비즈니스 로직 안에서 일어나는 경우가 많다. 시작된 트랜잭션 정보를 담은 오브젝트를 파라미터로 DAO에 전달하는 방법은 매우 비효율적이기 때문에 스프링이 제공하는 트랜잭션 동기화 기법을 활용하는 것이 편리하다. 자바에서 사용되는 트랜잭션 API의 종류와 방법은 다양하다. 환경과 서버에 따라서 트랜잭션 방법이 변경되면 경계설정 코드도 함께 변경돼야 한다. 트랜잭션 방법에 따라 비즈니스 로직을 담은 코드가 함께 변경되면 단일 책임 원칙에 위배되며, DAO가 사용하는 특정 기술에 대해 강한 결합을 만들어낸다. 트랜잭션 경계설정 코드가 비즈니스 로직 코드에 영향을 주지 않게 하려면 스프링이 제공하는 트랜잭션 서비스 추상화를 이용하면 된다. 서비스 추상화는 로우레벨의 트랜잭션 기술과 API의 변화에 상관없이 일괄된 API를 가진 추상화 계층을 도입한다. 서비스 추상화는 테스트하기 어려운 JavaMail 같은 기술에도 적용할 수 있다. 테스트를 편리하게 작성하도록 도와주는 것만으로도 서비스 추상화는 가치가 있다. 테스트 대상이 사용하는 의존 오브젝트를 대체할 수 있도록 만든 오브젝트를 테스트 대역이라고 한다. 테스트 대역은 테스트 대상 오브젝트가 원활하게 동작할 수 있도록 도우면서 테스트를 위해 간접적인 정보를 제공해주기도 한다. 테스트 대역 중에서 테스트 대상으로부터 전달받은 정보를 검증할 수 있도록 설계된 것을 목 오브젝트라고 한다. 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/04/08/Spring/toby-5/"},{"title":"토비의 스프링 3장 (템플릿)","text":"템플릿 개방 폐쇄 원칙 (OCP) 어떤 부분은 변경을 통해 그 기능이 다양해지고 확장하려는 성질이 있고, 어떤 부분은 고정되어 있고 변하지 않으려는 성질이 있다. 변화의 특성이 다른 부분을 구분해주고, 각각 다른 목적과 다른 이유에 의해 다른 시점에 독립적으로 변경될 수 있는 효율적인 구조를 만들어주는 것이 개방 폐쇄 원칙이다. 템플릿이란 성질이 다른 코드 중에서 변경이 거의 일어나지 않으며 일정한 패턴으로 유지되는 특성을 가진 부분을 자유롭게 변경되는 성질을 가진 부분으로부터 독립시켜서 효과적으로 활용할 수 있도록 하는 방법이다. 일반적으로 서버에서는 제한된 개수의 DB 커넥션을 만들어서 재사용 가능한 풀로 관리한다. DB 풀은 매번 getConnection()으로 가져간 커넥션을 명시적으로 close()해서 돌려줘야지만 다시 풀에 넣었다가 다음 커넥션 요청이 있을 때 재사용할 수 있다. 그런데 이런 식으로 오류가 날 때마다 미처 반횐되지 못한 Connection이 계속 쌓이면 어느 순간에 커넥션 풀에 여유가 없어지고 리소스가 모자란다는 심각한 오류를 내며 서버가 중단될 수 있다. 그래서 JDBC 코드에서는 어떤 상황에서도 가져온 리소스를 반환하도록 try/catch/finally 구문 사용을 권장하고 있다. (finally는 try 블록을 수행한 후에 예외가 발생하든 정상적으로 처리되든 상관없이 반드시 실행되는 코드를 넣을 때 사용한다.) 어느 시점에서 예외가 발생했는지에 따라서 close()를 사용할 수 있는 변수가 달라질 수 있기 때문에 finally에서는 반드시 c(Connection)와 ps(PreparedStatment)가 null이 아닌지 먼저 확인한 후에 close() 메소드를 호출해야 한다. 변하는 것과 변하지 않는 것이런 코드를 효과적으로 다룰 수 있는 방법은 없을까? 이 문제의 핵심은 변하지 않는, 그러나 많은 곳에서 중복되는 코드와 로직에 따라 자꾸 확장되고 자주 변하는 코드를 잘 분리해내는 작업이다. 분리와 재사용을 위한 디자인 패턴 적용메소드 추출1234567891011121314151617public void deleteAll() throws SQLException { ... try { c = dataSource.getConnection(); ps = makeStatement(c); // 변하는 부분을 메소드로 추출하고 변하지 않는 부분에서 호출하도록 만들었다. ps.executeUpdate(); } catch(SQLException e) ...}private PreparedStatement makeStatement(Connection c) throws SQLException { PreparedStatement ps; ps = c.prepareStatement(\"delete from users\"); return ps;} 자주 바뀌는 부분을 메소드로 독립시켰는데 별 이득이 없어 보인다. 왜냐하면 보통 메소드 추출 리펙토링을 적용하는 경우에는 분리시킨 메소드를 다른 곳에서 재사용할 수 있어야 하는데, 이건 반대로 분리시키고 남은 메소드가 재사용이 필요한 부분이고, 분리된 메소드는 DAO 로직마다 새롭게 만들어서 확장돼야 하는 부분이기 때문이다. 뭔가 반대로 됐다. 템플릿 메소드 패턴의 적용템플릿 메소드 패턴은 상속을 통해 기능을 확장해서 사용하는 부분이다. 변하지 않는 부분은 슈퍼클래스에 두고 변하는 부분은 추상 메소드로 정의해둬서 서브클래스에서 오버라이드하여 새롭게 정의해 쓰도록 하는 것이다. 1abstract protected PreparedStatement makeStatement(Connection c) throws SQLException; 1234567public class UserDaoDeleteAll extends UserDao { protected PreparedStatement makeStatement(Connection C) throws SQLException { PreparedStatment ps = c.prepareStatement(\"delete from users\"); return ps; }} 이제 UserDao 클래스의 기능을 확장하고 싶을 때마다 상속을 통해 자유롭게 확장할 수 있고, 확장 때문에 기존의 상위 DAO 클래스에 불필요한 변화는 생기지 않도록 할 수 있으니 객체지향 설계의 핵심 원리인 개방 폐쇄 원칙(OCP)을 그럭저럭 지키는 구조를 만들어낼 수는 있는것 같다. 그렇지만 아직 문제가 있다. 가장 큰 문제는 DAO 로직마다 상속을 통해 새로운 클래스를 만들어야 한다는 점이다. 이래서는 장점보다 단점이 더 많아 보인다. 변하지 않는 코드를 가진 UserDao의 JDBC try/catch/finally 블록과 변하는 PreparedStatement를 담고 있는 서브클래스들이 이미 클래스 레벨에서 컴파일 시점에 이미 그 관계가 결정되어 있다. 따라서 그 관계에 대한 유연성이 떨어진다. 전략 패턴의 적용개방 폐쇠 원칙(OCP)을 잘 지키는 구조이면서도 템플릿 메소드 패턴보다 유연하고 확장성이 뛰어난 것이, 오브젝트를 아예 둘로 분리하고 클래스 레벨에서는 인터페이스를 통해서만 의존하도록 만드는 전략 패턴이다. 전략 패턴은 OCP 관점에서 보면 확장에 해당하는 변하는 부분을 별도의 클래스로 만들어 추상화된 인터페이스를 통해 위임하는 방식이다. deleteAll()은 JDBC를 이용해 DB를 업데이트하는 작업이라는 변하지 않는 맥락(context)을 갖는다. deleteAll()의 컨텍스트를 정리해보면 다음과 같다. DB 커넥션 가져오기 PreparedStatement를 만들어줄 외부 기능 호출하기 전달받은 PreparedStatement 실행하기 예외가 발생하면 이를 다시 메소드 밖으로 던지기 모든 경우에 만들어진 PreparedStatement와 Connection을 적절히 닫아주기 두번째 작업에서 사용하는 PreparedStatement를 만들어주는 외부 기능이 바로 전략 패턴에서 말하는 전략이라고 볼 수 있다. 전략 패턴의 구조를 따라 이 기능을 인터페이스로 만들어두고 인터페이스 이 메소드를 통해 PreparedStatement 생성 전략을 호출해주면 된다. 여기서 눈여겨볼 것은 이 PreparedStatement를 생성하는 전략을 호출할 때는 이 컨텍스트 내에서 만들어둔 DB 커넥션을 전달해야 한다는 점이다. PreparedStatement를 만드는 전략의 인터페이스는 컨텍스트가 만들어준 Connection을 전달받아서, PreparedStatement를 만들고 만들어진 PreparedStatement 오브젝트를 돌려준다. 이 내용을 인터페이스로 정의하면 다음과 같다. 123public interface StatementStrategy { PreparedStatement makePreparedStatement(Connection c) throws SQLException;} StatementStrategy 인터페이스를 상속해서 실제 전략 클래스를 만들고 이 전략 클래스를 이용한 전략 패턴을 적용한 코드는 다음과 같다. 12345678910111213public void deleteAll() throws SQLException { ... try { c = dataSource.getConnection(); StatementStrategy strategy = new DeleteAllStatement(); ps = strategy.makePreparedStatement(c); ps.executeUpdate(); } catch (SQLException e) { ... }} 전략 패턴은 필요에 따라 컨텍스트는 그대로 유지되면서(OCP의 폐쇄 원칙) 전략을 바꿔 쓸 수 있다(OCP의 개방 원칙)는 것인데, 이렇게 컨텍스트 안에서 이미 구체적인 전략 클래스인 DeleteAllStatement를 사용하도록 고정되어 있다면 뭔가 이상하다. 컨텍스트가 StatementStrategy 인터페이스 뿐 아니라 특정 구현 클래스인 DeleteAllStatement를 직접 알고 있다는건, 전략 패턴에도 OCP에도 잘 들어맞는다고 볼 수 없기 때문이다. DI 적용을 위한 클라이언트/컨텍스트 분리전략 패턴에 따르면 Context가 어떤 전략을 사용하게 할 것인가는 Context를 사용하는 앞단의 Client가 결정하는게 일반적이다. Client가 구체적인 전략의 하나를 선택하고 오브젝트로 만들어서 Context에 전달하는 것이다. 결국 이 구조에서 전략 오브젝트 생성과 컨텍스트로의 전달을 담당하는 책임을 분리시킨 것이 바로 ObjectFactory이며, 이를 일반화한 것이 앞에서 살펴봤던 의존관계 주입(DI)이었다. 결국 DI란 이러한 전략 패턴의 장점을 일반적으로 활용할 수 있도록 만든 구조라고 볼 수 있다. 아무튼 여기서 이 패턴 구조를 코드에 적용해보자. 중요한 것은 컨텍스트에 해당하는 JDBC try/catch/finally 코드를 클라이언트 코드인 StatementStrategy를 만드는 부분에서 독립시켜야 한다는 것이다. 1234567891011121314151617public void jdbcContextWithStatementStrategy(StatementStrategy stmt) throws SQLException { connection c = null; PreparedStatement ps = null; try { c = dataSource.getConnection(); ps = stmt.makePreparedStatement(c); ps.executeUpdate(); } catch (SQLException e) { throw e; } finally { if (ps != null) { try { ps.close(); } catch (SQLException e) {} } if (c != null) { try { c.close(); } catch (SQLException e) {} } }} 이 메소드는 컨텍스트의 핵심적인 내용을 잘 담고 있다. 클라이언트로부터 StatementStrategy 타입의 전략 오브젝트를 제공받고 JDBC try/catch/finally 구조로 만들어진 컨텍스트 내에서 작업을 수행한다. 다음은 클라이언트에 해당하는 부분이다. 컨텍스트를 별도의 메소드로 분리했으니 deleteAll() 메소드가 클라이언트가 된다. deleteAll()은 전략 오브젝트를 만들고 컨텍스트를 호출하는 책임을 지고 있다. 1234public void deleteAll() throws SQLException { StatementStrategy st = new DeleteAllStatement(); // 선정한 전략 클래스의 오브젝트 생성 jdbcContextWithStatementStrategy(st); // 컨텍스트 호출. 전략 오브젝트 전달} 클라이언트가 컨텍스트가 사용할 전략을 정해서 전달하는 면에서 DI 구조라고 이해할 수도 있다. 마이크로 DI 의존관계 주입(DI)은 다양한 형태로 적용할 수 있다. DI의 가장 중요한 개념은 제3자의 도움을 통해 두 오브젝트 사이의 유연한 관계가 설정되도록 만든다는 것이다. 이 개념만 따른다면 DI를 이루는 오브젝트와 구성요소의 구조나 관계는 다양하게 만들 수 있다. 일반적으로 DI는 의존관계에 있는 두 개의 오브젝트와 이 관계를 다이내믹하게 설정해주는 오브젝트 팩토리(DI 컨테이너), 그리고 이를 사용하는 클라이언트라는 4개의 오브직트 사이에서 일어난다. 하지만 때로는 원시적인 전략패턴 구조를 따라 클라이언트가 오브젝트 팩토리의 책임을 함께 지고 있을 수도 있다. 이런 경우에는 DI가 매우 작은 단위의 코드와 메소드 사이에서 일어나기도 한다. 이렇게 DI의 장점을 단순화해서 IoC 컨테이너의 도움 없이 코드 내에서 적용한 경우를 마이크로 DI라고도 한다. 또는 코드에 의한 의미로 수동 DI라고 부를 수도 있다. JDBC 전략 패턴의 최적화전략과 클라이언트의 동거현재 구조에 두 가지 불만이 있다. DAO 메소드마다 새로운 StatementStrategy 구현 클래스를 만들어야 한다는 것. DAO 메소드에서 StatementStrategy에 전달할 User와 같은 부가적인 정보가 있는 경우, 이를 위해 오브젝트를 전달받는 생성자와 이를 저장해둘 인스턴스 변수를 번거롭게 만들어야 한다는 것. 이 두가지 문제를 해결할 수 있는 방법을 생각해보자. 로컬 클래스클래스 파일이 많아지는 문제는 간단한 해결 방법이 있다. StatementStrategy 전략 클래스를 매번 독립된 파일로 만들지 말고 UserDao 클래스 안에 내부 클래스로 정의해버리는 것이다. DeleteAllStatement나 AddStatement는 UserDao 밖에서는 사용되지 않는다. 둘 다 UserDao에서만 사용되고, UserDao의 메소드 로직에 강하게 결합되어 있다. 중첩 클래스의 종류 다른 클래스 내부에 정의되는 클래스를 중첩 클래스(nested class)라고 한다. 중첩 클래스는 독립적으로 오브젝트로 만들어질 수 있는 스태틱 클래스(static class)와 자신이 정의된 클래스의 오브젝트 안에서만 만들어질 수 있는 내부 클래스(inner class)로 구분된다. 내부 클래스는 다시 범위(scope)에 따라 세가지로 구분된다. 멤버 내부 클래스 : 멤버 필드처럼 오브젝트 레벨에 정의된다. 로컬 클래스 : 메소드 레벨에 정의된다. 익명 내부 클래스 : 이름을 갖지 않는 익명 클래스이다. 익명 내부 클래스의 범위는 선언된 위치에 따라서 다르다. 로컬 클래스의 장점은 클래스가 내부 클래스이기 때문에 자신이 선언된 곳의 정보에 접근할 수 있다는 것이다. 내부 메소드는 자신이 정의된 메소드의 로컬 변수에 직접 접근할 수 있기 때문이다. 다만, 내부 클래스에서 외부의 변수를 사용할 때는 외부 변수는 반드시 final로 선언해줘야 한다. 로컬 클래스로 만들어두니, 메소드마다 추가해야 했던 클래스 파일을 하나 줄일 수 있고 내부 클래스의 특징을 이용해 로컬 변수를 바로 가져다 사용할 수 있다는 장점도 생겼다. 익명 내부 클래스 익명 내부 클래스 익명 내부 클래스(anonymous inner class)는 이름을 갖지 않는 클래스다. 클래스 선언과 오브젝트 생성이 결합된 상태로 만들어지며, 상속할 클래스나 구현할 인터페이스를 생성자 대신 사용해서 다음과 같은 형태로 만들어 사용한다. 클래스를 재사용할 필요가 없고, 구현한 인터페이스 타입으로만 사용할 경우에 유용하다. new 인터페이스이름() { 클래스 본문 }; 익명 내부 클래스는 선언과 동시에 오브젝트를 생성한다. 이름이 없기 때문에 클래스 자신의 타입을 가질 수 없고, 구현한 인터페이스 타입의 변수에만 저장할 수 있다. 12345678910StatementStrategy st = new StatementStrategy() { public PreparedStatement makePreparedStatement(Connection c) throws SQLException { PreparedStatement ps = c.prepareStatement(\"insert into users(id, name, password) values(?,?,?)\"); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); return ps; }} 만들어진 익명 내부 클래스의 오브젝트는 딱 한 번만 사용할 테니 굳이 변수에 담아두지 말고 jdbcContextWithStatementStrategy() 메소드의 파라미터에서 바로 생성하는 편이 낫다. 1234567891011121314public void add(final User user) throws SQLException { jdbcContextWithStatementStrategy( new StatementStrategy() { public PreparedStatement makePreparedStatement(Connection c) throws SQLException { PreparedStatement ps = c.prepareStatement(\"insert into users(id, name, password) values(?,?,?)\"); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); return ps; } } );} 컨텍스트와 DI전략 패턴의 구조로 보자면 UserDao의 메소드가 클라이언트이고, 익명 내부 클래스로 만들어지는 것이 개별적인 전략이고, jdbcContextWithStatementStrategy() 메소드는 컨텍스트다. 그런데 JDBC의 일반적인 작업 흐름을 담고 있는 jdbcContextWithStatementStrategy()는 다른 DAO에서도 사용 가능하다. 그러니 jdbcContextWithStatementStrategy()를 UserDao 클래스 밖으로 독립시켜서 모든 DAO가 사용할 수 있게 해야한다. 클래스 분리분리해서 만들 클래스의 이름을 JdbcContext라고 하자. JdbcContext에 UserDao에 있던 컨텍스트 메소드를 workWithStatementStrategy()라는 이름으로 옮겨놓는다. 그런데, 이렇게 하면 DataSource가 필요한 것은 UserDao가 아니라 JdbcContext가 돼버린다. DB 커넥션을 필요로 하는 코드는 JdbcContext 안에 있기 때문이다. 따라서 JdbcContext가 DataSource에 의존하고 있으므로 DataSource 타입 빈을 DI 받을 수 있게 해줘야 한다. 빈 의존관계 변경UserDao는 이제 JdbcContext에 의존한다. 그런데 JdbcContext는 인터페이스인 DataSource와는 달리 구체 클래스다. 스프링의 DI는 기본적으로 인터페이스를 사이에 두고 의존 클래스를 바꿔서 사용하도록 하는게 목적이다. 하지만 이 경우 JdbcContext는 그 자체로 독립적인 JDBC 컨텍스트를 제공해주는 서비스 오브젝트로서 의미가 있을 뿐이고 구현 방법이 바뀔 가능성은 없다. 따라서 인터페이스를 구현하지 않고, UserDao와 JdbcContext는 인터페이스를 사이에 두지 않고 DI를 적용하는 특별한 구조가 된다. 스프링 빈으로 DI인터페이스를 사용해서 클래스를 자유롭게 변경할 수 있게 하지는 않았지만, JdbcContext를 UserDao와 DI 구조로 만들어야 할 이유는 다음과 같다. JdbcContext가 스프링 컨테이너의 싱글톤 레지스트리에서 관리되는 싱글톤 빈이 되기 때문이다. JdbcContext가 DI를 통해 다른 빈에 의존하고 있기 때문이다. JdbcContext는 dataSource 프로퍼티를 통해 JdbcContext 오브젝트를 주입받도록 되어 있다. DI를 위해서는 주입되는 오브젝트와 주입받는 오브젝트 양쪽 모두 스프링 빈으로 등록돼야 한다. 스프링이 생성하고 관리하는 IoC 대상이어야 DI에 참여할 수 있기 때문이다. 템플릿과 콜백전략 패턴은 복잡하지만 바뀌지 않는 일정한 패턴을 갖는 작업 흐름이 존재하고 그중 일부분만 자주 바꿔서 사용해야 하는 경우에 적합한 구조다. 전략 패턴의 기본 구조에 익명 내부 클래스를 활용한 방식이다. 이런 방식을 스프링에서는 템플릿/콜백 패턴이라고 부른다. 전략 패턴의 컨텍스트를 템플릿이라 부르고, 익명 내부 클래스로 만들어지는 오브젝트를 콜백이라고 부른다. 템플릿 템플릿은 어떤 목적을 위해 미리 만들어둔 모양이 있는 틀을 가리킨다. 템플릿 메소드 패턴은 고정된 틀의 로직을 가진 템플릿 메소드를 슈퍼클래스에 두고, 바뀌는 부분을 서브클래스의 메소드에 두는 구조로 이뤄진다. 콜백 콜백은 실행되는 것을 목적으로 다른 오브젝트의 메소드에 전달되는 오브젝트를 말한다. 자바에서는 메소드 자체를 파라미터로 전달할 방법이 없기 때문에 메소드가 담긴 오브젝트를 전달해야 한다. 그래서 펑서녈 오브젝트(functional object)라고도 한다. 템플릿/콜백의 동작원리템플릿은 고정된 작업 흐름을 가진 코드를 재사용한다는 의미에서 붙인 이름이다. 콜백은 템플릿 안에서 호출되는 것을 목적으로 만들어진 오브젝트를 말한다. 템플릿/콜백의 특징여러 개의 메소드를 가진 일반적인 인터페이스를 사용할 수 있는 전략 패턴의 전략과 달리 템플릿/콜백 패턴의 콜백은 보통 단일 메소드 인터페이스를 사용한다. 템플릿의 작업 흐름 중 특정 기능을 위해 한 번 호출되는 경우가 일반적이기 때문이다. 콜백은 일반적으로 하나의 메소드를 가진 인터페이스를 구현한 익명 내부 클래스로 만들어진다고 보면된다. 템플릿/콜백 패턴의 일반적인 작업 흐름은 다음과 같다. 클라이언트의 역할은 템플릿 안에서 실행될 로직을 담은 콜백 오브젝트를 만들고, 콜백이 참조할 정보를 제공하는 것이다. 만들어진 콜백은 클라이언트가 템플릿의 메소드를 호출할 때 파라미터로 전달된다. 템플릿은 정해진 작업 흐름을 따라 작업을 진행하다가 내부에서 생성한 참조정보를 가지고 콜백 오브젝트의 메소드를 호출한다. 콜백은 클라이언트 메소드에 있는 정보와 템플릿이 제공한 참조정보를 이용해서 작업을 수행하고 그 결과를 다시 템플릿에 돌려준다. 템플릿은 콜백이 돌려준 정보를 사용해서 작업을 마저 수행한다. 경우에 따라 최종 결과를 클라이언트에 다시 돌려주기도 한다. 템플릿/콜백 방식은 전략 패턴과 DI의 장점을 익명 내부 클래스 사용 전략과 결합한 독특한 활용법이라고 이해할 수 있다. 단순히 전략 패턴으로만 보기엔 독특한 특징이 많으므로 템플릿/콜백을 하나의 고유한 패턴으로 기억해두면 좋다. 편리한 콜백의 재활용템플릿/콜백 방식에서 한 가지 아쉬운 점이 있다. DAO 메소드에서 매번 익명 내부 클래스를 사용하기 때문에 상대적으로 코드를 작성하고 읽기가 조금 불편하다는 점이다. 12345678910111213public void deleteAll() throws SQLException { executeSql(\"delete from users\"); // 변하는 SQL 문장}------------------------------------------------------------private void executeSql(final String query) throws SQLException { this.jdbcContext.workWithStatementStrategy( new StatementStrategy() { public PreparedStatement makePreparedStatement(Connection c) throws SQLException { return c.prepareStatement(query); } } )} 바뀌지 않는 모든 부분을 빼내서 executeSql() 메소드로 만들었다. 바뀌는 부분인 SQL 문장만 파라미터로 받아서 사용하게 만들었다. SQL을 담은 파라미터를 final로 선언해서 익명 내부 클래스인 콜백 안에서 직접 사용할 수 있게 하는 것만 주의하면 된다. 이렇게 재사용 가능한 콜백을 담고 있는 메소드라면 DAO가 공유할 수 있는 템플릿 클래스 안으로 옮겨도 된다. 그 결과 결국 JdbcContext 안에 클라이언트와 템플릿, 콜백이 모두 함께 공존하면서 동작하는 구조가 됐다. 템플릿/콜백의 응용고정된 작업 흐름을 갖고 있으면서 여기저기서 자주 반복되는 코드가 있다면, 중복되는 코드를 분리할 방법을 생각해보는 습관을 기르자. 중복된 코드는 먼저 메소드로 분리하는 간단한 시도를 해본다. 그중 일부 작업을 필요에 따라 바꾸어 사용해야 한다면 인터페이스를 사이에 두고 분리해서 전략패턴을 적용하고 DI로 의존관계를 관리하도록 만든다. 그런데 바뀌는 부분이 한 애플리케이션 안에서 동시에 여러 종류가 만들어질 수 있다면 이번엔 템플릿/콜백 패턴을 적용하는 것을 고려해볼 수 있다. 가장 전형적인 템플릿/콜백 패턴의 후보는 try/catch/finally 블록을 사용하는 코드다. 템플릿/콜백을 적용할 때는 템플릿과 콜백의 경계를 정하고 템플릿이 콜백에게, 콜백이 템플릿에게 각각 전달하는 내용이 무엇인지 파악하는게 가장 중요하다. 그에 따라 콜백의 인터페이스를 정의해야 하기 때문이다. 클래스 이름이 Template으로 끝나거나 인터페이스 이름이 Callback으로 끝난다면 템플릿/콜백이 적용된 것이라고 보면 된다. 정리 JDBC와 같은 예외가 발생할 가능성이 있으며 공유 리소스의 반환이 필요한 코드는 반드시 try/catch/finally 블록으로 관리해야 한다. 일정한 작업 흐름이 반복되면서 그중 일부 기능만 바뀌는 코드가 존재한다면 전략 패턴을 적용한다. 바뀌지 않는 부분을 컨텍스트로, 바뀌는 부분은 전략으로 만들고 인터페이스를 통해 유연하게 전략을 변경할 수 있도록 구성한다. 클라이언트 메소드 안에 익명 내부 클래스를 사용해서 전략 오브젝트를 구현하면 코드도 간결해지고 메소드의 정보를 직접 사용할 수 있어서 편리하다. 컨텍스트가 하나 이상의 클라이언트 오브젝트에서 사용된다면 클래스를 분리해서 공유하도록 만든다. 단일 전략 메소드를 갖는 전략 패턴이면서 익명 내부 클래스를 사용해서 매번 전략을 새로 만들어 사용하고, 컨텍스트 호출과 동시에 전략 DI를 수행하는 방식을 템플릿/콜백 패턴이라고 한다. 콜백의 코드에도 일정한 패천이 반복된다면 콜백을 템플릿에 넣고 재활용하는 것이 편리하다. 템플릿과 콜백의 타입이 다양하게 바뀔 수 있다면 제네릭스를 이용한다. 템플릿은 한 번에 하나 이상의 콜백을 사용할 수도 있고, 하나의 콜백을 여러 번 호출할 수도 있다. 템플릿/콜백을 설계할 때는 템플릿과 콜백 사이에 주고받는 정보에 관심을 둬야한다. 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/04/01/Spring/toby-3/"},{"title":"토비의 스프링 4장 (예외)","text":"예외JdbcTemplate을 대표로 하는 스프링의 데이터 액세스 기능에 담겨 있는 예외처리와 관련된 접근 방법에 대해 알아보자. 사라진 SQLExceptionJdbcTemplate을 적용한 코드에서는 SQLException이 사라졌다. 이 SQLException은 어디로 간 것일까? 초난감 예외처리예외가 발생하면 그것을 catch 블록을 써서 잡아내는 것까지는 좋은데 그리고 아무것도 하지 않고 별문제 없는 것처럼 넘어가 버리는 건 정말 위험한 일이다. 원치 않는 예외가 발생하는 것보다도 훨씬 더 나쁜 일이다. 왜냐하면 프로그램 실행 중에 어디선가 오류가 있어서 예외가 발생했는데 그것을 무시하고 계속 진행해버리기 때문이다. 결국 발생한 예외로 인해 어떤 기능이 비정상적으로 동작하거나, 메모리나 리소스가 소진되거나, 예상치 못한 다른 문제를 일으킬 것이다. 예외를 처리할 때 반드시 지켜야할 핵심 원칙은 한 가지다. 모든 예외는 적절하게 복구되든지 아니면 작업을 중단시키고 운영자 또는 개발자에게 분명하게 통보돼야 한다. SQLException이 발생하는 이유는 SQL에 문법 에러가 있거나 DB에서 처리할 수 없을 정도로 데이터 액세스 로직에 심각한 버그가 있거나, 서버가 죽거나 네트워크가 끊기는 등의 심각한 상황이 벌어졌기 때문이다. 예외를 처리하는 2가지 나쁜 습관은 어떤 경우에도 용납하지 않아야 한다. 예외 블랙홀 무의미하고 무책임한 throws 예외의 종류와 특징예외를 어떻게 다뤄야 할까? 가장 큰 이슈는 체크 예외(checked exception)라고 불리는 명시적인 처리가 필요한 예외를 사용하고 다루는 방법이다. 자바에서 throw를 통해 발생시킬 수 있는 예외는 크게 세 가지가 있다. Error첫째는 java.lang.Error 클래스의 서브클래스들이다. 에러는 시스템에 뭔가 비정상적인 상황이 발생했을 경우에 사용된다. 그래서 주로 자바 VM에서 발생시키는 것이고 애플리케이션 코드에서 잡으려고 하면 안된다. 시스템 레벨에서 특별한 작업을 하는 게 아니라면 애플리케이션에서는 이런 에러에 대한 처리는 신경 쓰지 않아도 된다. Exception과 체크 예외java.lang.Exception 클래스와 그 서브클래스로 정의되는 예외들은 에러와 달리 개발자들이 만든 애플리케이션 코드의 작업 중에 예외상황이 발생했을 경우에 사용된다. Exception 클래스는 다시 체크 예외(checked exception)와 언체크 예외(Unchecked exception)로 구분된다. 전자는 Exception 크래스의 서브클래스이면서 RuntimeException 클래스를 상속하지 않은 것들이고, 후자는 RuntimeException을 상속한 클래스들을 말한다. RuntimeException은 Exception의 서브클래스이므로 Exception의 일종이긴 하지만 자바는 이 RuntimeException과 그 서브클래스는 특별하게 다룬다. 일반적으로 예외라고 하면 Exception 클래스의 서브클래스 중에서 RuntimeException을 상속하지 않은 것만을 말하는 체크 예외라고 생각해도 된다. 체크 예외가 발생할 수 있는 메소드를 사용할 경우 반드시 예외를 처리하는 코드를 함께 작성해야 한다. 사용할 메소드가 체크 예외를 던진다면 이를 catch 문으로 잡든지, 아니면 다시 throws를 정의해서 메소드 밖으로 던져야 한다. 그렇지 않으면 컴파일 에러가 발생한다. RuntimeException과 언체크/런타임 예외java.lang.RuntimeException 클래스를 상속한 예외들은 명시적인 예외처리를 강제하지 않기 때문에 언체크 예외라고 불린다. 또는 대표 클래스 이름을 따서 런타임 예외라고도 한다. 에러와 마찬가지로 이 런타임 예외는 catch 문으로 잡거나 throws로 선언하지 않아도 된다. 물론 명시적으로 잡거나 throw로 선언해줘도 상관없다. 대표적으로 오브젝트를 할당하지 않은 레퍼런스 변수를 사용하려고 시도했을 때 발생하는 NullPointerException이나, 허용되지 않는 값을 사용해서 메소드를 호출할 때 발생하는 IllegalArgumentException 등이 있다. 이런 예외는 코드에서 미리 조건을 체크하도록 주의 깊게 만든다면 피할 수 있다. 피할 수 있지만 개발자가 부주의해서 발생할 수 있는 경우에 발생하도록 만든 것이 런타임 예외다. 따라서 런타임 예외는 예상하지 못했던 예외상황에서 발생하는 게 아니기 때문에 굳이 catch나 throws를 사용하지 않아도 되도록 만든 것이다. 예외처리 방법예외 복구첫 번째 예외처리 방법은 예외상황을 파악하고 문제를 해결해서 정상 상태로 돌려놓는 것이다. 예외처리 코드를 강제하는 체크 예외들은 예외를 어떤 식으로든 복구할 가능성이 있는 경우에 사용한다. 예외처리 회피두 번째 방법은 예외처리를 자신이 담당하지 않고 자신을 호출한 쪽으로 던져버리는 것이다. throws 문으로 선언해서 예외가 발생하면 알아서 던져지게 하거나 catch 문으로 일단 예외를 잡은 후에 로그를 남기고 다시 예외를 던지는 것이다. 예외를 자신이 처리하지 않고 회피하는 방법이다. JdbcTemplate이 사용하는 콜백 오브젝트는 메소드 선언을 보면 알겠지만 ResultSet이나 PreparedStatement 등을 이용해서 작업하다 발생하는 SQLException을 자신이 처리하지 않고 템플릿으로 던져버린다. 콜백 오브젝트의 메소드는 모두 throws SQLException이 붙어있다. SQLException을 처리하는 일은 콜백 오브젝트의 일이 아니라고 보기 때문이다. 콜백 오브젝트의 메소드는 SQLException에 대한 예외를 회피하고 템플릿 레벨에서 처리하도록 던져준다. 예외를 회피하는 것은 예외를 복구하는 것처럼 의도가 분명해야 한다. 예외 전환마지막으로 예외를 처리하는 방법은 예외 전환을 하는 것이다. 예외 회피와 비슷하게 예외를 복구해서 정상적인 상태로는 만들 수 없기 때문에 예외를 메소드 밖으로 던지는 것이다. 하지만 예외 회피와 달리, 발생한 예외를 그대로 넘기는 게 아니라 적절한 예외로 전환해서 던진다는 특징이 있다. 예외 전환은 보통 두 가지 목적으로 사용된다. 첫째는 내부에서 발생한 예외를 그대로 던지는 것이 그 예외상황에 대한 적절한 의미를 부여해주지 못하는 경우에, 의미를 분명하게 해줄 수 있는 예외로 바꿔주기 위해서다. API가 발생하는 기술적인 로우레벨을 상황에 적합한 의미를 가진 예외로 변경하는 것이다. 보통 전환하는 예외에 원래 발생한 예외를 담아서 중첩 예외(nested exception)로 만드는 것이 좋다. 중첩 예외는 getCause() 메소드를 이용해서 처음 발생한 예외가 무엇인지 확인할 수 있다. 두번째 전환 방법은 예외를 처리하기 쉽고 단순하게 만들기 위해 포장하는 것이다. 중첩 예외를 이용해 새로운 예외를 만들고 원인이 되는 예외를 내부에 담아서 던지는 방식은 같다. 하지만 의미를 명확하게 하려고 다른 예외로 전환하는 것이 아니다. 주로 예외처리를 강제하는 체크 예외를 언체크 예외인 런타임 예외로 바꾸는 경우에 사용한다. 일반적으로 체크 예외를 계속 throws를 사용해 넘기는 건 무의미하다. 메소드 선언은 지저분해지고 아무런 장점이 없다. DAO에서 발생한 SQLException이 웹 컨트롤러 메소드까지 명시적으로 전달된다고 해서 무슨 소용이 있을까? 어차피 복구가 불가능한 예외라면 가능한 한 빨리 런타임 예외로 포장해 던지게 해서 다른 계층의 메소드를 작성할 때 불필요한 throws 선언이 들어가지 않도록 해줘야 한다. 대부분 서버 환경에서는 애플리케이션 코드에서 처리하지 않고 전달된 예외들을 일괄적으로 다룰 수 있는 기능을 제공한다. 예외처리 전략런타임 예외의 보편화일반적으로는 체크 예외가 일반적인 예외를 다루고, 언체크 예외는 시스템 장애나 프로그램사으이 오류에 사용된다고 했다. 문제는 체크 예외는 복구할 가능성이 조금이라도 있는, 말 그대로 예외적인 상황이기 때문에 자바는 이를 처리하는 catch 블록이나 throws 선언을 강제하고 있다는 점이다. 독립형 애플리케이션과 달리 서버의 특정 계층에서 예외가 밸생했을 때 작업을 일시 중지하고 사용자와 바로 커뮤니케이션하면서 예외상황을 복구할 수 있는 방법이 없다. 자바의 환경이 서버로 이동하면서 체크 예외의 활용도와 가치는 점점 떨어지고 있다. 자칫하면 throws Exception으로 점철된 아무런 의미도 없는 메소드들을 낳을 뿐이다. 그래서 대응이 불가능한 체크 예외라면 빨리 런타임 예외로 전환해서 던지는게 낫다. 자바 초기부터 있었던 JDK의 API와 달리 최근에 등장하는 표준 스펙 또는 오픈소스 프레임워크에서는 API가 발생시키는 예외를 체크 예외 대신 언체크 예외로 정의하는 것이 일반화되고 있다. 언체크 예외라도 필요하다면 얼마든지 catch 블록으로 잡아서 복구하거나 처리할 수 있다. 하지만 대개는 복구 불가능한 상황이고 보나마나 RuntimeException 등으로 포장해서 던져야 할 테니 아예 API 차원에서 런타임 예외를 던지도록 한 것이다. 애플리케이션 예외런타임 예외 중심의 전략은 굳이 이름을 붙이자면 낙관적인 예외처리 기법이라고 할 수 있다. 일단 복구할 수 있는 예외는 없다고 가정하고 예외가 생겨도 어차피 런타임 예외이므로 시스템 레벨에서 알아서 처리해줄 것이고, 꼭 필요한 경우는 런타임 예외라도 잡아서 복구하거나 대응해줄 수 있으니 문제 될 것이 없다는 낙관적인 태도를 기반으로 하고 있다. 보통 시스템 또는 외부의 예외상황이 원인이 아니라 애플리케이션 자체의 로직에 의해 의도적으로 발생시키는 애플리케이션 예외를 가지는 메소드를 설계하는 방법에는 두 가지가 있다. 첫 번째 방법은 정상적인 처리를 했을 경우와 애플리케이션 자체의 로직에 의해 의도적으로 예외를 발생시키고자 하는 경우에 각각 다른 종류의 리턴 값을 돌려주는 것이다. 하지만 이렇게 리턴 값으로 결과를 확인하고, 예외상황을 체크하면 불편한 점도 있다. 우선 예외 상황에 대한 리턴 값을 명확하게 코드화하고 잘 관리하지 않으면 혼란이 생길 수 있다. 또 한 가지 문제는 결과 값을 확인하는 조건문이 자주 등장한다는 점이다. 두 번째 방법은 정상적인 흐름을 따르는 코드는 그대로 두고, 애플리케이션 자체의 로직에 의해 의도적으로 예외를 발생시키고자 하는 경우에는 비즈니스적인 의미를 띤 예외를 던지도록 만드는 것이다. 이때 사용하는 예외는 의도적으로 체크 예외로 만든다. 그래서 개발자가 잊지 않고 자주 발생 가능한 예외상황에 대한 로직을 구현하도록 강제해주는 게 좋다. SQLException은 어떻게 됐나?먼저 생각해볼 사항은 SQLException은 과연 복구가 가능한 예외인가이다. 대부분의 SQLException은 복구가 불가능하다. 더군다나 DAO 밖에서 SQLException을 다룰 수 있는 가능성은 거의 없다. 따라서 예외처리 전략을 적용해야 한다. 필요도 없는 기계적인 throws 선언이 등장하도록 방치하지 말고 가능한한 빨리 언체크/런타임 예외로 전환해줘야 한다. 스프링의 JdbcTemplate은 바로 이 예외처리 전략을 따르고 있다. JdbcTemplate 템플릿과 콜백 안에서 발생하는 모든 SQLException을 런타임 예외인 DataAccessException으로 포장해서 던져준다. 따라서 JdbcTemplate을 사용하는 UserDao 메소드에선 꼭 필요한 경우에만 런타임 예외인 DataAccessException을 잡아서 처리하면 되고 그 외의 경우에는 무시해도 된다. 그 밖에도 스프링의 API 메소드에 정의되어 있는 대부분의 예외는 런타임 예외다. 따라서 발생 가능한 예외가 있다고 하더라도 이를 처리하도록 강제하지 않는다. 예외 전환예외를 다른 것으로 바꿔서 던지는 예외 전환의 목적은 두 가지이다. 하나는 런타임 예외로 포장해서 굳이 필요하지 않은 catch/throws를 줄여주는 것이고, 다른 하나는 로우레벨의 예외를 좀 더 의미 있고 추상화된 예외로 바꿔서 던져주는 것이다. 스프링의 JdbcTemplate이 던지는 DataAccessException은 일단 런타임 예외로 SQLException을 포장해주는 역할을 한다. 그래서 대부분 복구가 불가능한 예외인 SQLException에 대해 애플리케이션 레벨에서는 신경 쓰지 않도록 해주는 것이다. 또한 DataAccessException은 SQLException에 담긴 다루기 힘든 상세한 예외정보를 의미 있고 일관성 있는 예외로 전환해서 추상화해주려는 용돌 쓰이기도 한다. JDBC의 한계JDBC는 자바 표준 JDK에서도 가장 많이 사용되는 기능 중의 하나다. 호환성 없는 SQLException의 DB 에러정보DB마다 SQL 뿐만 아니라 에러의 종류와 원인도 제각각이다. 그래서 JDBC는 데이터 처리 중에 발생하는 다양한 예외를 그냥 SQLException 하나에 모두 담아버린다. SQLException은 예외가 발생했을 때의 DB 상태를 담은 SQL 상태정보를 부가적으로 제공한다. getSQLState() 메소드로 예외상황에 대한 상태정보를 가져올 수 있다. 이 상태정보는 DB별로 달라지는 에러 코드를 대신할 수 있도록, 스펙에 정의된 SQL 상태 코드를 따르도록 되어있다. 그러나 결국 호환성 없는 에러 코드와 표준을 잘 따르지 않는 상태 코드를 가진 SQLException 만으로 DB에 독립적인 유연한 코드를 작성하는 건 불가능에 가깝다. DB 에러 코드 매핑을 통한 전환SQLException에 담긴 SQL 상태 코드는 신뢰할 만한게 아니므로 더 이상 고려하지 않는다. 차라리 DB 업체별로 만들어 유지해오고 있는 DB 전용 에러 코드가 더 정확한 정보라고 불 수 있다. 스프링은 DataAccessException이라는 SQLException을 대체할 수 있는 런타임 예외를 정의하고 있을 뿐 아니라 DataAccessException의 서브클래스로 세분화된 예외 클래스들을 정의하고 있다. 디에터 엑세스 작업 중에 발생 할 수 있는 예외 상황을 수십 가지 예외로 분류하고 이를 추상화해 정의한 다양한 예외 클래스를 제공한다. JdbcTemplate은 SQLException을 단지 런타임 예외인 DataAccessException으로 포장하는 것이 아니라 DB의 에러 코드를 DataAccessException 계층구조의 클래스 중 하나로 매핑해준다. 전환되는 JdbcTemplate에서 던지는 예외는 모두 DataAccessException의 서브클래스 타입이다. DB별로 미리 준비된 매핑정보를 참고해서 적절한 예외 클래스를 선택하기 때문이 DB가 달라져도 같은 종류의 에러라면 동일한 예외를 받을 수 있다. 데이터 엑세스 기술에 독립적인 추상화된 예외를 제공하는 것이다. JdbcTemplate을 이용한다면 JDBC에서 발생하는 DB 관련 예외는 거의 신경 쓰지 않아도 된다. JDK 1.6에 포함된 JDBC 4.0부터는 기존에 JDBC의 단일 예외 클래스였던 SQLException을 스프링의 DataAccessException과 비슷한 방식으로 좀 더 세분화해서 정의하고 있다. DAO 인터페이스와 DataAccessException 계층구조DataAccessException은 JDBC의 SQLException을 전환하는 용도로만 만들어진 건 아니다. JDBC 외의 자바 데이터 엑세스 기술에서 발생하는 예외에도 적용된다. DataAccessException은 의미가 같은 예외라면 데이터 액세스 기술의 종류와 상관없이 일관된 예외가 발생하도록 만들어준다. 데이터 액세스 기술에 독립적인 추상화된 예외를 제공하는 것이다. DAO 인터페이스와 구현의 분리DAO를 굳이 따로 만들어서 사용하는 이유는 무엇일까? 가장 중요한 이유는 데이터 액세스 로직을 담은 코드를 성격이 다른 코드에서 분리해놓기 위해서다. 대부분의 데이터 액세스 예외는 애플리케이션에서는 복구 불가능하거나 할 필요가 없는 것이다. 그렇다고 모든 예외를 다 무시해야 하는 건 아니다. 중복 키 에러처럼 비즈니스 로직에서 의미 있게 처리할 수 잇는 예외도 있다. 애플리케이션에서는 사용하지 않더라도 시스템 레벨에서 데이터 액세스 예외를 의미 있게 분류할 필요도 있다. 문제는 데이터 액세스 기술이 달라지면 같은 상황에서도 다른 종류의 예외가 던져진다는 점이다. 따라서 DAO를 사용하는 클라이언트 입장에서는 DAO의 사용 기술에 따라서 예외 처리 방법이 달라져야 한다. 결국 클라이언트가 DAO의 기술에 의존적이 될 수 밖에 없다. 데이터 액세스 예외 추상화스프링은 자바의 다양한 데이터 액세스 기술을 사용할 때 발생하는 예외들을 추상화해서 DataAccessException 계층구조 안에 정리해놓았다. 스프링의 DataAccessException은 자바의 주요 데이터 액세스 기술에서 발생할 수 있는 대부분의 예외를 추상화하고 있으며 이런 기술에서만 공통적으로 나타나는 예외를 포함해서 데이터 엑세스 기술에서 발상 가능한 대부분의 예외를 계층구조로 분류해놓았다. JdbcTemplate과 같이 스프링의 데이터 액세스 지원 기술을 이용해 DAO를 만들면 사용 기술에 독립적인 일관성 있는 예외를 던질 수 있다. 결국 인터페이스 사용, 런타임 예외 전환과 함께 DataAccessException 예외 추상화를 적용하면 데이터 액세스 기술과 구현 방법에 독립적인 이상적인 DAO를 만들 수가 있다. DataAccessException 활용시 주의사항스프링을 활용하면 DB 종류나 데이터 액세스 기술에 상관없이 키 값이 중복이 되는 상황에서는 동일한 예외가 발생하리라고 기대할 것이다. 하지만 안타깝게도 DuplicateKeyException은 아직까지는 JDBC를 이용하는 경우에만 발생한다. 데이터 액세스 기술을 하이버네이트나 JPA를 사용했을 때도 동일한 예외가 발생할 것으로 기대하지만 실제로 다른 예외가 던져진다. 그 이유는 SQLException에 담긴 DB의 에러 코드를 바로 해석하는 JDBC의 경우와 달리 JPA나 하이버네이트, JDO 등에서는 각 기술이 재정의한 예외를 가져와 스프링이 최종적으로 DataAccessException으로 변환하는데, DB의 에러 코드와 달리 이런 예외들은 세분화되어 있지 않기 때문이다. DataAccessException이 기술에 상관없이 어느 정도 추상화된 공통 예외로 변환해주긴 하지만 근본적인 한계 때문에 완벽하다고 기대할 수는 없다. 따라서 사용에 주의를 기울여야 한다. 스프링은 SQLException을 DataAccessException으로 전환하는 다양한 방법을 제공한다. 가장 보편적이고 효과적인 방법은 DB 에러 코드를 이용하는 것이다. SQLException을 코드에서 직접 전환하고 싶다면 SQLExceptionTranslator 인터페이스를 구현한 클래스 중에서 SQLErrorCodeSQLExceptionTranslator를 사용하면 된다. 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/04/04/Spring/toby-4/"},{"title":"Android In-App Purchase Validation","text":"Index 어떤 문제가 발생했는가? Subscriptions and In-App Purchases API API 사용을 위한 서비스 계정 연결 API 사용하기 (With node-iap) 마치며 얼마전 아랍어 번역을 마치고 몇개 국가에 앱을 출시하게 되면서 결제 관련 문제가 발생하기 시작했습니다. 앱과 서버의 결제 관련 코드를 모두 제가 맡아 작성했기 때문에 계속해서 발생하는 문제로 인해 정신적 충격이 상당했습니다… “Android In-App Billing 보안 완벽 정리”의 글을 참고해 결국에는 앱내 구매(In-App Billing)시 프리덤(Freedom)과 같은 결제 해킹 앱에 의해 문제가 발생하게 된다는것을 알게 되었습니다. 이에 서버에서 In-App Purchase Validation(앱내 구매 유효성 검사)을 하는 코드를 추가했고 위의 문제를 해결할 수 있었습니다. 이번 포스팅에서는 In-App Purchase Validation에 대해서 알아보겠습니다. (In-App 결제 구현에 대한 내용은 다루지 않습니다!) 1. 어떤 문제가 발생했는가?어느날 이상한일이 벌어졌다. 분명 Admin을 통해 앱에서 결제한 내용을 확인했을때는 상당한 내역이 있었는데, Google Play Console의 주문 관리를 통해 확인했을 때는 결제 내역이 없는 것이다. 결제 관련된 부분에서 버그가 발생했기에 무척이나 마음이 심란했다. 반복되는 테스트에서도 재현할 수 없는 현상에 라이브 채팅을 통해 Google에 문의하였지만 돌아오는 답변은 사용자의 결제 관련 설정(예를들면 카드)이 잘못되어 있을 것이라는 말뿐, 정확한 해결 방법을 알려주지 않았다. 그러던 도중 결제 관련 DB를 살펴보다가 이상한 부분을 발견했다. 한명의 사람이 말도 안되는 짧은 시간에 한 품목을 여러변 결제한 것이다. 그리고 이 결제 관련 내용은 Google Play Console의 주문 관리에서도 확인이 불가능했다. (기록이 남지 않았다.) 결국 글의 도입부에서 말씀드렸던 것처럼 결제 해킹 문제임을 알게되었고 In-App Purchase Validation에 대해 알아보게 되었습니다. 2. Subscriptions and In-App Purchases APIGoogle에서는 Subscriptions and In-App Purchases API를 제공하고 있습니다. (전에는 이 API를 “Purchase Status API” 라고 불렀습니다.) Document를 참고하면 해당 API를 인앱 상품과 구독으로 구성된 앱의 카탈로그를 관리할 수 있으며, 개별 구매에 대한 정보, 구매와 구독의 만료 확인 등, 여러 가지 용도로 사용할 수 있음을 알 수 있습니다. 따라서 실제 결제가 이루어졌고, Google Play Console의 주문 관리에 그 내역이 있는지 확인이 가능한 것입니다. 해당 API는 Google Play Developer API로서 허용되는 사용 할당량이 매일 200,000개의 요청으로 제한됩니다. 이 정도면 충분한 구독, 결제 유효성 검사 요구를 충족시킬 수 있으며, 만약 더 많은 요청이 필요하다면 Google Developer Console에서 요청할 수 있다고 합니다. 3. API 사용을 위한 서비스 계정 연결API를 사용하기 위해서는 Google Developer Console에서 서비스 계정을 생성한 후 API 엑세스 권한을 부여해주어야 합니다. 몇가지 단계를 거쳐야 하는데 같이 해보겠습니다. 1.Google Play Console에 관리자 계정으로 로그인합니다. 2.설정 - API 액세스로 이동합니다. (서비스 약관은 수락합니다.) 3.새 프로젝트 만들기 후 하단의 서비스 계정 만들기를 선택합니다. 4.Google API 콘솔로 이동합니다. 5.서비스 계정 만들기를 선택한 후 다음과 같이 내용을 입력합니다. 6.서비스 계정을 생성하면 자동으로 .json 파일이 다운로드 됩니다. .json 파일에는 API 호출을 위한 인증 정보가 포함되어 있습니다. 관리 및 백업이 필요합니다. 7.Google Play Console로 돌아와, 완료 버튼을 클릭한 후 서비스 계정이 생성되었는지 확인합니다. 8.엑세스 권한 부여를 클릭합니다. 9.역할을 금융으로 선택한 후, 재무 데이터 보기 권한을 설정합니다.(구매내역 및 영수증 검증을 하기 위해서는 재무 보고서 보기 권한이 필요합니다 . 역할을 금융으로 선택해 주면 해당 권한이 자동으로 선택됩니다. 영수증 검증을 위해서는 금융 역할을 갖는 서비스 계정이 필요합니다.) 4. API 사용하기 (With node-iap)복잡하게 토큰을 관리하며 HTTP/REST API를 사용할것 없이 Google은 다양한 언어에 맞게 Client 라이브러리를 제공하고 있습니다. Access Google APIs more easily를 통해서 다양한 언어의 라이브러리를 찾아 사용할 수 있습니다. google-api-nodejs-client를 사용하면 되지만, 다른 Platform(apple)에도 대응할 수 있는 node-iap(In-app purchase verification for Apple App Store and Google Play)를 사용하겠습니다. 사용방법은 생각보다 정말 간단합니다. 1234567891011121314const iap = require('iap');let platform = 'google';let payment = { receipt: 'receipt data', // always required (purchaseToken) productId: 'abc', packageName: 'my.app', keyObject: '', // always required (user auth key) subscription: false, // optional, if google play subscription};iap.verifyPayment(platform, payment, function (error, response) { /* your code */}); node-iap는 google과 apple에서 모두 사용가능하기 때문에 platform을 명시해야 합니다. payment에는 확인하고자 하는 인앱결제 내역을 넣습니다. Android In-App 결제를 하고나면 purchaseToken과 productId를 알 수 있습니다. payment의 receipt에는 purchaseToken 값을 넣습니다. productId와 packageName을 넣고 KeyObject에는 좀전에 사용자 계정을 추가하면서 다운로드 받았던 .json 파일의 값을 넣어주면 됩니다. (require 혹은 import하여 그대로 넣어주면 됩니다.) Android 단말을 통해 테스트 결제 후 iap를 통해 purchase validation을 하면 다음과 같은 response를 얻을 수 있습니다.123456789101112{ \"receipt\": { \"kind\": \"androidpublisher#productPurchase\", \"purchaseTimeMillis\": \"1410835105408\", \"purchaseState\": 1, \"consumptionState\": 1, \"developerPayload\": \"\" }, \"transactionId\": \"ghbbkjheodjokkipdmlkjajn.AO-J1OwfrtpJd2fkzzZqv7i107yPmaUD9Vauf9g5evoqbIVzdOGYyJTSEMhSTGFkCOzGtWccxe17dtbS1c16M2OryJZPJ3z-eYhEJYiSLHxEZLnUJ8yfBmI\", \"productId\": \"abc\", \"platform\": \"google\"} 여기서 중요한 부분은 purchaseState의 값이 0이면 결제가 완료된 상태를 뜻하며 1이면 환불이 완료된 상태를 의미합니다. 만약 사용자가 제대로 된 결제를 하지 않는다면 purchaseToken 값은 유효하지 않아 purchase validation 과정에서 err가 발생할 것입니다. 5. 마치며굉장히 큰 문제라고 생각했지만 생각보다 조치하는 과정에 있어서 큰 어려움은 없었습니다. 아직 제가 더 생각하지 못한 부분이 있을수도 있을거라 생각합니다. 혹시나 더 추가해야 하는 부분이 있다면 알려주세요! 저는 추가적으로 가짜 결제를 시도하는 유저들의 로그를 DB에 남기고 자동으로 block 처리를 해 게임을 못하도록 막았습니다. purchase validation 구현 후 바로 다음날 다시 또 가짜 결제가 이루어졌는데 유효성 검사가 제대로 이루어지는 것을 보고 정말 다행이라 생각했습니다. 제가 지금까지 회사에서 일하며 발생했던 가장 크리티컬했던 부분이라고 생각하는데 혹시나 이 글을 읽으시는 분중 아직 purchase validation을 하지 않고 계시다면 지금이라도 꼭 코드를 추가하셨으면 합니다. 참고 Google Play Developer API Android In-App Billing 보안 완벽 정리 Android In-App Billing 서버사이드 보안 완벽 정리","link":"/2017/08/11/Node/check-in-app-billing-purchase-validation/"},{"title":"Java와 함께하는 Web","text":"서론Javascript를 이용한 Node.js로 서버프로그래밍을 하다가 최근 Java를 이용한 Spring Framework를 사용하게 되면서 JavaEE, Servlet, JSP, Tomcat, MVC, WAS와 같은 용어들을 마주하게 되었습니다. 이번 포스팅을 통해서 Java를 이용한 웹 개발의 히스토리와 여러 용어들을 정리해보고자 합니다. 시작은 JavaEE기존에는 기업용 서버 소프트웨어 개발이라는 것이 C나 C++을 사용해서 다양한 회사의 미들웨어(middleware) 제품들을 사용해서 개발하는 방식이었습니다. 그러나 이 경우 개발자들은 운영체제와 사용하는 미들웨어 제품에 종속될 수 밖에 없는데, 자바의 플랫폼 독립적 특성을 활용해서 미들웨어에 필요한 공통 API를 제공하면 그런 문제를 해결할 수 있을 것이라는 생각을 했습니다.그래서 서버 개발에 필요한 기능을 모아서 J2EE라는 표준을 만들었습니다. 그리고 이 J2EE는 버전 5.0 이후로 Java EE로 개칭됩니다. 자바 플랫폼, 엔터프라이즈 에디션(Java Platform, Enterprise Edition; Java EE)은 자바를 이용한 서버측 개발을 위한 플랫폼입니다. Java EE 플랫폼은 PC에서 동작하는 표준 플랫폼인 Java SE에 부가하여, 웹 애플리케이션 서버에서 동작하는 장애복구 및 분산 멀티티어를 제공하는 자바 소프트웨어의 기능을 추가한 서버를 위한 플랫폼입니다. 이러한 Java EE 스펙에 따라 제품으로 구현한 것을 웹 애플리케이션 서버 또는 WAS라 부릅니다. WAS란?인터넷 상에서 HTTP를 통해 사용자 컴퓨터나 장치에 애플리케이션을 수행해 주는 미들웨어(소프트웨어 엔진)이다. 웹 애플리케이션 서버는 동적 서버 콘텐츠를 수행하는 것으로 일반적인 웹 서버와 구별이 되며, 주로 데이터베이스 서버와 같이 수행이 된다.&lt; 사용자 요청(웹 브라우저) -&gt; 웹 서버 -&gt; WAS(동적 처리) -&gt; 웹 서버 -&gt; 사용자 응답 메세지(웹 브라우저) &gt;예로, 웹 서버에서 JSP를 요청하면 톰캣에서는 JSP 파일을 서블릿으로 변환하여 컴파일을 수행하고, 서블릿의 수행결과를 웹 서버에서 전달하게 된다. 그렇게 시작된 자바EE는 출발부터 많은 관심을 받았고, 특히 웹 개발을 위해 자바EE 표준에 포함된 서블릿(Servlet)과 JSP는 당시 막 유행하던 PHP나 ASP와 함께 CGI를 몰아내며 자바 언어가 인기를 얻는데 한 몫을 담당했습니다. CGI란? (인용 - http://www.terms.co.kr/CGI.htm)CGI는 웹서버에 있어 사용자의 요구를 응용프로그램에 전달하고 그 결과를 사용자에게 되돌려주기 위한 표준적인 방법이다. 사용자가 하이퍼링크를 클릭 하거나 웹사이트의 주소를 입력함으로써 웹 페이지를 요청하면, 서버는 요청된 페이지를 보내준다. 그러나, 사용자가 웹페이지의 양식에 내용을 기재하여 보냈을 때, 그것은 보통 응용프로그램에 의해 처리될 필요가 있다. 웹 서버는 그 양식 정보를 조그만 응용프로그램에 전달하는데, 이 프로그램은 데이터를 처리하고 필요에 따라 확인 메시지를 보내주기도 한다. 이렇게 서버와 응용 프로그램간에 데이터를 주고받기 위한 방법이나 규약들을 CGI라고 부른다. 이것은 웹의 HTTP 프로토콜의 일부이다.만약 웹사이트를 만들 때 어떠한 제어를 위해 CGI 프로그램을 사용하기 원하면, HTML 파일 내에 있는 URL 내에 그 프로그램의 이름을 기술하면 된다. 만약 폼을 만들려고 할 때, 이 URL은 FORMS 태그의 일부로서 기술될 수 있는데, 예를 들어 아래와 같이 쓸 수 있을 것이다.이 태그의 결과로서 mybiz.com에 있는 서버는 입력된 데이터를 저장하기 위해 제어권을 “formprog.pl”이라는 CGI 프로그램에 넘기고, 확인 메시지를 되돌려준다 (여기서 .pl은 Perl로 작성된 프로그램이라는 것을 가리키지만, CGI는 다른 언어로도 작성될 수 있다).1&lt;FORM METHOD=POST ACTION=http://www.mybiz.com/cgi-local/formprog.pl&gt; 자바EE의 핵심은 EJB(Enterprise Java Beans)라는 기술이었습니다. EJB는 자바EE가 대체하는 미들웨어에서 구동되던 기업의 핵심 서비스를 만들기 위한 분산처리 및 트랜잭션, 보안 등을 지원하는 컴포넌트 모델을 제공하는 기술입니다. 이러한 EJB는 주목을 받으며 널리 쓰이게 되었지만 시간이 지남에 따라 몇 가지 심각한 문제들로 비판을 받게 되었고, 이러한 문제점을 개선하기 위해 Spring Framework가 처음 개발되었습니다. 특히 고가의 풀스택 자바EE 서버가 아닌 톰캣과 같은 일반 서블릿 컨테이너에서도 구동된다는 것이 큰 강점으로 작용했습니다. 다시 말하면, 이는 Spring을 통해 비싼 자바EE 서버를 구매하지 않아도 EJB보다 훨씬 간편한 방식으로 EJB가 제공하던 선언적 트랜잭션 및 보안 처리, 분산 환경 지원 등 주요 기능을 모두 사용할 수 있게 되었음을 뜻하며, 무엇보다 이제는 더 이상 각 자바EE 서버 제품에 특화된 설정을 따로 공부하거나 서버 제품을 바꿀 때마다 포팅 작업이 필요없이 Spring만 이용하면 톰캣이든 레진(Resin)이든 기존의 풀스택 자바EE 서버이든 관계없이 간단하게 배포가 가능하다는 뜻입니다. ServletServlet은 Java 기반의 확장된 CGI로서 동일하게 동적인 웹 애플리케이션을 작성할 수 있는 기술입니다. CGI와 비슷하게 클라이언트의 요청을 받아 해당하는 프로그램을 실행시켜주지만 CGI와는 조금 다른 동작 형태를 보입니다.Servlet은 CGI와 달리 효율적입니다. CGI의 멀티 프로세스 동작이 아닌 멀티 스레드 방식의 동작으로 서블릿이 생성되면 서버가 종료되지 않는 이상 메모리로 남게 됩니다. 따라서 이후에 오는 요청에 대해서는 서블릿을 새로 생성하지 않고 동작을 이어갈 수 있기 때문에 시스템 자원(메모리)에서 큰 이점이 있습니다. 그로인해 Servlet은 CGI 보다 적은 시스템 자원으로 많은 요청을 처리할 수 있는 구조를 가지고 있습니다. 멀티 프로세스 동작 방식클라이언트의 요청을 받아 웹 애플리케이션을 직접 실행하는 구조로 각각의 요청에 대해 프로세스를 생성하고 응답한 뒤 종료하는 형태이다. 이는 각각의 많은 요청이 들어오는 경우 프로세스를 계속 생성하므로(프로세스를 생성하는 작업은 필요이상의 부담을 주게 된다) 시스템 부하가 커지게 되 안정적인 서비스가 힘들다. 멀티 스레드 동작 방식클라이언트의 요청을 받으면 웹 애플리케이션을 거치지 않고 웹 컨테이너로 요청이 전달된다. 그리고 웹 컨테이너가 요청을 처리할 스레드를 생성하는 형태이다. 멀티스레드 방식은 최초 요청 시 웹 애플리케이션을 실행한 후 종료하지 않은 상태에서 같은 요청이 여러 번 오는 경우, 실행되고 있는 웹 애플리케이션의 스레드를 생성해 요청을 처리하는 방법이다. CGI에서 사용하는 멀티프로세스 방식보다 시스템 부하를 줄여 안정적인 서비스를 제공할 수 있다. 컨테이너란? (인용 - 컨테이너란?? 무엇일까?)컨테이너는 Servlet을 실행하고 관리하는 역할을 합니다. 개발자가 해야하는 역할을 대신 함으로써, 개발자가 해야하는 일을 대폭 줄여줍니다. 컨테이너는 개발자가 웹서버와 통신하기 위하여 소켓을 생성하고, 특정 포트에 리스닝하고, 스트림을 생성하는 등의 복잡한 일들을 대신합니다. 또한 Servlet의 생성부터 소멸까지 일련의 과정을 관리하며, 요청이 들어올 때마다 새로운 자바 스레드를 하나 생성합니다.톰캣을 예로 들면 아파치와 같은 웹서버가 사용자로부터 Servlet에 대한 요청을 받으면 이것을 바로 호출하는 것이 아니라 컨테이너에게 이 요청을 넘겨주고 이 컨테이너는 request와 response 객체를 생성하고 해당하는 Servlet의 스레드를 생성하여 앞의 두 객체를 인자로 넘깁니다.스레드 생성 후 이 스레드의 service() 메소드를 호출하고 처음에 사용자로부터 요청받은 방식이 get인지 post인지에 따라 doGet()과 doPost() 메소드 중 선택 생성합니다. 만약 doPost가 생성되었다고 가정하면, 이 doPost() 메소드는 독 페이지를 생성하고, 이것을 처음 받은 response 객체에 실어서 컨테이너에게 보냅니다. 컨테이너는 이 객체를 HTTPResponse로 변환하여 클라이언트에게 보냅니다. 그런 다음 처음에 생성한 객체 Request와 Response를 소멸시킵니다. Servlet 동작 방식 사용자가 URL을 클릭하면 HTTP Request를 Servlet Container에 보낸다. Servlet Container는 HttpServletRequest, HttpServletResponse 두 객체를 생성한다. 사용자가 요청한 URL을 분석하여 어느 서블릿에 대한 요청인지 찾는다. (DD를 참조하여 분석) 컨테이너는 서블릿 service() 메소드를 호출하며, POST, GET여부에 따라 doGet() 또는 doPost()가 호출된다. doGet() or doPost() 메소드는 동적인 페이지를 생성한 후 HttpServletResponse객체에 응답을 보낸다. 응답이 완료되면 HttpServletRequest, HttpServletResponse 두 객체를 소멸시킨다. DD (배포서술자, Deployment Descriptor) = web.xml Servlet, Error Page, Listener, Fillter, 보안 설정등 Web Application의 설정 파일이다. URL과 실제 서블릿의 매핑 정보도 담고 있다. 하나의 웹 어플리케이션에 하나만 존재한다. 보통 Web Document Root 디렉토리에 WEB-INF 폴더 아래 web.xml 파일로 존재한다. 한마디로 정리하자면 톰캣과 같은 WAS 가 java 파일을 컴파일해서 Class로 만들고 메모리에 올려 Servlet 객체를 만들게 되고 이 Servlet 객체는 doPost, doGet을 통해 요청에 응답합니다. 초기화 과정을 더 자세히 보면 다음과 같습니다.init, Service, destory 이런 콜백이 각 시점에 불리는걸 볼 수 있습니다. init은 Servlet이 메모리에 로드 될때 실행됩니다. destory는 마찬가지로 언로드되기 전에 수행되는 콜백입니다. service 메소드는 HTTP Method 타입에 따라 doGet 혹은 doPost를 호출합니다.기억해야 할 점은, 초기화된 Servlet이 클라이언트의 요청이 있을 때 마다 Thread를 생성해서 병렬적으로 service를 수행한다는 것. 서블릿 객체는 여러개 생성되지 않습니다. Servlet 예시 코드다음은 Servlet의 예시 코드입니다. 자바 코드 안에 HTML을 넣기 굉장히 불편합니다.12345678910111213141516public class HelloServlet extends HttpServlet { public void doGet(HttpServletRequest req, HttpServletResponse res) throws ServletException,IOException { res.setContentType(\"text/html;charset=UTF-8\"); PrintWriter out = res.getWriter(); out.println(\"&lt;HTML&gt;\"); out.println(\"&lt;BODY&gt;\"); out.println(\"Hello World!!\"); out.println(\"&lt;/BODY&gt;\"); out.println(\"&lt;/HTML&gt;\"); out.close(); }} JSPHTML을 넣기 불편한 구조로 인해 JSP가 등장하게 됬습니다. Servlet의 확장된 기술로 브라우저에 표현하기 위한 HTML 코드에 JAVA 코드를 혼용하여 사용할 수 있게 합니다. 이로써 디자인과 로직 개발을 분업화시켜 효율적인 코드를 생산해 낼 수 있게됩니다. JSP 동작 방식JSP 라는 새로운 개발 방법이 나왔지만, 사실 이 JSP 도 내부적으로는 아래 그림 처럼 Tomcat이 Servlet으로 바꾸어서 돌립니다. 클라이언트가 브라우저를 통해 서버에 HTTP 프로토콜로 요청한다. 서버는 컨테이너에게 처리를 요청하고 컨테이너는 해당 파일을 찾는다. 찾은 파일을 서블릿으로 변환한다. 만약 이미 변환 되어있는 파일이 있다면 그 파일을 바로 실행⑤한다. 서블릿 파일을 실행가능한 class파일로 컴파일 한다. 컴파일된 class파일을 메모리에 적재하고 실행한 결과를 웹서버에 넘겨준다. 웹서버는 브라우저가 인식할수 있는 정적페이지를 구성하여 클라이언트에게 응답한다. JSP 예시 코드HTML 내부에 Java 코드가 있어 HTML 코드를 작성하기 쉽습니다. 그러나 로직과 디자인이 한 파일내에 섞여있어 유지보수가 어렵습니다. 하나가 편한대신, 다른 불편한 점들이 생긴것 입니다. 그래서 이를 해결하기 위해 MVC Model이 등장하였습니다.123456789101112131415&lt;%@page import=\"java.util.Calendar\" %&gt;&lt;%@ page contentType=\"text/html; charset=UTF-8\"%&gt;&lt;% String str=String.format(\"%tF\",Calendar.getInstance());%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt; &lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; 오늘은 &lt;%=str%&gt;&lt;br/&gt;&lt;/body&gt;&lt;/html&gt; MVC Model 1Model1 방식은 사용자로부터 요청을 JSP가 받아(더 정확히는 JSP 에서 사용자가 요청을 합니다.) Java Bean(DTO, DAO)을 호출해 처리합니다.이 방식은 개발 속도가 빠르고 배우기 쉽지만 프레젠테이션 로직과 비즈니스 로직이 혼재하기 때문에 JSP 코드가 복잡해져 유지 보수가 어려워진다는 단점이 있습니다. MVC Model 2단순히 JSP만 사용하거나, Servlet만 사용하는 것이 아니라 두개의 장단점을 모두 취해 View 는 JSP로, Controller는 Servlet을 사용한 것이 Model2 입니다. 보여지는 부분은 HTML이 중심이 되는 JSP, 다른 자바 클래스에게 데이터를 넘겨주는 부분은 Java 코드가 중심이 되는 Servlet이 담당하게 됩니다. 그리고 Model 영역 에서는 DTO, DAO를 통해 Mysql 과 같은 데이터베이스에 접근합니다. 참고 자바EE의 역사 및 스프링과의 관계 위키백과 - 자바 플랫폼, 엔터프라이즈 에디션 서블릿-자바-서블릿으로-알아보는-웹-프로그래밍 Servlet - Concept Java Servlet 이란? (개념 및 예제) JSP와 Servlet, 왜 같이 쓸까? JSP - Concept Model1, Model2 개발 방식","link":"/2018/02/05/Spring/web-with-java/"},{"title":"토비의 스프링 8장 (스프링이란 무엇인가?)","text":"스프링이란 무엇인가?스프링의 정의스프링이란 어떤 것이다라고 한마디로 정의하기는 쉽지 않다. 스프링에 대해 가장 잘 알려진 정의는 이렇다. 자바 엔터프라이즈 개발을 편하게 해주는 오픈소스 경량급 애플리케이션 프레임워크 정의를 봐도 스프링이 무엇인지 감이 바로 오지는 않는다. 하지만 이 정의에는 스프링의 중요한 특징이 잘 담겨 있다. 애플리케이션 프레임워크 일반적으로 라이브러리나 프레임워크는 특정 업무 분야나 한 가지 기술에 특화된 목표를 가지고 만들어진다. 그러나 애플리케이션 프레임워크는 조금 다르다.애플리케이션 프레임워크는 특정 계층이나, 기술, 업무 분야에 국한되지 않고 애플리케이션의 전 영역을 포괄하는 범용적인 프레임워크를 말한다. 애플리케이션 프레임워크는 애플리케이션 개발의 전 과정을 빠르고 편리하며 효율적으로 진행하는데 일차적인 목표를 두는 프레임워크다.단지 여러 계층의 다양한 기술을 한데 모아뒀기 때문에 애플리케이션 프레임워크라고 불리는 건 아니다. 애플리케이션의 전 영역을 관통하는 일관된 프로그래밍 모델과 핵심 기술을 바탕으로 해서 각 분야의 특성에 맞는 필요를 채워주고 있기 때문이다. 경량급 스프링이 경량급이라는 건 스프링 자체가 아주 가볍다거나 작은 규모의 코드로 이뤄졌다는 뜻은 아니다.그럼에도 가볍다고 하는 이유는 불필요하게 무겁지 않다는 의미다. 특히 스프링이 처음 등장하던 시절의 자바 주류 기술이었던 예전의 EJB 같은 과도한 엔지니어링이 적용된 기술과 스프링을 대비시켜 설명하려고 사용했던 표현이다.스프링은 가장 단순한 서버환경인 톰캣(Tomcat)이나 제티(Jetty)에서도 완벽하게 동작한다. 단순한 개발툴과 기본적인 개발환경으로도 엔터프라이즈 개발에서 필요로 하는 주요한 기능을 갖춘 애플리케이션을 개발하기에 충분하다. 스프링의 장점은 그런 가볍고 단순한 환경에서도 복잡한 EJB와 고가의 WAS를 갖춰야만 가능했던 엔터프라이즈 개발의 고급 기술을 대부분 사용할 수 있다는 점이다.결과적으로 스프링은 EJB를 대표로 하는 기존의 많은 기술이 불필요하게 무겁고 복잡했음을 증명한 셈이고, 그런 면에서 스프링은 군더더기 없이 깔끔한 기술을 가진 ‘경량급’ 프레임워크라고 불린 것이다.만들어진 코드가 지원하는 기술수준은 비슷하더라도 그것을 훨씬 빠르고 간편하게 작성하게 해줌으로써 생산성과 품질 면에서 유리하다는 것이 바로 경량급이라는 말로 표현되는 스프링의 특징이다. 자바 엔터프라이즈 개발을 편하게 스프링은 근본적인 부분에서 엔터프라이즈 개발의 복잡함을 제거해내고 진정으로 개발을 편하게 해주는 해결책을 제시한다. 단순히 편리한 몇 가지 도구나 기능을 제공해주는 차원이 아니다.편리한 애플리케이션 개발이란 개발자가 복잡하고 실수하기 쉬운 로우레벨 기술에 많은 신경을 쓰지 않으면서도 애플리케이션의 핵심인 사용자의 요구사항, 즉 비즈니스 로직을 빠르고 효과적으로 구현하는 것을 말한다. 오픈소스 스프링의 목적스프링을 사용해서 엔터프라이즈 애플리케이션 개발을 편하게 하려는 이유는 뭘까? 원래 엔터프라이즈 개발이란 편하지 않기 때문이다. 엔터프라이즈 개발의 복잡함자바 엔터프라이즈(JavaEE) 개발이 실패하는 가장 대표적인 이유는 ‘엔터프라이즈 시스템 개발이 너무 복잡해져서’였다. 복잡합의 근본적인 이유엔터프라이즈 시스템 개발이 복잡한 원인은 크게 두 가지가 있다. (엔터프라이즈 시스템이란 서버에서 동작하며 기업과 조직의 업무를 처리해주는 시스템을 말한다.) 기술적인 제약조건과 요구사항이 늘어가기 때문이다. 엔터프라이즈 애플리케이션이 구현해야 할 핵심기능인 비즈니스 로직의 복잡함이 증가하기 때문이다. 전통적인 자바 엔터프라이즈 개발 기법은 대부분 비즈니스 로직의 복잡한 구현 코드와 엔터프라이즈 서비스를 이용하는 기술적인 코드가 자꾸 혼재될 수 밖에 없는 방식이었다. 결국 개발자가 동시에 그 두 가지를 모두 신경 써서 개발해야 하는 과도한 부담을 줬고, 그에 따라 전체적인 복잡함은 몇 배로 가중됐다. 복잡함을 해결하려는 도전제거될 수 없는 근본적인 복잡함엔터프라이즈 개발의 근본적인 복잡함의 원인은 제거할 대상은 아니다. 현실적으로는 불가능하기 때문이다. 근본적으로 엔터프라이즈 개발에 나타나는 복잡함의 원인은 제거 대상이 아니다. 대신 그 복잡함을 효과적으로 상대할 수 있는 전략과 기법이 필요하다. 문제는 비즈니스 로직의 복잡함을 효과적으로 다루기 위한 방법과 기술적인 복잡함을 효과적으로 처리하는 데 적용되는 방법이 다르다는 점이다. 따라서 두 가지 복잡함이 코드에 한데 어우러져 나타나는 전통적인 개발 방식에서는 효과적으로 복잡함을 다루기가 힘들다. 따라서 가장 먼저 할 일은 성격이 다른 이 두 가지 복잡함을 분리해내는 것이다. 복잡함을 상대하는 스프링의 전략스프링의 기본적인 전략은 비즈니스 로직을 담은 애플리케이션 코드와 엔터프라이즈 기술을 처리하는 코드를 분리시키는 것이다. 이 분리를 통해 두 가지 복잡함의 문제를 효과적으로 공략하게 해준다. 기술적 복잡함을 상대하는 전략기술적인 복잡함을 분리해서 생각하면 그것을 효과적으로 상대할 수 있는 적절한 전략을 발견할 수 있다. 스프링은 엔터프라이즈 기술을 적용했을 때 발생하는 복잡함의 문제를 두 가지로 분류하고 각각에 대한 적절한 대응 방법을 제공한다. 첫 번째 문제 : 기술에 대한 접근 방식이 일관성이 없고, 특정 환경에 종속적이다. 일관성 없는 기술과 서버환경의 변화에 대한 스프링의 공략 방법은 바로 서비스 추상화다. 앞에서 보았던 트랜잭션 추상화, OXM 추상화, 데이터 액세스에 관한 일관된 예외변환 기능, 데이터 액세스 기술에 독립적으로 적용 가능한 트랜잭션 동기화 기법 등이 대포적인 예다. 기술적인 복잡합은 일단 추상화를 통해 로우레벨의 기술 구현 부분과 기술을 사용하는 인터페이스를 분리하고, 환경과 세부기술에 독립적인 접근 인터페이스를 제공하는 것이 가장 좋은 해결책이다. 두 번째 문제 : 기술적인 처리를 담당하는 코드가 성격이 다른 코드에 섞여서 등장한다. 책임에 따라 계층을 구분하고 그 사이에 서로의 기술과 특성에 의존적인 인터페이스나 예외처리 등을 최대한 제거한다고 할지라도 근본적으로 엔터프라이즈 서비스를 적용하는 한 이런 문제는 쉽게 해결할 수 없다. 이런 기술과 비즈니스 로직의 혼재로 발생하는 복잡함을 해결하기 위한 스프링의 접근 방법은 바로 AOP다.AOP는 최후까지 애플리케이션 로직을 담당하는 코드에 남아 있는 기술 관련 코드를 깔끔하게 분리해서 별도의 모듈로 관리하게 해주는 강력한 기술이다. 비즈니스와 애플리케이션 로직의 복잡함을 상대하는 전략비즈니스 로직의 복잡함을 상대하는 전략은 자바라는 객체지향 기술 그 자체다. 스프링은 단지 객체지향 언어의 장점을 제대로 살리지 못하게 방해했던 요소를 제거하도록 도와줄 뿐이다. 핵심 도구 : 객체지향과 DI객체지향의 설계 기법을 잘 적용할 수 있는 구조를 만들기 위해 DI 같은 유용한 기술을 편하게 적용하도록 도와주는 것이 스프링의 기본 전략이다. 지금까지 보았듯이 기술적인 복잡함을 효과적으로 다루게 해주는 기법은 모두 DI를 바탕으로 하고 있다. 서비스 추상화, 템플릿/콜백, AOP와 같은 스프링의 기술은 DI 없이는 존재할 수 없는 것들이다. 그리고 DI는 객체지향 설계 기술 없이는 그 존재의미가 없다. DI란 특별한 기술이라기보다는 유연하게 확장할 수 있는 오브젝트 설계를 하다 보면 자연스럽게 적용하게 되는 객체지향 프로그래밍 기법일 뿐이다. 스프링은 단지 그것을 더욱 편하고 쉽게 사용하도록 도와줄 뿐이다. 기술적인 복잡함을 해결하는 문제나 기술적인 복잡함이 비즈니스 로직에 침범하지 못하도록 분리하는 경우에도 DI가 바탕이 된 여러 가지 기법이 활용된다. 반면에 비즈니스 로직 자체의 복잡함을 해결하려면 DI보다는 객체지향 설계 기법이 더 중요하다. POJO 프로그래밍스프링 핵심 개발자들은 “스프링의 정수(essence)”는 엔터프라이즈 서비스 기능을 POJO에 제공하는 것”이라고 했다. 엔터프라이즈 서비스라고 하는 것은 보안, 트랜잭션과 같은 엔터프라이즈 시스템에서 요구되는 기술을 말한다. 이런 기술을 POJO에 제공한다는 말은, 뒤집어 생각해보면 엔터프라이즈 서비스 기술과 POJO라는 애플리케이션 로직을 담은 코드를 분리했다는 뜻이기도 하다. ‘분리됐지만 반드시 필요한 엔터프라이즈 서비스 기술을 POJO 방식으로 개발된 애플리케이션 핵심 로직을 담은 코드에 제공한다’는 것이 스프링의 가장 강력한 특징과 목표다. 스프링의 핵심 : POJO스프링 애플리케이션은 POJO를 이용해서 만든 애플리케이션 코드와, POJO가 어떻게 관계를 맺고 동작하는지를 정의해놓은 설계정보로 구분된다. DI의 기본 아이디어는 유연하게 확장 가능한 오브젝트를 만들어두고 그 관계는 외부에서 다이내믹하게 설정해준다는 것이다. 이런 DI의 개념을 애플리케이션 전반에 걸쳐 적용하는 것이 스프링의 프로그래밍 모델이다. 스프링의 주요 기술인 IoC/DI, AOP, 서비스추상화는 애플리케이션을 POJO로 개발할 수 있게 해주는 가능기술이라고 불린다. POJO란 무엇인가?POJO는 Plain Old Java Object의 첫 글자를 따서 만든 약자다. POJO의 조건단순하게 보자면 그냥 평범한 자바오브젝트라고 할 수 있지만 좀 더 명확하게 하자면 적어도 다음의 조건을 충족해야 POJO라고 불릴 수 있다. 특정 규약에 종속되지 않는다. POJO는 자바 언어와 꼭 필요한 API 외에는 종속되지 않아야 한다. 따라서 EJB2와 같이 특정 규약을 따라 비즈니스 컴포넌트를 만들어야 하는 경우는 POJO가 아니다. 특정 규약을 따라 만들게 하는 경우는 대부분 규약에서 제시하는 특정 클래스를 상속하도록 요구한다. 그럴 경우 자바의 단일 상속 제한 때문에 더 이상 해당 클래스에 객체지향적인 설계 기법을 적용하기가 어려워지는 문제가 생긴다. 또한 규약이 적용된 환경에 종속적이 되기 때문에 다른 환경으로 이전이 힘들다는 문제점이 있다. 특정 환경에 종속되지 않는다. 어떤 경우는 특정 벤더의 서버나 특정 기업의 프레임워크 안에서만 동작 가능한 코드로 작성되기도 한다. 또 환경에 종속적인 클래스나 API를 직접 쓴 경우도 있다. 순수한 애플리케이션 로직을 담고 있는 오브젝트 코드가 특정 환경에 종속되게 만드는 경우라면 그것 역시 POJO라고 할 수 없다. POJO는 환경에 독립적이어야한다.특히 비즈니스 로직을 담고 있는 POJO 클래스는 웹이라는 환경정보나 웹 기술을 담고 있는 클래스나 인터페이스를 사용해서는 안된다. 비즈니스 로직을 담은 코드에 HttpServletRequest나 HttpSession, 캐시와 관련된 API가 등장하거나 웹 프레임워크의 클래스를 직접 이용하는 부분이 있다면 그것은 진정한 POJO라고 볼 수 없다.단지 자바의 문법을 지키고, 순수하게 JavaSE API만을 사용했다고 해서 그 코드를 POJO라고 할 수는 없다. POJO는 객체지향적인 자바 언어의 기본에 충실하게 만들어져야 하기 때문이다. POJO의 장점POJO가 될 수 있는 조건이 그대로 POJO의 장점이 된다. 특정한 기술과 환경에 종속되지 않는 오브젝트는 그만큼 깔끔한 코드가 될 수 있다. 로우레벨의 기술과 환경에 종속적인 코드가 비즈니스 로직과 함께 섞여 나오는 것만큼 지저분하고 복잡한 코드도 없다. POJO로 개발된 코드는 자동화된 테스트에 매우 유리하다. 환경의 제약은 코드의 자동화된 테스트를 어렵게 한다. 컨테이너에서만 동작을 확인할 수 있는 EJB 2는 테스트하려면 서버의 구동 및 빌드와 배치 과정까지 필요하다. 자동화된 테스트가 불가능한 건 아니지만 매우 복잡하고 번거로우므로 대부분 수동 테스트 방식을 선호한다. 그에 반해 어떤 환경에도 종속되지 않은 POJO 코드는 매우 유연한 방식으로 원하는 레벨에서 코드를 빠르고 명확하게 테스트할 수 있다. 객체지향적인 설계를 자유롭게 적용할 수 있다는 것도 큰 장점이다. POJO 프레임워크스프링은 POJO를 이용한 엔터프라이즈 애플리케이션 개발을 목적으로 하는 프레임워크이다. POJO 프로그래밍이 가능하도록 기술적인 기반을 제공하는 프레임워크를 POJO 프레임워크라고 한다. 스프링은 엔터프라이즈 애플리케이션 개발의 모든 영역과 계층에서 POJO 방식의 구현이 가능하게 하려는 목적으로 만들어졌다. 스프링을 이용하면 POJO 프로그래밍의 장점을 그대로 살려서 엔터프라이즈 애플리케이션의 핵심 로직을 객체지향적인 POJO를 기반으로 깔끔하게 구현하고, 동시에 엔터프라이즈 환경의 각종 서비스와 기술적인 필요를 POJO 방식으로 만들어진 코드에 적용할 수 있다. 스프링은 비즈니스 로직의 복잡함과 엔터프라이즈 기술의 복잡함을 분리해서 구성할 수 있게 도와준다. 하지만 자신은 기술영역에만 관여하지 비즈니스 로직을 담당하는 POJO에서는 모습을 감춘다. 데이터 액세스 로직이나 웹 UI 로직을 다룰 때만 최소한의 방법으로 관여한다. POJO 프레임워크로서 스프링은 자신을 직접 노출하지 않으면서 애플리케이션을 POJO로 쉽게 개발할 수 있게 지원해준다. 스프링의 기술제어의 역전(IoC) / 의존관계 주입(DI)왜 두 개의 오브젝트를 분리해서 만들고, 인터페이스를 두고 느슨하게 연결한 뒤, 실제 사용할 대상은 DI를 통해 외부에서 지정하는 것일까? 직접 자신이 사용할 오브젝트를 new 키워드로 생성해서 사용하는 강한 결합을 쓰는 방법보다 나은 점은 무엇일까? 가장 간단한 답변은 ‘유연한 확징이 가능하게 하기 위함’이다. DI는 개방 폐쇄 원칙(OCP)이라는 객체지향 설계 원칙으로 잘 설명될 수 있다. 유연한 확장이라는 장점은 OCP의 ‘확장에는 열려 있다(개방)’에 해당한다. DI는 역시 OCP의 ‘변경에는 닫혀 있다(폐쇄)’라는 말로도 설명이 가능하다. 폐쇄 관점에서 볼 때 장점은 ‘재사용이 가능하다’라고 볼 수 있다. DI의 활용 방법 핵심기능의 변경 DI의 가장 대표적인 적용 방법은 바로 의존 대상의 구현을 바꾸는 것이다. 디자인 패턴의 전략 패턴이 대표적인 예다. 실제 의존하는 대상이 가진 핵심기능을 DI 설정을 통해 변경하는 것이 대표적인 DI의 활용 방법이다. 핵심기능의 동적인 변경 두 번째 활용 방법은 첫 번째랑 비슷하게 의존 오브젝트의 핵심 기능 자체를 바꾸는 것이다. DI도 기본적으로는 런타임 시에 동적으로 의존 오브젝트를 연결해주는 것이긴 하지만, 일단 DI 되고 나면 그 후로는 바뀌지 않는다. 즉 동적인 방식으로 연결되지만 한 번 DI되면 바뀌지 않는 정적인 관계를 맺어주는 것이다. 하지만 DI를 잘 활용하면 애플리케이션이 동작하는 중간에 그 의존 대상을 다이내믹하게 변경할 수 있다. 부가기능의 추가 세 번째 활용 방법은 핵심기능은 그대로 둔 채로 부가기능을 추가하는 것이다. 데코레이터 패턴을 생각해보면 된다. 인터페이스를 두고 사용하게 하고, 실제 사용할 오브젝트는 외부에서 주입하는 DI를 적용해두면 데코레이터 패턴을 쉽게 적용할 수 있다. 그래서 핵심기능과 클라이언트 코드에는 전혀 영향을 주지 않으면서 부가적인 기능을 얼마든지 추가할 수 있다. 인터페이스의 변경 사용하려고 하는 오브젝트가 가진 인터페이스가 클라이언트와 호환되지 않는 경우가 있다. 이렇게 클라이언트가 사용하는 인터페이스와 실제 오브젝트 사이에 인터페이스가 일치하지 않는 경우에도 DI가 유용하다. 디자인 패턴에서 말하는 오브젝트 방식의 어댑터 패턴의 응용이라고 볼 수 있다.이를 좀 더 일반화해서 아예 인터페이스가 다른 다양한 구현을 같은 방식으로 사용하도록, 중간에 인터페이스 어댑터 역할을 해주는 레이어를 하나 추가하는 방법도 있다. 서비스 추상화(PSA)가 그런 방법이다. PSA는 클라이언트가 일관성 있게 사용할 수 있는 인터페이스를 정의해주고 DI를 통해 어댑터 역할을 하는 오브젝트를 이용하게 해준다. 이를 통해 다른 인터페이스를 가진 로우레벨의 기술을 변경하거나 확장해가면서 사용할 수 있는 것이다. 프록시 필요한 시점에서 실제 사용할 오브젝트를 초기화하고 리소스를 준비하게 해주는 지연된 로딩(lazy loading)을 적용하려면 프록시가 필요하다. 원격 오브젝트를 호출할 때 마치 로컬에 존재하는 오브젝트처럼 사용할 수 있게 해주는 원격 프록시를 적용하려고 할 때도 프록시가 필요하다. 두 가지 방법 모두 DI를 필요로 한다. 템플릿과 콜백 템플릿/콜백 패턴은 DI의 특별한 적용 방법이다. 반복적으로 등장하지만 항상 고정적인 작업 흐름과 그 사이에서 자주 바뀌는 부분을 분리해서 템플릿과 콜백으로 만들 고 이를 DI 원리를 응용해 적용하면 지저분하게 매번 만들어야 하는 코드를 간결하게 만들 수 있다. 싱글톤과 오브젝트 스코프 DI가 필요한 중요한 이유 중 한 가지는 DI 할 오브젝트의 생명주기를 제어할 수 있다는 것이다. DI를 프레임워크로 이용한다는 건 DI 대상 오브젝트를 컨테이너가 관리한다는 의미다. 오브젝트의 생성부터 관계 설정, 이용, 소멸에 이르기까지의 모든 과정을 DI 컨테이너가 주관하기 때문에 그 오브젝트의 스코프를 자유롭게 제어할 수 있다.스프링의 DI는 기본적으로 싱글톤으로 오브젝트를 만들어서 사용하게 한다. 컨테이너가 알아서 싱글톤으로 만들고 관리하기 때문에 클래스 자체는 싱글톤을 고려하지 않고 자유롭게 설계해도 된다는 장점이 있다. 테스트 다른 오브젝트와 협력해서 동작하는 오브젝트를 효과적으로 테스트하는 방법은 가능한 한 고립시키는 것이다. 즉 다른 오브젝트와의 사이에서 일어나는 일을 테스트를 위해 조작할 수 있도록 만든다. 그래야만 테스트 대상인 오브젝트의 기능에 충실하게 테스트가 가능하다. 복잡한 테스트할 대상에 의존하는 오브젝트를, 테스트를 목적으로 만들어진 목 오브젝트로 대체하면 유용하다. 애스펙트 지향 프로그래밍(AOP)AOP도 스프링의 3개 기술중의 하나다. 사실 애스펙트 지향 프로그래밍은 객체지향 프로그래밍(OOP)처럼 독립적인 프로그래밍 패러다임이 아니다. AOP와 OOP는 서로 배타적이 아니라는 말이다. 객체지향 기술은 매우 성공적은 프로그래밍 방식임에 분명하다. 하지만 한편으로는 복잡해져 가는 애플리케이션의 요구조건과 기술적인 난해함을 모두 해결하는데 한계가 있기도 하다. AOP는 바로 이러한 객체지향 기술의 한계와 단점을 극복하도록 도와주는 보조적인 프로그래밍 기술이다. IOC/DI를 이용해서 POJO에 선언적인 엔터프라이즈 서비스를 제공할 수 있지만 일부 서비스는 순수한 객체지향 기법만으로는 POJO의 조건을 유지한 채로 적용하기 힘들다. 바로 이런 문제를 해결하기 위해 AOP가 필요하다. AOP 적용 기법AOP를 자바 언어에 적용하는 기법은 크게 두 가지로 분류할 수 있다. 스프링과 같이 다이내믹 프록시를 사용하는 방법 이 방법은 기존 코드에 영향을 주지 않고 부가기능을 적용하게 해주는 데코레이터 패턴을 응용한 것이다. 만들기 쉽고 적용하기 간편하지만 부가기능을 부여할 수 있는 곳은 메소드의 호출이 일어나는 지점뿐이라는 제약이 있다. 인터페이스와 DI를 활용하는 데코레이터 패턴이 기반원리이기 때문이다. 자바 언어의 한계를 넘어서는 언어의 확장을 이용하는 방법 AspectJ라는 유명한 오픈소스 AOP 툴이 있다. AspectJ는 프록시 방식의 AOP에서는 불가능한 다양한 조인포인트를 제공한다. 메소드 호출뿐 아니라 인스턴스 생성, 필드 액세스, 특정 호출 경로를 가진 메소드 호출 등에도 부가기능을 제공할 수 있다. 이런 고급 AOP 기능을 적용하려면 자바 언어와 JDK의 지원만으로는 불가능하다. 그 대신 별도의 AOP 컴파일러를 이용한 빌드 과정을 거치거나, 클래스가 메모리로 로딩될 때 그 바이트 코드를 조작하는 위빙과 같은 별도의 방법을 이용해야 한다. 포터블 서비스 추상화(PSA)세 번째 기능기술은 환경과 세부 기술의 변화에 관계없이 일관된 방식으로 기술에 접근 할 수 있게 해주는 PSA(Portable Service Abstraction)다. POJO로 개발된 코드는 특정 환경이나 구현 방식에 종속적이지 않아야 한다. 스프링은 JavaEE를 기존 플랫폼으로 하는 자바 엔터프라이즈 개발에 주로 사용된다. 따라서 다양한 JavaEE 기술에 의존적일 수밖에 없다 .특정 환경과 기술에 종속적이지 않다는 게 그런 기술을 사용하지 않는다는 뜻은 아니다. 다만 POJO 코드가 그런 기술에 직접 노출되어 만들어지지 않는다는 말이다. 이를 위해 스프링이 제공하는 대표적인 기술이 바로 일관성 있는 서비스 추상화 기술이다. 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/05/20/Spring/toby-8/"},{"title":"젠킨스","text":"젠킨스젠킨스 는 자바로 작성된 오픈 소스 소트트웨어로 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 제공한다. 웹 애플리케이션 형태로 제공되고 있어서 어떠한 환경에서도 손쉽게 설치할 수 있으며 도커를 사용해 설치할 수도 있다. 또한 천 개 이상의 플러그인으로 다양한 시스템과 연동할 수 있다. 젠킨스의 주요 기능은 다음과 같다. 형상관리 도구와의 연동 소스 코드 체크아웃 웹 인터페이스 테스트 보고서 생성 빌드 및 테스트 자동화 실행 결과 통보 코드 품질 감시 다양한 인증 기반과 결합한 인증 및 권한 관리 배포 관리 자동화 분산 빌드(마스터 슬레이브) 그루비 스크립트를 이용한 자유로운 잡 스케줄링 젠킨스는 개발자가 소스코드를 추가, 수정한 뒤 형상관리 도구에 저장하면 자동으로 읽어 빌드 및 테스트를 실행한다. 젠킨스 설치젠킨스를 사용하려면 JDK와 메이븐이 필요하다. macOS에서 brew를 이용해 쉽게 설치가 가능하다. 1$ brew install jenkins 추후 필요하다면 다음과 같이 삭제할 수도 있다. 1$ brew remove jenkins 설치 후 다음과 같이 젠킨스를 백그라운드 서비스로 구동 및 중지가 가능하다. 12$ brew services start jenkins$ brew services stop jenkins 젠킨스를 실행 후 웹사이트에 접속한다. http://localhost:8080 처음 접속 시 Administrator password를 입력하게 되어 있는데 아래의 경로에 있는 파일에서 키를 확인해 입력한다. /Users/{사용자 계정}/.jenkins/secrets/initialAdminPassword 젠킨스를 어떻게 설치할지 결정할 수 있다. ‘Install suggested plugins’를 선택하면 젠킨스에서 추천하는 플러그인들이 같이 설치되고, ‘Select plugins to install’을 선택하면 필요한 플러그인을 선택하여 설치할 수 있다. 필요한 플러그인들을 자동으로 설치하기 시작한다. 설치가 끝나면 관리자 정보 입력 화면이 나온다. 정보를 입력한 후 ‘Save and Finish’ 버튼을 클릭한다. 빌드 잡(job) 생성하기 좌측 메뉴 상단에 있는 ‘새로운 Item’을 클릭한다. ‘Enter an item name’에 적당한 이름을 넣고 아래의 템플릿 중 ‘Freestyle project’를 선택한 후 ‘OK’ 버튼을 클릭한다. (Freestyle project는 거의 모든 젠킨스의 설정을 자유롭게 설정할 수 있다.) Github에 테스트를 위해 간단하게 만들어 놓은 프로젝트를 가져와 빌드를 테스트 한다. Github에서 프로젝트를 가져오기 위해서는 자격 증명을 추가해야 한다. ssh-key를 등록하거나 Github의 계정을 입력해야 한다. Credentials 선택 박스에서 조금 전 추가한 계정을 선택한 후 ‘저장’ 버튼을 클릭한다. ‘Build Now’를 클릭해 빌드를 진행한다. ‘Console Output’을 누르면 빌드가 성공한 것을 확인할 수 있다.","link":"/2018/08/09/Tool/jenkins/"},{"title":"토비의 스프링 6장 (AOP)","text":"AOPAOP는 IoC/DI, 서비스 추상화와 더불어 스프링의 3대 기반기술중 하나다. AOP를 바르게 이용하려면 OOP를 대체하려고 하는 것처럼 보이는 AOP라는 이름 뒤에 감춰진, 그 필연적인 등장배경과 스프링이 그것을 도입한 이유, 그 적용을 통해 얻을 수 있는 장점이 무엇인지에 대한 충분한 이해가 필요하다. 스프링에 적용된 가장 인기 있는 AOP의 적용 대상은 바로 선언적 트랜잭션 기능이다. 서비스 추상화를 통해 많은 근본적인 문제를 해결했던 트랜잭션 경계설정 기능을 AOP를 이용해 더욱 세련되고 깔끔한 방식으로 바꿔보자. 트랜잭션 코드의 분리1234567891011121314151617public void upgradeLevels() throws Exception { TransactionStatus status = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try { List&lt;User&gt; users = userDao.getAll(); for (User user : users) { if (canUpgradeLevel(user)) { upgradeLevel(user); } } this.transactionManager.commit(status); } catch (Exception e) { this.transactionManager.rollback(status); throw e; }} 얼핏 보면 트랜잭션 경계설정 코드와 비즈니스 로직 코드가 복잡하게 얽혀 있는듯이 보이지만, 자세히 살펴보면 뚜렷하게 두 가지 종류의 코드가 구분되어 있음을 알 수 있다. 비즈니스 로직 코드를 사이에 두고 트랜잭션 시작과 종료를 담당하는 코드가 앞뒤에 위치하고 있다. 또, 이 코드의 특징은 트랜잭션 경계설정의 코드와 비즈니스 로직 코드 간에 서로 주고받는 정보가 없다는 점이다. 다만 이 비즈니스 로직을 담당하는 코드가 트랜잭션의 시작과 종료 작업 사이에서 수행돼야 한다는 사항만 지켜지면 된다. DI를 이용한 클래스의 분리DI 적용을 이용한 트랜잭션 분리지금 UserService는 UserServiceTest가 클라이언트가 되어서 사용하고 있다. 현재 구조는 UserService 클래스와 그 사용 클라이언트 간의 관계가 강한 결합도로 고정되어 있다. 그래서 UserService를 인터페이스로 만들고 기존 코드는 UserService 인터페이스의 구현 클래스를 만들어넣도록 한다. 그러면 클라이언트와 결합이 약해지고, 직접 구현 클래스에 의존하고 있지 않기 때문에 유연한 확장이 가능해진다. 그런데 보통 이렇게 인터페이스를 이용해 구현 클래스를 클라이언트에 노출하지 않고 런타임 시에 DI를 통해 적용하는 방법을 쓰는 이유는, 일반적으로 구현 클래스를 바꿔가면서 사용하기 위해서다. 하지만 꼭 그래야 한다는 제약은 없다. 지금 해결하려고 하는 문제는 UserService에는 순수하게 비즈니스 로직을 담고 있는 코드만 두고 트랜잭션 경계설정을 담당하는 코드를 외부로 빼내려는 것이다. 그래서 다음과 같은 구조를 생각해볼 수 있다. UserService를 구현한 또 다른 구현 클래스를 만든다. 이 클래스는 사용자 관리 로직을 담고 있는 구현 클래스인 UserServiceImpl을 대신하기 위해 만든 게 아니다. 단지 트랜잭션의 경계설정이라는 책임을 맡고 있을 뿐이다. 그리고 스스로는 비즈니스 로직을 담고 있지 않기 때문에 또 다른 비즈니스 로직을 담고 있는 UserService의 구현 클래스에 실제적인 로직 처리 작업은 위임하는 것이다. UserService 인터페이스 도입먼저 기존의 UserService 클래스를 UserServiceImpl로 이름을 변경한다. 그리고 클라이언트가 사용할 로직을 담은 핵심 메소드만 UserService 인터페이스로 만든 후 UserServiceImpl이 구현하도록 만든다. UserService 인터페이스의 구현 클래스인 UserServiceImpl은 기존 UserService 클래스의 내용을 대부분 그대로 유지하면 된다. 단, 트랜잭션 관련된 코드는 독립시키기로 했으니 모두 제거한다. 123456789101112131415public class UserServiceImpl implements userService { UserDao userDao; MailSender mailSender; public void upgradeLevels() { List&lt;User&gt; users = userDao.getAll(); for (User user : users) { if (canUpgradeLevel(user)) { upgradeLevel(user); } } } ...} 분리된 트랜잭션 기능비즈니스 트랜잭션 처리를 담은 UserServiceTx를 만들어보자. UserServiceTx는 기본적으로 UserService를 구현하게 만든다. 그리고 같은 인터페이스를 구현한 다른 오브젝트에게 고스란히 작업을 위임하게 만들면 된다. 1234567891011121314151617public class UserServiceTx implements UserService { UserService userService; // UserService를 구현한 다른 오브젝트를 DI 받는다. public void setUserService(UserService userService) { this.userService = userService; } // DI 받은 UserService 오브젝트에 모든 기능을 위임한다. public void add(User user) { userService.add(user); } public void upgradeLevels() { userService.upgradeLevels(); }} UserServiceTx는 UserService 인터페이스를 구현했으니, 클라이언트에 대해 UserService 타입 오브젝트의 하나로서 행세할 수 있다. UserServiceTx는 사용자 관리라는 비즈니스 로직을 전혀 갖지 않고 고스란히 다른 UserService 구현 오브젝트에 기능을 위임한다. 이렇게 준비된 UserServiceTx에 트랜잭션의 경계설정이라는 부가적인 작업을 부여해보자. 1234567891011121314151617181920212223242526272829public class UserServiceTx implements UserService { UserService userService; PlatformTransactionManager transactionManager; public void setTransactionManager(PlatformTransactionManager transactionManager) { this.transactionManager = transactionManager; } public void setUserService(UserService userService) { this.userService = userService; } public void add(User user) { userService.add(user); } public void upgradeLevels() { TransactionStatus status = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try { userService.upgradeLevels(); this.transactionManager.commit(status); } catch (RuntimeException e) { this.transactionManager.rollback(status); throw e; } }} 트랜잭션을 위한 DI 설정클라이언트가 UserService라는 인터페이스를 통해 사용자 관리 로직을 이용하려고 할 때 먼저 트랜잭션을 담당하는 오브젝트가 사용돼서 트랜잭션에 관련된 작업을 진행해주고, 실제 사용자 관리 로직을 담은 오브젝트가 이후에 호출돼서 비즈니스 로직에 관련된 작업을 수행하도록 만든다. 트랜잭션 경계설정 코드 분리의 장점 비즈니스 로직을 담당하고 있는 UserServiceImpl의 코드를 작성할 때는 트랜잭션과 같은 기술적인 내용에는 전혀 신경 쓰지 않아도 된다. 트랜잭션의 적용이 필요한지도 신경 쓰지 않아도 된다. 비즈니스 로직에 대한 테스트를 손쉽게 만들어낼 수 있다. 고립된 단위 테스트가장 편하고 좋은 테스트 방법은 가능한 한 작은 단위로 쪼개서 테스트하는 것이다. 하지만 현재 UserService는 UserDao, TransactionManager, MailSender라는 세 가지 의존관계를 갖고 있다. 따라서 그 세 가지 의존관계를 갖는 오브젝트들이 테스트가 진행되는 동안에 같이 실행된다. UserService라는 테스트 대상이 테스트 단위인 것처럼 보이지만 사실은 그 뒤에 의존관계를 따라 등장하는 오브젝트와 서비스, 환경 등이 모두 합쳐져 테스트 대상이 되는 것이다. 테스트 대상 오브젝트 고립시키기그래서 테스트의 대상이 환경이나, 외부 서버, 다른 클래스의 코드에 종속되고 영향을 받지 않도록 고립시킬 필요가 있다. 테스트를 의존 대상으로부터 분리해서 고립시키는 방법은 테스트를 위한 대역을 사용하는 것이다. 테스트를 위한 UserServiceImpl 고립의존 오브젝트나 외부 서비스에 의존하지 않는 고립된 테스트 방식으로 만든 UserServiceImpl은 아무리 그 기능이 수행돼도 그 결과가 DB 등을 통해서 남지 않으니, 기존의 방법으로는 작업 결과를 검증하기 힘들다. upgradeLevels()처럼 결과가 리턴되지 않는 경우는 더더욱 그렇다. 그래서 이럴 땐 테스트 대상인 UserServiceImpl과 그 협력 오브젝트인 UserDao에게 어떤 요청을 했는지를 확인하는 작업이 필요하다. 테스트 중에 DB에 결과가 반영되지는 않았지만, UserDao의 update() 메소드를 호출하는 것을 확인할 수 있다면, 결국 DB에 그 결과가 반영될 것이라고 결론을 내릴 수 있기 때문이다. UserDao와 같은 역할을 하면서 UserServiceImpl과의 사이에서 주고받은 정보를 저장해뒀다가, 테스트의 검증에 사용할 수 있게 하는 목 오브젝트를 만들 필요가 있다. 단위 테스트와 통합 테스트단위 테스트의 단위는 정하기 나름이다. 사용자 관리 기능 전체를 하나의 단위로 볼 수도 있고 하나의 클래스나 하나의 메소드를 단위로 볼 수도 있다. 중요한 것은 하나의 단위에 초점을 맞춘 테스트라는 점이다. ‘테스트 대상 클래스를 목 오브젝트 등의 테스트 대역을 이용해 의존 오브젝트나 외부의 리소스를 사용하지 않도록 고립시켜서 테스트 하는 것’을 단위 테스트라고 부른다. 반면에 두 개 이상의, 성격이나 계층이 다른 오브젝트가 연동하도록 만들어 테스트하거나, 또는 외부의 DB나 파일, 서비스 등의 리소스가 참여하는 테스트는 통합 테스트라고 부른다. 통합 테스트란 두 개 이상의 단위가 결합해서 동작하면서 테스트가 수행되는 것이라고 보면 된다. 스프링의 테스트 컨텍스트 프레임워크를 이용해서 컨텍스트에서 생성되고 DI된 오브젝트를 테스트하는 것도 통합 테스트다. 아래는 단위 테스트와 통합 테스트 중에서 어떤 방법을 쓸지 어떻게 결장할 것인지에 대한 가이드 라인이다. 항상 단위 테스트를 먼저 고려한다. 하나의 클래스나 성격과 목적이 같은 긴밀한 클래스 몇 개를 모아서 외부와의 의존관계를 모두 차단하고 필요에 따라 스텁이나 목 오브젝트 등의 테스트 대역을 이용하도록 테스트를 만든다. 단위 테스트는 테스트 작성도 간단하고 실행 속도도 빠르며 테스트 대상 외의 코드나 환경으로부터 테스트 결과에 영향을 받지도 않기 때문에 가장 빠른 시간에 효과적인 태스트를 작성하기에 유리하다. 외부 리소스를 사용해야만 가능한 테스트는 통합 테스트로 만든다. 단위 테스트로 만들기가 어려운 코드도 있다. 대표적인 게 DAO다. DAO는 그 자체로 로직을 담고 있기보다는 DB를 통해 로직을 수행하는 인터페이스와 같은 역할을 한다. SQL을 JDBC를 통해 실행하는 코드만으로는 고립된 테스트를 작성하기가 힘들다. 작성한다고 해도 가치가 없는 경우가 대부분이다. 따라서 DAO는 DB까지 연동하는 테스트로 만드는 편이 효과적이다. DB를 사용하는 테스트는 DB에 테스트 데이터를 준비하고, DB를 사용하는 테스트는 DB에 테스트 데이터를 준비하고, DB에 직접 확인을 하는 드의 부가적인 작업이 필요하다. DAO 테스트는 DB라는 외부 리소스를 사용하기 때문에 통합 테스트로 분류된다. 하지만 코드에서 보자면 하나의 기능 단위를 테스트하는 것이기도 하다. DAO를 테스트를 통해 충분히 검증해두면, DAO를 이용하는 코드는 DAO 역할을 스텁이나 목 오브젝트로 대체해서 테스트할 수 있다. 이후에 실제 DAO와 연동했을 때도 바르게 동작하리라고 확신할 수 있다. 물론 각각의 단위 테스트가 성공했더라도 여러 개의 단위를 연결해서 테스트하면 오류가 발생할 수도 있다. 하지만 충분한 단위 테스트를 거친다면 통합 테스트에서 오류가 발생할 확률도 줄어들고 발생한다고 하더라도 쉽게 처리할 수 있다. 여러 개의 단위가 의존관계를 가지고 동작할 때를 위한 통합 테스트는 필요하다. 다만, 단위 테스트를 충분히 거쳤다면 통합 테스트의 부담은 상대적으로 줄어든다. 단위 테스트를 만들기가 너무 복잡하다고 판단되는 코드는 처음부터 통합 테스트를 고려해본다. 이때도 통합 테스트에 참여하는 코드 중에서 가능한 한 많은 부분을 미리 단위 테스트로 검증해두는 게 유리하다. 스프링 테스트 컨텍스트 프레임워크를 이용하는 테스트는 통합 테스트다. 간으하면 스프링의 지원 없이 직접 코드 레벨의 DI를 사용하면서 단위 테스트를 하는게 좋겠지만 스프링의 설정 자체도 테스트 대상이고, 스프링을 이용해 좀 더 추상적인 레벨에서 테스트해야 할 경우도 종종 있다. 이럴 땐 스프링 테스트 컨텍스트 프레임워크를 이용해 통합 테스트를 작성한다. 목 프레임워크단위 테스트를 만들기 위해서는 스텁이나 목 오브젝트의 사용이 필수적이다. 의존관계가 없는 단순한 클래스나 세부 로직을 검증하기 위해 메소드 단위로 테스트할 때가 아니라면, 대부분 의존 오브젝트를 필요로 하는 코드를 테스트하게 되기 때문이다. 목 오브젝트를 만드는 일은 번거로울 수 있다. 그러나 이런 번거로운 목 오브젝트를 편리하게 작성하도록 도와주는 다양한 목 오브젝트 지원 프레임워크가 있다. Mockito 프레임워크Mockito라는 프레임워크는 사용하기도 편리하고, 코드도 직관직이라 최근 많은 인기를 끌고 있다. Mockito와 같은 목 프레임워크의 특징은 목 클래스를 일일이 준비해둘 필요가 없다는 것이다. 간단한 메소드 호출만으로 다이내믹하게 특정 인터페이스를 구현한 테스트용 목 오브젝트를 만들 수 있다. USerDao 인터페이스를 구현한 테스트용 목 오브젝트는 다음과 같이 Mockito의 스태틱 메소드를 한 번 호출해주면 만들어진다. 1UserDao mockUserDao = mock(UserDao.class); 이렇게 만들어진 목 오브젝트는 아직 아무런 기능이 없다. 여기에 먼저 getAll() 메소드가 불려올 때 사용자 목록을 리턴하도록 스텁 기능을 추가해줘야 한다. 1when(mockUserDao.getAll()).thenReturn(this.users); mockUserDao.getAll()이 호출됐을 때(when), users 리스트를 리턴해주라(thenReturn)는 선언이다. Mocktio를 통해 만들어진 목 오브젝트는 메소드의 호출과 관련된 모든 내용을 자동으로 저장해두고, 이를 간단한 메소드로 검증할 수 있게 해준다. 테스트를 진행하는 동안 mockUserDao의 update() 메소드가 두 번 호출됐는지 확인하고 싶다면, 다음과 같이 검증 코드를 넣어주면 된다. 1verify(mockUserDao, times(2)).update(any(User.class)); User 타입의 오브젝트를 파라미터로 받으며 update() 메소드가 두 번 호출됐는지(times(2)) 확인하라(verify)는 것이다. Mockito 목 오브젝트는 다음의 네 단계를 거쳐서 사용하면 된다. 두 번째와 네 번째는 각각 필요할 경우에만 사용할 수 있다. 인터페이스를 이용해 목 오브젝트를 만든다. 목 오브젝트가 리턴할 값이 있으면 이를 지정해준다. 메소드가 호출되면 예외를 강제로 던지게 만들 수도 있다. 테스트 대상 오브젝트에 DI 해서 목 오브젝트가 테스트 중에 사용되도록 만든다. 테스트 대상 오브젝트를 사용한 후에 목 오브젝트의 특정 메소드가 호출됐는지, 어떤 값을 가지고 몇 번 호출됐는지를 검증한다. ArgumentCaptor는 목 오브젝트에 전달된 파라미터를 가져와 내용을 검증하기 위해 사용한다. 파라미터를 직접 비교하기 보다는 파라미터의 내부 정보를 확인해야 하는 경우에 유용하다. 다이내믹 프록시와 팩토리빈프록시와 프록시 패턴, 데코레이터 패턴부가기능 외의 나머지 모든 기능은 원래 핵심기능을 가진 클래스로 위임해줘야 한다. 핵심 기능은 부가기능을 가진 클래스의 존재 자체를 모른다. 따라서 부가기능이 핵심기능을 사용하는 구조가 되는 것이다 문제는 이렇게 구성했더라도 클라이언트가 핵심기능을 가진 클래스를 직접 사용해 버리면 부가기능이 적용될 기회가 없다는 점이다. 그래서 부가기능은 마치 자신이 핵심 기능을 가진 클래스인 것처럼 꾸며서, 클라이언트가 자신을 거쳐서 핵심기능을 사용하도록 만들어야 한다. 그러기 위해서는 클라이언트는 인터페이스를 통해서만 핵심기능을 사용하게 하고, 부가기능 자신도 같은 인터페이스를 구현한 뒤에 자신이 그 사이에 끼어들어야 한다. 이렇게 마치 자신이 클라이언트가 사용하려고 하는 실제 대상인 것처럼 위장해서 클라이언트의 요처을 받아주는 것을 대리자, 대리인과 같은 역할을 한다고 해서 프록시(proxy)라고 부른다. 그리고 프록시를 통해 최종적으로 요처을 위임받아 처리하는 실제 오브젝트를 타깃(target) 또는 실체(real subject)라고 부른다. 프록시의 특징은 타깃과 같은 인터페이스를 구현했다는 것과 프록시가 타깃을 제어할 수 있는 위치에 있다는 것이다. 프록시는 사용 목적에 따라 두 가지로 구분할 수 있다. 첫째는 클라이언트가 타깃에 접근하는 방법을 제어하기 위해서다. 두 번째는 타깃에 부가적인 기능을 부여해주기 위해서다. 두 가지 모두 대리 오브젝트라는 개념의 프록시를 두고 사용한다는 점은 동일하지만, 목적에 따라서 디자인 패턴에서느 다른 패턴으로 구분한다. 데코레이터 패턴데코레이터 패턴은 타깃에 부가적인 기능을 런타임 시에 다이내믹하게 부여해주기 위해 프록시를 사용하는 패턴을 말한다. 다이내믹하게 기능을 부여한다는 의미는 컴파일 시점, 즉 코드상에서는 어떤 방법과 순서로 프록시와 타깃이 연결되어 사용되는지 정해져 있지 않다는 뜻이다. 데코레이터 패턴에서는 프록시가 꼭 한 개로 제한되지 않는다. 데코레이터 패턴에서는 같은 인터페이스를 구현한 타겟과 여러 개의 프록시를 사용할 수 있다. 프록시로서 동작하는 각 데코레이터는 위임하는 대상에도 인터페이스로 접근하기 때문에 자신이 최종 타깃으로 위임하는지, 아니면 다음 단계의 데코레이터 프록시로 위임하는지 알지 못한다. 그래서 데코레이터의 다음 위임 대상은 인터페이스로 선언하고 생성자나 수정자 메소드를 통해 위임 대상을 외부에서 런타임 시에 주입받을 수 있도록 만들어야 한다. 인터페이스를 통한 데코레이터 정의와 런타임 시의 다이내믹한 구성 방법은 스프링의 DI를 이요하면 아주 편리하다. 데코레이터 빈의 프로퍼티로 같은 인터페이스를 구현한 다른 데코레이터 또는 타깃 빈을 설정하면 된다. 데코레이터 패턴은 타깃의 코드를 손대지 않고, 클라이언트가 호출하는 방법도 변경하지 않은 채로 새로운 기능을 추가할 때 유용한 방법이다. 프록시 패턴일반적으로 사용하는 프록시라는 용어와 디자인 패턴에서 말하는 프록시 패턴은 구분할 필요가 있다. 전자는 클라이언트와 사용 대상 사이에 대리 역할을 맡은 오브젝트를 두는 방법을 말한다면, 후자는 프록시를 사용하는 방법 중에서 타깃에 대한 접근 방법을 제어하려는 목적을 가진 경우를 가리킨다. 프록시 패턴의 프록시는 타깃의 기능을 확장하거나 추가하지 않는다. 대신 클라이언트가 타깃에 접근하는 방식을 변경해준다. 프록시 패턴은 타깃의 기능 자체에는 관여하지 않으면서 접근하는 방법을 제어해주는 프록시를 이용하는 것이다. 구조적으로 보자면 프록시와 데코레이터는 유사하다. 다만 프록시는 코드에서 자신이 만들거나 접근할 타깃 클래스 정보를 알고 있는 경우가 많다. 생성을 지연하는 프록시라면 구체적인 생성 방법을 알아야 하기 때문에 타깃 클래스에 대한 직접적인 정보를 알아야 한다. 물론 프록시 팽턴이라고 하더라도 인터페이스를 통해 위임하도록 만들 수도 있다. 인터페이스를 토앻 다음 호출 대상으로 접근하게 되면 그 사이에 다른 프록시나 데코레이터가 계속 추가될 수 있기 때문이다. 앞으로는 타깃과 동일한 인터페이스를 구현하고 클라이언트와 타깃 사이에 존재하면서 기능의 부가 또는 접근 제어를 담당하는 오브젝트를 모두 프록시라고 부르겠다. 하지만 그때마다 사용의 목적이 기능의 부가인지, 접근 제어인지를 구분해보면 각각 어떤 목적으로 프록시가 사용됐는지, 그에 따라 어떤 패턴이 적용됐는지 알 수 있을 것이다. 다이내믹 프록시목 오브젝트를 만드는 불편함을 목 프레임워크를 사용해 편리하게 바꿨던 것처럼 프록시도 일일이 모든 인터페이스를 구현해서 클래스를 새로 정의하지 않고도 편리하게 만들어서 사용할 방법이 있다. 자바에는 java.lang.reflect 패키지 안에 프록시를 손쉽게 만들 수 있도록 지원해주는 클래스들이 있다. 일일이 프록시 클래스를 정의하지 않고도 몇 가지 API를 이용해 프록시처럼 동작하는 오브젝트를 다이내믹하게 생성하는 것이다. 프록시의 구성과 프록시 작성의 문제점프록시는 다음의 두 가지 기능으로 구성된다. 타깃과 같은 메소드를 구현하고 있다가 메소드가 호출되면 타깃 오브젝트로 위임한다. 지정된 요청에 대해서는 부가기능을 수행한다. 프록시를 만들기가 번거로운 이유는 두 가지가 있다. 첫째는 타깃의 인터페이스를 구현하고 위임하는 코드를 작성하기가 번거롭다는 점이다. 부가기능이 필요 없는 메소드도 구현해서 타깃으로 위임하는 코드를 일일이 만들어줘야 한다. 또, 타깃 인터페이스의 메소드가 추가되거나 변경될 때마다 함께 수정해줘야 한다는 부담도 있다. 두 번째 문제점은 부가기능 코드가 중복될 가능성이 많다는 점이다. 첫 번째 문제인 인터페이스 메소드의 구현과 위임 기능 문제는 간단해 보이지 않는다. 바로 이런 문제를 해결하는 데 유용한 것이 바로 JDK의 다이내믹 프록시다. 리플렉션다이내믹 프록시는 리플렉션 기능을 이용해서 프록시를 만들어준다. 리플렉션은 자바의 코드 자체를 추상화해서 접근하도록 만든 것이다. 자바의 모든 클래스는 그 클래스 자체의 구성정보를 담은 Class 타입의 오브젝트를 하나씩 갖고 있다. ‘클래스이름.class’라고 하거나 오브젝트의 getClass() 메소드를 호출하면 클래스 정보를 담은 Class 타입의 오브젝트를 가져올 수 있다. 클래스 오브젝트를 이용하면 크래스 코드에 대한 메타정보를 가져오거나 오브젝트를 조작할 수 있다. 1234567891011121314151617181920package springbook.learningtest.jdk;...public class ReflectionTest { @Test public void invokeMethod() throws Exception() { String name = \"Spring\"; // length() assertThat(name.length(), is(6)); Method lengthMethod = String.class.getMethod(\"length\"); assertThat((Integer)lengthMethod.invoke(name), is(6)); // charAt() assertThat(name.charAt(0), is('S')); Method charAtMethod = String.class.getMethod(\"charAt\", int.class); assertThat((Character)charAtMethod.invoke(name, 0), is('S')); }} 다이내믹 프록시 적용 다이내믹 프록시는 프록시 팩토리에 의해 런타임 시 다이내믹하게 만들어지는 오브젝트다. 다이내믹 프록시 오브젝트는 타깃의 인터페이스와 같은 타입으로 만들어진다. 클라이언트는 다이내믹 프록시 오브젝트를 타깃 인터페이스를 통해 사용할 수 있다. 이 덕분에 프록시를 만들 때 인터페이스를 모두 구현해가면서 클래스를 정의하는 수고를 덜 수 있다. 프록시 팩토리에게 인터페이스 정보만 제공해주면 해당 인터페이스를 구현한 클래스의 오브젝트를 자동으로 만들어주기 때문이다. 다이내믹 프록시가 인터페이스 구현 클래스의 오브젝트는 만들어주지만, 프록시로서 필요한 부가기능 제공 코드는 직접 생성해야 한다. 부가기능은 프록시 오브젝트와 독립적으로 InvocationHandler를 구현한 오브젝트에 담는다. InvocationHandler 인터페이스는 다음과 같은 메소드 한 개만 가진 간단한 인터페이스다. 1public Object invoke(Object proxy, Method method, Object[] args) invoke() 메소드는 리플렉션의 MEthod 인터페이스를 파라미터로 받는다. 메소드를 호출할 때 전달되는 파라미터도 args로 받는다. 다이내믹 프록시 오브젝트는 클라이언트의 모든 요청을 리플렉션 정보로 변환해서 InvocationHandler 구현 오브젝트의 invoke() 메소드로 넘기는 것이다. 타깃 인터페이스의 모든 메소드 요청이 하나의 메소드로 집중되기 때문에 중복되는 기능을 효과적으로 제공할 수 있다. InvocationHandler 구현 오브젝트가 타깃 오브젝트 레퍼런스를 갖고 있다면 리플렉션을 이용해 간단히 위임 코드를 만들어 낼 수 있다. InvocationHandler 인터페이스를 구현한 오브젝트를 제공해주면 다이내믹 프록시가 받는 모든 요청을 InvocationHandler의 invoke() 메소드로 보내준다. 다이내믹 프록시로부터 요청을 전달받으려면 InvocationHandler를 구현해야 한다. 메소드는 invoke() 하나뿐이다. 다이내믹 프록시가 클라이언트로부터 받는 모든 요청은 incoke() 메소드로 전달된다. 다이내믹 프록시를 통해 요청이 전달되면 리플렉션 API를 이용해 타깃 오브젝트의 메소드를 호출한다. 타깃 오브젝트는 생성자를 통해 미리 전달받아 둔다. 다이내믹 프록시의 생성은 Proxy 클래스의 newProxyInstance() 스태틱 팩토리 메소드를 이용하면 된다. 12345678// 생성된 다이내믹 프록시 오브젝트는 Hello 인터페이스를 구현하고 있으므로 Hello 타입으로 캐스팅해도 안전하다.Hello proxiedHello = (Hello)Proxy.newProxyInstance( // 동적으로 생성되는 다이내믹 프록시 클래스의 로딩에 사용할 클래스 로더 getClass().getClassLoader(), // 구현할 인터페이스 new Class[] { Hello.class }, // 부가기능과 위임 코드를 담은 InvocationHandler new UppercaseHandler(new HelloTarget())); 다이내믹 프록시의 확장12345678910111213141516public class UppercaseHandler implements InvocationHandler { // 어떤 종류의 인터페이스를 구현한 타깃에도 적용 가능하도록 Object 타입으로 수정 Object target; private UppercaseHandler(Object target) { this.target = target; } public Object invoke(Object proxy, Method method, Object[] args) thorws Throwable { Object ret = method.invoke(target, args); if (Ret instanceof String) { return ((String)ret).toUpperCase(); } else { return ret; } }} 다이내믹 프록시를 이용한 트랜잭션 부가기능트랜잭션 InvocationHandler12345678910111213141516171819202122232425262728293031323334353637public class TransactionHandler implements InvocationHandler { private Object target; private PlatformTransactionManager transactionManager; private String pattern; public void setTarget(Object target) { this.target = target; } public void setTransactionManager(PlatformTransactionManager transactionManager) { this.transactionManager = transactionManager; } public void setPattern(String pattern) { this.pattern = pattern; } public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if (method.getName().startsWith(pattern)) { return invokeInTransaction(method, args); } else { return method.invoke(target, args); } } private Object invokeTransaction(Method method, Object[] args) throws Throwable { TransactionStatus = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try { Object ret = method.invoke(target, args); this.transactionManager.commit(status); return ret; } catch (InvocationTargetException e) { this.transactionManager.rollback(status); throw e.getTargetException(); } }} TransactionHandler와 다이내믹 프록시를 이용하는 테스트12345678910@Testpublic void upgradeAllOrNothing() throws Exception { ... TransactionHandler txHandler = new TransactionHandler(); txHandler.setTarget(testUserService); txHandler.setTransactionManager(transactionManager); txHandler.setPattern(\"upgradeLevels\"); UserService txUSerService = (UserService)Proxy.newProxyInstance(getClass().getClassLoader(), new Class[] {UserService.class }, txHandler); ...} 다이내믹 프록시를 위한 팩토리 빈이제 TransactionHandler와 다이내믹 프록시를 스프링의 DI를 통해 사용할 수 있도록 만들어야 할 차례다. 스프링의 빈은 기본적으로 클래스 이름과 프로퍼티로 정의된다. 스프링은 지정된 클래스 이름을 가지고 리플렉션을 이용해서 해당 클래스의 오브젝트를 만든다. 클래스의 이름을 갖고 있다면 다음과 같은 방법으로 새로운 오브젝트를 생성할 수 있다. Class의 newInstance() 메소드는 해당 클래스의 파라미터가 없는 생성자를 호출하고, 그 결과 생성되는 오브젝트를 돌려주는 리플렉션 API다. 1Date now = (Date) Class.forName(\"java.util.Date\").newInstance(); 스프링은 내부적으로 리플렉션 API를 이용해서 빈 정의에 나오는 클래스 이름을 가지고 빈 오브젝트를 생성한다. 문제는 다이내믹 프록시 오브젝트는 이런 식으로 프록시 오브젝트가 생성되지 않는다는 점이다. 사실 다이내믹 프록시 오브젝트의 클래스가 어떤 것인지 알 수도 없다. 클래스 자체도 내부적으로 다이내믹하게 새로 정의해서 사용하기 때문이다. 따라서 사전에 프록시 오브젝트의 클래스 정보를 미리 알아내서 스프링의 빈에 정의할 방법이 없다. 다이내믹 프록시는 Proxy 클래스의 newProxyInstance()라는 스태틱 팩토리 메소드를 통해서만 만들 수 있다. 팩토리 빈스프링은 클래스 정보를 가지고 디폴트 생성자를 통해 오브젝트를 만드는 방법 외에도 빈을 만들 수 있는 여러 가지 방법을 제공한다. 대표적으로 팩토리 빈을 이용한 빈 생성 방법을 들 수 있다. 팩토리 빈이란 스프링을 대신해서 오브젝트의 생성로직을 담당하도록 만들어진 특별한 빈을 말한다. 팩토리 빈을 만드는 방법에는 여러 가지가 있는데, 가장 간단한 방법은 스프링의 FactoryBean이라는 인터페이스를 구현하는 것이다. 사실 스프링은 private 생성자를 가진 클래스도 빈으로 등록해주면 리플렉션을 이용해 오브젝트를 만들어준다. 1234567package org.springframework.beans.factory;public interface FactoryBean&lt;T&gt; { T getObject() throws Exception; // 빈 오브젝트를 생성해서 돌려준다. Class&lt;? extends T&gt; getOBjectType(); // 생성되는 오브젝트의 타입을 알려준다. boolean isSingleton(); // getObject()가 돌려주는 오브젝트가 항상 같은 싱글톤 오브젝트인지 알려준다.} 다이내믹 프록시를 만들어주는 팩토리 빈Proxy의 newPRoxyInstance() 메소드를 통해서만 생성이 가능한 다이내믹 프록시 오브젝트는 일반적인 방법으로는 스프링의 빈을 등록할 수 없다. 대신 팩토리 빈을 사용하면 다이내믹 프록시 오브젝트를 스프링의 빈으로 만들어줄 수가 있다. 팩토리 빈의 getObject() 메소드에 다이내믹 프록시 오브젝트를 만들어주는 코드를 넣으면 되게 때문이다. 스프링 빈에는 팩토리 빈과 UserServiceImpl만 빈으로 등록한다. 팩토리 빈은 다이내믹 프록시가 위임할 타깃 오브젝트인 UserServiceImpl에 대한 레퍼런스를 프로퍼티를 통해 DI 받아둬야 한다. 다이내믹 프록시와 함께 생성할 TransactionHandler에게 타깃 오브젝트를 전달해줘야 하기 때문이다. 그 외에도 다이내믹 프록시나 TransactionHandler를 만들 때 필요한 정보는 팩토리 빈의 프로퍼티로 설정해뒀다가 다이내믹 프록시를 만들면서 전달해줘야 한다. 프록시 팩토리 빈 방식의 장점과 한계다이내믹 프록시를 생성해주는 팩토리 빈을 사용하는 방법은 여러 가지 장점이 있다. 한번 부가기능을 가진 프록시를 생성하는 팩토리 빈을 만들어두면 타깃의 타입에 상관없이 재사용할 수 있기 때문이다. 프록시 팩토리 빈 방식의 장점다이내믹 프록시를 이용하면 타깃 인터페이스를 구현하는클래스를 일일이 만드는 번거로움을 제거할 수 있다. 하나의 핸들러 메소드를 구현하는 것만으로도 수많은 메소드에 부가기능을 부여해줄 수 있으니 부가기능 코드의 중복 문제도 사라진다. 다이내믹 프록시에 팩토리 빈을 이용한 DI까지 더해주면 번거로운 다이내믹 프록시 생성 코드도 제거할 수 있다. DI 설정만으로 다양한 타깃 오브젝트에 적용도 가능하다. 프록시 팩토리 빈의 한계프록시를 통해 타깃에 부가기능을 제공하는 것은 메소드 단위로 일어나는 일이다. 하나의 크래스 안에 존재하는 여러 개의 메소드에 부가기능을 한 번에 제공하는 건 어렵지 않게 가능했다. 하지만 한 번에 여러 개의 크래스에 공통적인 부가기능을 제공하는 일은 지금까지 살펴본 방법으로는 불가능하다. 하나의 타깃에 여러 개의 부가기능을 적용하려고 할 때도 문제다. 프록시 팩토리 빈 설정이 부가기능의 개수만큼 따라 붙어야 한다. 스프링의 프록시 팩토리 빈ProxyFactoryBean자바에는 JDK에서 제공하는 다이내믹 프록시 외에도 편리하게 프록시를 만들 수 있도록 지원해주는 다양한 기술이 존재한다. 따라서 스프링은 일관된 방법으로 프록시를 만들 수 있게 도와주는 추상 레이어를 제공한다. 생성된 프록시는 스프링의 빈으로 등록돼야 한다. 스프링은 프록시 오브젝트를 생성해주는 기술을 추상화한 팩토리 빈을 제공해준다. 스프링의 ProxyFactoryBean은 프록시를 생성해서 빈 오브젝트로 등록하게 해주는 팩토리 빈이다. ProxyFactoryBean은 순수하게 프록시를 생성하는 작업만을 담당하고 프록시를 통해 제공해줄 부가기능은 별도의 빈에 둘 수 있다. ProxyFactoryBean이 생성하는 프록시에서 사용할 부가기능은 MethodInterceptor 인터페이스를 구현해서 만든다. MethodInterceptor는 InvocationHandler와 비슷하지만 한 가지 다른 점이 있다. InvocationHandler의 invoke() 메소드는 타깃 오브젝트에 대한 정보를 제공하지 않는다. 따라서 타깃은 InvocationHandler를 구현한 크래스가 직접 알고 있어야 한다. 반면에 MethodInterceptor의 invoke() 메소드는 ProxyFactoryBean으로부터 타깃 오브젝트에 대한 정보까지도 함께 제공받는다. 그 차이 덕분에 MethodInterceptor는 타깃 오브젝트에 상관없이 독립적으로 만들어질 수 있다. 따라서 MethodInterceptor 오브젝트는 타깃이 다른 여러 프록시에서 함께 사용할 수 있고, 싱글톤 빈으로 등록 가능하다. 어드바이스: 타깃이 필요 없는 순수한 부가기능MethodInvocation은 일종의 콜백 오브젝트로, proceed() 메소드를 실행하면 타깃 오브젝트의 메소드를 내부적으로 실행해주는 기능이 있다. ProxyFactoryBean은 작은 단위의 템플릿/콜백 구조를 응용해서 적용했기 때문에 템플릿 역할을 하는 MethodInvocation을 싱글톤으로 두고 공유할 수 있다. MethodInterceptor처럼 타깃 오브젝트에 적용하는 부가기능을 담은 오브젝트를 스프링에서는 어드바이스(advice)라고 부른다. ProxyFactoryBean은 기본적으로 JDK가 제공하는 다이내믹 프록시를 만들어준다. 경우에 따라서는 CGLib이라고 하는 오픈소스 바이트코드 생성 프레임워크를 이용해 프록시를 만들기도 한다. 어드바이스는 타깃 오브젝트에 종속되지 않는 순수한 부가기능을 담은 오브젝트라는 사실을 잘 기억해두자. 포인트컷: 부가기능 적용 대상 메소드 선정 방법MethodInterceptor 오브젝트는 여러 프록시가 공유해서 사용할 수 있다. 그러기 위해서 MethodInterceptor 오브젝트는 타깃 정보를 갖고 있지 않도록 만들었다. 그 덕분에 MethodInterceptor를 스프링의 싱글톤 빈으로 등록할 수 있었다. 그런데 여기에다 트랜잭션 적용 대상 메소드 이름 패턴을 넣어주는 것은 곤란하다. 트랜잭션 적용 메소드 패턴은 프록시마다 다를 수 있기 때문에 여러 프록시가 공유하는 MethodInterceptor에 특정 프록시에만 적용되는 패턴을 넣으면 문제가 된다. InvocationHandler는 타깃과 메소드 선정 알고리즘 코드에 의존하고 있지만, 스프링의 ProxyFactoryBean 방식은 두 가지 확장 기능인 부가기능(Advice)과 메소드 선정 알고리즘(Pointcut)을 활용하는 유연한 구조를 제공한다. 스프링은 부가기능을 제공하는 오브젝트를 어드바이스라고 부르고, 메소드 선정 알고리즘을 담은 오브젝트를 포인트컷이라고 부른다. 어드바이스와 포인트컷은 모두 프록시에 DI로 주입돼서 사용된다. 두 가지 모두 여러 프록시에서 공유가 가능하도록 만들어지기 때문에 스프링의 싱글톤 빈으로 등록이 가능하다. 프록시는 클라이언트로부터 요청을 받으면 먼저 포인트컷에게 부가기능을 부여할 메소드인지를 확인해달라고 요청한다. 포인트컷은 Pointcut 인터페이스를 구현해서 만들면 된다. 프록시는 포인트컷으로부터 부가기능을 적용할 대상 메소드인지 확인받으면, MethodInterceptor 타입의 어드바이스를 호출한다. 어드바이스는 JDK의 다이내믹 프록시의 InvocationHandler와 달리 직접 타깃을 호출하지 않는다. 어드바이스가 일종의 템플릿이 되고 타깃을 호출하는 기능을 갖고 있는 MethodInvocation 오브젝트가 콜백이 되는 것이다. 템플릿은 한 번 만들면 재사용이 가능하고 여러 빈이 공유해서 사용할 수 있듯이, 어드바이스도 독립적인 싱글톤 빈으로 등록하고 DI를 주입해서 여러 프록시가 사용하도록 만들 수 있다. 프록시로부터 어드바이스와 포인트컷을 독립시키고 DI를 사용하게 한 것은 전형적인 전략 패턴 구조다. 12345678910111213141516171819@Testpublic void pointcutAdvisor() { ProxyFactoryBean pfBean = new ProxyFactoryBean(); pfBean.setTarget(new HelloTarget()); // 메소드 이름을 비교해서 대상을 선정하는 알고리즘을 제공하는 포인트컷 생성 NameMatchMethodPointcut pointcut = new NameMatchMethodPointcut(); // 이름 비교조건 설정. sayH로 시작하는 모든 메소드를 선택하게 한다. pointcut.setMappedName(\"syaH*\"); // 포인트컷과 어드바이스를 advisor로 묶어서 한 번에 추가 pfBean.addAdvisor(new DefaultPointcutAdvisor(pointcut, new UppercaseAdvice())); Hello proxiedHello = (Hello) pfBean.getObject(); assertThat(proxiedHello.sayHello(\"Toby\"), is(\"HELLO TOBY\")); assertThat(proxiedHello.sayHi(\"Toby\"), is(\"HI TOBY\")); assertThat(proxiedHello.sayThankYou(\"Toby\"), is(\"Thank You Toby\"));} ProxyFactoryBean에는 여러 개의 어드바이스와 포인트컷이 추가될 수 있다. 포인트컷과 어드바이스를 따로 등록하면 어떤 어드바이스(부가 기능)에 대해 어떤 포인트컷(메소드 선정)을 적용할지 애매해지기 때문이다. 그래서 이 둘을 Advisor 타입의 오브젝트에 담아서 조합을 만들어 등록하는 것이다. 여러 개의 어드바이스가 등록되더라도 각각 다른 포인트컷과 조합될 수 있기 때문에 각기 다른 메소드 선정 방식을 적용할 수 있다. 이렇게 어드바이스와 포인트 컷을 묶은 오브젝트를 인터페이스 이름을 따서 어드바이저라고 부른다. 어드바이저 = 포인트컷(메소드 선정 알고리즘) + 어드바이스(부가기능) 어드바이스와 포인트컷의 재사용ProxyFactoryBean은 스프링의 DI와 템플릿/콜백 패턴, 서비스 추상화 등의 기법이 모두 적용된 것이다. 그 덕분에 독립적이며, 여러 프록시가 공유할 수 있는 어드바이스와 포인트컷으로 확장 기능을 분리할 수 있었다. 스프링 AOP자동 프록시 생성중복 문제의 접근 방법JDK의 다이내믹 프록시는 특정 인터페이스를 구현한 오브젝트에 대해서 프록시 역할을 해주는 클래스를 런타임 시 내부적으로 만들어준다. 런타임 시에 만들어져 사용되기 때문에 클래스 소스가 따로 남지 않을 뿐이지 타깃 인터페이스의 모든 메소드를 구현하는 클래스가 분명히 만들어진다. 변하지 않는 타깃으로의 위임과 부가기능 적용 여부 판단이라는 부분은 코드 생성기법을 이용하는 다이내믹 프록시 기술에 맡기고, 변하는 부가기능 코드는 별도로 만들어서 다이내믹 프록시 생성 팩토리에 DI로 제공하는 방법을 사용한 것이다. 좀 독특하긴 하지만 변하는 로직과 변하지 않는 기계적인 코드를 잘 분리해낸 것이다. 반복적인 프록시의 메소드 구현은 코드 자동생성 기법을 이용해 해결했다면 반복적인 ProxyFactoryBean 설정 문제는 설정 자동등록 기법으로 해결할 수 없을까? 하지만 지금까지 살펴본 방법에서는 한 번에 여러 개의 빈에 프록시를 적용할 만한 방법은 없었다. 빈 후처리기를 이용한 자동 프록시 생성기스프링은 컨테이너로서 제공하는 기능 중에서 변하지 않는 핵심적인 부분외에는 대부분 확장할 수 있도록 확장 포인트를 제공해준다. 그 중에서 관심을 가질 만한 확장 포인트는 BeanPostProcessor 인터페이스를 구현해서 만든 빈 후처리기다. 빈 후처리기는 이름 그대로 스프링 빈 오브젝트로 만들어지고 난 후에, 빈 오브젝트를 다시 가공할 수 있게 해준다. 스프링은 빈 후처리기 중의 하나로 DefaultAdvisorAutoProxyCreator를 제공한다. DefaultAdvisorAutoProxyCreator는 어드바이저를 이용한 자동 프록시 생성기다. 빈 후처리기를 스프링에 적용하는 방법은 간단하다. 빈 후처리기 자체를 빈으로 등록하는 것이다. 스프링은 빈 후처리기가 빈으로 등록되어 있으면 빈 오브젝트가 생성될 때마다 빈 후처리기에 보내서 후처리 작업을 요청한다. 빈 후처리기는 빈 오브젝트의 프로퍼티를 강제로 수정할 수도 있고 별도의 초기화 작업을 수행할 수도 있다. 심지어는 만들어진 빈오브젝트 자체를 바꿔치기할 수도 있다. 따라서 스프링이 설정을 참고해서 만든 오브젝트가 아닌 다른 오브젝트를 빈으로 등록시키는 것이 가능하다. 이를 잘 활용하면 스프링이 생성하는 빈 오브젝트의 일부를 프록시로 포장하고, 프록시를 빈으로 대신 등록할 수도 있다. DefaultAdvisorAutoProxyCreator 빈 후처리기가 등록되어 있으면 스프링은 빈 오브젝트를 만들 때마다 후처리기에게 빈을 보낸다. DefaultAdvisorAutoProxyCreator는 빈으로 등록된 모든 어드바이저 내의 포인트컷을 이용해 전달받은 빈이 프록시 적용 대상인지 확인한다. 프록시 적용 대상이면 그때는 내장된 프록시 생성기에게 현재 빈에 대한 프록시를 만들게 하고, 만들어진 프록시에 어드바이저를 연결해준다. 빈 후처리기는 프록시가 생성되면 원래 컨테이너가 전달해준 빈 오브젝트 대신 프록시 오브젝트를 컨테이너에게 돌려준다. 컨테이너는 최종적으로 빈 후처리기가 돌려준 오브젝트를 빈으로 등록하고 사용한다. 적용할 빈을 선정하는 로직이 추가된 포인트컷이 담긴 어드바이저를 등록하고 빈 후처리기를 사용하면 일일이 ProxyFactoryBean 빈을 등록하지 않아도 타깃 오브젝트에 자동으로 프록시가 적용되게 할 수 있다. 확장된 포인트컷포인트컷은 클래스 필터와 메소드 매처 두 가지를 돌려주는 메소드를 갖고 있다. 실제 포인트컷의 선별 로직은 이 두가지 타입의 오브젝트에 담겨 있다. 1234public interface Pointcut { ClassFilter getClassFilter(); // 프록시를 적용할 클래스인지 확인해준다. MethodMatcher getMethodMatcher(); // 어드바이스를 적용할 메소드인지 확인해준다.} 만약 Pointcut 선정 기능을 모두 적용한다면 먼저 프록시를 적용할 클래스인지 판단하고 나서, 적용 대상 클래스인 경우에는 어드바이스를 적용할 메소드인지 확인하는 식으로 동작한다. 결국 이 두 가지 조건이 모두 충족되는 타깃의 메소드에 어드바이스가 적용되는 것이다. 모든 빈에 대해 프록시 자동 적용 대상을 선별해야 하는 빈 후처리기인 DefaultAdvisorAutoProxyCreator는 클래스와 메소드 선정 알고리즘을 모두 갖고 있는 포인트컷이 필요하다. 정확히는 그런 포인트컷과 어드바이스가 결합되어 있는 어드바이저가 등록되어 있어야 한다. DefaultAdvisorAutoProxyCreator의 적용클래스 필터를 적용할 포인트컷 작성메소드 이름만 비교하던 포인트컷인 NameMatchMethodPointcut을 상속해서 프로퍼티로 주어진 이름 패턴을 가지고 클래스 이름을 비교하는 ClassFilter를 추가하도록 만든다. 1234567891011121314151617181920package springbook.learningtest.jdk.proxy;//...public class NameMatchClassMethodPointcut extends NameMatchMethodPointcut { public void setMappedClassName(String mappedClassName) { // 모든 클래스를 다 허용하던 디폴트 클래스 필터를 프로퍼티로 받은 클래스 이름을 이용해서 필터를 만들어 덮어씌운다. this.setClassFilter(new SimpleClassFilter(mappedClassName)); } static Class SimpleClassFilter implements ClassFilter { String mappedName; private SimpleClassFilter(String mappedName) { this.mappedName = mappedName; } public boolean matches(Class&lt;?&gt; clazz) { return PatternMatchUtils.simpleMatch(mappedName, clazz.getSimpleName()); } }} 어드바이저를 이용하는 자동 프록시 생성기 등록자동 프록시 생성기인 DefaultAdvisorAutoProxyCreator는 등록된 빈 중에서 Advisor 인터페이스를 구현한 것을 모두 찾는다. 그리고 생성되는 모든 빈에 대해 어드바이저의 포인트컷을 적용해보면서 프록시 적용 대상을 선정한다. 빈 클래스가 프록시 선정 대상이라면 프록시를 만들어서 원래 빈 오브젝트와 바꿔치기한다. 원래 빈 오브젝트는 프록시 뒤에 연결돼서 프록시를 통해서만 접근 가능하게 바뀌며, 타깃 빈에 의존한다고 정의한 다른 빈들은 등록시 프록시 오브젝트를 대신 DI 받게 된다. DefaultAdvisorAutoProxyCreator 등록은 다음 한 줄과 같다. 1&lt;bean class=\"org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\" /&gt; 다른 빈에서 참조되거나 코드에서 빈 이름으로 조회될 필요가 없는 빈이라면 아이디를 등록하지 않아도 무방하다. 포인트컷 표현식을 이용한 포인트컷스프링은 아주 간단하고 효과적인 방법으로 포인트컷의 클래스와 메소드를 선정하는 알고리즘을 작성할 수 있는 방법을 제공한다. 정규식이나 JSP의 EL과 비슷한 일종의 표현식 언어를 사용해서 포인트컷을 작성할 수 있도록 하는 방법이다. 그래서 이것을 포인트컷 표현식이라고 부른다. 포인트컷 표현식포인트컷 표현식을 지원하는 포인트컷을 적용하려면 AspectJExpressionPointcut 클래스를 사용하면 된다. Pointcut 인터페이스를 구현해야 하는 스프링의 포인트컷은 클래스 선정을 위한 클래스 필터와 메소드 선정을 위한 메소드 매처 두 가지를 각각 제공해야 한다. 하지만 AspectJExpressionPointcut은 클래스와 메소드의 선정 알고리즘을 포인트컷 표현식을 이용해 한 번에 지정할 수 있게 해준다. 포인트컷 표현식은 자바의 RegEx 클래스가 지원하는 정규식처럼 간단한 문자열로 복잡한 선정조건을 쉽게 만들어낼 수 있는 강력한 표현식을 지원한다. 사실 스프링이 사용하는 포인트컷 표현식은 AspectJ라는 유명한 프로엠워크에서 제공하는 것을 가져와 일부 문법을 확장해서 사용하는 것이다. 포인트컷 표현식을 이용하는 포인트컷 적용포인트컷 표현식은 메소드의 시그니처를 비교하는 방식인 execution() 외에도 몇 가지 표현식 스타일을 갖고 있다. 대표적으로 스프링에서 사용될 때 빈의 이름으로 비교하는 bean()이 있다. 또 특정 애노테이션이 타입, 메소드, 파라미터에 적용되어 있는 것을 보고 메소드를 선정하게 하는 포인트컷도 만들 수 있다. 애노테이션만 부여해놓고, 포인트컷을 통해 자동으로 선정해서, 부가기능을 제공하게 해주는 방식은 스프링 내에서도 애용되는 편리한 방법이다. 클래스 이름은 ServiceImpl로 끝나고 메소드 일므은 upgrade로 시작하는 모든 클래스에 적용되도록 하는 표현식을 만들고 이를 적용한 빈 설정은 다음과 같다. 123&lt;bean id=\"transactionPointcut\" class=\"org.springframework.aop.aspectj.AspectJExpressionPointcut\"&gt; &lt;property name=\"expression\" value\"execution(* * .. *ServiceImpl.upgrade*(..))\" /&gt;&lt;/bean&gt; AOP란 무엇인가?AOP: 애스펙트 지향 프로그래밍부가기능 모듈화 작업은 기존의 객체지향 설계 패러다임과는 구분되는 새로운 특성이 있다고 생각했다. 그래서 이런 부가기능 모듈을 객체지향 기술에서는 주로 사용하는 오브젝트와는 다르게 특별한 이름으로 부르기 시작했다. 그것이 바로 애스펙트(aspect)다. 애스펙트란 그 자체로 애플리케이션의 핵심기능을 담고 있지는 않지만, 애플리케이션을 구성하는 중요한 한 가지 요소이고, 핵심기능에 부가되어 의미를 갖는 특별한 모듈을 가리킨다. 애스펙트는 부가될 기능을 정의한 코드인 어드바이스와, 어드바이스를 어디에 적용할지를 결정하는 포인트컷을 함께 갖고 있다. 독립된 측면에 존재하는 애스팩트로 분리한 덕에 핵심기능은 순수하게 그 기능을 담은 코드로만 존재하고 독립적으로 살펴볼 수 있도록 구분된 면에 존재하게 된 것이다. 이렇게 애플리케이션의 핵심적인 기능에서 부가적인 기능을 분리해서 애스펙트라는 독특한 모듈로 만들어서 설계하고 개발하는 방법을 애스펙트 지향 프로그래밍(Aspect Oriented Programming) 또는 약자로 AOP라고 부른다. AOP는 OOP를 돕는 보조적인 기술이지 OOP를 완전히 대체하는 새로운 개념은 아니다. AOP는 애스펙트를 분리함으로써 핵심기능을 설계하고 구현할 때 객체지향적인 가치를 지킬 수 있도록 도와주는 것이라고 보면 된다. AOP를 관점 지향 프로그래밍이라고도 한다. AOP 적용기술바이트코드 생성과 조작을 통한 AOP프록시 방식이 아닌 AOP도 있다. AOP 기술의 원조이자, 가장 강력한 AOP 프레임워크로 꼽히는 AspectJ는 프록시를 사용하지 않는 대표적인 AOP 기술이다. AspectJ는 스프링처럼 다이내믹 프록시 방식을 사용하지 않는다. AspectJ는 프록시처럼 간접적인 방법이 아니라, 타깃 오브젝트를 뜯어고쳐서 부가기능을 직접 넣어주는 직접적인 방법을 사용한다. 컴파일된 타깃의 클래스 파일 자체를 수정하거나 클래스가 JVM에 로딩되는 시점을 가로채서 바이트코드를 조작하는 복잡한 방법을 사용한다. AspectJ가 프록시 같은 방법이 있지만 컴파일된 클래스 파일 수정이나 바이트코드 조작과 같은 복잡한 방법을 사용하는 것에는 두 가지 이유가 있다. 바이트코드를 조작해서 타깃 오브젝트를 직접 수정해버리면 스프링과 같은 DI 컨테이너의 도움을 받아서 자동 프록시 생성 방식을 사용하지 않아도 AOP를 적용할 수 있기 때문. 프록시 방식보다 훨씬 강력하고 유연한 AOP가 가능하기 때문. 바이트코드를 직접 조작해서 AOP를 적용하면 오브젝트의 생성, 필드 값이 조회와 조작, 스태틱 초기화 등의 다양한 작업에 부가기능을 부여해줄 수 있다. 트랜잭션 속성트랜잭션이라고 모두 같은 방식으로 동작하는 것이 아니다. DefaultTransactionDefinition이 구현하고 있는 TransactionDefinition 인터페이스는 트랜잭션 동작방식에 영향을 줄 수 있는 4가지 속성을 정의하고 있다. 트랜잭션 전파트랜잭션의 경계에서 이미 진행 중인 트랜잭션이 있을 때 또는 없을 때 어떻게 동작할 것인가를 결정하는 방식 격리수준모든 DB 트랜잭션은 격리수준(isolation level)을 갖고 있다. 격리수준은 기본적으로 DB에 설정되어 있지만 JDBC 드라이버나 DataSource 등에서 재설정할 수 있고, 필요하다면 트랜잭션 단위로 격리수준을 조정할 수 있다. 제한시간트랜잭션을 수행하는 제한시간(timeout)을 설정할 수 있다. DefaultTransactionDefinition의 기본 설정은 제한시간이 없다. 읽기전용읽기전용(read only)으로 설정해두면 트랜잭션 내에서 데이터를 조작하는 시도를 막아줄 수 있다. 또한 데이터 액세스 기술에 따라서 성능이 향상될 수도 있다. 포인트컷과 트랜잭션 속성의 적용 전략프록시 방식 AOP는 같은 타깃 오브젝트 내의 메소드를 호출할 때는 적용되지 않는다이건 전략이라기보다는 주의사항이다. 프록시 방식의 AOP에서는 프록시를 통한 부가 기능의 적용은 클라이언트로부터 호출이 일어날 때만 가능하다. 여기서 클라이언트는 인터페이스를 통해 타깃 오브젝트를 사용하는 다른 모든 오브젝트를 말한다. 반대로 타깃 오브젝트가 자기 자신의 메소드를 호출할 떄는 프록시를 통한 부가기능의 적용이 일어나지 않는다. 따라서 같은 오브젝트 안에서의 호출은 새로운 트랜잭션 속성을 부여하지 못한다는 사실을 의식하고 개발할 필요가 있다. 타깃 안에서의 호출에는 프록시가 적용되지 않는 문제를 해결할 수 있는 방법은 두 가지가 있다. 스프링 API를 이용해 프록시 오브젝트에 대한 레퍼런스를 가져온 뒤에 같은 오브젝트의 메소드 호출도 프록시를 이용하도록 강제하는 방법(별로 추천되지 않음) AspectJ와 같은 타깃의 바이트코드를 직접 조작하는 방식의 AOP 기술을 적용하는 방법 트랜잭션 속성 적용트랜잭션 경계설정의 일원화트랜잭션 경계설정의 부가기능을 여러 계층에서 중구난방으로 적용하는 건 좋지 않다. 일바적으로 특정 계층의 경계를 트랜잭션 경계와 일치시키는 것이 바람직하다. 비즈니스 로직을 담고 있는 서비스 계층 오브젝트의 메소드가 트랜잭션 경계를 부여하기에 가장 적절한 대상이다. 트랜잭션 지원 테스트선언적 트랜잭션과 트랜잭션 전파 속성AOP를 이용해 코드 외부에서 트랜잭션의 기능을 부여해주고 속성을 지정 할 수 있게 하는 방법을 선언적 트랜잭션이라고 한다. 반대로 TransactionTemplate이나 개별 데이터 기술의 트랜잭션 API를 사용해 직접 코드 안에서 사용하는 방법은 프로그램에 의한 트랜잭션이라고 한다. 스프링은 이 두 가지 방법을 모두 지원하고 있다. 물론 특별한 경우가 아니라면 선언적 방식의 트랜잭션을 사용하는 것이 바람직하다. 트랜잭션 매니저와 트랜잭션 동기화트랜잭션 추상화 기술의 핵심은 트랜잭션 매니저와 트랜잭션 동기화다. PlatformTransactionManager 인터페이스를 구현한 트랜잭션 매니저를 통해 구체적인 트랜잭션 기술의 종류에 상관없이 일관된 트랜잭션 제어가 가능했다. 또한 트랜잭션 동기화 기술이 있었기에 시작된 트랜잭션 정보를 저장소에 보관해뒀다가 DAO에서 공유할 수 있었다. 트랜잭션 동기화 기술은 트랜잭션 전파를 위해서도 중요한 역할을 한다. 진행 중인 트랜잭션이 있는지 확인하고, 트랜잭션 전파 속성에 따라서 이에 참여할 수 있도록 만들어주는 것도 트랜잭션 동기화 기술 덕분이다. JdbcTemplate과 같이 스프링이 제공하는 데이터 액세스 추상화를 적용한 DAO에도 동일한 영향을 미친다. JdbcTemplate은 트랜잭션이 시작된 것이 있으면 그 트랜잭션에 자동으로 참여하고, 없으면 트랜잭션 없이 자동커밋 모드로 JDBC 작업을 수행한다. 개념은 조금 다르지만 JdbcTemplate의 메소드 단위로 마치 트랜잭션 전파 속성이 REQUIRED인 것처럼 동작한다고 볼 수 있다. 정리 트랜잭션 경계설정 코드를 분리해서 별도의 클래스로 만들고 비즈니스 로직 클래스와 당일한 인터페이스를 구현하면 DI의 확장 기능을 이용해 클라이언트의 변경 없이도 깔끔하게 분리된 트랜잭션 부가기능을 만들 수 있다. 트랜잭션처럼 환경과 외부 리소스에 영향을 받는 코드를 분리하면 비즈니스 로직에만 충실한 테스트를 만들 수 있다. 목 오브젝트를 활용하면 의존관계 속에 있는 오브젝트도 손 쉽게 고립된 테스트로 만들 수 있다. DI를 이용한 트랜잭션의 분리는 데코레이터 패턴과 프록시 패턴으로 이해될 수 있다. 번거로운 프록시 클래스 작성은 JDK의 다이내믹 프록시를 사용하면 간단하게 만들 수 있다. 다이내믹 프록시는 스태틱 팩토리 메소드를 사용하기 때문에 빈으로 등록하기 번거롭다. 따라서 팩토리 빈으로 만들어야 한다. 스프링은 자동 프록시 생성 기술에 대한 추상화 서비스를 제공하는 프록시 팩토리 빈을 제공한다. 프록시 팩토리 빈의 설정이 반복되는 문제를 해결하기 위해 자동 프록시 생성기와 포인트 컷을 활용할 수 있다. 자동 프록시 생성기는 부가기능이 담긴 어드바이스를 제공하는 프록시를 스프링 컨테이너 초기화 시점에 자동으로 만들어준다. 포인트컷은 AspectJ 포인트컷 표현식을 사용해서 작성하면 편리하다. AOP는 OOP만으로는 모듈화하기 힘든 부가기능을 효과적으로 모듈화하도록 도와주는 기술이다. 스프링은 자주 사용되는 AOP 설정과 트랜잭션 속성을 지정하는데 사용할 수 있는 전용 태그를 제공한다. AOP를 이용해 트랜잭션 속성을 지정하는 방법에는 포인트컷 표현식과 메소드 이름 패턴을 이용하는 방법과 타깃에 직접 부여하는 @Transactional 애노테이션을 사용하는 방법이 있다. @Transactgional을 이용한 트랜잭션 속성을 테스트에 적용하면 손쉽게 DB를 사용하는 코드의 테스트를 만들 수 있다. 참고토비의 스프링 3.1 Vol. 1 스프링의 이해와 원리","link":"/2018/04/15/Spring/toby-6/"},{"title":"그레이들 기초","text":"그레이들그루비와 그레이들그루비 는 자바 가상머신에서 동작하는 오픈 소스 스크립트 언어이다. 그루비는 자바 문법을 더욱 쉽게 쓰기 위해 스크립트 언어와 비슷한 문법으로 되어 있어서, 대부분의 자바 프로그래머는 자바 코드를 작성하는 느낌으로 그루비를 작성할 수 있다. 동적 언어이며 자바와 달리 작성한 스크립트를 컴파일할 필요 없이 직접 실행할 수도 있다. 또한, 일부 자바 프레임워크에서는 그루비를 지원한다. 대표적인 스프링 프레임워크에서도 그루비를 이용할 수 있다. 이처럼 자바와 거의 같고, 스크립트 언어처럼 부담 없이 작성해서 바로 실행할 수 있는 특징을 고려하면, 그루비를 사용해서 자바 빌드 도구를 만들려는 생각은 자연스럽다. 그루비의 이러한 이점을 최대한 활용해서 개발한 빌드 도구가 그레이들 이다. 그레이들이란그레이들은 그루비를 사용한 빌드 도구이다. 메이븐은 XML을 이용하여 빌드 정보를 기술했는데, 그레이들은 그루비를 이용해 빌드 정보를 기술하기 한다. 때문에 자바 프로그래머가 좀 더 쉽게 다룰 수 있다. 그레이들의 특징은 다음과 같다. 유연한 언어로 기술그루비라는 프로그래밍 언어를 사용해서 기술하기 때문에 유연하게 각종 처리를 수행할 수 있다. 또한 기술하는 내용을 분할하거나 구조화하는 것도 간단하다. 태스크로 처리그레이들은 ‘태스크’라는 개념을 이용해 프로그램을 작성한다. 다양한 용도별로 태스크를 만들어서 그 안에 처리를 기술한다. 자바/그루비/스칼라 기본 지원 + 알파그레이들은 자바 가상 머신에서 동작하는 언어를 중심으로 지원한다. (별도의 네이티브 코드 플러그인을 사용하면 C/C++ 등, 다른 언어에도 대응할 수 있다.) 각종 도구와 통합여러 도구들(앤트, 아파치 아이비 등)과 통합되어 처리를 실행할 수 있다. 또한, 메이븐의 pom.xml을 그레이들용으로 변환하는 도구도 있다. 메이븐 중앙 저장소 대응그레이들에서는 메이븐 중앙 저장소를 지원하기 때문에, 중앙 저장소에 있는 라이브러리 모두 그대로 이용 가능하다. 그레이들 사용하기그레이들 소프트웨어에는 그루비가 포함되어 있기 때문에, 단지 그레이들을 사용하는 용도라면 그루비를 설치할 필요는 없다. (그레이들을 설치하는 것만으로는 그루비 언어를 이용해서 프로그래밍할 수는 없다.) 그레이들 프로젝트 생성그레이들 명령어를 사용해 프로젝트를 생성할 수 있다. 123mkdir gradle-appcd gradle-appgradle init --type java-library gradle init 그레이들 명령어는 gradle OO 형태로 실행한다. 위에서 프로젝트를 생성하며 사용한 init은 그레이들에서 '태스크' 라고 부른다. 이 init은 프로젝트의 기본적은 파일과 폴더를 생성한다. –type은 생성할 프로젝트의 타입을 지정하는 옵션인데, java-library는 자바 프로젝트임을 나타낸다. 지정한 언어의 샘플 코드를 생성한다. 이 옵션을 생략하면 그레이들 프로젝트의 기본적인 파일들만 생성된다. 그레이들 실행과 태스크 그레이들에서는 다양한 처리를 위해 ‘태스크’를 이용한다. 태스크란, 실행할 처리를 모아놓은 단위로 그레이들에서 처음부터 포함된 것도 있고, 프로그래머가 작성할 수도 있다. 이 태스크를 실행하는 것이 그레이들에서 빌드를 관리하는 기본적인 방법이다. 프로젝트를 컴파일하거나, 실행하는 모든 처리에 태스크를 이용한다. 생성된 gradle-app 폴더 내부의 구조를 살펴보자. .gradle 폴더 : 태스크로 생성된 파일 등을 보존한다. gradle 폴더 : 기본값으로는 그레이들 환경을 모아놓은 wrapper 파일이라고 하는 파일들이 들어 있다. src 폴더 : 소스 코드 관련 파일을 이곳에 작성한다. build.gradle : 그레이들 빌드 파일, 이곳에 프로젝트의 빌드 내용을 기술한다. settings.gradle : 빌드 설정 정보를 기술한 파일. 빌드를 실행하기 전에 읽히기 때문에, 필요한 라이브러리를 읽는 등의 기술을 할 수 있다. 이번에는 생성된 파일의 코드를 확인해보자. build.gradle 123456789101112131415// 자바 프로그램을 빌드할 경우에는 java 플러그인을 로드한다.apply plugin: 'java'// 저장소 정보를 관리하는 프로퍼티이다. 이곳에서 저장소를 설정할 수 있다. (로컬 환경이나 원격 저장소 기술)// jcenter는 그레이들에서 중앙 저장소로 이용되는 저장소이다.// 메이븐 중앙 저장소는 mavenCentral 메서드를 이용해서 사용할 수 있다.repositories { jcenter()}// 의존성에 관한 설정을 관리하는 프로퍼티이다. 필요한 라이브러리등의 정보를 기술한다.dependencies { compile 'org.slf4j:slf4j-api:1.7.21' testCompile 'junit:junit:4.12'} settings.gradle 12// 루트 프로젝트의 이름을 설정한다. 루트 프로젝트는 다수의 프로젝트를 관리할 때 기본이 되는 프로젝트를 가리킨다. 여기에서는 '이 빌드 파일로 빌드할 프로젝트의 이름'이라고 생각하면 된다.rootProject.name = 'gradle-app' 인텔리제이에서 사용하기인텔리제이는 표준으로 그레이들을 지원한다. 인텔리제이에서 그레이들용 프로젝트를 생성할 경우, gradle init –type java-library 명령어를 사용하는 경우와 결과가 조금 다르다. build.gradle 1234567891011121314group 'com.jongmin'version '1.0-SNAPSHOT'apply plugin: 'java'sourceCompatibility = 1.8repositories { mavenCentral()}dependencies { testCompile group: 'junit', name: 'junit', version: '4.12'} 시작 부분에 그룹 ID와 버전을 지정하는 문장이 포함되어 있다. gradle init으로 작성한 build.gradle에서는 포함되지 않았는데, 그 이유는 메이븐 저장소를 이용하기 때문이다. 메이븐에는 모든 프로그램에 그룹 ID와 아티팩트 ID가 할당되어 있다. sourceCompatibility는 자바 소스 코드의 버전을 가리킨다. 태스크 실행메이븐과 마찬가지로 실행할 내용을 ‘Run…’ -&gt; ‘Edit Configurations’ 메뉴에서 컨피그레이션에 설정하면 인텔리제이의 ‘Run’으로 프로그램의 빌드와 실행, 디버그 등의 기능을 수행할 수 있다. build.gradle그래이들은 build.gradle에 기술한 코드를 필요에 따라 실행하여 빌드를 실행한다. 그레이들은 ‘그루비를 사용하는 빌드 도구’이다. 하지만 이는 정확한 설명은 아니다. 그레이들은 ‘그루비 그 자체’는 아니고 ‘그루비 기반의 DSL(Domain Specific Language)’이다. DSL은 ‘도메인 고유 언어’라고 불리는데, 특정한 용도에 한정된 언어를 말한다. 그 언어 그 자체는 아니고, 특정한 용도에 맞게 해당 언어를 기반으로 각색한 것이다. 그레이들에서 사용되는 언어는 ‘그루비를 기반으로 작성된 Gradle DLS’이다. 그레이들은 기본적으로 태스크를 작성하여 실행한다. 태스크는 실행할 처리를 모아서 명령어로서 실행할 수 있게 한 것이다. 다음과 같은 형식으로 정의한다. 123task 이름{ ...실행할 처리...} 이렇게 정의한 태스크는 명령행에서 gradle 이름 형태로 실행할 수 있다. 간단한 예제를 작성해 실행해보자. 다음과 같이 build.gradle을 수정한다. 123456789task hello { doLast { println(); println(\"=================\"); println(\"Welcome to Gradle!\"); println(\"=================\"); println(); }} 수정한 후, 명령행에서 다음과 같이 실행한다. 1gradle hello 결과는 다음과 같다. 12345678&gt; Task :hello=================Welcome to Gradle!=================BUILD SUCCESSFUL in 2s1 actionable task: 1 executed 그레이들은 기본적으로 빌드 도구이지만, 여기에서는 빌드도 컴파일도 하지 않고, 단지 메시지를 표시했다. 태스크는 작성된 처리를 실행할 뿐이지, 반드시 빌드와 관련된 기능이 포함되어야 하는 것은 아니다. quiet 모드로 실행이번에는 quiet 모드로 실행해보자. 1gradle -q hello 결과는 다음과 같다. 123=================Welcome to Gradle!================= 이렇게 하면 hello에서 println한 내용만 출력되며, 그 이외의 내용은 표시되지 않는다. -q 옵션은 태스크를 quiet 모드로 실행해 예외 발생 등 중요한 문제 이외의 표시가 제한된다. 태스크의 실행 결과만 알고 싶을 때 편리한 옵션이다. 액션 리스트 태스크는 다양한 ‘액션’을 내부에 가지고 있다. 태스크를 실행하면 준비된 액션이 순서대로 실행된다. 이 액션을 관리하는 것이 ‘액션 리스트’이다. 액션은 어떤 역할을 하는지가 정해져 있다. 필요에 따라 액션에 처리를 추가해 태스크를 조합할 수 있다. 액션 중에서도 doFirst와 doLast가 가장 많이 사용된다. 각각 ‘처음에 실행되는 액션’과 ‘마지막에 실행되는 액션’이다. 이들을 이용해 태스크의 처음과 마지막에 처리를 실행할 수 있다. 매개변수 이용태스크를 실행할 때 어떤 정보를 태스크에 전달하고 싶은 경우도 있다. 이럴 때 매개변수를 이용할 수 있다. 123456789task hello { doLast { def total = 0; for(def i in 1..num.toInteger()) { total += i; } println(\"total: \" + total); }} 1에서 num까지 합하는 태스크이다. 여기서 사용되는 num이 매개변수로 전달되는 프로퍼티이다. 이처럼 매개변수에서 전달되는 값을 프로퍼티로 사용할 수 있다. 단, 주의할 점은 값이 String이라는 것이다. hello 태스크는 다음과 같이 실행한다. 1gradle hello -q -Pnum=100 이처럼 태스크를 실행하는 동안에는 -P프로퍼티=값 형태로 특정 변수에 값을 전달할 수 있다. 동적 태스크 실행스크립트를 사용해서 동적으로 태스크를 생성할 수도 있다. 12345678def arr = [\"one\", \"two\", \"three\"];arr.each {s -&gt; task \"$s\" { doLast { println(\"this is $s task.\"); } }} 다음과 같이 실행한다. 1gradle -q one java 플러그인 사용하기자바로 개발할 때 필요한 기본적인 기능은 ‘java’ 플러그인에 포함되어 있다. build.gradle에서 로드하여 이용한다. 1apply plugin: 'java' 다음의 명령어로 빌드한다. 1gradle java 위 명령어를 실행하면 프로젝트가 컴파일되고 JAR 파일이 생성된다. 컴파일로 생성된 파일들은 build 폴더에 보관된다. 이 안의 libs 폴더 안에 gradle-app.jar 파일이 생성된다. build 폴더 안에는 classes 폴더도 있는데, 여기에는 컴파일된 클래스 파일이 보관된다. gradle java에서는 우선 소스 코드를 컴파일하여 클래스 파일을 작성한 후, 이를 모아서 JAR 파일로 만드는 일련의 처리가 자동으로 수행된다. gradle java와 gradle build grade java는 자바 프로그램의 빌드를 수행하지만, gradle build는 어떤 언어로 작성된 프로젝트라도 빌드한다. (그레이들은 자바 이외에도 그루비나 스칼라 등 많은 언어를 지원하고 각각의 언어에서 빌드를 수행하는 플러그인을 제공한다.) java 플러그인의 태스크java 플러그인에는 이 외에도 몇 가지 태스크가 더 있다. java자바 소스 코드를 컴파일하고 그 외에 필요한 리소스 파일들을 모아서 JAR 파일을 생성한다. 프로그램을 배포할 때 이 태스크로 JAR 파일을 만들면 유용하다. 단, 이 java 태스크로 생성된 JAR 파일은 Executable이 아니라는 점에 주의해야 한다. compileJava자바 소스 코드를 모두 컴파일한다. 보존할 장소(build 안의 classes 폴더)가 없다면 폴더를 자동으로 생성하고 그 안에 클래스 파일을 작성한다. processResources리소스 파일을 클래스 디렉터리(classes 폴더) 안에 복사한다. classes소스 코드 컴파일과 리소스 파일 복사를 실행한다. compileJava와 processResources가 합쳐진 것이라 생각해도 된다. test프로그램 테스트를 실행한다. 소스 코드와 관련된 컴파일을 수행하고 테스트에 필요한 리소스 복사 등을 수행한 뒤 JUnit으로 테스트를 실행한다. JUnit 라이브러리를 이용할 수 없는 상태에서는 테스트를 실행할 때 오류가 발생한다. jar프로그램을 컴파일하고 리소스 파일 등을 준비한 뒤, JAR 파일로 패키징한다. 단, 파일을 단순히 JAR 파일에 모을 뿐이며 Executable jar을 작성하는 것은 아니다. javadoc소스 코드를 해석하여 Javadoc 파일을 생성한다. build 안의 docs 폴더 안에 javadoc 폴더를 작성하여 파일을 보관한다. clean빌드로 생성된 파일을 모두 삭제한다. java 플러그인의 태스크 이용하기12345task doit(dependsOn: [compileJava, jar]) { doLast { println \"*** compiled and created jar! ***\" }} doit 태스크에는 매개변수가 포함되어 있다. dependsOn은 이 매개변수가 ‘의존성’을 지정하는 것을 가리킨다. ‘compileJava, jar’은 2개의 태스크를 모아놓은 배열이다. 즉, doit이 compileJava와 jar이라는 2개의 태스크에 의존한다. 이 상태에서 dependsOn에서 태스크를 지정하면 그 태스크가 실행되기 전에 의존하는 모든 태스크가 실행된다. 그리고 의존하는 태스크의 실행이 완료된 후에 doit 태스크의 doLast가 호출된다. 의존성을 지정해서 실행하는 방법 이외에 태스크를 직접 실행할 수도 있는데, 태스크의 execute 메서드를 호출하면 된다. 12345678task doit { doLast { println \"*** compiled now! ***\" tasks.compileJava.execute() println \"*** create jar! ***\" tasks.jar.execute() }} 실행하면 의존성을 지정해서 실행할 때와 같은 결과를 얻지만, “Deprecated Gradle features were used in this build, making it incompatible with Gradle 5.0.” 라는 메시지가 출력된다. 그레이들 버전 5.0 부터는 execute 메서드를 직접 호출하는 것이 호환되지 않기 때문이다. application 플러그인java 플러그인에는 프로그램을 실행하는 태스크가 없어 application 플러그인을 사용해 애플리케이션을 실행해야 한다. 1apply plugin: 'application\" build.gradle에 이처럼 작성하고 그 다음에 mainClassName 프로퍼티에 메인 클래스(실행할 클래스)를 설정한다. 1mainClassName = \"com.jongmin.gradle.App\" application 플러그인에는 run 태스크가 포함되어 있다. 이것을 실행하면 mainClassName에 지정된 클래스가 실행된다. 1gradle run 다음과 같이 작성하면 jar을 실행한 후 run으로 클래스를 실행할 수 있다. 12345678910apply plugin: 'java'apply plugin: 'application'mainClassName = \"com.jongmin.gradle.App\"task doit(dependsOn:[jar, run]) { doLast { println(\"*** do it! ***\") }}","link":"/2018/08/08/Tool/gradle_basic/"},{"title":"소나큐브","text":"해당 포스팅은 ‘자바 필수 프로젝트 유틸리티‘ 책의 8.3 소나큐브 부분을 참고해 작성했습니다. 소나큐브소나큐브를 사용해서 작성한 코드를 정적 분석하고 작성한 테스트로 얼마나 검증했는지 측정할 수 있다. 소나큐브를 로컬 환경에 설치하고 젠킨스와 소나큐브를 연결해서 소나큐브의 기본 퀄리티 게이트(Quality Gate)를 실행시켜보자. 퀄리티 게이트는 조직의 모든 소스가 통과해야만 하는 소스의 품질을 정의해둔 것으로 소스의 품질을 보증하는 수단으로 이용된다. 기능과 특징소나큐브의 주요 기능은 아래와 같다. 복잡도 확인 코드 중복 검출 코딩 규칙 확인 잠재적 버그 검출 단위 테스트 커버리지 소나큐브 자체에서 지원하는 심플한 UI를 이용해 프로젝트의 소스 코드가 얼마나 개선되고 있는지를 직관적으로 확인할 수 있다. 소나큐브의 특징은 다음과 같다. 서버는 크게 웹 서버, 검색 서버, 연산 서버로 구성된다. 데이터베이스는 소나큐브 자체의 설정과 각 프로젝트의 정보가 저장된다. 플러그인을 추가할 수 있다. 소나큐브 스캐너(SonarQube Scanner)로 코드를 분석한다. 설치brew를 이용해 설치 후 실행한다. 12$ brew install sonarqube$ brew services start sonarqube brew를 이용해 설치하게 되면 다음과 /usr/local/Cellar/sonarqube/7.2.1/libexec/conf 디렉터리에 설치된다. 각 디렉터리의 역할은 다음과 같다. bin : 운영체제별 실행파일이 있다. conf : 소나큐브의 설정 팡리이 있다. 설정 파일에서 데이터베이스 연결과 웹 서버의 설정 등을 한다. data : 기본 데이터베이스인 H2 데이터베이스를 사용할 때 데이터가 저장되는 곳이다. 테스트 목적이 아니라면, 실제 운영할 때는 다른 데이터베이스를 사용해야 한다. elasticsearch : 루씬 기반의 검색 엔진인 elasticsearch가 포함되어 있다. extensions : jdbc-driver와 플러그인이 포함된다. lib : 실제 애플리케이션 바이너리가 포함되어 있다. logs : 각 로그가 출력되는 디렉터리이다. 설정 파일에서 변경 가능하다. temp : 서버 실행 시에 필요한 임시 파일이 저장된다. 실행 중에 삭제하면 안된다. web : UI에 필요한 이미지와 CSS, JS 파일이 있다. 실행 후 http://localhost:9000에 접속하면 다음과 같은 화면을 볼 수 있다. 관리자로 접속해서 젠킨스와 연결할 사용자를 만들어 보자. 오른쪽 상단 위에 있는 ‘Log in’ 을 클릭한 후 초기 ID/PW인 admin/admin을 입력해서 로그인한다. 로그인이 완료되면 튜토리얼 페이지가 나온다. 우측 상단의 ‘Skip this tutorial’ 을 클릭해서 스킵한다. 아래와 같이 프로젝트 페이지를 확인할 수 있다. 젠킨스 사용자 생성젠킨스에서 소나큐브에 접속할 때 사용할 사용자를 생성한다. 화면 상단의 메뉴에서 ‘Administration’ -&gt; ‘Security’ -&gt; ‘Users’ -&gt; ‘Create User’ 를 클릭해서 사용자 생성 창을 출력한다. jenkins라는 이름으로 사용자를 생성한다. 젠킨스에서 접속할 때 사용할 토큰을 생성한다. 조금전 생성한 jenkins 유저의 ‘Token’ 을 클릭한다. ‘Enter Token Name’ 에 적당한 이름을 넣고 ‘Generate’ 버튼을 눌러서 생성한다. 생성된 토큰 앞에 있는 ‘Copy’ 버튼을 눌러 젠킨스에서 사용할 키를 저장한다. 소나큐브 스캐너 설정이번에는 젠킨스의 빌드 과정에서 소나큐브를 연동한다. ‘Jenkins 관리’ -&gt; ‘플러그인 관리’에서 ‘SonarQube Scanner’를 설치 한다. ‘Jenkins 관리’ -&gt; ‘시스템 설정’ 으로 이동하면, ‘SonarQube servers’ 라는 설정이 추가된것을 확인할 수 있다. 만약 플러그인을 설치했는데도 해당 설정이 표시되지 않는다면 젠킨스 서버를 재실행해본다. ‘Add SonarQube’ 를 클릭한다. ‘고급’ 버튼을 클릭한 후 시스템 환경 변수를 사용하도록 각각 다음과 같이 설정한다. Environment variables : 체크 박스 선택 Name : SonarQube-Local 입력 (스페이스와 한글을 입력하지 않는다.) Server URL : 소나큐브의 URL 입력(여기서는 default인 http://localhost:9000) Server authentication token : 소나큐브에서 생성한 토큰 입력 Additional analysis properties :sonar.sources=src sonar.java.binaries=target/classes, target/test-classes ‘저장’ 을 클릭해서 저장한다. 소나큐브 스캐너를 추가하는 작업을 진행한다. ‘Jenkins 관리’ -&gt; ‘Global Tool Configuration’ 을 클릭한다. ‘SonarQube Scanner for MSBuild’와 ‘SonarQube Scanner’ 아래의 버튼을 클릭해서 각각 스캐너를 추가한다. ‘Name’에 적당한 이름을 넣고 ‘Install automatically’ 가 체크되어 있는지 확인 후 저장한다. 새로운 잡을 생성해서 테스트 해보자. 젠킨스 메인 페이지에서 ‘새로운 Item’을 클릭하고 잡 이름에 ‘SonarQubeTset’를 입력하고 ‘Freestyle project’를 선택 후 저장 버튼을 클릭한다. 소스 코드 관리 : 테스트 프로젝트의 깃허브 주소를 넣는다. (여기서는 ‘자바 필수 프로젝트 유틸리티‘ 책에서 제공한 ‘spring-mvc-example‘ 프로젝트를 fork해 사용했다.) Credentials : 저장되어 있는 자격증명에서 선택한다. 빌드 환경에서 ‘Prepare SonarQube Scanner environment’를 선택한다. (이번 테스트에서는 필요하지는 않지만, ‘빌드 환경’에서 호나경 변수를 사용할 수 있게 하려고 체크하는 것이다.) Build : ‘Invoke top-level Maven targets’를 선택한다. Goals : ‘clean install’을 입력한다. (다른 골을 추가해도 된다.) 다시 Build의 ‘Add build step’을 클릭해서 ‘Execute SonarQube Scaner’를 추가한 후 ‘Analysis properties’에 아래의 정보를 입력한다. 123sonar.projectKey=spring-mvc-examplesonar.projectName=spring-mvc-examplesonar.projectVersion=1.0.0 이 테스트에서는 고정값으로 입력했지만 매개변수로 처리하거나 환경 변수에서 치환하는 방법도 많이 사용한다. ‘저장’ 버튼을 클릭해서 잡 대시보드로 이동한다. 소나큐브의 아이콘이 추가된것을 확인할 수 있다. 소나큐브 빌드‘Build Now’ 를 클릭해서 빌드한다. 정상 종료되면 ‘SonarQube Quality Gate’ 가 표시되고 실행 결과를 알려준다. 화면에 표시되는 ‘SonarQube’ 링크나 ‘OK’를 클릭하면 소나큐브의 대시보드로 이동한다. 상단의 메뉴에서 ‘Issues’, ‘Code’를 통해 각 결과를 확인할 수 있다.","link":"/2018/08/12/Tool/sonarqube/"},{"title":"빌드 도구와 메이븐","text":"빌드 도구빌드 도구란?개발 환경의 변화와 빌드자바를 처음 공부할 때는 이클립스 혹은 인텔리제이 같은 IDE만으로 프로그램을 뚝딱 만들 수 있다. 그러나 현업에 투입되면 무언가 복잡한 환경을 만나게 된다. 하지만 실제 자바 입문시절에 배운 과정과 현업에서 사용하는 과정에 차이는 없다. 다만 다양한 도구를 사용하여 더 전문화하여 현업 도구에 활용할 뿐이다. 명령행에서 컴파일하기아주 간단한 프로그램이라면 명령행에서 javac를 이용하는 것만으로도 충분하다. 하지만 라이브러리 등을 이용하면, classpath에 다수의 라이브러리 경로를 기술한 뒤에 컴파일 해야 한다. 또한 생성된 클래스 파일을 모아 JAR 파일을 생성하려면 이 역시 모두 명령어로 실행해야 한다.소스 코드의 컴파일에서 JAR 파일의 생성까지 긴 과정을 수행하려면 방대한 명령어가 필요한데, 이를 매번 수작업으로 작성하면 큰 수고가 든다. 프로젝트 및 라이브러리 설치최근에는 개발할 때 모든 프로그램을 처음부터 만드는 경우가 거의 없다. 프로그램에 필요한 기능은 라이브러리를 이용하거나, 프레임워크를 이용하여 애플리케이션을 개발한다.이런 경우, 필요한 소프트웨어를 갖추고 정해진 대로 파일을 구성해야 한다. 테스트 자동화단순한 프로그램이라면 컴파일 후 실행 및 동작만 확인하는 것으로 충분하지만, 어느 정도 규모 있는 프로그램은 프로그램 생성과 함께 테스트를 실행하는 것이 일반적이다. 프로그램 배포웹 애플리케이션은 구현한 프로그램을 서버에 배포하게 된다. 이런 작업을 수작업으로 시행하기가 번거롭다. 빌드 도구의 역할‘빌드 도구’는 단순히 프로그램을 컴파일하여 애플리케이션을 생성하는 작업 그 이상으로 다양한 기능을 제공한다. 프로그램 빌드프로그램을 컴파일하고, 지정된 디렉터리에 필요한 리소스를 모아서 프로그램을 완성한다. 그때 라이브러리등 필요한 파일을 설치하도록 지정할 수 있다. 프로그램 테스트와 실행빌드된 프로그램의 실행뿐 아니라 테스트 기능도 제공한다. 빌드를 실행 할 때, 빌드가 완료되면 곧바로 테스트를 실행하는 도구도 있다. 라이브러리 관리프로그램에서 필요한 라이브러리들을 관리한다. 빌드 실행 시 자동으로 라이브러리를 다운로드하고 설치하는 등의 작업을 한다. 배포 작업빌드한 프로그램을 배포하는 기능을 제공한다. 개발 도구와 빌드 도구개발 도구에 있어 빌드 도구를 다루는 방식은 크게 두 가지이다. 빌드 도구를 이용하는 기능이 포함된 경우이클립스는 메이븐, 인텔리제이는 메이븐과 그레이들을 지원한다. 개발 도구에서 명령어로 실행하는 경우 메이븐 기초메이븐은 아파치 소프트웨어 재단이 개발하는 오픈 소스 빌드 도구이다. ‘아파치 앤트(Ant)’의 후속으로 개발되었고, 자바 프로그램 개발을 대상으로 한 오픈 소스 빌드 도구이다. 메이븐 특징 빌드 파일은 XML로 작성 단위 작업 ‘골’골은 메이븐에서 실행하는 작업의 목적을 지정한다. 메이븐 명령어를 실행할 때 골을 지정하면, 어떤 작업을 수행하여 무엇을 작성할지 지정할 수 있다. 라이브러리 관리와 중앙 저장소빌드를 실행하는 사이에, 빌드 파일에 기술된 정보를 바탕으로 필요한 라이브러리를 자동으로 다운로드하여 포함시킨다. 이를 가능하게 하는 것이 중앙 저장소이다. 중앙 저장소는 메이븐에서 이용 가능한 라이브러리를 모아서 관리하는 웹 서비스이다. 테스트와 문서 생성엔트의 표준에는 포함되지 않았던 JUnit 테스트 및 Javadoc 문서 생성 등의 기능을 갖추고 있다. 플러그인을 이용한 확장플러그인을 사용하면 메이븐에 기능을 추가할 수 있다. 메이븐 프로젝트 생성메이븐에 포함된 archetype:generate라는 골을 이용하면, 간단하게 프로젝트의 기본 부분을 만들 수 있다. 아키타입(archetype)은 프로그램의 템플릿 모음이다. Intellij를 이용해서도 메이븐을 기반으로 프로그램을 빌드하는 프로젝트를 생성할 수 있다. New Project -&gt; 목록에서 Maven 선택 -&gt; Create from archetype 체크 -&gt; maven-archetype-quickstart 선택 메이븐에서는 mvn 명령어로 각종 조작을 할 수 있는데, 이 명령어들을 인텔리제이의 ‘Run’을 이용하여 실행할 수 있다. 실행할 내용을 컨피그레이션에 설정하면 인텔리제이의 ‘Run’으로 프로그램의 빌드와 실행, 디버그 등의 기능을 수행할 수 있다. (‘Run…’ -&gt; Edit Configurations’ 메뉴에서 설정 가능) pom.xmlpom.xml 파일에서 POM은 ‘Project Object Model’을 말한다. 이 파일에 프로젝트에 관한 각종 정보를 기술한다. &lt;project&gt;와 기본속성 모델 버전 1&lt;modeVersion&gt;4.0.0&lt;/modeVersion&gt; 기본적으로 메이븐은 하위 호환성을 지원하기 때문에 이후 새로운 버전이 되더라도 이곳의 버전 번호를 바꾸면 이외 부분은 크게 수정하지 않고도 사용할 수 있다. 그룹 ID 1&lt;groupId&gt;com.jongmin&lt;/groupId&gt; 그룹 ID는 작성할 프로그램이 어디에 소속되어 있는지를 나타낸다. 아티팩트 ID 1&lt;artifactId&gt;mvn-app&lt;/artifactId&gt; 그룹 ID와 함께 프로그램을 식별하는 데 사용된다. ID이기 때문에 같은 그룹 내에서 같은 프로젝트 이름이 중복되지 않도록 주의해야 한다. 버전 1&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; 메이븐을 사용하는 프로젝트를 빌드하거나 패키징한 경우 여기서 지정된 번호가 생성된 프로그램의 버전으로 설정된다. 보통은 생성된 JAR 파일의 파일명에도 사용된다. 패키지 종류 1&lt;packaging&gt;jar&lt;/packaging&gt; 보통은 jar을 지정하지만, zip이라고 지정하면 ZIP 파일로 패키징한다. 애플리케이션 이름 1&lt;name&gt;mvn-app&lt;/name&gt; 작성하는 애플리케이션의 이름을 지정한다. 그룹 ID나 아티팩트 ID와 달리 유일한 값일 필요가 없다. URL 1&lt;url&gt;http://maven.apache.org&lt;/url&gt; 기본값으로는 메이븐 사이트의 URL이 지정되어 있다. &lt;properties&gt;는 pom.xml에서 이용되는 속성값을 설정한다. 123&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt; 기본값으로는 &lt;project.build.sourceEncoding&gt;라는 항목이 설정되어 있는데 이는 소스 파일의 문자 인코딩 방식을 지정한다. &lt;dependencies&gt;와 의존성 설정dependencies 태크를 통해 필요한 라이브러리를 관리할 수 있다. 여기에 의존성을 적어두면 필요한 라이브러리 등을 자동으로 다운로드하여 설치 등을 할 수 있다. &lt;dependency&gt; 태그를 설정하는 것만으로 의존 라이브러리가 자동으로 로드되는 것은 메이븐의 중앙 저장소 때문이다. 중앙 저장소는 메이븐을 개발한 아파치 소프트웨어 재단이 운영하는 사이트이다. 기본적인 ‘골’메이븐은 골을 지정하여 실행할 처리의 역할을 정한다. 1mvn 골 compile 1mvn compile 자바 소스 코드 파일을 컴파일 한다. 프로젝트 폴더 내에 target 폴더가 생성된다. test-compile 1mvn test-compile 유닛 테스트용 클래스를 컴파일한다. src 폴더 안의 test 안에 작성된 유닛 테스트용 소스 코드 파일을 컴파일하여, target 폴더 안에 test-class 폴더를 작성하고 그 안에 클래스 파일을 생성한다. test 1mvn test 메이븐은 테스트(유닛 테스트)가 거의 표준 기능으로 포함되어 있다. 테스트를 개별적으로 실행하는 골이 test이다.작성한 유닛 테스트용 클래스를 이용하여 테스트가 실행되고 그 결과가 출력된다. package 1mvn package mvn compile을 실행하면 클래스 파일이 생성되지만, 일반적으로 자바 프로그램은 클래스파일을 그대로 배포하지는 않는다. 일반적으로 JAR 파일 등으로 패키징하여 배포한다. 명령 한 번으로 프로그램을 컴파일하여 유닛 테스트를 실행한 후 JAR 파일로 패키징하는 처리가 모두 자동적으로 수행된다. 실행 후 target 폴더 안에 jar 파일이 생성된다. clean 1mvn clean 메이븐은 프로그램을 빌드하면서 컴파일된 클래스 파일 뿐만 아니라, 테스트, 압축을 실행하는 파일 등을 만든다. clean은 부가적으로 생성된 파일을 모두 지운다. 프로그램 실행하기클래스가 하나인 코드는 java 명령어로도 쉽게 실행할 수 있다. 그러나 다양한 라이브러리를 이용하는 프로젝트에서는 모든 클래스 경로를 직접 지정해야 하기 때문에 java 명령어를 이용해 실행하는 일은 번거롭다. 메이븐에는 표준으로 자바 프로그램을 실행하는 골은 없다. 하지만 exec-java-plugin 플러그인을 이용하면 프로그램을 실행할 수 있다. pom.xml의 &lt;project&gt; 태그 안에 있는 &lt;dependencies&gt; 종료 태그의 다음 행에 다음과 같이 플러그인을 추가한다. 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0&lt;/version&gt; &lt;configuration&gt; &lt;mainClass&gt;com.jongmin.App&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 명령행에 다음과 같이 실행하면 App 클래스가 실행된다. 만약 mvn clean으로 프로젝트의 빌드 결과물을 제거한 경우 다시 mvn package로 빌드한 후에 실행한다. 1mvn exec:java exec-maven-plugin은 메인 클래스를 지정해야 한다. 플러그인에 정보를 지정할 때는 &lt;configuration&gt; 태그를 이용한다. 빌드 플러그인&lt;build&gt; 태그는 빌드에 관한 정보를 기술하는 태그이다. 형태는 다음과 같다. 1234567&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt;...&lt;/plugin&gt; &lt;plugin&gt;...&lt;/plugin&gt; ... &lt;/plugins&gt;&lt;/build&gt; &lt;build&gt;와 &lt;plugins&gt; 태그는 여러 개 사용할 수 없다. 반드시 1개씩 있고, 그 안에 모든 &lt;plugin&gt;을 모아서 사용한다. 메이븐의 골과 플러그인exec:java 골은 플러그인을 사용해 추가된 것이다. 사실, 지금까지 사용했던 모든 골들도 플러그인으로 추가된 것이다. compile : maven-compiler-plugin package : maven-jar-plugin test : maven-surefire-plugin 하지만 위의 플러그인은 표준으로 포함되어 있기 때문에 플러그인이라고 의식하지 못했던 것이다. 표준이 아닌 &lt;plugin&gt; 태그에 의해 추가된 플러그인의 골을 지정하는 경우에는 xx:xx와 같이 요소가 둘인 경우가 일반적이다. 플러그인 하나가 여러 골을 가질 수도 있기 때문에 ‘플로그인:골’ 형태로 기술한다. &lt;plugin&gt;이 필수는 아니다. 플러그인으로 추가하여 이용하는 골이라고 해서 &lt;plugin&gt;에 기술하지 않으면 사용하지 못하는 것은 아니다. &lt;plugin&gt;은 플러그인에 포함된 설정 등의 정보를 기술하는 태그이다. 그렇기 때문에 설정이 필요하지 않으면 기술할 필요가 없다. 인텔리제이에서 사용하기플러그인을 통해 개발 도구의 프로젝트로 변환이 가능하다. 1mvn idea:idea 위 골을 실행하면 인텔리제이에서 프로젝트를 다루는데 필요한 파일들이 생성된다. 1mvn idea:clean 인텔리제이 프로젝트에서 인텔리제이 관련 파일을 삭제하여 원래의 메이븐 프로젝트로 돌리려면 위의 골을 실행한다. 실행 가능한 JAR 파일 만들기앞서 mvn package로 패키징했지만 이렇게 생성된 JAR 파일은 단순히 패키징 된 것이기 때문에 실행되지는 않는다. 1java -jar 00.jar 따라서 위의 명렁을 실행해도 00.jar에 기본 Manifest 속성이 없어 실행에 실패하게 된다. 실행 가능한 JAR 파일을 만들기 위해서는 maven-jar-plugin을 이용해 다음과 같은 &lt;plugin&gt; 태그를 작성하면 된다. 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;버전&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;mainClass&gt;메인 클래스&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt;&lt;/plugin&gt; &lt;archive&gt; 태그는 압축에 관한 설정이다. addClasspath는 클래스 경로에 JAR 파일이 있는 경로를 추가하기 위한 태그인데 보통은 true로 지정한다. 이렇게 설정 후 다시 mvn package로 JAR 파일을 생성한 후 java -jar로 실행해보면 문제없이 실행할 수 있다. 저장소 이용&lt;dependency&gt; 를 추가하는 것만으로 필요한 라이브러리를 추가해 사용할 수 있었던 것은 중앙 저장소 때문이다. 그런데 저장소가 중앙 저장소만 있는 것은 아니다. 다른 원격 저장소나 로컬 저장소도 있다. 로컬 저장소자신이 만든 라이브러린, 그다지 유명하지 않은 라이브러리라면 아직 중앙 저장소에 공개되지 않을 수도 있다. 이러한 라이브러리는 로컬 저장소를 이용해 사용할 수 있다. 원격 저장소 : 네트워크를 거쳐 서버에 접속하여 이용하는 공개된 저장소. 중앙 저장소도 원격 저장소의 한 종류이다. 로컬 저장소 : 로컬 환경에 있는 저장소이다. 원격 저장소 이용원격 저장소는 pom.xml에 &lt;repositories&gt; 태그 안에 저장소 정보를 기술한다. 1234567&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;저장소 ID&lt;/id&gt; &lt;name&gt;이름&lt;/name&gt; &lt;url&gt;저장소 주소(URL)&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 로컬 저장소에 라이브러리 추가하기추가하고자 하는 라이브러리 프로젝트에서 다음과 같이 실행하면 target에 빌드된 JAR 파일을 로컬 저장소에 설치한다. 1mvn install 또는 설치할 JAR 파일이 별도로 준비되어 있다면 install:install-file 골을 실행해서 지정한 라이브러리 파일을 로컬 저장소에 설치할 수 있다. 123456mvn install:install-file-Dfile=\"라이브러리 jar의 경로\"-DgroupId=\"그룹 ID\"-DartifactId=\"아티팩트 ID\"-Dpackaging=\"패키징(jar)\"-Dversio=\"버전(1.0)\" 로컬 저장소의 위치 알아보기로컬 저장소의 위치는 다음과 같다. 1홈 디렉터리/.m2/repository 이 폴더에는 라이브러리가 그룹 ID마다 폴더로 정리되어 있다.","link":"/2018/08/06/Tool/maven_basic/"},{"title":"힙 정렬 (Heap sort) - 2","text":"저번 포스팅에서는 힙(Heap)과 max-heapify에 대해 알아보았습니다. 이번 포스팅에서는 직접 1차원 배열을 heap 구조로 변경한 후 힙 정렬을 해보겠습니다. 1차원 배열을 힙(Heap) 으로 만들기먼저 의사 코드는 다음과 같습니다.1234BUILD-MAX-HEAP heap-size[A]&lt;-length[A] for i &lt;- |length[A]/2| downto 1 do MAX-HEAPIFY(A,i) i가 A 배열의 길이 / 2 부터 시작하는 이유는 리프 노드에서는 max-heapify 과정이 필요 없기 때문입니다. 힙을 만드는데의 시간 복잡도는 다음과 같습니다.MAX-HEAPIFY 연산의 시간 복잡도는 log(n) 입니다. 그런데 for 문이 n/2 돌기 때문에 n/2*log(n)이며 빅 오로 표기하면 O(n*log(n))이 됩니다.이는 루트 노드만 고려하여 상당히 러프하게 계산한 것이기 때문에, 정확하게 계산한다면 시간 복잡도는 O(n)이 됩니다. 힙 정렬(Heap sort) 하기힙 정렬은 다음과 같은 순서로 실행됩니다.1) 주어진 데이터를 힙으로 만든다2) 힙에서 최대값(루트 노드)을 가장 마지막 값과 바꾼다.3) 힙의 크기가 1 줄어든 것으로 간주한다. 즉, 마지막 값은 힙의 일부가 아닌것으로 간주한다.4) 루트 노드에 대해서 HEAPIFY(1)한다.5) 2~4번을 반복한다. 데이터를 힙으로 만들면 인덱스 1의 값이 가장 최대값 이므로 마지막 값과 바꿉니다.그리고 마지막값은 정렬된 값으로 간주하고 더 이상 신경쓰지 않아도 됩니다.그렇게 줄여나간다면 결국 정렬된 상태의 배열이 완성됩니다. 힙 정렬의 의사 코드는 다음과 같습니다.123456HEAPSORT(A) BUILD-MAX-HEAP(A) // O(n) for i &lt;-heap-size downto 2 do // n-1 times exchange A[1] &lt;-&gt; A[i] // O(1) heap_size &lt;- heap_size -1 // O(1) MAX-HEAPIFY(A,1) // O(log(n)) 총 시간 복잡도는 nlogn이 됩니다. C++로 힙 정렬 구현하기다음과 같이 C++로 힙 정렬을 구현할 수 있습니다.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#define ITEM_SIZE 10using namespace std;void print_arr(int a[], int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; a[i] &lt;&lt; ' '; } cout &lt;&lt; '\\n';}void max_heapify(int a[], int size, int idx) { int left = idx * 2; int right = (idx * 2) + 1; int largest = idx; int tmp = 0; // 왼쪽 자식 노드와 비교 if (left &lt; size &amp;&amp; a[left] &gt; a[largest]) { largest = left; } // 오른쪽 자식 노드와 비교 if (right &lt; size &amp;&amp; a[right] &gt; a[largest]) { largest = right; } // 부모 노드보다 자식 노드가 큰 경우 교환 if (largest != idx) { tmp = a[largest]; a[largest] = a[idx]; a[idx] = tmp; // 재귀 호출 max_heapify(a, size, largest); }}void build_max_heap(int a[], int size) { for (int i = size / 2; i &gt; 0; i--) { max_heapify(a, size, i); }}void heap_sort(int a[], int size) { int tmp = 0; build_max_heap(a, size); for (int count = size - 1; count &gt; 0; count--) { // 루트 노드를 가장 마지막 노드와 교환 tmp = a[count]; a[count] = a[1]; a[1] = tmp; // 힙 구조 유지 max_heapify(a, count, 1); }}int main() { int a[ITEM_SIZE] = { 0, }; // 루트 노드는 1번 인덱스 부터 시작 for (int i = 1; i &lt; ITEM_SIZE; i++) { a[i] = (rand() % (ITEM_SIZE * 10)) + 1; } print_arr(a, ITEM_SIZE); heap_sort(a, ITEM_SIZE); print_arr(a, ITEM_SIZE); return 0;} 출처 : 2015 봄학기 알고리즘 - 부경대 권오흠 교수님","link":"/2017/11/19/Algorithm/Concept/heap-sort-2/"},{"title":"이진 탐색 (Binary Search)","text":"주어진 배열에서 특정한 요소(target) 을 찾아내는 상황을 가정해 봅시다. 가장 쉬운 방법은 각각의 배열 요소와 target 값을 같은지 순차적으로 모두 비교하는 것입니다. 만약 배열의 크기가 n이라고 했을때, 이 알고리즘의 시간복잡도를 Big-O notation을 이용해 나타낸다면 O(n)이 될 것 입니다.그러나 더 효율적이고 빠르게 target 을 찾아내는 방법이 있습니다. 이 방법은 매 탐색마다 target을 찾기위한 배열의 크기를 절반으로 줄여가면서 탐색을 하는 것입니다. 정확히는 기존의 배열은 유지하지만 탐색해야하는 범위를 계속 절반으로 줄이는 것입니다. 이런식으로 탐색하는 방법이 바로 이진 탐색(Binary Search) 알고리즘입니다. 다만 이진 탐색 알고리즘은 순차 탐색과는 달리 배열의 데이터들이 정렬된 상태에서만 적용할 수 있다는 특징이 있습니다. 정렬이 되지 않은 데이터는 이진 탐색을 적용할 수 없습니다.쉽게 생각해보면 만약 배열의 요소들이 정렬되지 않은 상태라면, 매 탐색마다 target을 찾기 위해 검사해야하는 배열의 범위를 줄이지 못할 것입니다. (정렬되어 있다 라는 기준이 없기 때문에 탐색해야 하는 배열의 시작과 끝 범위를 정할 수 있는 근거가 없기 때문입니다.) 이진 탐색 절차크기가 n인 리스트 data에서 target 이라는 특정 요소를 찾아낸다고 가정했을 때, 이진 탐색의 절차는 다음과 같습니다. (리스트는 오름차순으로 정렬되어 있습니다.) begin = 0, end = n − 1 로 초기화 합니다. mid 는 (begin + end) 를 2 로 나눈 몫으로 결정합니다. data[mid] 와 target 이 서로 같으면 목적을 달성했으므로 탐색을 종료합니다. 만약 target &lt; data[mid] 이면 end = mid-1 로 업데이트 한 후, 2번으로 돌아갑니다. 만약 target &gt; data[mid] 라면 begin = mid+1 로 업데이트 한 후, 2번으로 돌아갑니다. 위 과정에서 begin, end, mid는 리스트의 index를 의미합니다. 또한 target과 data[mid]의 대소관계에 따라 다음 탐색 방향을 선택하게 됩니다. 이 과정은 리스트의 요소가 오름차순인지 내림차순인지에 따라 다르게 구현됩니다. 먼저 코드를 작성하기 전에 그림과 함께 과정을 살펴보겠습니다. 위의 리스트에서 15라는 데이터를 탐색하겠습니다. 먼저 첫번째 과정으로 데이터 집합의 중앙 요소를 선택합니다. 두번째 과정으로는 중앙 요소의 값과 찾으려는 값을 서로 비교하게 되는데, 만약 찾으려는 값이 중앙 요소의 값보다 작다면 중앙 요소의 왼편에서 중앙 요소를 다시 선택하고, 반대로 찾으려는 값이 중앙 요소의 값보다 크다면 오른편에서 중앙 요소를 다시 선택합니다. 그리고 다시 이 과정을 반복하는 것입니다. 위의 경우에는 찾으려는 값인 15가 중앙값 9보다 크기 때문에 중앙값 왼편은 탐색할 필요가 없습니다. 따라서 중앙 요소의 오른편에서 다시 중앙값을 선택합니다. 이제는 중앙값이 17입니다. 중앙값이 찾고자 하는 값인 15보다 크기 때문에 중앙값 왼편에서 다시 테이터를 탐색합니다. 왼편에서 중앙값을 택합니다. 이제 중앙값과 찾고자 하는 데이터가 같기 때문에 탐색을 종료합니다. 이진 탐색 성능이진 탐색은 한번 비교를 할때마다, 탐색의 범위가 반으로 줄어듭니다. 데이터 리스트의 크기를 n이라 하고, 반복 횟수를 k라고 한다면 다음과 같은 수식이 만들어 집니다.위는 데이터 리스트의 크기인 n을 2로 몇번을 나누어야 1이 되는지 말해주는 식으로, 위 수식을 정리하면 k=log2(n)이 되는 것입니다. 위 수식을 통해 데이터 리스트의 크기가 500만개라면 최대 22회, 1000만개라면 최대 23회의 탐색으로 데이터를 찾아낼 수 있다는 것입니다. 의사 코드 (수도 코드)먼저 의사 코드를 살펴보겠습니다.1234567891011BinarySearch(A[0...N-1], target, begin, end) { if (begin &gt; end) return -1 // not found mid = (begin + end) / 2 if (A[mid] &lt; target) return BinarySearch(A, target, mid+1, end) else if (A[mid] &gt; target) return BinarySearch(A, target, begin, mid-1) else return mid // found} 출처 : 위키백과 - 이진 검색 알고리즘 C++ 코드위의 의사 코드를 C++ 코드로 다시 작성하면 다음과 같습니다.1234567891011int BinarySearch(int A[], int target, int begin, int end) { if (begin &gt; end) return -1; mid = (begin + end) / 2; if (A[mid] &lt; target) return BinarySearch(A, target, mid + 1, end); else if (A[mid] &gt; target) return BinarySearch(A, target, begin, mid + 1); else return mid;}","link":"/2017/10/23/Algorithm/Concept/binary-search/"},{"title":"기본적인 정렬 알고리즘 (선택, 삽입, 버블)","text":"정렬 알고리즘 종류와 특징 선택 정렬선택 정렬은 해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택한다라고 생각하면 이해하기 쉽습니다. 현재 위의 예시에서는 각 순서마다 정렬되지 않은 범위에서 가장 큰 원소를 찾아 맨 마지막 값의 자리와 변경합니다. 가장 큰값을 찾아 맨 오른쪽 원소와 변경해 오름차순으로 정렬했지만, 매 순서마다 가장 작은 값을 찾아 맨 왼쪽의 원소와 변경해주어도 오름차순 정렬을 구현할 수 있습니다. 순서를 간략히 정리하면 다음과 같습니다각 루프마다1.최대 원소를 찾는다.2.최대 원소와 맨 오른쪽 원소를 교환한다.3.맨 오른쪽 원소를 제외한다.하나의 원소만 남을 때까지 위의 루프를 반복 의사 코드는 다음과 같습니다.123456selectionSort(A[], n) { for last &lt;- downto 2 { A[1...last] 중 가장 큰 수 A[k]를 찾는다 A[K] &lt;-&gt; A[last]; A[k]와 A[last]값을 교환 }} 시간 복잡도를 계산한다면1)for 루프는 n-1번 반복 되고2)가장 큰 수를 찾기 위한 비교 횟수는 n-1, n-2, … , 2, 13)교환은 상수 시간 작업이므로 T(n) = (n-1) + (n-2) + … + 2 + 1 = n(n-1)/2 = O(n^2) 시간 복잡도는 O(n^2)가 됩니다. 이제 마지막으로 c++ 코드로 작성하면 다음과 같습니다.(위의 예시에서는 매 순서마다 가장 값이 큰 원소를 가장 오른쪽 원소와 변경함으로써 오름차순 정렬을 구현했지만, 아래의 코드에서는 매 순서마다 가장 값이 작은 원소를 가장 왼쪽의 원소와 변경함으로써 오름차순 정렬을 구현했습니다.)1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;void print_arr(int a[], int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; a[i] &lt;&lt; ' '; } cout &lt;&lt; '\\n';}void selection_sort(int a[], int size) { int min_idx, tmp; for (int i = 0; i &lt; size - 1; i++) { min_idx = i; for (int j = i + 1; j &lt; size; j++) { if (a[j] &lt; a[min_idx]) { min_idx = j; } } tmp = a[min_idx]; a[min_idx] = a[i]; a[i] = tmp; }}int main() { int a[] = { 15, 2, 24, 18, 7, 13, 12, 4, 21, 9 }; int size = sizeof(a) / sizeof(int); print_arr(a, size); selection_sort(a, size); print_arr(a, size); return 0;} 삽입 정렬삽입 정렬은 매 순서마다 해당 원소를 삽입할 수 있는 위치를 찾아 해당 위치에 넣는다고 이해하면 쉽습니다.(선택 정렬은 위치가 정해져있고 이 위치에 어떤 원소를 넣을지 선택하는 것이었다면, 삽입 정렬은 원소는 정해져있고 이 원소를 어디에 넣을지 선택하는 것이라고 이해하면 될 것 같습니다.) 위의 그림은 삽입 정렬의 전체적인 과정을 보여주는 것이고, 아래 사진은 삽입 정렬의 전체과정 중 한 과정을 상세하게 보여주고 있습니다. 이번에 선택된 원소는 4이고, 이 원소를 어떤 자리에 삽입할지 탐색하는 과정을 보여줍니다. 삽입 정렬의 의사 코드는 다음과 같습니다.12345insertionSort(A[], n){ for i&lt;- 2 to n{ A[1...i]의 적당한 자리에 A[i]를 삽입한다. }} 시간 복잡도를 계산한다면1)for 루프는 n-1번 반복 되고2)최악의 경우 데이터 삽입을 위한 비교는 i-1번 비교 따라서 최악의 경우 T(n) = (n-1) + (n-2) + … + 2 + 1 = n(n-1)/2 = O(n^2) 시간 복잡도는 O(n^2)가 됩니다. 이제 마지막으로 c++ 코드로 작성하면 다음과 같습니다. 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;void print_arr(int a[], int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; a[i] &lt;&lt; ' '; } cout &lt;&lt; '\\n';}void insert_sort(int a[], int size) { int tmp; for (int i = 1; i &lt; size; i++) { tmp = a[i]; int j = i; while (j &gt; 0 &amp;&amp; a[j - 1] &gt; tmp) { a[j] = a[j - 1]; j--; } a[j] = tmp; }}int main() { int a[] = { 15, 2, 24, 18, 7, 13, 12, 4, 21, 9 }; int size = sizeof(a) / sizeof(int); print_arr(a, size); insert_sort(a, size); print_arr(a, size); return 0;} 버블 정렬버블 정렬은 선택 정렬과 기본 개념이 비슷합니다. 버블 정렬에서도 선택 정렬과 같이 이미 해당 순서에 원소를 넣을 위치는 정해져 있고, 어떤 원소를 넣을지 선택한다라고 생각하면 됩니다. 다만 선택 정렬과는 다르게 최대값을 찾고, 그 최대값을 맨 마지막 원소와 교환하는 과정에서 차이가 있습니다. 버블 정렬의 의사 코드는 다음과 같습니다.123456bubbleSort(A[], n){ for last &lt;- downto 2{ for i &lt;- 1 to last - 1 if(A[i]&gt;A[i+1]) then A[i] &lt;-&gt; A[i+1] // 교환 }} 시간 복잡도를 계산한다면1)바깥 for 루프는 n-1번 반복 되고2)안쪽 for 루프는 n-1, n-2, …, 2, 1번 반복3)원소 교환은 상수시간 작업 따라서 T(n) = (n-1) + (n-2) + … + 2 + 1 = n(n-1)/2 = O(n^2)** 시간 복잡도는 O(n^2)가 됩니다. 이제 마지막으로 c++ 코드로 작성하면 다음과 같습니다. 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;void print_arr(int a[], int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; a[i] &lt;&lt; ' '; } cout &lt;&lt; '\\n';}void buuble_sort(int a[], int size) { int tmp; for (int i = 0; i &lt; size - 1; i++) { for (int j = i + 1; j &lt; size; j++) { if (a[i] &gt; a[j]) { tmp = a[i]; a[i] = a[j]; a[j] = tmp; } } }}int main() { int a[] = { 15, 2, 24, 18, 7, 13, 12, 4, 21, 9 }; int size = sizeof(a) / sizeof(int); print_arr(a, size); buuble_sort(a, size); print_arr(a, size); return 0;} 출처 : 2015 봄학기 알고리즘 - 부경대 권오흠 교수님","link":"/2017/11/06/Algorithm/Concept/basic-sort/"},{"title":"힙 정렬 (Heap sort) - 1","text":"힙 정렬은 힙, 바이너리 힙, 이진 힙이라고 부르는 자료구조를 이용하는 정렬 알고리즘입니다. 힙 정렬의 특징은 다음과 같습니다.1.최악의 경우에도 시간 복잡도가 nlogn이 되는 빠른 정렬이다.2.힙 정렬은 알고리즘을 구현하는데 추가적인 배열이 필요하지 않다.3.이진 힙(바이너리 힙) 자료구조를 사용한다. 먼저 힙 정렬을 구현하기 전에, 힙 이라는 자료구조에 대해 알아보겠습니다. 힙(Heap) 이란?힙(Heap)은1) complete binary tree(완전 이진 트리) 이면서2) heap property를 만족해야 합니다. 위의 그림에서는 full binary tree(포화 이진 트리)와 complete binary tree(완전 이진 트리)에 대해 설명하고 있습니다. binary tree(이진 트리)란 한 노드가 최대 2개의 자식 노드를 가지는 트리 입니다. 따라서, 위의 2개 트리는 모두 이진 트리입니다. 이진 트리는 이진 탐색 트리(BST)와 이진 힙(Binary Heap)의 구현에 흔히 사용됩니다. full binary tree(포화 이진 트리)란 이진 트리중에 모든 레벨의 노드 들이 꽉 차있는 형태를 말합니다. complete binary tee(완전 이진 트리)는 마지막 레벨을 제외하면 완전히 꽉 차있고, 마지막 레벨에는 가장 오른쪽 부터 연속된 몇개의 노드가 비어있을 수 있는 트리를 말합니다. 따라서 포화 이진 트리는 완전 이진 트리이기도 합니다. 위의 2번째 조건에서 heap property를 만족해야 한다고 했습니다. 이 heap property는 2개의 조건으로 나누어집니다. 1) max heap property - 부모 노드는 자식 노드보다 데이터가 크거나 같다.2) min heap property - 부모 노드는 자식 노드보다 데이터가 크거나 작다. max와 min 모두 대칭적 관계이므로 모든 알고리즘에 적용되나 상황에 따라서 간단하게 사용할 수 있는 것을 씁니다. 여기서는 max-heap property를 다루겠습니다. (a)의 3개 트리는 모두 heap 입니다. (완전 이진 트리이면서 heap property를 만족합니다.)(b)의 3개 트리는 heap이 아닙니다. (완전 이진 트리이지만, (max)heap property를 만족하지 않습니다.)(c)의 2개 트리도 heap이 아닙니다. (완전 이진 트리를 만족하지 않습니다.) 위의 (a), (b), (c)는 모두 다 heap입니다.(a), (b), (c)는 동일한 데이터를 갖고 있는 서로 다른 heap입니다. 즉, 여러가지 모양의 heap이 존재할 수 있는 것입니다. Heap은 1차원 배열을 사용해 표현할 수 있습니다. 같은 레벨에서 왼쪽부터 배열로 저장하면 1차원 배열이 됩니다. 일반적인 트리에서는 부모 자식간의 관계를 식을 통해 표현할 수 없지만 Heap은 complete binary tree이므로 배열의 인덱스만으로 부모와 자식의 관계를 표현할 수 있습니다. 루트 노드가 배열의 1번 인덱스부터 시작한다면 다음과 같은 표현식을 사용할 수 있습니다. 루트 노드 : A[1] A[i]의 부모 노드 : A[i/2] A[i]의 왼쪽 자식 노드 : A[2i] A[i]의 오른쪽 자식 노드 : A[2i+1] 따라서 Heap은 1차원 배열을 통해 표현이 가능하기 때문에 불필요하게 트리 자료구조를 따로 만들어 사용해 구현할 필요가 없습니다. Max-heapify 란?지금부터는 어떤 1차원 배열의 데이터가 있을 때 이 1차원 배열을 Heap으로 변환하는 과정에 대해 알아보겠습니다. (이번 포스팅에서는 max heap만을 다루기로 했으므로 max heap을 만드는 방법에 대해 알아보겠습니다.)일반 1차원 배열은 max-heapify라는 연산 과정을 통해 max heap으로 만들수 있습니다. max-heapify 연산을 하기 위한 전제조건을 위의 그림에서 보여주고 있습니다.1) 트리의 전체 모양은 complete binary tree이다.2) 왼쪽 서브 트리(subtree)는 그 자체로 heap이다.3) 오른쪽 서브 트리(subtree)는 그 자체로 heap이다. 여기서 유일하게 루트 노드만이 heap property를 만족하지 않을때, max-heapify 연산을 통해 heap property를 만족하게 만들 수 있습니다. 위의 그림에서 루트 노드는 자신의 자식 노드중에 더 큰값과 자리를 교체 합니다. 그 후 교체된 노드에서 다시 max-heapify 연산을 통해 max-heap property를 만족할 때까지 반복합니다. 결국 max-heapify는 동일한 과정을 반복하고 있기 때문에 recursion(재귀)로 구현이 가능합니다.123456789MAX-HEAPIFY(A, i){ if there is no child of A[i] return; k &lt;- index of the biggest child of i; if A[i]&gt;=A[k] return; exchange A[i] and A[k]; MAX-HEAPIFY(A, k);} 첫번째 조건은 base case로서, 자식 노드가 없다면 가장 아래의 레벨에 위치한 리프노드이기 때문에 종료합니다. 만약 자식 노드가 있다면 큰 자식 노드의 인덱스를 k로 지정합니다. 그 후 부모 노드와 값을 비교해 부모 노드가 크다면 max-heapify 과정을 종료하고, 자식 노드의 값이 크다면 부모 노드와 값을 교환한 후 다시 max-heapify를 재귀 호출 합니다. 123456789MAX-HEAPIFY(A, i){ while A[i] has a child do k&lt;- index of the biggest child of i; if A[i]&gt;= A[k]; return; exchange A[i] and A[k]; i=k; end} 같은 함수를 iterate하게 구현한 코드입니다. 주요 함수의 동작 원리는 같습니다. max-heapify의 시간 복잡도는 루트 노드로부터 마지막 레벨까지 비교, 교환 연산을 하므로 트리의 높이보다 많은 시간이 필요하지 않습니다. 따라서 시간 복잡도는 높이에 의해서 결정되며, O(h)입니다.일반적인 이진트리가 아닌 complete binary tree이므로 노드의 개수를 n이라 하면, 시간 복잡도는 O(logn)이 됩니다. 출처 : 2015 봄학기 알고리즘 - 부경대 권오흠 교수님","link":"/2017/11/19/Algorithm/Concept/heap-sort-1/"},{"title":"힙 응용 - 우선순위 큐 (Priority queue)","text":"우선순위 큐 (Priority queue) 란?큐는 여러개의 데이터를 넣을 수 있는 자료구조 입니다. 데이터가 넣고 뺄때는 First In First Out(FIFO) 구조를 가집니다. 우선순위 큐는 이러한 큐의 한종류로써 최대 우선순위 큐와 최소 우선순위 큐로 나뉩니다. 최대 우선순위 큐최대 우선순위 큐는 다음의 두가지 연산을 지원하는 자료구조 입니다. (최소 우선순위 큐는 EXTRACT-MAX 대신 EXTRACT-MIN을 지원하는 자료구조입니다.)1) INSERT(x) : 새로운 원소 x를 삽입2) EXTRACT_MAX() : 최대값을 삭제하고 반환 MAX HEAP을 이용해서 최대 우선순위 큐를 구현할 수 있습니다. INSERT 위의 그림은 MAX HEAP의 형태로 저장되어 있는 우선순위 큐 입니다. 현재 heap은1) complete binary tree2) max heap property조건을 만족하기 때문에 이를 유지하면서 INSERT 연산을 하기 위해서는 고려할 사항들이 있습니다. INSERT는 새로운 노드를 추가해야하는데 complete binary tree 를 만족하기 위해서는 가장 마지막 레벨의 leaf에 추가 될 수 밖에 없습니다. 그리고 새로운 노드가 추가된 후 max heap property를 만족하기 위해서는 max-heapify 연산이 필요합니다.INSERT의 의사 코드는 다음과 같습니다. 123456789MAX-HEAP-INSERT(A, key){ heap_size = heap_size + 1; A[heap_size] = key; i = heap_size; while(i &gt; 1 and A[PARENT(i)] &lt; A[i]){ exchange A[i] and A[PARENT(i)]; i = PARENT(i); }} 위의 코드에서 A는 heap의 사이즈를 1증가 시키고, 그 자리에 새로운 key값을 넣습니다. i는 새로 추가된 노드의 인덱스입니다.그 후 while 문에서 i &gt; 1 (root 노드가 아니라는 의미) 이며, A[PARENT(i)] &lt; A[i] (부모 노드에 저장된 값보다 크다는 의미) 라면 부모 노드와 값을 교환합니다. 즉, 루트 노드가 될 때까지 혹은 자신의 부모 노드보다 작을 때 까지 계속해서 교환연산을 진행합니다. 따라서 시간 복잡도는 트리의 높이에 비례하게 되고, heap은 complete binary tree이므로 O(nlogn)입니다. EXTRACT_MAX 위의 그림은 EXTRACT_MAX 과정을 나타내고 있습니다. heap은 complete binary tree 성질을 유지하기 위해서 아무 노드나 삭제하는 것이 아니라 마지막 노드를 삭제하게 됩니다. 이때 루트 노드와 마지막 노드의 자리를 변경해 마지막 노드를 삭제 후 max-heapify를 통해 다시 max heap property를 만족하도록 만들 수 있습니다.HEAP-EXTRACT-MAX의 의사 코드는 다음과 같습니다. 123456789HEAP-EXTRACT-MAX(A){ if heap-size[A] &lt; 1 then error \"heap underflow\" max &lt;- A[1] A[1] &lt;- A[heap-size[A]] heap-size[A] &lt;- heap-size[A] - 1 MAX-HEAPIFY(A, 1) return max} C++로 구현하기1234567891011121314151617181920212223242526void max_heap_insert(int a[], int size, int key) { int i, tmp; size = size + 1; a[size] = key; i = size; while (i &gt; 1 &amp;&amp; a[i / 2] &lt; a[i]) { tmp = a[i / 2]; a[i / 2] = a[i]; a[i] = tmp; i = i / 2; }}int heap_extract_max(int a[], int size) { if (size &lt; 1) { cout &lt;&lt; \"heap underflow\\n\"; return -1; } int max = a[1]; a[1] = a[size]; max_heapify(a, size-1, 1); return max;} 출처 : 2015 봄학기 알고리즘 - 부경대 권오흠 교수님","link":"/2017/11/20/Algorithm/Concept/priority-queue/"},{"title":"소수 구하기 (에라토스테네스의 체)","text":"소수(Prime Number)는 약수로 1과 자기 자신만을 가지는 정수입니다. 정수론의 기본 정리에 의해 모든 자연수는 단 하나의 소수들의 곱으로 표현됩니다. 소수 구하는 알고리즘1. 기본적인 접근소수는 1과 N만을 약수로 가진다. 그럼 2부터 N-1까지의 수로는 나눠져서는 안된다. 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;int main(){ unsigned int num; cout &lt;&lt; \"소수를 구할 수를 입력하세요 : \"; cin &gt;&gt; num; bool isPrime = true; // 2부터 N-1의 수로 나눠서 나눠지는 수가 있으면 반복문 종료 for (int i=2; i&lt;num; i++) { if (num % i == 0) { isPrime = false; break; } } if(isPrime) { cout &lt;&lt; num &lt;&lt; \"은 소수입니다.\" &lt;&lt; endl; } else { cout &lt;&lt; num &lt;&lt; \"은 소수가 아닙니다.\" &lt;&lt; endl; } return 0;} 연산 횟수 : N-2번 2. 에라토스테네스의 접근주어진 자연수 N이 소수이기 위한 필요충분 조건은 N이 N의 제곱근보다 크지 않은 어떤 소수로도 나눠지지 않는다. 수가 수를 나누면 몫이 발생하게 되는데 몫과 나누는 수, 둘 중 하나는 반드시 N의 제곱근 이하이기 때문이다. 즉, 2부터 N의 제곱근 까지 나눠보면 됩니다. 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;math.h&gt;using namespace std;int main(){ unsigned int num; cout &lt;&lt; \"소수를 구할 수를 입력하세요 : \"; cin &gt;&gt; num; bool isPrime = true; // 2부터 N의 제곱근까지의 수로 나눠서 나눠지는 수가 있으면 반복문 종료 for (int i=2; i&lt;=sqrt(num); i++) { if (num % i == 0) { isPrime = false; break; } } if(isPrime) { cout &lt;&lt; num &lt;&lt; \"은 소수입니다.\" &lt;&lt; endl; } else { cout &lt;&lt; num &lt;&lt; \"은 소수가 아닙니다.\" &lt;&lt; endl; } return 0;} 연산 횟수 : 루트(N-2) 번 3. 에라토스테네스의 체에라토스테네스의 체는 매우 간단한 아이디어입니다. 위에서 모든 자연수는 소수들의 곱으로 표현이 된다고 했습니다. 제일 작은 소수 2부터 시작합니다. 2부터 N-1까지의 수 중에서 2의 배수를 모두 체로 거르고 남은 숫자들 중에서 3의 배수로 거르고를 반복해서 제곱근N 까지 나눠서 걸러지지 않고 남은 수들이 모두 소수가 됩니다. 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;math.h&gt;using namespace std;int main(){ unsigned int num; cout &lt;&lt; \"소수를 구할 수를 입력하세요 : \"; cin &gt;&gt; num; bool* prime = new bool[num+1]; memset(prime, 0, sizeof(bool) * (num + 1)); for (int i=2; i&lt;=num; i++) { if (prime[i] == false) { for (int j=i*2; j&lt;=num; j+=i) { prime[j] = true; } } } for (int i=0; i&lt;=num; i++) { prime[i] = !prime[i]; } if(prime[num]) { cout &lt;&lt; num &lt;&lt; \"은 소수입니다.\" &lt;&lt; endl; } else { cout &lt;&lt; num &lt;&lt; \"은 소수가 아닙니다.\" &lt;&lt; endl; } return 0;} 주어진 수가 소수인지 아닌지 판별만 할 경우는 2번째 방법을 사용하는 것이 좋습니다.그러나 다음 문제처럼 주어진 수 까지의 모든 소수를 구하기 위해서는 에라토스테네스의 체를 사용합니다. 다시 한번 간단하게 에라토스테네스의 체를 정리하며 마무리 하겠습니다. 12345678910111213prime[10000];for (int i = 2; i &lt; 10000; i++) { if (prime[i] == false) { for (int j = i*2; j &lt; 10000; j += i) { prime[j] = true; } }}for (int i = 0; i &lt; 10000; i++) { prime[i] = !prime[i];} 참고 : 에라토스테네스의 체 - 위키백과","link":"/2017/11/05/Algorithm/Concept/prime/"},{"title":"합병 정렬 (Merge sort)","text":"분할정복법과 합병 정렬 (Merge sort)합병 정렬은 앞서 알아본 선택, 삽입, 버블 정렬과는 다르게 분할정복법이라는 개념을 사용합니다. 분할정복법(Divide-And-Conquer)이라는 것은 주어진 문제를 다음과 같은 3단계의 절차를 통해 해결하는 방법입니다. 분할 : 해결하고자 하는 문제를 작은 크기의 동일한 문제들로 분할한다. 정복 : 각각의 작은 문제를 순환적으로 해결한다. 합병 : 작은 문제의 해를 합하여(merge) 원래 문제에 대한 해를 구한다. 그럼 이를 토대로 합병 정렬의 과정을 살펴보겠습니다. 합병 정렬은 여러 개의 데이터를 한 번에 정렬하는 것이 아닌 이를 계속해서 반으로 나눈 후 다시 합병하는 과정에서 정렬이 이루어집니다. 분할을 반복하다보면 마지막은 길이가 1인 구간으로 나뉘어집니다. 더이상 분할이 불가능할때 다시 합병하면서 정렬을 하는것입니다. 그렇기 때문에 합병 정렬에서 가장 중요한 부분은 실제 정렬을 수행하는 합병(merge)하는 과정입니다. 그럼 합병과정에서 정렬은 어떻게 이루어질까요? 다음 그림을 통해서 실제 정렬이 이루어지는 합병 과정을 좀 더 자세히 알아보겠습니다. 먼저 위 그림은 합병이 이루어 지기 위한 이미 정렬된 2개의 블록이 존재하는 모습입니다. 현재 두개의 블록은 이미 길이가 1인 구간으로 나눠진 배열부터 시작해 각각 합병 과정을 거쳐 정렬된 상태로 만들어진 배열입니다.이 두개의 블록을 정렬된 상태를 유지하며 합치기 위해서는 i 인덱스에 있는 값과, j 인덱스에 있는 값을 하나씩 비교한 후 추가배열에 저장하면 됩니다. 위 그림처럼 하나의 블록이 모두 합쳐 졌을 경우 나머지 블록은 순서대로 배열에 저장하면 됩니다. 모든 합병을 마친 후 이 추가배열의 값으로 기존 배열의 해당 구간에 복사하면 됩니다. 합병 정렬 의사 코드의사 코드는 다음과 같습니다.12345678910111213mergeSort(A[],p,r){ if(p&lt;r) then{ q &lt;- (p+r)/2; mergeSort(A,p,q); mergeSort(A,q+1,r); merge(A, p, q, r); }}merge(A[], p, q, r){ 정렬되어 있는 ㅜ 배열 A[p..q]와 A[q+1...r]을 합하여 정렬된 하나의 배열 A[p...r]을 만든다.} 합병 정렬 c++ 코드이제 의사 코드를 바탕으로 c++ 코드를 작성하면 다음과 같습니다.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;#define ITEM_SIZE 10using namespace std;void print_arr(int a[], int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; a[i] &lt;&lt; ' '; } cout &lt;&lt; '\\n';}void merge(int a[], int left, int mid, int right) { int i, j, k; i = left; j = mid + 1; k = left; int tmp_arr[ITEM_SIZE]; // left 부터 mid 까지의 블록과 mid + 1 부터 right 까지의 블록을 서로 비교 while (i &lt;= mid &amp;&amp; j &lt;= right) { if (a[i] &lt;= a[j]) { tmp_arr[k] = a[i]; i++; } else { tmp_arr[k] = a[j]; j++; } k++; } // left 블록의 값이 다 처리되었지만, right 블록의 index가 남아 있는 경우 // right 블록의 남은 부분을 순차적으로 tmp_arr에 복사 if (i &gt; mid) { for (int m = j; m &lt;= right; m++) { tmp_arr[k] = a[m]; k++; } } // left 블록의 남은 부분을 순차적으로 tmp_arr에 복사 else { for (int m = i; m &lt;= mid; m++) { tmp_arr[k] = a[m]; k++; } } // 임시 배열인 tmp_arr의 값을 원본 배열에 복사한다. for (int m = left; m &lt;= right; m++) { a[m] = tmp_arr[m]; }}void merge_sort(int a[], int left, int right) { int mid; if (left &lt; right) { // 절반으로 나누기 위해 중간 위치 찾기 mid = (left + right) / 2; // 분할 merge_sort(a, left, mid); merge_sort(a, mid + 1, right); // 합병 merge(a, left, mid, right); }}int main() { int a[ITEM_SIZE] = { 15, 2, 24, 18, 7, 13, 12, 4, 21, 9 }; print_arr(a, ITEM_SIZE); merge_sort(a, 0, ITEM_SIZE - 1); print_arr(a, ITEM_SIZE); return 0;} 합병 정렬 시간 복잡도이제 마지막으로 합병 정렬의 시간 복잡도를 알아보겠습니다. 데이터가 n개 일때 합병 정렬로 계산하는 시간을 T(n)이라고 하겠습니다.정렬을 위해서 반으로 분할한 후 n/2개의 블럭에 재귀함수를 호출하면, 반으로 분할된 블럭 2개에 대한 정렬을 수행해야하므로 T(n/2) + T(n/2)의 시간이 걸립니다. 두개의 정렬된 블럭을 merge할 때 두 블럭을 한번씩 비교하므로 merge 시간은 n입니다.따라서, merge sort의 시간 복잡도는 T(n) = T(n/2) + T(n/2) + n이 됩니다. 결국 분할을 반복하면 위와 같은 그림의 식을 도출할 수 있고, 이 식을 수학적으로 풀어보면 O(nlogn)이 됩니다. 합병 정렬과 퀵 정렬 비교아직 퀵 정렬에 대해 다루지 않았지만 합병 정렬과 퀵 정렬 모두 시간 복잡도로 O(nlogn)을 갖습니다. 그러나 퀵 정렬과 합병 정렬에는 서로 다른 특징이 있습니다. 합병 정렬은 합병 과정에서 임시적인 저장공간으로 데이터를 담고 있는 배열과 같은 크기인 추가 배열을 사용하기 때문에 추가적인 메모리가 필요합니다. 그러나 퀵 정렬은 추가 메모리를 사용하지 않고 내부 교환만으로 수행되는 차이가 있습니다. 또한 합병 정렬은 어떤 상황이라도 항상 O(nlogn)의 시간 복잡도를 갖지만 퀵 정렬의 경우 아이러니하게도 정렬하기 위해 정렬이 되어 있는 데이터를 사용할 경우 O(n^2)의 시간복잡도를 갖게 됩니다. (이 경우는 다음에 퀵 정렬에 대해 포스팅하며 알아보겠습니다.) 그러나 최악의 경우가 아닐 경우 일반적으로 퀵 정렬이 합병 정렬에 비해 빠른 성능을 보입니다. 합병 정렬은 퀵 정렬보다 성능이 전반적으로 떨어지고, 데이터 크기만한 메모리가 더 필요하지만 최대의 장점은 stable sort라는 점입니다. 퀵 정렬의 경우 만약 배열 A[25] = 100, A[33] = 100 인 정수형 배열을 정렬한다고 할 때, 33번째에 있던 100이 25번째에 있던 100보다 앞으로 오는 경우가 생길 수 있습니다. 그에 반해서 합병 정렬은 이전의 순서를 유지하면서 정렬된 상태를 만들 수 있습니다. 출처 : 2015 봄학기 알고리즘 - 부경대 권오흠 교수님","link":"/2017/11/06/Algorithm/Concept/merge-sort/"},{"title":"퀵 정렬 (Quick sort)","text":"분할정복법과 퀵 정렬 (Quick sort)퀵 정렬은 합병 정렬과 마찬가지로 분할정복법을 사용하지만 그 방법에 있어서 차이가 있습니다.퀵 정렬에서는 정렬할 데이터가 주어지면 하나의 값을 기준값(pivot)으로 사용하여 정렬을 합니다. 어떤 값을 기준값으로 설정하는지가 퀵정렬의 성능을 좌우합니다. 분할정복법 3단계를 바탕으로 퀵정렬의 과정을 알아보겠습니다. 분할 : 하나의 값을 기준값(pivot)으로 설정 한 후 데이터들을 기준값보다 큰 값과 작은값으로 분류한다. 정복 : 분할한 양쪽을 각각 재귀로 퀵 정렬한다. 합병 : 이미 분할 과정에서 정렬이 완료되었기 때문에 따로 과정이 없다. 퀵 정렬 의사 코드의사 코드는 다음과 같습니다.123456789101112quickSort(A[], p, r) { if(p&lt;r) then{ q = partition(A, p, r); // 분할 quickSort(A, p, q-1); // 왼쪽 부분배열 정렬 quickSort(A, q+1, r); // 오른쪽 부분배열 정렬 }}partition(A[], p, r) { 배열 A[p...r]의 원소들을 A[r]을 기준으로 양쪽으로 재배치하고 A[r]이 자리한 위치를 return} 배열 A의 인덱스 p에서 r사이에 있는 데이터를 정렬합니다. 조건문으로 p가 r보다 작은 경우에만 알고리즘이 실행되도록 합니다. 다음으로 partion 함수는 기준값(pivot)을 기준으로 전체 데이터를 나눠주고 피봇 인덱스를 반환하는 역할을 합니다. 따라서, q는 피봇이 됩니다. [p, q-1] 은 배열의 왼쪽 부분, 작은 값이고[q+1, r] 까지는 배열의 오른쪽 부분, 큰 값입니다.재귀적으로 quickSort 함수를 호출해 정렬합니다. 위의 그림에서 기준값(pivot)으로 인덱스의 마지막 값을 사용하고 있습니다. 위의 그림 기준에서 현재 인덱스 j의 값이 기준값보다 크다면 j를 증가시켜 다음값으로 넘어갑니다.그러나 인덱스 j의 값이 기준값보다 작다면 앞쪽으로 보내야하는데, 이때 i값을 1 증가 시킨 후 그 값과 교환합니다. 위의 과정은 기준값을 마지막 인덱스의 값인 15로 설정하고 i와 j를 증가시키면서 정렬하는 과정을 보여줍니다. 모든 정렬이 완료되면 인덱스 i+1의 값과 기준값의 위치를 변경합니다. 12345678910Partition(A, p, r){ x&lt;-A[r]; i&lt;-p-1; for j&lt;-p to r-1 if A[j] &lt;= x then i&lt;-i+1; exchange A[i] and A[j]; exchange A[i+1] and A[r]; return i+1;} Partition 함수를 더 자세한 의사 코드로 나타냈습니다. 앞서 설명한 위치 변환과 인덱스 증가로 정렬을 완료하고 마지막으로 기준값(pivot)의 인덱스를 리턴합니다. 퀵 정렬 c++ 코드이제 의사 코드를 바탕으로 c++ 코드를 작성하면 다음과 갖습니다. (의사 코드와는 완전히 일치하지는 않습니다.) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#define ITEM_SIZE 10using namespace std;void print_arr(int a[], int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; a[i] &lt;&lt; ' '; } cout &lt;&lt; '\\n';}int partition(int a[], int left, int right) { int pivot = right; int i = left - 1; int j = left; int tmp; if (left &lt; right) { while (j &lt; right) { if (a[j] &lt; a[pivot]) { tmp = a[j]; a[j] = a[i + 1]; a[i + 1] = tmp; i++; } j++; } tmp = a[pivot]; a[pivot] = a[i + 1]; a[i + 1] = tmp; } pivot = i + 1; return pivot;}void quick_sort(int a[], int left, int right) { if (left &lt; right) { int pivot = partition(a, left, right); quick_sort(a, left, pivot - 1); quick_sort(a, pivot + 1, right); }}int main() { int a[ITEM_SIZE] = { 15, 2, 24, 18, 7, 13, 12, 4, 21, 9 }; print_arr(a, ITEM_SIZE); quick_sort(a, 0, ITEM_SIZE - 1); print_arr(a, ITEM_SIZE); return 0;} 퀵 정렬 시간 복잡도퀵 정렬에서의 시간 복잡도는 파티션(분할) 하는데 모든 데이터를 한번씩 비교하면 되므로 n이 됩니다. 정확하게 말하자면 데이터의 개수가 n개일때, n-1 번의 비교가 이루어집니다. 합병 정렬보다는 시간 복잡도를 구하는게 조금 더 복잡한데, 합병 정렬은 항상 2개로 나뉘는것과 달리 퀵 정렬은 항상 양쪽이 고르게 나누어지지 않기 때문입니다. 먼저 최악의 경우부터 생각해보면 모든 배열이 정렬되어있을 때, 기준값이 최대/최소 값일 때, 최악의 시간 복잡도가 발생합니다. 분할은 0개와 나머지 전체로 나누어지므로 결국 데이터는 아무변화가 없고 똑같은 루틴이 반복되기 때문에 시간 복잡도는 O(n^2)가 됩니다. 반대로 최선의 경우는 항상 절반으로 분할되는 경우로, 이 때는 합병 정렬과 동일한 시간인 O(nlogn)의 시간을 같습니다. 퀵 정렬은 다른 정렬 알고리즘보다 대체로 빠르기 때문에 퀵 정렬 이라는 이름이 붙었습니다. 그렇지만 최악의 경우에는 O(n^2)의 느린 속도를 보여줬는데 왜 퀵 정렬이 다른 알고리즘 보다 빠른 걸가요? 최선의 경우와 최악의 경우는 극단적인 케이스라서 실제적으로 일어나기 어려운 상황입니다. 현식적으로 가정했을 때, n개의 데이터가 항상 9:1로 분할 된다고 하면 한 단계 당 분할되는 시간을 구하면 항상 n이므로 전체 비교 연산은 트리의 깊이 n 입니다.트리는 대칭적이지 않으므로 가장 깊은 오른쪽 경로(최악의 경우)를 예로 들면 (9/10)^k n = 1이 됩니다.따라서 시간 복잡도 k = log9/10(n)이 됩니다. 이 예가 의미하는 것은 퀵 정렬의 성능은 파티션이 얼마나 밸런스있게 나뉘냐에 결정된다는 것입니다. 극단적인 경우만 아니라면 퀵 정렬의 시간 복잡도는 nlogn 이 되므로 실제로 상당히 빠른 정렬 방법이 됩니다. 출처 : 2015 봄학기 알고리즘 - 부경대 권오흠 교수님","link":"/2017/11/07/Algorithm/Concept/quick-sort/"}],"tags":[{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"BOJ","slug":"BOJ","link":"/tags/BOJ/"},{"name":"백준","slug":"백준","link":"/tags/백준/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"book","slug":"book","link":"/tags/book/"},{"name":"review","slug":"review","link":"/tags/review/"},{"name":"servlet container","slug":"servlet-container","link":"/tags/servlet-container/"},{"name":"Emily","slug":"Emily","link":"/tags/Emily/"},{"name":"bot","slug":"bot","link":"/tags/bot/"},{"name":"RaspberryPi","slug":"RaspberryPi","link":"/tags/RaspberryPi/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"scheduling","slug":"scheduling","link":"/tags/scheduling/"},{"name":"express","slug":"express","link":"/tags/express/"},{"name":"s3","slug":"s3","link":"/tags/s3/"},{"name":"web hosting","slug":"web-hosting","link":"/tags/web-hosting/"},{"name":"신입 개발자","slug":"신입-개발자","link":"/tags/신입-개발자/"},{"name":"취업 준비","slug":"취업-준비","link":"/tags/취업-준비/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Pull Request","slug":"Pull-Request","link":"/tags/Pull-Request/"},{"name":"Create a merge commit","slug":"Create-a-merge-commit","link":"/tags/Create-a-merge-commit/"},{"name":"Squash and merge","slug":"Squash-and-merge","link":"/tags/Squash-and-merge/"},{"name":"Rebase and merge","slug":"Rebase-and-merge","link":"/tags/Rebase-and-merge/"},{"name":"crawling","slug":"crawling","link":"/tags/crawling/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Armeria","slug":"Armeria","link":"/tags/Armeria/"},{"name":"Open source","slug":"Open-source","link":"/tags/Open-source/"},{"name":"HTML","slug":"HTML","link":"/tags/HTML/"},{"name":"Viewport","slug":"Viewport","link":"/tags/Viewport/"},{"name":"Gradle","slug":"Gradle","link":"/tags/Gradle/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Replication","slug":"Replication","link":"/tags/Replication/"},{"name":"MMM","slug":"MMM","link":"/tags/MMM/"},{"name":"TIL","slug":"TIL","link":"/tags/TIL/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"ES6","slug":"ES6","link":"/tags/ES6/"},{"name":"Class","slug":"Class","link":"/tags/Class/"},{"name":"Translation","slug":"Translation","link":"/tags/Translation/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"JavaScript 완벽가이드","slug":"JavaScript-완벽가이드","link":"/tags/JavaScript-완벽가이드/"},{"name":"Promise","slug":"Promise","link":"/tags/Promise/"},{"name":"Memoization","slug":"Memoization","link":"/tags/Memoization/"},{"name":"Design Pattern","slug":"Design-Pattern","link":"/tags/Design-Pattern/"},{"name":"Linux & Ubuntu","slug":"Linux-Ubuntu","link":"/tags/Linux-Ubuntu/"},{"name":"bash","slug":"bash","link":"/tags/bash/"},{"name":"ls","slug":"ls","link":"/tags/ls/"},{"name":"Prototype","slug":"Prototype","link":"/tags/Prototype/"},{"name":"EC2","slug":"EC2","link":"/tags/EC2/"},{"name":"Screen","slug":"Screen","link":"/tags/Screen/"},{"name":"File monitoring","slug":"File-monitoring","link":"/tags/File-monitoring/"},{"name":"tail -f","slug":"tail-f","link":"/tags/tail-f/"},{"name":"less +F","slug":"less-F","link":"/tags/less-F/"},{"name":"Node","slug":"Node","link":"/tags/Node/"},{"name":"Module","slug":"Module","link":"/tags/Module/"},{"name":"exports","slug":"exports","link":"/tags/exports/"},{"name":"Require","slug":"Require","link":"/tags/Require/"},{"name":"NVM","slug":"NVM","link":"/tags/NVM/"},{"name":"Node Version","slug":"Node-Version","link":"/tags/Node-Version/"},{"name":"design pattern","slug":"design-pattern","link":"/tags/design-pattern/"},{"name":"adapter","slug":"adapter","link":"/tags/adapter/"},{"name":"Sequelize","slug":"Sequelize","link":"/tags/Sequelize/"},{"name":"ORM","slug":"ORM","link":"/tags/ORM/"},{"name":"iterator","slug":"iterator","link":"/tags/iterator/"},{"name":"Async","slug":"Async","link":"/tags/Async/"},{"name":"ExecutorService","slug":"ExecutorService","link":"/tags/ExecutorService/"},{"name":"Future","slug":"Future","link":"/tags/Future/"},{"name":"FutureTask","slug":"FutureTask","link":"/tags/FutureTask/"},{"name":"ListenableFuture","slug":"ListenableFuture","link":"/tags/ListenableFuture/"},{"name":"DeferredResult","slug":"DeferredResult","link":"/tags/DeferredResult/"},{"name":"ResponseBodyEmitter","slug":"ResponseBodyEmitter","link":"/tags/ResponseBodyEmitter/"},{"name":"RestTemplate","slug":"RestTemplate","link":"/tags/RestTemplate/"},{"name":"AsyncRestTemplate","slug":"AsyncRestTemplate","link":"/tags/AsyncRestTemplate/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"Collection","slug":"Collection","link":"/tags/Collection/"},{"name":"Hash","slug":"Hash","link":"/tags/Hash/"},{"name":"Encryption","slug":"Encryption","link":"/tags/Encryption/"},{"name":"Message Digest","slug":"Message-Digest","link":"/tags/Message-Digest/"},{"name":"MD5","slug":"MD5","link":"/tags/MD5/"},{"name":"SHA256","slug":"SHA256","link":"/tags/SHA256/"},{"name":"CompletableFuture","slug":"CompletableFuture","link":"/tags/CompletableFuture/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"select","slug":"select","link":"/tags/select/"},{"name":"multiplexing","slug":"multiplexing","link":"/tags/multiplexing/"},{"name":"Lambda","slug":"Lambda","link":"/tags/Lambda/"},{"name":"Stream","slug":"Stream","link":"/tags/Stream/"},{"name":"socket","slug":"socket","link":"/tags/socket/"},{"name":"nonblocking","slug":"nonblocking","link":"/tags/nonblocking/"},{"name":"poll","slug":"poll","link":"/tags/poll/"},{"name":"epoll","slug":"epoll","link":"/tags/epoll/"},{"name":"non-blocking io","slug":"non-blocking-io","link":"/tags/non-blocking-io/"},{"name":"reactor","slug":"reactor","link":"/tags/reactor/"},{"name":"Mockito","slug":"Mockito","link":"/tags/Mockito/"},{"name":"TDD","slug":"TDD","link":"/tags/TDD/"},{"name":"Reactive","slug":"Reactive","link":"/tags/Reactive/"},{"name":"IoT","slug":"IoT","link":"/tags/IoT/"},{"name":"Jasper","slug":"Jasper","link":"/tags/Jasper/"},{"name":"Unix","slug":"Unix","link":"/tags/Unix/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"VNC","slug":"VNC","link":"/tags/VNC/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"Vi","slug":"Vi","link":"/tags/Vi/"},{"name":"GPIO","slug":"GPIO","link":"/tags/GPIO/"},{"name":"LED","slug":"LED","link":"/tags/LED/"},{"name":"BreadBoard","slug":"BreadBoard","link":"/tags/BreadBoard/"},{"name":"Raspbian","slug":"Raspbian","link":"/tags/Raspbian/"},{"name":"라즈베리파이 한글","slug":"라즈베리파이-한글","link":"/tags/라즈베리파이-한글/"},{"name":"RSA","slug":"RSA","link":"/tags/RSA/"},{"name":"카메라(V2)","slug":"카메라-V2","link":"/tags/카메라-V2/"},{"name":"온습도(SZH-EK024)","slug":"온습도-SZH-EK024","link":"/tags/온습도-SZH-EK024/"},{"name":"조도(BH1750)","slug":"조도-BH1750","link":"/tags/조도-BH1750/"},{"name":"초음파(HC-SR04)","slug":"초음파-HC-SR04","link":"/tags/초음파-HC-SR04/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"Vim","slug":"Vim","link":"/tags/Vim/"},{"name":"Gist","slug":"Gist","link":"/tags/Gist/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"Retrofit2","slug":"Retrofit2","link":"/tags/Retrofit2/"},{"name":"OkHttp3","slug":"OkHttp3","link":"/tags/OkHttp3/"},{"name":"Timeout","slug":"Timeout","link":"/tags/Timeout/"},{"name":"LongPolling","slug":"LongPolling","link":"/tags/LongPolling/"},{"name":"STT","slug":"STT","link":"/tags/STT/"},{"name":"TTS","slug":"TTS","link":"/tags/TTS/"},{"name":"음성인식","slug":"음성인식","link":"/tags/음성인식/"},{"name":"Retrospect","slug":"Retrospect","link":"/tags/Retrospect/"},{"name":"OAuth","slug":"OAuth","link":"/tags/OAuth/"},{"name":"OAuth 2.0","slug":"OAuth-2-0","link":"/tags/OAuth-2-0/"},{"name":"Naver Login","slug":"Naver-Login","link":"/tags/Naver-Login/"},{"name":"Hackerton","slug":"Hackerton","link":"/tags/Hackerton/"},{"name":"Uniton","slug":"Uniton","link":"/tags/Uniton/"},{"name":"Computer System","slug":"Computer-System","link":"/tags/Computer-System/"},{"name":"Interrupt","slug":"Interrupt","link":"/tags/Interrupt/"},{"name":"System call","slug":"System-call","link":"/tags/System-call/"},{"name":"User mode","slug":"User-mode","link":"/tags/User-mode/"},{"name":"Kernel mode","slug":"Kernel-mode","link":"/tags/Kernel-mode/"},{"name":"Chrome","slug":"Chrome","link":"/tags/Chrome/"},{"name":"Chrome Extension","slug":"Chrome-Extension","link":"/tags/Chrome-Extension/"},{"name":"Google Translator","slug":"Google-Translator","link":"/tags/Google-Translator/"},{"name":"OOP","slug":"OOP","link":"/tags/OOP/"},{"name":"HMAC","slug":"HMAC","link":"/tags/HMAC/"},{"name":"IntelliJ","slug":"IntelliJ","link":"/tags/IntelliJ/"},{"name":"단축키","slug":"단축키","link":"/tags/단축키/"},{"name":"React Native","slug":"React-Native","link":"/tags/React-Native/"},{"name":"Redux","slug":"Redux","link":"/tags/Redux/"},{"name":"React Native Image","slug":"React-Native-Image","link":"/tags/React-Native-Image/"},{"name":"create react native app","slug":"create-react-native-app","link":"/tags/create-react-native-app/"},{"name":"CRNA","slug":"CRNA","link":"/tags/CRNA/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Bean Validation","slug":"Bean-Validation","link":"/tags/Bean-Validation/"},{"name":"Actuator","slug":"Actuator","link":"/tags/Actuator/"},{"name":"Micrometer","slug":"Micrometer","link":"/tags/Micrometer/"},{"name":"Prometheus","slug":"Prometheus","link":"/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"Bean","slug":"Bean","link":"/tags/Bean/"},{"name":"Closeable","slug":"Closeable","link":"/tags/Closeable/"},{"name":"AutoClosable","slug":"AutoClosable","link":"/tags/AutoClosable/"},{"name":"DisposableBeanAdapter","slug":"DisposableBeanAdapter","link":"/tags/DisposableBeanAdapter/"},{"name":"AOP","slug":"AOP","link":"/tags/AOP/"},{"name":"MVC","slug":"MVC","link":"/tags/MVC/"},{"name":"DispatcherServlet","slug":"DispatcherServlet","link":"/tags/DispatcherServlet/"},{"name":"HandlerMapping","slug":"HandlerMapping","link":"/tags/HandlerMapping/"},{"name":"ViewResolver","slug":"ViewResolver","link":"/tags/ViewResolver/"},{"name":"Toby","slug":"Toby","link":"/tags/Toby/"},{"name":"IoC","slug":"IoC","link":"/tags/IoC/"},{"name":"DI","slug":"DI","link":"/tags/DI/"},{"name":"@Configuration","slug":"Configuration","link":"/tags/Configuration/"},{"name":"@Bean","slug":"Bean","link":"/tags/Bean/"},{"name":"Bean references","slug":"Bean-references","link":"/tags/Bean-references/"},{"name":"RequestBody","slug":"RequestBody","link":"/tags/RequestBody/"},{"name":"ResponseBody","slug":"ResponseBody","link":"/tags/ResponseBody/"},{"name":"JUnit","slug":"JUnit","link":"/tags/JUnit/"},{"name":"Testing","slug":"Testing","link":"/tags/Testing/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"Transaction","slug":"Transaction","link":"/tags/Transaction/"},{"name":"Context & DI","slug":"Context-DI","link":"/tags/Context-DI/"},{"name":"Template & Callback","slug":"Template-Callback","link":"/tags/Template-Callback/"},{"name":"Exception","slug":"Exception","link":"/tags/Exception/"},{"name":"DataAccessException","slug":"DataAccessException","link":"/tags/DataAccessException/"},{"name":"In-App","slug":"In-App","link":"/tags/In-App/"},{"name":"Purchase Validation","slug":"Purchase-Validation","link":"/tags/Purchase-Validation/"},{"name":"JavaEE","slug":"JavaEE","link":"/tags/JavaEE/"},{"name":"Servlet","slug":"Servlet","link":"/tags/Servlet/"},{"name":"JSP","slug":"JSP","link":"/tags/JSP/"},{"name":"Tomcat","slug":"Tomcat","link":"/tags/Tomcat/"},{"name":"POJO","slug":"POJO","link":"/tags/POJO/"},{"name":"jenkins","slug":"jenkins","link":"/tags/jenkins/"},{"name":"ci & cd","slug":"ci-cd","link":"/tags/ci-cd/"},{"name":"build tool","slug":"build-tool","link":"/tags/build-tool/"},{"name":"gradle","slug":"gradle","link":"/tags/gradle/"},{"name":"sonarqube","slug":"sonarqube","link":"/tags/sonarqube/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"mvn","slug":"mvn","link":"/tags/mvn/"},{"name":"Sort","slug":"Sort","link":"/tags/Sort/"},{"name":"Heap sort","slug":"Heap-sort","link":"/tags/Heap-sort/"},{"name":"Search","slug":"Search","link":"/tags/Search/"},{"name":"Bubble sort","slug":"Bubble-sort","link":"/tags/Bubble-sort/"},{"name":"Insert sort","slug":"Insert-sort","link":"/tags/Insert-sort/"},{"name":"Slection sort","slug":"Slection-sort","link":"/tags/Slection-sort/"},{"name":"Priority queue","slug":"Priority-queue","link":"/tags/Priority-queue/"},{"name":"Prime","slug":"Prime","link":"/tags/Prime/"},{"name":"소수 구하기","slug":"소수-구하기","link":"/tags/소수-구하기/"},{"name":"에라토스테네스의 체","slug":"에라토스테네스의-체","link":"/tags/에라토스테네스의-체/"},{"name":"Merge sort","slug":"Merge-sort","link":"/tags/Merge-sort/"},{"name":"Quick sort","slug":"Quick-sort","link":"/tags/Quick-sort/"}],"categories":[{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"Project","slug":"Project","link":"/categories/Project/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"Tip","slug":"Tip","link":"/categories/Tip/"},{"name":"AWS","slug":"Programming/AWS","link":"/categories/Programming/AWS/"},{"name":"BOJ","slug":"Algorithm/BOJ","link":"/categories/Algorithm/BOJ/"},{"name":"Emily","slug":"Project/Emily","link":"/categories/Project/Emily/"},{"name":"Git","slug":"Programming/Git","link":"/categories/Programming/Git/"},{"name":"Java","slug":"Programming/Java","link":"/categories/Programming/Java/"},{"name":"HTML","slug":"Programming/HTML","link":"/categories/Programming/HTML/"},{"name":"Gradle","slug":"Programming/Gradle","link":"/categories/Programming/Gradle/"},{"name":"JavaScript","slug":"Programming/JavaScript","link":"/categories/Programming/JavaScript/"},{"name":"Linux & Ubuntu","slug":"Programming/Linux-Ubuntu","link":"/categories/Programming/Linux-Ubuntu/"},{"name":"Node","slug":"Programming/Node","link":"/categories/Programming/Node/"},{"name":"Spring","slug":"Programming/Spring","link":"/categories/Programming/Spring/"},{"name":"RaspberryPi","slug":"Programming/RaspberryPi","link":"/categories/Programming/RaspberryPi/"},{"name":"React Native","slug":"Programming/React-Native","link":"/categories/Programming/React-Native/"},{"name":"Tool","slug":"Programming/Tool","link":"/categories/Programming/Tool/"},{"name":"Concept","slug":"Algorithm/Concept","link":"/categories/Algorithm/Concept/"}]}